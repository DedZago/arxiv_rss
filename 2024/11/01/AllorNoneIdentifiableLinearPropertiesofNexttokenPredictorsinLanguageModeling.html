<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>All or None: Identifiable Linear Properties of Next-token Predictors in Language Modeling</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="All or None: Identifiable Linear Properties of Next-token Predictors in Language Modeling" />
<meta name="author" content="Emanuele Marconato, Sébastien Lachapelle, Sebastian Weichwald, Luigi Gresele" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We analyze identifiability as a possible explanation for the ubiquity of linear properties across language models, such as the vector difference between the representations of “easy” and “easiest” being parallel to that between “lucky” and “luckiest”. For this, we ask whether finding a linear property in one model implies that any model that induces the same distribution has that property, too. To answer that, we first prove an identifiability result to characterize distribution-equivalent next-token predictors, lifting a diversity requirement of previous results. Second, based on a refinement of relational linearity [Paccanaro and Hinton, 2001; Hernandez et al., 2024], we show how many notions of linearity are amenable to our analysis. Finally, we show that under suitable conditions, these linear properties either hold in all or none distribution-equivalent next-token predictors." />
<meta property="og:description" content="We analyze identifiability as a possible explanation for the ubiquity of linear properties across language models, such as the vector difference between the representations of “easy” and “easiest” being parallel to that between “lucky” and “luckiest”. For this, we ask whether finding a linear property in one model implies that any model that induces the same distribution has that property, too. To answer that, we first prove an identifiability result to characterize distribution-equivalent next-token predictors, lifting a diversity requirement of previous results. Second, based on a refinement of relational linearity [Paccanaro and Hinton, 2001; Hernandez et al., 2024], we show how many notions of linearity are amenable to our analysis. Finally, we show that under suitable conditions, these linear properties either hold in all or none distribution-equivalent next-token predictors." />
<link rel="canonical" href="https://dedzago.github.io/arxiv_rss/2024/11/01/AllorNoneIdentifiableLinearPropertiesofNexttokenPredictorsinLanguageModeling.html" />
<meta property="og:url" content="https://dedzago.github.io/arxiv_rss/2024/11/01/AllorNoneIdentifiableLinearPropertiesofNexttokenPredictorsinLanguageModeling.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-11-01T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="All or None: Identifiable Linear Properties of Next-token Predictors in Language Modeling" />
<script type="application/ld+json">
{"description":"We analyze identifiability as a possible explanation for the ubiquity of linear properties across language models, such as the vector difference between the representations of “easy” and “easiest” being parallel to that between “lucky” and “luckiest”. For this, we ask whether finding a linear property in one model implies that any model that induces the same distribution has that property, too. To answer that, we first prove an identifiability result to characterize distribution-equivalent next-token predictors, lifting a diversity requirement of previous results. Second, based on a refinement of relational linearity [Paccanaro and Hinton, 2001; Hernandez et al., 2024], we show how many notions of linearity are amenable to our analysis. Finally, we show that under suitable conditions, these linear properties either hold in all or none distribution-equivalent next-token predictors.","mainEntityOfPage":{"@type":"WebPage","@id":"https://dedzago.github.io/arxiv_rss/2024/11/01/AllorNoneIdentifiableLinearPropertiesofNexttokenPredictorsinLanguageModeling.html"},"@type":"BlogPosting","author":{"@type":"Person","name":"Emanuele Marconato, Sébastien Lachapelle, Sebastian Weichwald, Luigi Gresele"},"headline":"All or None: Identifiable Linear Properties of Next-token Predictors in Language Modeling","url":"https://dedzago.github.io/arxiv_rss/2024/11/01/AllorNoneIdentifiableLinearPropertiesofNexttokenPredictorsinLanguageModeling.html","dateModified":"2024-11-01T00:00:00+00:00","datePublished":"2024-11-01T00:00:00+00:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://dedzago.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-11-01 00:00:00 +0000">11-01</time>
  </p>
  
  <h1>All or None: Identifiable Linear Properties of Next-token Predictors in Language Modeling</h1>
  <br>Emanuele Marconato, Sébastien Lachapelle, Sebastian Weichwald, Luigi Gresele</h3>
  <br> [stat.ML]

  <p>We analyze identifiability as a possible explanation for the ubiquity of linear properties across language models, such as the vector difference between the representations of “easy” and “easiest” being parallel to that between “lucky” and “luckiest”. For this, we ask whether finding a linear property in one model implies that any model that induces the same distribution has that property, too. To answer that, we first prove an identifiability result to characterize distribution-equivalent next-token predictors, lifting a diversity requirement of previous results. Second, based on a refinement of relational linearity [Paccanaro and Hinton, 2001; Hernandez et al., 2024], we show how many notions of linearity are amenable to our analysis. Finally, we show that under suitable conditions, these linear properties either hold in all or none distribution-equivalent next-token predictors.</p>

<p><a href="https://arxiv.org/abs/2410.23501">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>