<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Multiscale Neural Networks for Approximating Green's Functions</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Multiscale Neural Networks for Approximating Green’s Functions" />
<meta name="author" content="Wenrui Hao, Rui Peng Li, Yuanzhe Xi, Tianshi Xu, Yahong Yang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Neural networks (NNs) have been widely used to solve partial differential equations (PDEs) in the applications of physics, biology, and engineering. One effective approach for solving PDEs with a fixed differential operator is learning Green’s functions. However, Green’s functions are notoriously difficult to learn due to their poor regularity, which typically requires larger NNs and longer training times. In this paper, we address these challenges by leveraging multiscale NNs to learn Green’s functions. Through theoretical analysis using multiscale Barron space methods and experimental validation, we show that the multiscale approach significantly reduces the necessary NN size and accelerates training." />
<meta property="og:description" content="Neural networks (NNs) have been widely used to solve partial differential equations (PDEs) in the applications of physics, biology, and engineering. One effective approach for solving PDEs with a fixed differential operator is learning Green’s functions. However, Green’s functions are notoriously difficult to learn due to their poor regularity, which typically requires larger NNs and longer training times. In this paper, we address these challenges by leveraging multiscale NNs to learn Green’s functions. Through theoretical analysis using multiscale Barron space methods and experimental validation, we show that the multiscale approach significantly reduces the necessary NN size and accelerates training." />
<link rel="canonical" href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MultiscaleNeuralNetworksforApproximatingGreensFunctions.html" />
<meta property="og:url" content="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MultiscaleNeuralNetworksforApproximatingGreensFunctions.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-10-29T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Multiscale Neural Networks for Approximating Green’s Functions" />
<script type="application/ld+json">
{"description":"Neural networks (NNs) have been widely used to solve partial differential equations (PDEs) in the applications of physics, biology, and engineering. One effective approach for solving PDEs with a fixed differential operator is learning Green’s functions. However, Green’s functions are notoriously difficult to learn due to their poor regularity, which typically requires larger NNs and longer training times. In this paper, we address these challenges by leveraging multiscale NNs to learn Green’s functions. Through theoretical analysis using multiscale Barron space methods and experimental validation, we show that the multiscale approach significantly reduces the necessary NN size and accelerates training.","author":{"@type":"Person","name":"Wenrui Hao, Rui Peng Li, Yuanzhe Xi, Tianshi Xu, Yahong Yang"},"datePublished":"2024-10-29T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MultiscaleNeuralNetworksforApproximatingGreensFunctions.html"},"url":"https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MultiscaleNeuralNetworksforApproximatingGreensFunctions.html","headline":"Multiscale Neural Networks for Approximating Green’s Functions","@type":"BlogPosting","dateModified":"2024-10-29T00:00:00+00:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-10-29 00:00:00 +0000">10-29</time>
  </p>
  
  <h1>Multiscale Neural Networks for Approximating Green's Functions</h1>
  <br>Wenrui Hao, Rui Peng Li, Yuanzhe Xi, Tianshi Xu, Yahong Yang</h3>
  <br> []

  <p>Neural networks (NNs) have been widely used to solve partial differential equations (PDEs) in the applications of physics, biology, and engineering. One effective approach for solving PDEs with a fixed differential operator is learning Green’s functions. However, Green’s functions are notoriously difficult to learn due to their poor regularity, which typically requires larger NNs and longer training times. In this paper, we address these challenges by leveraging multiscale NNs to learn Green’s functions. Through theoretical analysis using multiscale Barron space methods and experimental validation, we show that the multiscale approach significantly reduces the necessary NN size and accelerates training.</p>

<p><a href="https://arxiv.org/abs/2410.18439">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>