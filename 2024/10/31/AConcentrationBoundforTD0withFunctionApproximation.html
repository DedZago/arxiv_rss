<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>A Concentration Bound for TD(0) with Function Approximation</title><!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="A Concentration Bound for TD(0) with Function Approximation" />
<meta name="author" content="Siddharth Chandak, Vivek S. Borkar" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We derive a concentration bound of the type `for all $n \geq n_0$ for some $n_0$’ for TD(0) with linear function approximation. We work with online TD learning with samples from a single sample path of the underlying Markov chain. This makes our analysis significantly different from offline TD learning or TD learning with access to independent samples from the stationary distribution of the Markov chain. We treat TD(0) as a contractive stochastic approximation algorithm, with both martingale and Markov noises. Markov noise is handled using the Poisson equation and the lack of almost sure guarantees on boundedness of iterates is handled using the concept of relaxed concentration inequalities." />
<meta property="og:description" content="We derive a concentration bound of the type `for all $n \geq n_0$ for some $n_0$’ for TD(0) with linear function approximation. We work with online TD learning with samples from a single sample path of the underlying Markov chain. This makes our analysis significantly different from offline TD learning or TD learning with access to independent samples from the stationary distribution of the Markov chain. We treat TD(0) as a contractive stochastic approximation algorithm, with both martingale and Markov noises. Markov noise is handled using the Poisson equation and the lack of almost sure guarantees on boundedness of iterates is handled using the concept of relaxed concentration inequalities." />
<link rel="canonical" href="https://dedzago.github.io/arxiv_rss/2024/10/31/AConcentrationBoundforTD0withFunctionApproximation.html" />
<meta property="og:url" content="https://dedzago.github.io/arxiv_rss/2024/10/31/AConcentrationBoundforTD0withFunctionApproximation.html" />
<meta property="og:site_name" content="Stat Arxiv of Today" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-10-31T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="A Concentration Bound for TD(0) with Function Approximation" />
<script type="application/ld+json">
{"description":"We derive a concentration bound of the type `for all $n \\geq n_0$ for some $n_0$’ for TD(0) with linear function approximation. We work with online TD learning with samples from a single sample path of the underlying Markov chain. This makes our analysis significantly different from offline TD learning or TD learning with access to independent samples from the stationary distribution of the Markov chain. We treat TD(0) as a contractive stochastic approximation algorithm, with both martingale and Markov noises. Markov noise is handled using the Poisson equation and the lack of almost sure guarantees on boundedness of iterates is handled using the concept of relaxed concentration inequalities.","mainEntityOfPage":{"@type":"WebPage","@id":"https://dedzago.github.io/arxiv_rss/2024/10/31/AConcentrationBoundforTD0withFunctionApproximation.html"},"@type":"BlogPosting","author":{"@type":"Person","name":"Siddharth Chandak, Vivek S. Borkar"},"headline":"A Concentration Bound for TD(0) with Function Approximation","url":"https://dedzago.github.io/arxiv_rss/2024/10/31/AConcentrationBoundforTD0withFunctionApproximation.html","dateModified":"2024-10-31T00:00:00+00:00","datePublished":"2024-10-31T00:00:00+00:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://dedzago.github.io/arxiv_rss/feed.xml" title="Stat Arxiv of Today" /><link rel="shortcut icon" type="image/x-icon" href="" />
  <link rel="stylesheet" href="/arxiv_rss/assets/css/main.css" />


<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/arxiv_rss/">..</a><article>
  <p class="post-meta">
    <time datetime="2024-10-31 00:00:00 +0000">10-31</time>
  </p>
  
  <h1>A Concentration Bound for TD(0) with Function Approximation</h1>
  <br>Siddharth Chandak, Vivek S. Borkar</h3>
  <br> [stat.ML]

  <p>We derive a concentration bound of the type `for all $n \geq n_0$ for some $n_0$’ for TD(0) with linear function approximation. We work with online TD learning with samples from a single sample path of the underlying Markov chain. This makes our analysis significantly different from offline TD learning or TD learning with access to independent samples from the stationary distribution of the Markov chain. We treat TD(0) as a contractive stochastic approximation algorithm, with both martingale and Markov noises. Markov noise is handled using the Poisson equation and the lack of almost sure guarantees on boundedness of iterates is handled using the concept of relaxed concentration inequalities.</p>

<p><a href="https://arxiv.org/abs/2312.10424">Read more</a></p>

</article>

      </div>
    </main>
  </body>
</html>