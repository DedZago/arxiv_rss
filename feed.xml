<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="https://dedzago.github.io/arxiv_rss/feed.xml" rel="self" type="application/atom+xml" /><link href="https://dedzago.github.io/arxiv_rss/" rel="alternate" type="text/html" /><updated>2024-10-31T07:13:51+00:00</updated><id>https://dedzago.github.io/arxiv_rss/feed.xml</id><title type="html">Stat Arxiv of Today</title><subtitle></subtitle><author><name>Daniele Zago</name></author><entry><title type="html">A Bertalanffy-Richards growth model perturbed by a time-dependent pattern, statistical analysis and applications</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ABertalanffyRichardsgrowthmodelperturbedbyatimedependentpatternstatisticalanalysisandapplications.html" rel="alternate" type="text/html" title="A Bertalanffy-Richards growth model perturbed by a time-dependent pattern, statistical analysis and applications" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ABertalanffyRichardsgrowthmodelperturbedbyatimedependentpatternstatisticalanalysisandapplications</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ABertalanffyRichardsgrowthmodelperturbedbyatimedependentpatternstatisticalanalysisandapplications.html">&lt;p&gt;We analyze a modification of the Richards growth model by introducing a time-dependent perturbation in the growth rate. This modification becomes effective at a special switching time, which represents the first-crossing-time of the Richards growth curve through a given constant boundary. The relevant features of the modified growth model are studied and compared with those of the original one. A sensitivity analysis on the switching time is also performed. Then, we define two different stochastic processes, i.e. a non-homogeneous linear birth-death process and a lognormal diffusion process, such that their means identify to the growth curve under investigation. For the diffusion process, we address the problem of parameters estimation through the maximum likelihood method. The estimates are obtained via meta-heuristic algorithms (namely, Simulated Annealing and Ant Lion Optimizer). A simulation study to validate the estimation procedure is also presented, together with a real application to oil production in France. Special attention is devoted to the approximation of switching time density, viewed as the first-passage-time density for the lognormal process.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22860&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Antonio Di Crescenzo, Paola Paraggio, Francisco Torres-Ruiz</name></author><category term="stat.AP" /><summary type="html">We analyze a modification of the Richards growth model by introducing a time-dependent perturbation in the growth rate. This modification becomes effective at a special switching time, which represents the first-crossing-time of the Richards growth curve through a given constant boundary. The relevant features of the modified growth model are studied and compared with those of the original one. A sensitivity analysis on the switching time is also performed. Then, we define two different stochastic processes, i.e. a non-homogeneous linear birth-death process and a lognormal diffusion process, such that their means identify to the growth curve under investigation. For the diffusion process, we address the problem of parameters estimation through the maximum likelihood method. The estimates are obtained via meta-heuristic algorithms (namely, Simulated Annealing and Ant Lion Optimizer). A simulation study to validate the estimation procedure is also presented, together with a real application to oil production in France. Special attention is devoted to the approximation of switching time density, viewed as the first-passage-time density for the lognormal process.</summary></entry><entry><title type="html">A Concentration Bound for TD(0) with Function Approximation</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/AConcentrationBoundforTD0withFunctionApproximation.html" rel="alternate" type="text/html" title="A Concentration Bound for TD(0) with Function Approximation" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/AConcentrationBoundforTD0withFunctionApproximation</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/AConcentrationBoundforTD0withFunctionApproximation.html">&lt;p&gt;We derive a concentration bound of the type `for all $n \geq n_0$ for some $n_0$’ for TD(0) with linear function approximation. We work with online TD learning with samples from a single sample path of the underlying Markov chain. This makes our analysis significantly different from offline TD learning or TD learning with access to independent samples from the stationary distribution of the Markov chain. We treat TD(0) as a contractive stochastic approximation algorithm, with both martingale and Markov noises. Markov noise is handled using the Poisson equation and the lack of almost sure guarantees on boundedness of iterates is handled using the concept of relaxed concentration inequalities.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2312.10424&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Siddharth Chandak, Vivek S. Borkar</name></author><category term="stat.ML" /><summary type="html">We derive a concentration bound of the type `for all $n \geq n_0$ for some $n_0$’ for TD(0) with linear function approximation. We work with online TD learning with samples from a single sample path of the underlying Markov chain. This makes our analysis significantly different from offline TD learning or TD learning with access to independent samples from the stationary distribution of the Markov chain. We treat TD(0) as a contractive stochastic approximation algorithm, with both martingale and Markov noises. Markov noise is handled using the Poisson equation and the lack of almost sure guarantees on boundedness of iterates is handled using the concept of relaxed concentration inequalities.</summary></entry><entry><title type="html">A Generalized Framework for Multiscale State-Space Modeling with Nested Nonlinear Dynamics: An Application to Bayesian Learning under Switching Regimes</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/AGeneralizedFrameworkforMultiscaleStateSpaceModelingwithNestedNonlinearDynamicsAnApplicationtoBayesianLearningunderSwitchingRegimes.html" rel="alternate" type="text/html" title="A Generalized Framework for Multiscale State-Space Modeling with Nested Nonlinear Dynamics: An Application to Bayesian Learning under Switching Regimes" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/AGeneralizedFrameworkforMultiscaleStateSpaceModelingwithNestedNonlinearDynamicsAnApplicationtoBayesianLearningunderSwitchingRegimes</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/AGeneralizedFrameworkforMultiscaleStateSpaceModelingwithNestedNonlinearDynamicsAnApplicationtoBayesianLearningunderSwitchingRegimes.html">&lt;p&gt;In this work, we introduce a generalized framework for multiscale state-space modeling that incorporates nested nonlinear dynamics, with a specific focus on Bayesian learning under switching regimes. Our framework captures the complex interactions between fast and slow processes within systems, allowing for the analysis of how these dynamics influence each other across various temporal scales. We model these interactions through a hierarchical structure in which finer time-scale dynamics are nested within coarser ones, while facilitating feedback between the scales. To promote the practical application of our framework, we address the problem of identifying switching regimes and transient dynamics. In particular, we develop a Bayesian learning approach to estimate latent states and indicators corresponding to switching dynamics, enabling the model to adapt effectively to regime changes. We employ Sequential Monte Carlo, or particle filtering, for inference. We illustrate the utility of our framework through simulations. The results demonstrate that our Bayesian learning approach effectively tracks state transitions and achieves accurate identification of switching dynamics in multiscale systems.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.19074&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Nayely Vélez-Cruz, Manfred D. Laubichler</name></author><category term="stat.ML" /><summary type="html">In this work, we introduce a generalized framework for multiscale state-space modeling that incorporates nested nonlinear dynamics, with a specific focus on Bayesian learning under switching regimes. Our framework captures the complex interactions between fast and slow processes within systems, allowing for the analysis of how these dynamics influence each other across various temporal scales. We model these interactions through a hierarchical structure in which finer time-scale dynamics are nested within coarser ones, while facilitating feedback between the scales. To promote the practical application of our framework, we address the problem of identifying switching regimes and transient dynamics. In particular, we develop a Bayesian learning approach to estimate latent states and indicators corresponding to switching dynamics, enabling the model to adapt effectively to regime changes. We employ Sequential Monte Carlo, or particle filtering, for inference. We illustrate the utility of our framework through simulations. The results demonstrate that our Bayesian learning approach effectively tracks state transitions and achieves accurate identification of switching dynamics in multiscale systems.</summary></entry><entry><title type="html">A Survey Analyzing Generalization in Deep Reinforcement Learning</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ASurveyAnalyzingGeneralizationinDeepReinforcementLearning.html" rel="alternate" type="text/html" title="A Survey Analyzing Generalization in Deep Reinforcement Learning" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ASurveyAnalyzingGeneralizationinDeepReinforcementLearning</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ASurveyAnalyzingGeneralizationinDeepReinforcementLearning.html">&lt;p&gt;Reinforcement learning research obtained significant success and attention with the utilization of deep neural networks to solve problems in high dimensional state or action spaces. While deep reinforcement learning policies are currently being deployed in many different fields from medical applications to large language models, there are still ongoing questions the field is trying to answer on the generalization capabilities of deep reinforcement learning policies. In this paper, we will formalize and analyze generalization in deep reinforcement learning. We will explain the fundamental reasons why deep reinforcement learning policies encounter overfitting problems that limit their generalization capabilities. Furthermore, we will categorize and explain the manifold solution approaches to increase generalization, and overcome overfitting in deep reinforcement learning policies. From exploration to adversarial analysis and from regularization to robustness our paper provides an analysis on a wide range of subfields within deep reinforcement learning with a broad scope and in-depth view. We believe our study can provide a compact guideline for the current advancements in deep reinforcement learning, and help to construct robust deep neural policies with higher generalization skills.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2401.02349&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ezgi Korkmaz</name></author><category term="stat.ML" /><summary type="html">Reinforcement learning research obtained significant success and attention with the utilization of deep neural networks to solve problems in high dimensional state or action spaces. While deep reinforcement learning policies are currently being deployed in many different fields from medical applications to large language models, there are still ongoing questions the field is trying to answer on the generalization capabilities of deep reinforcement learning policies. In this paper, we will formalize and analyze generalization in deep reinforcement learning. We will explain the fundamental reasons why deep reinforcement learning policies encounter overfitting problems that limit their generalization capabilities. Furthermore, we will categorize and explain the manifold solution approaches to increase generalization, and overcome overfitting in deep reinforcement learning policies. From exploration to adversarial analysis and from regularization to robustness our paper provides an analysis on a wide range of subfields within deep reinforcement learning with a broad scope and in-depth view. We believe our study can provide a compact guideline for the current advancements in deep reinforcement learning, and help to construct robust deep neural policies with higher generalization skills.</summary></entry><entry><title type="html">Adaptive Robust Confidence Intervals</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/AdaptiveRobustConfidenceIntervals.html" rel="alternate" type="text/html" title="Adaptive Robust Confidence Intervals" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/AdaptiveRobustConfidenceIntervals</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/AdaptiveRobustConfidenceIntervals.html">&lt;p&gt;This paper studies the construction of adaptive confidence intervals under Huber’s contamination model when the contamination proportion is unknown. For the robust confidence interval of a Gaussian mean, we show that the optimal length of an adaptive interval must be exponentially wider than that of a non-adaptive one. An optimal construction is achieved through simultaneous uncertainty quantification of quantiles at all levels. The results are further extended beyond the Gaussian location model by addressing a general family of robust hypothesis testing. In contrast to adaptive robust estimation, our findings reveal that the optimal length of an adaptive robust confidence interval critically depends on the distribution’s shape.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22647&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yuetian Luo, Chao Gao</name></author><category term="stat.ME," /><category term="stat.TH" /><summary type="html">This paper studies the construction of adaptive confidence intervals under Huber’s contamination model when the contamination proportion is unknown. For the robust confidence interval of a Gaussian mean, we show that the optimal length of an adaptive interval must be exponentially wider than that of a non-adaptive one. An optimal construction is achieved through simultaneous uncertainty quantification of quantiles at all levels. The results are further extended beyond the Gaussian location model by addressing a general family of robust hypothesis testing. In contrast to adaptive robust estimation, our findings reveal that the optimal length of an adaptive robust confidence interval critically depends on the distribution’s shape.</summary></entry><entry><title type="html">Adaptive Transfer Clustering: A Unified Framework</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/AdaptiveTransferClusteringAUnifiedFramework.html" rel="alternate" type="text/html" title="Adaptive Transfer Clustering: A Unified Framework" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/AdaptiveTransferClusteringAUnifiedFramework</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/AdaptiveTransferClusteringAUnifiedFramework.html">&lt;p&gt;We propose a general transfer learning framework for clustering given a main dataset and an auxiliary one about the same subjects. The two datasets may reflect similar but different latent grouping structures of the subjects. We propose an adaptive transfer clustering (ATC) algorithm that automatically leverages the commonality in the presence of unknown discrepancy, by optimizing an estimated bias-variance decomposition. It applies to a broad class of statistical models including Gaussian mixture models, stochastic block models, and latent class models. A theoretical analysis proves the optimality of ATC under the Gaussian mixture model and explicitly quantifies the benefit of transfer. Extensive simulations and real data experiments confirm our method’s effectiveness in various scenarios.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21263&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yuqi Gu, Zhongyuan Lyu, Kaizheng Wang</name></author><category term="stat.ME," /><category term="stat.ML," /><category term="stat.TH" /><summary type="html">We propose a general transfer learning framework for clustering given a main dataset and an auxiliary one about the same subjects. The two datasets may reflect similar but different latent grouping structures of the subjects. We propose an adaptive transfer clustering (ATC) algorithm that automatically leverages the commonality in the presence of unknown discrepancy, by optimizing an estimated bias-variance decomposition. It applies to a broad class of statistical models including Gaussian mixture models, stochastic block models, and latent class models. A theoretical analysis proves the optimality of ATC under the Gaussian mixture model and explicitly quantifies the benefit of transfer. Extensive simulations and real data experiments confirm our method’s effectiveness in various scenarios.</summary></entry><entry><title type="html">An Iterative Algorithm for Regularized Non-negative Matrix Factorizations</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/AnIterativeAlgorithmforRegularizedNonnegativeMatrixFactorizations.html" rel="alternate" type="text/html" title="An Iterative Algorithm for Regularized Non-negative Matrix Factorizations" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/AnIterativeAlgorithmforRegularizedNonnegativeMatrixFactorizations</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/AnIterativeAlgorithmforRegularizedNonnegativeMatrixFactorizations.html">&lt;p&gt;We generalize the non-negative matrix factorization algorithm of Lee and Seung to accept a weighted norm, and to support ridge and Lasso regularization. We recast the Lee and Seung multiplicative update as an additive update which does not get stuck on zero values. We apply the companion R package rnnmf to the problem of finding a reduced rank representation of a database of cocktails.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22698&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Steven E. Pav</name></author><category term="stat.AP," /><category term="stat.CO" /><summary type="html">We generalize the non-negative matrix factorization algorithm of Lee and Seung to accept a weighted norm, and to support ridge and Lasso regularization. We recast the Lee and Seung multiplicative update as an additive update which does not get stuck on zero values. We apply the companion R package rnnmf to the problem of finding a reduced rank representation of a database of cocktails.</summary></entry><entry><title type="html">An Overview of Causal Inference using Kernel Embeddings</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/AnOverviewofCausalInferenceusingKernelEmbeddings.html" rel="alternate" type="text/html" title="An Overview of Causal Inference using Kernel Embeddings" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/AnOverviewofCausalInferenceusingKernelEmbeddings</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/AnOverviewofCausalInferenceusingKernelEmbeddings.html">&lt;p&gt;Kernel embeddings have emerged as a powerful tool for representing probability measures in a variety of statistical inference problems. By mapping probability measures into a reproducing kernel Hilbert space (RKHS), kernel embeddings enable flexible representations of complex relationships between variables. They serve as a mechanism for efficiently transferring the representation of a distribution downstream to other tasks, such as hypothesis testing or causal effect estimation. In the context of causal inference, the main challenges include identifying causal associations and estimating the average treatment effect from observational data, where confounding variables may obscure direct cause-and-effect relationships. Kernel embeddings provide a robust nonparametric framework for addressing these challenges. They allow for the representations of distributions of observational data and their seamless transformation into representations of interventional distributions to estimate relevant causal quantities. We overview recent research that leverages the expressiveness of kernel embeddings in tandem with causal inference.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22754&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Dino Sejdinovic</name></author><category term="stat.ML," /><category term="stat.ME" /><summary type="html">Kernel embeddings have emerged as a powerful tool for representing probability measures in a variety of statistical inference problems. By mapping probability measures into a reproducing kernel Hilbert space (RKHS), kernel embeddings enable flexible representations of complex relationships between variables. They serve as a mechanism for efficiently transferring the representation of a distribution downstream to other tasks, such as hypothesis testing or causal effect estimation. In the context of causal inference, the main challenges include identifying causal associations and estimating the average treatment effect from observational data, where confounding variables may obscure direct cause-and-effect relationships. Kernel embeddings provide a robust nonparametric framework for addressing these challenges. They allow for the representations of distributions of observational data and their seamless transformation into representations of interventional distributions to estimate relevant causal quantities. We overview recent research that leverages the expressiveness of kernel embeddings in tandem with causal inference.</summary></entry><entry><title type="html">Analysis of cohort stepped wedge cluster-randomized trials with non-ignorable dropout via joint modeling</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Analysisofcohortsteppedwedgeclusterrandomizedtrialswithnonignorabledropoutviajointmodeling.html" rel="alternate" type="text/html" title="Analysis of cohort stepped wedge cluster-randomized trials with non-ignorable dropout via joint modeling" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Analysisofcohortsteppedwedgeclusterrandomizedtrialswithnonignorabledropoutviajointmodeling</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Analysisofcohortsteppedwedgeclusterrandomizedtrialswithnonignorabledropoutviajointmodeling.html">&lt;p&gt;Stepped wedge cluster-randomized trial (CRTs) designs randomize clusters of individuals to intervention sequences, ensuring that every cluster eventually transitions from a control period to receive the intervention under study by the end of the study period. The analysis of stepped wedge CRTs is usually more complex than parallel-arm CRTs due to more complex intra-cluster correlation structures. A further challenge in the analysis of closed-cohort stepped wedge CRTs, which follow groups of individuals enrolled in each period longitudinally, is the occurrence of dropout. This is particularly problematic in studies of individuals at high risk for mortality, which causes non-ignorable missing outcomes. If not appropriately addressed, missing outcomes from death will erode statistical power, at best, and bias treatment effect estimates, at worst. Joint longitudinal-survival models can accommodate informative dropout and missingness patterns in longitudinal studies. Specifically, within the joint longitudinal-survival modeling framework, one directly models the dropout process via a time-to-event submodel together with the longitudinal outcome of interest. The two submodels are then linked using a variety of possible association structures. This work extends linear mixed-effects models by jointly modeling the dropout process to accommodate informative missing outcome data in closed-cohort stepped wedge CRTs. We focus on constant intervention and general time-on-treatment effect parametrizations for the longitudinal submodel and study the performance of the proposed methodology using Monte Carlo simulation under several data-generating scenarios. We illustrate the methodology in practice by reanalyzing data from the `Frail Older Adults: Care in Transition’ (ACT) trial, a stepped wedge CRT of a multifaceted geriatric care model versus usual care in 35 primary care practices in the Netherlands.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2404.14840&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Alessandro Gasparini, Michael J. Crowther, Emiel O. Hoogendijk, Fan Li, Michael O. Harhay</name></author><category term="stat.ME" /><summary type="html">Stepped wedge cluster-randomized trial (CRTs) designs randomize clusters of individuals to intervention sequences, ensuring that every cluster eventually transitions from a control period to receive the intervention under study by the end of the study period. The analysis of stepped wedge CRTs is usually more complex than parallel-arm CRTs due to more complex intra-cluster correlation structures. A further challenge in the analysis of closed-cohort stepped wedge CRTs, which follow groups of individuals enrolled in each period longitudinally, is the occurrence of dropout. This is particularly problematic in studies of individuals at high risk for mortality, which causes non-ignorable missing outcomes. If not appropriately addressed, missing outcomes from death will erode statistical power, at best, and bias treatment effect estimates, at worst. Joint longitudinal-survival models can accommodate informative dropout and missingness patterns in longitudinal studies. Specifically, within the joint longitudinal-survival modeling framework, one directly models the dropout process via a time-to-event submodel together with the longitudinal outcome of interest. The two submodels are then linked using a variety of possible association structures. This work extends linear mixed-effects models by jointly modeling the dropout process to accommodate informative missing outcome data in closed-cohort stepped wedge CRTs. We focus on constant intervention and general time-on-treatment effect parametrizations for the longitudinal submodel and study the performance of the proposed methodology using Monte Carlo simulation under several data-generating scenarios. We illustrate the methodology in practice by reanalyzing data from the `Frail Older Adults: Care in Transition’ (ACT) trial, a stepped wedge CRT of a multifaceted geriatric care model versus usual care in 35 primary care practices in the Netherlands.</summary></entry><entry><title type="html">BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/BLASTBlockLevelAdaptiveStructuredMatricesforEfficientDeepNeuralNetworkInference.html" rel="alternate" type="text/html" title="BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/BLASTBlockLevelAdaptiveStructuredMatricesforEfficientDeepNeuralNetworkInference</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/BLASTBlockLevelAdaptiveStructuredMatricesforEfficientDeepNeuralNetworkInference.html">&lt;p&gt;Large-scale foundation models have demonstrated exceptional performance in language and vision tasks. However, the numerous dense matrix-vector operations involved in these large networks pose significant computational challenges during inference. To address these challenges, we introduce the Block-Level Adaptive STructured (BLAST) matrix, designed to learn and leverage efficient structures prevalent in the weight matrices of linear layers within deep learning models. Compared to existing structured matrices, the BLAST matrix offers substantial flexibility, as it can represent various types of structures that are either learned from data or computed from pre-existing weight matrices. We demonstrate the efficiency of using the BLAST matrix for compressing both language and vision tasks, showing that (i) for medium-sized models such as ViT and GPT-2, training with BLAST weights boosts performance while reducing complexity by 70% and 40%, respectively; and (ii) for large foundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2x compression while exhibiting the lowest performance degradation among all tested structured matrices. Our code is available at https://github.com/changwoolee/BLAST.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21262&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Changwoo Lee, Soo Min Kwon, Qing Qu, Hun-Seok Kim</name></author><category term="stat.ML" /><summary type="html">Large-scale foundation models have demonstrated exceptional performance in language and vision tasks. However, the numerous dense matrix-vector operations involved in these large networks pose significant computational challenges during inference. To address these challenges, we introduce the Block-Level Adaptive STructured (BLAST) matrix, designed to learn and leverage efficient structures prevalent in the weight matrices of linear layers within deep learning models. Compared to existing structured matrices, the BLAST matrix offers substantial flexibility, as it can represent various types of structures that are either learned from data or computed from pre-existing weight matrices. We demonstrate the efficiency of using the BLAST matrix for compressing both language and vision tasks, showing that (i) for medium-sized models such as ViT and GPT-2, training with BLAST weights boosts performance while reducing complexity by 70% and 40%, respectively; and (ii) for large foundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2x compression while exhibiting the lowest performance degradation among all tested structured matrices. Our code is available at https://github.com/changwoolee/BLAST.</summary></entry><entry><title type="html">BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/BLoBBayesianLowRankAdaptationbyBackpropagationforLargeLanguageModels.html" rel="alternate" type="text/html" title="BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/BLoBBayesianLowRankAdaptationbyBackpropagationforLargeLanguageModels</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/BLoBBayesianLowRankAdaptationbyBackpropagationforLargeLanguageModels.html">&lt;p&gt;Large Language Models (LLMs) often suffer from overconfidence during inference, particularly when adapted to downstream domain-specific tasks with limited data. Previous work addresses this issue by employing approximate Bayesian estimation after the LLMs are trained, enabling them to quantify uncertainty. However, such post-training approaches’ performance is severely limited by the parameters learned during training. In this paper, we go beyond post-training Bayesianization and propose Bayesian Low-Rank Adaptation by Backpropagation (BLoB), an algorithm that continuously and jointly adjusts both the mean and covariance of LLM parameters throughout the whole fine-tuning process. Our empirical results verify the effectiveness of BLoB in terms of generalization and uncertainty estimation, when evaluated on both in-distribution and out-of-distribution data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.11675&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yibin Wang, Haizhou Shi, Ligong Han, Dimitris Metaxas, Hao Wang</name></author><category term="stat.ML" /><summary type="html">Large Language Models (LLMs) often suffer from overconfidence during inference, particularly when adapted to downstream domain-specific tasks with limited data. Previous work addresses this issue by employing approximate Bayesian estimation after the LLMs are trained, enabling them to quantify uncertainty. However, such post-training approaches’ performance is severely limited by the parameters learned during training. In this paper, we go beyond post-training Bayesianization and propose Bayesian Low-Rank Adaptation by Backpropagation (BLoB), an algorithm that continuously and jointly adjusts both the mean and covariance of LLM parameters throughout the whole fine-tuning process. Our empirical results verify the effectiveness of BLoB in terms of generalization and uncertainty estimation, when evaluated on both in-distribution and out-of-distribution data.</summary></entry><entry><title type="html">Bandits with Preference Feedback: A Stackelberg Game Perspective</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/BanditswithPreferenceFeedbackAStackelbergGamePerspective.html" rel="alternate" type="text/html" title="Bandits with Preference Feedback: A Stackelberg Game Perspective" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/BanditswithPreferenceFeedbackAStackelbergGamePerspective</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/BanditswithPreferenceFeedbackAStackelbergGamePerspective.html">&lt;p&gt;Bandits with preference feedback present a powerful tool for optimizing unknown target functions when only pairwise comparisons are allowed instead of direct value queries. This model allows for incorporating human feedback into online inference and optimization and has been employed in systems for fine-tuning large language models. The problem is well understood in simplified settings with linear target functions or over finite small domains that limit practical interest. Taking the next step, we consider infinite domains and nonlinear (kernelized) rewards. In this setting, selecting a pair of actions is quite challenging and requires balancing exploration and exploitation at two levels: within the pair, and along the iterations of the algorithm. We propose MAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, and chooses action pairs that are informative and yield favorable rewards. MAXMINLCB consistently outperforms existing algorithms and satisfies an anytime-valid rate-optimal regret guarantee. This is due to our novel preference-based confidence sequences for kernelized logistic estimators.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.16745&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Barna Pásztor, Parnian Kassraie, Andreas Krause</name></author><category term="stat.ML" /><summary type="html">Bandits with preference feedback present a powerful tool for optimizing unknown target functions when only pairwise comparisons are allowed instead of direct value queries. This model allows for incorporating human feedback into online inference and optimization and has been employed in systems for fine-tuning large language models. The problem is well understood in simplified settings with linear target functions or over finite small domains that limit practical interest. Taking the next step, we consider infinite domains and nonlinear (kernelized) rewards. In this setting, selecting a pair of actions is quite challenging and requires balancing exploration and exploitation at two levels: within the pair, and along the iterations of the algorithm. We propose MAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, and chooses action pairs that are informative and yield favorable rewards. MAXMINLCB consistently outperforms existing algorithms and satisfies an anytime-valid rate-optimal regret guarantee. This is due to our novel preference-based confidence sequences for kernelized logistic estimators.</summary></entry><entry><title type="html">Bayesian Counterfactual Prediction Models for HIV Care Retention with Incomplete Outcome and Covariate Information</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/BayesianCounterfactualPredictionModelsforHIVCareRetentionwithIncompleteOutcomeandCovariateInformation.html" rel="alternate" type="text/html" title="Bayesian Counterfactual Prediction Models for HIV Care Retention with Incomplete Outcome and Covariate Information" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/BayesianCounterfactualPredictionModelsforHIVCareRetentionwithIncompleteOutcomeandCovariateInformation</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/BayesianCounterfactualPredictionModelsforHIVCareRetentionwithIncompleteOutcomeandCovariateInformation.html">&lt;p&gt;Like many chronic diseases, human immunodeficiency virus (HIV) is managed over time at regular clinic visits. At each visit, patient features are assessed, treatments are prescribed, and a subsequent visit is scheduled. There is a need for data-driven methods for both predicting retention and recommending scheduling decisions that optimize retention. Prediction models can be useful for estimating retention rates across a range of scheduling options. However, training such models with electronic health records (EHR) involves several complexities. First, formal causal inference methods are needed to adjust for observed confounding when estimating retention rates under counterfactual scheduling decisions. Second, competing events such as death preclude retention, while censoring events render retention missing. Third, inconsistent monitoring of features such as viral load and CD4 count lead to covariate missingness. This paper presents an all-in-one approach for both predicting HIV retention and optimizing scheduling while accounting for these complexities. We formulate and identify causal retention estimands in terms of potential return-time under a hypothetical scheduling decision. Flexible Bayesian approaches are used to model the observed return-time distribution while accounting for competing and censoring events and form posterior point and uncertainty estimates for these estimands. We address the urgent need for data-driven decision support in HIV care by applying our method to EHR from the Academic Model Providing Access to Healthcare (AMPATH) - a consortium of clinics that treat HIV in Western Kenya.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22481&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Arman Oganisian, Joseph Hogan, Edwin Sang, Allison DeLong, Ben Mosong, Hamish Fraser, Ann Mwangi</name></author><category term="stat.ME" /><summary type="html">Like many chronic diseases, human immunodeficiency virus (HIV) is managed over time at regular clinic visits. At each visit, patient features are assessed, treatments are prescribed, and a subsequent visit is scheduled. There is a need for data-driven methods for both predicting retention and recommending scheduling decisions that optimize retention. Prediction models can be useful for estimating retention rates across a range of scheduling options. However, training such models with electronic health records (EHR) involves several complexities. First, formal causal inference methods are needed to adjust for observed confounding when estimating retention rates under counterfactual scheduling decisions. Second, competing events such as death preclude retention, while censoring events render retention missing. Third, inconsistent monitoring of features such as viral load and CD4 count lead to covariate missingness. This paper presents an all-in-one approach for both predicting HIV retention and optimizing scheduling while accounting for these complexities. We formulate and identify causal retention estimands in terms of potential return-time under a hypothetical scheduling decision. Flexible Bayesian approaches are used to model the observed return-time distribution while accounting for competing and censoring events and form posterior point and uncertainty estimates for these estimands. We address the urgent need for data-driven decision support in HIV care by applying our method to EHR from the Academic Model Providing Access to Healthcare (AMPATH) - a consortium of clinics that treat HIV in Western Kenya.</summary></entry><entry><title type="html">Bayesian Inference for Relational Graph in a Causal Vector Autoregressive Time Series</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/BayesianInferenceforRelationalGraphinaCausalVectorAutoregressiveTimeSeries.html" rel="alternate" type="text/html" title="Bayesian Inference for Relational Graph in a Causal Vector Autoregressive Time Series" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/BayesianInferenceforRelationalGraphinaCausalVectorAutoregressiveTimeSeries</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/BayesianInferenceforRelationalGraphinaCausalVectorAutoregressiveTimeSeries.html">&lt;p&gt;We propose a method for simultaneously estimating a contemporaneous graph structure and autocorrelation structure for a causal high-dimensional vector autoregressive process (VAR). The graph is estimated by estimating the stationary precision matrix using a Bayesian framework. We introduce a novel parameterization that is convenient for jointly estimating the precision matrix and the autocovariance matrices. The methodology based on the new parameterization has several desirable properties. A key feature of the proposed methodology is that it maintains causality of the process in its estimates and also provides a fast feasible way for computing the reduced rank likelihood for a high-dimensional Gaussian VAR. We use sparse priors along with the likelihood under the new parameterization to obtain the posterior of the graphical parameters as well as that of the temporal parameters. An efficient Markov Chain Monte Carlo (MCMC) algorithm is developed for posterior computation. We also establish theoretical consistency properties for the high-dimensional posterior. The proposed methodology shows excellent performance in simulations and real data applications.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22617&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Arkaprava Roy, Anindya Roy, Subhashis Ghosal</name></author><category term="stat.ME," /><category term="stat.TH" /><summary type="html">We propose a method for simultaneously estimating a contemporaneous graph structure and autocorrelation structure for a causal high-dimensional vector autoregressive process (VAR). The graph is estimated by estimating the stationary precision matrix using a Bayesian framework. We introduce a novel parameterization that is convenient for jointly estimating the precision matrix and the autocovariance matrices. The methodology based on the new parameterization has several desirable properties. A key feature of the proposed methodology is that it maintains causality of the process in its estimates and also provides a fast feasible way for computing the reduced rank likelihood for a high-dimensional Gaussian VAR. We use sparse priors along with the likelihood under the new parameterization to obtain the posterior of the graphical parameters as well as that of the temporal parameters. An efficient Markov Chain Monte Carlo (MCMC) algorithm is developed for posterior computation. We also establish theoretical consistency properties for the high-dimensional posterior. The proposed methodology shows excellent performance in simulations and real data applications.</summary></entry><entry><title type="html">Bayesian Optimisation with Unknown Hyperparameters: Regret Bounds Logarithmically Closer to Optimal</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/BayesianOptimisationwithUnknownHyperparametersRegretBoundsLogarithmicallyClosertoOptimal.html" rel="alternate" type="text/html" title="Bayesian Optimisation with Unknown Hyperparameters: Regret Bounds Logarithmically Closer to Optimal" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/BayesianOptimisationwithUnknownHyperparametersRegretBoundsLogarithmicallyClosertoOptimal</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/BayesianOptimisationwithUnknownHyperparametersRegretBoundsLogarithmicallyClosertoOptimal.html">&lt;p&gt;Bayesian Optimization (BO) is widely used for optimising black-box functions but requires us to specify the length scale hyperparameter, which defines the smoothness of the functions the optimizer will consider. Most current BO algorithms choose this hyperparameter by maximizing the marginal likelihood of the observed data, albeit risking misspecification if the objective function is less smooth in regions we have not yet explored. The only prior solution addressing this problem with theoretical guarantees was A-GP-UCB, proposed by Berkenkamp et al. (2019). This algorithm progressively decreases the length scale, expanding the class of functions considered by the optimizer. However, A-GP-UCB lacks a stopping mechanism, leading to over-exploration and slow convergence. To overcome this, we introduce Length scale Balancing (LB) - a novel approach, aggregating multiple base surrogate models with varying length scales. LB intermittently adds smaller length scale candidate values while retaining longer scales, balancing exploration and exploitation. We formally derive a cumulative regret bound of LB and compare it with the regret of an oracle BO algorithm using the optimal length scale. Denoting the factor by which the regret bound of A-GP-UCB was away from oracle as $g(T)$, we show that LB is only $\log g(T)$ away from oracle regret. We also empirically evaluate our algorithm on synthetic and real-world benchmarks and show it outperforms A-GP-UCB, maximum likelihood estimation and MCMC.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.10384&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Juliusz Ziomek, Masaki Adachi, Michael A. Osborne</name></author><category term="stat.ML" /><summary type="html">Bayesian Optimization (BO) is widely used for optimising black-box functions but requires us to specify the length scale hyperparameter, which defines the smoothness of the functions the optimizer will consider. Most current BO algorithms choose this hyperparameter by maximizing the marginal likelihood of the observed data, albeit risking misspecification if the objective function is less smooth in regions we have not yet explored. The only prior solution addressing this problem with theoretical guarantees was A-GP-UCB, proposed by Berkenkamp et al. (2019). This algorithm progressively decreases the length scale, expanding the class of functions considered by the optimizer. However, A-GP-UCB lacks a stopping mechanism, leading to over-exploration and slow convergence. To overcome this, we introduce Length scale Balancing (LB) - a novel approach, aggregating multiple base surrogate models with varying length scales. LB intermittently adds smaller length scale candidate values while retaining longer scales, balancing exploration and exploitation. We formally derive a cumulative regret bound of LB and compare it with the regret of an oracle BO algorithm using the optimal length scale. Denoting the factor by which the regret bound of A-GP-UCB was away from oracle as $g(T)$, we show that LB is only $\log g(T)$ away from oracle regret. We also empirically evaluate our algorithm on synthetic and real-world benchmarks and show it outperforms A-GP-UCB, maximum likelihood estimation and MCMC.</summary></entry><entry><title type="html">Bayesian shared parameter joint models for heterogeneous populations</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Bayesiansharedparameterjointmodelsforheterogeneouspopulations.html" rel="alternate" type="text/html" title="Bayesian shared parameter joint models for heterogeneous populations" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Bayesiansharedparameterjointmodelsforheterogeneouspopulations</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Bayesiansharedparameterjointmodelsforheterogeneouspopulations.html">&lt;p&gt;Joint models (JMs) for longitudinal and time-to-event data are an important class of biostatistical models in health and medical research. When the study population consists of heterogeneous subgroups, the standard JM may be inadequate and lead to misleading results. Joint latent class models (JLCMs) and their variants have been proposed to incorporate latent class structures into JMs. JLCMs are useful for identifying latent subgroup structures, obtaining a more nuanced understanding of the relationships between longitudinal outcomes, and improving prediction performance. We consider the generic form of JLCM, which poses significant computational challenges for both frequentist and Bayesian approaches due to the numerical intractability and multimodality of the associated model’s likelihood or posterior. Focusing on the less explored Bayesian paradigm, we propose a new Bayesian inference framework to tackle key limitations in the existing method. Our algorithm leverages state-of-the-art Markov chain Monte Carlo techniques and parallel computing for parameter estimation and model selection. Through a simulation study, we demonstrate the feasibility and superiority of our proposed method over the existing approach. Our simulations also generate important computational insights and practical guidance for implementing such complex models. We illustrate our method using data from the PAQUID prospective cohort study, where we jointly investigate the association between a repeatedly measured cognitive score and the risk of dementia and the latent class structure defined from the longitudinal outcomes.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22534&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Sida Chen, Danilo Alvares, Marco Palma, Jessica K. Barrett</name></author><category term="stat.ME," /><category term="stat.CO" /><summary type="html">Joint models (JMs) for longitudinal and time-to-event data are an important class of biostatistical models in health and medical research. When the study population consists of heterogeneous subgroups, the standard JM may be inadequate and lead to misleading results. Joint latent class models (JLCMs) and their variants have been proposed to incorporate latent class structures into JMs. JLCMs are useful for identifying latent subgroup structures, obtaining a more nuanced understanding of the relationships between longitudinal outcomes, and improving prediction performance. We consider the generic form of JLCM, which poses significant computational challenges for both frequentist and Bayesian approaches due to the numerical intractability and multimodality of the associated model’s likelihood or posterior. Focusing on the less explored Bayesian paradigm, we propose a new Bayesian inference framework to tackle key limitations in the existing method. Our algorithm leverages state-of-the-art Markov chain Monte Carlo techniques and parallel computing for parameter estimation and model selection. Through a simulation study, we demonstrate the feasibility and superiority of our proposed method over the existing approach. Our simulations also generate important computational insights and practical guidance for implementing such complex models. We illustrate our method using data from the PAQUID prospective cohort study, where we jointly investigate the association between a repeatedly measured cognitive score and the risk of dementia and the latent class structure defined from the longitudinal outcomes.</summary></entry><entry><title type="html">Bootstrap-based goodness-of-fit test for parametric families of conditional distributions</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Bootstrapbasedgoodnessoffittestforparametricfamiliesofconditionaldistributions.html" rel="alternate" type="text/html" title="Bootstrap-based goodness-of-fit test for parametric families of conditional distributions" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Bootstrapbasedgoodnessoffittestforparametricfamiliesofconditionaldistributions</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Bootstrapbasedgoodnessoffittestforparametricfamiliesofconditionaldistributions.html">&lt;p&gt;In various scientific fields, researchers are interested in exploring the relationship between some response variable Y and a vector of covariates X. In order to make use of a specific model for the dependence structure, it first has to be checked whether the conditional density function of Y given X fits into a given parametric family. We propose a consistent bootstrap-based goodness-of-fit test for this purpose. The test statistic traces the difference between a nonparametric and a semi-parametric estimate of the marginal distribution function of Y. As its asymptotic null distribution is not distribution-free, a parametric bootstrap method is used to determine the critical value. A simulation study shows that, in some cases, the new method is more sensitive to deviations from the parametric model than other tests found in the literature. We also apply our method to real-world datasets.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2409.20262&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Gitte Kremling, Gerhard Dikta</name></author><category term="stat.ME" /><summary type="html">In various scientific fields, researchers are interested in exploring the relationship between some response variable Y and a vector of covariates X. In order to make use of a specific model for the dependence structure, it first has to be checked whether the conditional density function of Y given X fits into a given parametric family. We propose a consistent bootstrap-based goodness-of-fit test for this purpose. The test statistic traces the difference between a nonparametric and a semi-parametric estimate of the marginal distribution function of Y. As its asymptotic null distribution is not distribution-free, a parametric bootstrap method is used to determine the critical value. A simulation study shows that, in some cases, the new method is more sensitive to deviations from the parametric model than other tests found in the literature. We also apply our method to real-world datasets.</summary></entry><entry><title type="html">Clustering Computer Mouse Tracking Data with Informed Hierarchical Shrinkage Partition Priors</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ClusteringComputerMouseTrackingDatawithInformedHierarchicalShrinkagePartitionPriors.html" rel="alternate" type="text/html" title="Clustering Computer Mouse Tracking Data with Informed Hierarchical Shrinkage Partition Priors" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ClusteringComputerMouseTrackingDatawithInformedHierarchicalShrinkagePartitionPriors</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ClusteringComputerMouseTrackingDatawithInformedHierarchicalShrinkagePartitionPriors.html">&lt;p&gt;Mouse-tracking data, which record computer mouse trajectories while participants perform an experimental task, provide valuable insights into subjects’ underlying cognitive processes. Neuroscientists are interested in clustering the subjects’ responses during computer mouse-tracking tasks to reveal patterns of individual decision-making behaviors and identify population subgroups with similar neurobehavioral responses. These data can be combined with neuro-imaging data to provide additional information for personalized interventions. In this article, we develop a novel hierarchical shrinkage partition (HSP) prior for clustering summary statistics derived from the trajectories of mouse-tracking data. The HSP model defines a subjects’ cluster as a set of subjects that gives rise to more similar (rather than identical) nested partitions of the conditions. The proposed model can incorporate prior information about the partitioning of either subjects or conditions to facilitate clustering, and it allows for deviations of the nested partitions within each subject group. These features distinguish the HSP model from other bi-clustering methods that typically create identical nested partitions of conditions within a subject group. Furthermore, it differs from existing nested clustering methods, which define clusters based on common parameters in the sampling model and identify subject groups by different distributions. We illustrate the unique features of the HSP model on a mouse tracking dataset from a pilot study and in simulation studies. Our results show the ability and effectiveness of the proposed exploratory framework in clustering and revealing possible different behavioral patterns across subject groups.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22675&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ziyi Song, Weining Shen, Marina Vannucci, Alexandria Baldizon, Paul M. Cinciripini, Francesco Versace, Michele Guindani</name></author><category term="stat.ME" /><summary type="html">Mouse-tracking data, which record computer mouse trajectories while participants perform an experimental task, provide valuable insights into subjects’ underlying cognitive processes. Neuroscientists are interested in clustering the subjects’ responses during computer mouse-tracking tasks to reveal patterns of individual decision-making behaviors and identify population subgroups with similar neurobehavioral responses. These data can be combined with neuro-imaging data to provide additional information for personalized interventions. In this article, we develop a novel hierarchical shrinkage partition (HSP) prior for clustering summary statistics derived from the trajectories of mouse-tracking data. The HSP model defines a subjects’ cluster as a set of subjects that gives rise to more similar (rather than identical) nested partitions of the conditions. The proposed model can incorporate prior information about the partitioning of either subjects or conditions to facilitate clustering, and it allows for deviations of the nested partitions within each subject group. These features distinguish the HSP model from other bi-clustering methods that typically create identical nested partitions of conditions within a subject group. Furthermore, it differs from existing nested clustering methods, which define clusters based on common parameters in the sampling model and identify subject groups by different distributions. We illustrate the unique features of the HSP model on a mouse tracking dataset from a pilot study and in simulation studies. Our results show the ability and effectiveness of the proposed exploratory framework in clustering and revealing possible different behavioral patterns across subject groups.</summary></entry><entry><title type="html">Conditional Forecasting of Margin Calls using Dynamic Graph Neural Networks</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ConditionalForecastingofMarginCallsusingDynamicGraphNeuralNetworks.html" rel="alternate" type="text/html" title="Conditional Forecasting of Margin Calls using Dynamic Graph Neural Networks" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ConditionalForecastingofMarginCallsusingDynamicGraphNeuralNetworks</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ConditionalForecastingofMarginCallsusingDynamicGraphNeuralNetworks.html">&lt;p&gt;We introduce a novel Dynamic Graph Neural Network (DGNN) architecture for solving conditional $m$-steps ahead forecasting problems in temporal financial networks. The proposed DGNN is validated on simulated data from a temporal financial network model capturing stylized features of Interest Rate Swaps (IRSs) transaction networks, where financial entities trade swap contracts dynamically and the network topology evolves conditionally on a reference rate. The proposed model is able to produce accurate conditional forecasts of net variation margins up to a $21$-day horizon by leveraging conditional information under pre-determined stress test scenarios. Our work shows that the network dynamics can be successfully incorporated into stress-testing practices, thus providing regulators and policymakers with a crucial tool for systemic risk monitoring.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23275&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Matteo Citterio, Marco D&apos;Errico, Gabriele Visentin</name></author><category term="stat.ML" /><summary type="html">We introduce a novel Dynamic Graph Neural Network (DGNN) architecture for solving conditional $m$-steps ahead forecasting problems in temporal financial networks. The proposed DGNN is validated on simulated data from a temporal financial network model capturing stylized features of Interest Rate Swaps (IRSs) transaction networks, where financial entities trade swap contracts dynamically and the network topology evolves conditionally on a reference rate. The proposed model is able to produce accurate conditional forecasts of net variation margins up to a $21$-day horizon by leveraging conditional information under pre-determined stress test scenarios. Our work shows that the network dynamics can be successfully incorporated into stress-testing practices, thus providing regulators and policymakers with a crucial tool for systemic risk monitoring.</summary></entry><entry><title type="html">Conformal Classification with Equalized Coverage for Adaptively Selected Groups</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ConformalClassificationwithEqualizedCoverageforAdaptivelySelectedGroups.html" rel="alternate" type="text/html" title="Conformal Classification with Equalized Coverage for Adaptively Selected Groups" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ConformalClassificationwithEqualizedCoverageforAdaptivelySelectedGroups</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ConformalClassificationwithEqualizedCoverageforAdaptivelySelectedGroups.html">&lt;p&gt;This paper introduces a conformal inference method to evaluate uncertainty in classification by generating prediction sets with valid coverage conditional on adaptively chosen features. These features are carefully selected to reflect potential model limitations or biases. This can be useful to find a practical compromise between efficiency – by providing informative predictions – and algorithmic fairness – by ensuring equalized coverage for the most sensitive groups. We demonstrate the validity and effectiveness of this method on simulated and real data sets.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.15106&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yanfei Zhou, Matteo Sesia</name></author><category term="stat.ML" /><summary type="html">This paper introduces a conformal inference method to evaluate uncertainty in classification by generating prediction sets with valid coverage conditional on adaptively chosen features. These features are carefully selected to reflect potential model limitations or biases. This can be useful to find a practical compromise between efficiency – by providing informative predictions – and algorithmic fairness – by ensuring equalized coverage for the most sensitive groups. We demonstrate the validity and effectiveness of this method on simulated and real data sets.</summary></entry><entry><title type="html">Data subsampling for Poisson regression with pth-root-link</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/DatasubsamplingforPoissonregressionwithpthrootlink.html" rel="alternate" type="text/html" title="Data subsampling for Poisson regression with pth-root-link" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/DatasubsamplingforPoissonregressionwithpthrootlink</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/DatasubsamplingforPoissonregressionwithpthrootlink.html">&lt;p&gt;We develop and analyze data subsampling techniques for Poisson regression, the standard model for count data $y\in\mathbb{N}$. In particular, we consider the Poisson generalized linear model with ID- and square root-link functions. We consider the method of coresets, which are small weighted subsets that approximate the loss function of Poisson regression up to a factor of $1\pm\varepsilon$. We show $\Omega(n)$ lower bounds against coresets for Poisson regression that continue to hold against arbitrary data reduction techniques up to logarithmic factors. By introducing a novel complexity parameter and a domain shifting approach, we show that sublinear coresets with $1\pm\varepsilon$ approximation guarantee exist when the complexity parameter is small. In particular, the dependence on the number of input points can be reduced to polylogarithmic. We show that the dependence on other input parameters can also be bounded sublinearly, though not always logarithmically. In particular, we show that the square root-link admits an $O(\log(y_{\max}))$ dependence, where $y_{\max}$ denotes the largest count presented in the data, while the ID-link requires a $\Theta(\sqrt{y_{\max}/\log(y_{\max})})$ dependence. As an auxiliary result for proving the tightness of the bound with respect to $y_{\max}$ in the case of the ID-link, we show an improved bound on the principal branch of the Lambert $W_0$ function, which may be of independent interest. We further show the limitations of our analysis when $p$th degree root-link functions for $p\geq 3$ are considered, which indicate that other analytical or computational methods would be required if such a generalization is even possible.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22872&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Han Cheng Lie, Alexander Munteanu</name></author><category term="stat.ML" /><summary type="html">We develop and analyze data subsampling techniques for Poisson regression, the standard model for count data $y\in\mathbb{N}$. In particular, we consider the Poisson generalized linear model with ID- and square root-link functions. We consider the method of coresets, which are small weighted subsets that approximate the loss function of Poisson regression up to a factor of $1\pm\varepsilon$. We show $\Omega(n)$ lower bounds against coresets for Poisson regression that continue to hold against arbitrary data reduction techniques up to logarithmic factors. By introducing a novel complexity parameter and a domain shifting approach, we show that sublinear coresets with $1\pm\varepsilon$ approximation guarantee exist when the complexity parameter is small. In particular, the dependence on the number of input points can be reduced to polylogarithmic. We show that the dependence on other input parameters can also be bounded sublinearly, though not always logarithmically. In particular, we show that the square root-link admits an $O(\log(y_{\max}))$ dependence, where $y_{\max}$ denotes the largest count presented in the data, while the ID-link requires a $\Theta(\sqrt{y_{\max}/\log(y_{\max})})$ dependence. As an auxiliary result for proving the tightness of the bound with respect to $y_{\max}$ in the case of the ID-link, we show an improved bound on the principal branch of the Lambert $W_0$ function, which may be of independent interest. We further show the limitations of our analysis when $p$th degree root-link functions for $p\geq 3$ are considered, which indicate that other analytical or computational methods would be required if such a generalization is even possible.</summary></entry><entry><title type="html">Denoising diffusion probabilistic models are optimally adaptive to unknown low dimensionality</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Denoisingdiffusionprobabilisticmodelsareoptimallyadaptivetounknownlowdimensionality.html" rel="alternate" type="text/html" title="Denoising diffusion probabilistic models are optimally adaptive to unknown low dimensionality" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Denoisingdiffusionprobabilisticmodelsareoptimallyadaptivetounknownlowdimensionality</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Denoisingdiffusionprobabilisticmodelsareoptimallyadaptivetounknownlowdimensionality.html">&lt;p&gt;The denoising diffusion probabilistic model (DDPM) has emerged as a mainstream generative model in generative AI. While sharp convergence guarantees have been established for the DDPM, the iteration complexity is, in general, proportional to the ambient data dimension, resulting in overly conservative theory that fails to explain its practical efficiency. This has motivated the recent work Li and Yan (2024a) to investigate how the DDPM can achieve sampling speed-ups through automatic exploitation of intrinsic low dimensionality of data. We strengthen this line of work by demonstrating, in some sense, optimal adaptivity to unknown low dimensionality. For a broad class of data distributions with intrinsic dimension $k$, we prove that the iteration complexity of the DDPM scales nearly linearly with $k$, which is optimal when using KL divergence to measure distributional discrepancy. Notably, our work is closely aligned with the independent concurrent work Potaptchik et al. (2024) – posted two weeks prior to ours – in establishing nearly linear-$k$ convergence guarantees for the DDPM.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.18784&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Zhihan Huang, Yuting Wei, Yuxin Chen</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">The denoising diffusion probabilistic model (DDPM) has emerged as a mainstream generative model in generative AI. While sharp convergence guarantees have been established for the DDPM, the iteration complexity is, in general, proportional to the ambient data dimension, resulting in overly conservative theory that fails to explain its practical efficiency. This has motivated the recent work Li and Yan (2024a) to investigate how the DDPM can achieve sampling speed-ups through automatic exploitation of intrinsic low dimensionality of data. We strengthen this line of work by demonstrating, in some sense, optimal adaptivity to unknown low dimensionality. For a broad class of data distributions with intrinsic dimension $k$, we prove that the iteration complexity of the DDPM scales nearly linearly with $k$, which is optimal when using KL divergence to measure distributional discrepancy. Notably, our work is closely aligned with the independent concurrent work Potaptchik et al. (2024) – posted two weeks prior to ours – in establishing nearly linear-$k$ convergence guarantees for the DDPM.</summary></entry><entry><title type="html">Designing Algorithmic Recommendations to Achieve Human-AI Complementarity</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/DesigningAlgorithmicRecommendationstoAchieveHumanAIComplementarity.html" rel="alternate" type="text/html" title="Designing Algorithmic Recommendations to Achieve Human-AI Complementarity" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/DesigningAlgorithmicRecommendationstoAchieveHumanAIComplementarity</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/DesigningAlgorithmicRecommendationstoAchieveHumanAIComplementarity.html">&lt;p&gt;Algorithms frequently assist, rather than replace, human decision-makers. However, the design and analysis of algorithms often focus on predicting outcomes and do not explicitly model their effect on human decisions. This discrepancy between the design and role of algorithmic assistants becomes particularly concerning in light of empirical evidence that suggests that algorithmic assistants again and again fail to improve human decisions. In this article, we formalize the design of recommendation algorithms that assist human decision-makers without making restrictive ex-ante assumptions about how recommendations affect decisions. We formulate an algorithmic-design problem that leverages the potential-outcomes framework from causal inference to model the effect of recommendations on a human decision-maker’s binary treatment choice. Within this model, we introduce a monotonicity assumption that leads to an intuitive classification of human responses to the algorithm. Under this assumption, we can express the human’s response to algorithmic recommendations in terms of their compliance with the algorithm and the active decision they would take if the algorithm sends no recommendation. We showcase the utility of our framework using an online experiment that simulates a hiring task. We argue that our approach can make sense of the relative performance of different recommendation algorithms in the experiment and can help design solutions that realize human-AI complementarity. Finally, we leverage our approach to derive minimax optimal recommendation algorithms that can be implemented with machine learning using limited training data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.01484&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Bryce McLaughlin, Jann Spiess</name></author><category term="stat.ML" /><summary type="html">Algorithms frequently assist, rather than replace, human decision-makers. However, the design and analysis of algorithms often focus on predicting outcomes and do not explicitly model their effect on human decisions. This discrepancy between the design and role of algorithmic assistants becomes particularly concerning in light of empirical evidence that suggests that algorithmic assistants again and again fail to improve human decisions. In this article, we formalize the design of recommendation algorithms that assist human decision-makers without making restrictive ex-ante assumptions about how recommendations affect decisions. We formulate an algorithmic-design problem that leverages the potential-outcomes framework from causal inference to model the effect of recommendations on a human decision-maker’s binary treatment choice. Within this model, we introduce a monotonicity assumption that leads to an intuitive classification of human responses to the algorithm. Under this assumption, we can express the human’s response to algorithmic recommendations in terms of their compliance with the algorithm and the active decision they would take if the algorithm sends no recommendation. We showcase the utility of our framework using an online experiment that simulates a hiring task. We argue that our approach can make sense of the relative performance of different recommendation algorithms in the experiment and can help design solutions that realize human-AI complementarity. Finally, we leverage our approach to derive minimax optimal recommendation algorithms that can be implemented with machine learning using limited training data.</summary></entry><entry><title type="html">Directional data analysis using the spherical Cauchy and the Poisson kernel-based distribution</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/DirectionaldataanalysisusingthesphericalCauchyandthePoissonkernelbaseddistribution.html" rel="alternate" type="text/html" title="Directional data analysis using the spherical Cauchy and the Poisson kernel-based distribution" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/DirectionaldataanalysisusingthesphericalCauchyandthePoissonkernelbaseddistribution</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/DirectionaldataanalysisusingthesphericalCauchyandthePoissonkernelbaseddistribution.html">&lt;p&gt;In 2020, two novel distributions for the analysis of directional data were introduced: the spherical Cauchy distribution and the Poisson kernel-based distribution. This paper provides a detailed exploration of both distributions within various analytical frameworks. To enhance the practical utility of these distributions, alternative parametrizations that offer advantages in numerical stability and parameter estimation are presented, such as implementation of the Newton-Raphson algorithm for parameter estimation, while facilitating a more efficient and simplified approach in the regression framework. Additionally, a two-sample location test based on the log-likelihood ratio test is introduced. This test is designed to assess whether the location parameters of two populations can be assumed equal. The maximum likelihood discriminant analysis framework is developed for classification purposes, and finally, the problem of clustering directional data is addressed, by fitting finite mixtures of Spherical Cauchy or Poisson kernel-based distributions. Empirical validation is conducted through comprehensive simulation studies and real data applications, wherein the performance of the spherical Cauchy and Poisson kernel-based distributions is systematically compared.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2409.03292&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Michail Tsagris, Panagiotis Papastamoulis</name></author><category term="stat.ME" /><summary type="html">In 2020, two novel distributions for the analysis of directional data were introduced: the spherical Cauchy distribution and the Poisson kernel-based distribution. This paper provides a detailed exploration of both distributions within various analytical frameworks. To enhance the practical utility of these distributions, alternative parametrizations that offer advantages in numerical stability and parameter estimation are presented, such as implementation of the Newton-Raphson algorithm for parameter estimation, while facilitating a more efficient and simplified approach in the regression framework. Additionally, a two-sample location test based on the log-likelihood ratio test is introduced. This test is designed to assess whether the location parameters of two populations can be assumed equal. The maximum likelihood discriminant analysis framework is developed for classification purposes, and finally, the problem of clustering directional data is addressed, by fitting finite mixtures of Spherical Cauchy or Poisson kernel-based distributions. Empirical validation is conducted through comprehensive simulation studies and real data applications, wherein the performance of the spherical Cauchy and Poisson kernel-based distributions is systematically compared.</summary></entry><entry><title type="html">Dynamic prediction of death risk given a renewal hospitalization process</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Dynamicpredictionofdeathriskgivenarenewalhospitalizationprocess.html" rel="alternate" type="text/html" title="Dynamic prediction of death risk given a renewal hospitalization process" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Dynamicpredictionofdeathriskgivenarenewalhospitalizationprocess</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Dynamicpredictionofdeathriskgivenarenewalhospitalizationprocess.html">&lt;p&gt;Predicting the risk of death for chronic patients is highly valuable for informed medical decision-making. This paper proposes a general framework for dynamic prediction of the risk of death of a patient given her hospitalization history, which is generally available to physicians. Predictions are based on a joint model for the death and hospitalization processes, thereby avoiding the potential bias arising from selection of survivors. The framework accommodates various submodels for the hospitalization process. In particular, we study prediction of the risk of death in a renewal model for hospitalizations, a common approach to recurrent event modelling. In the renewal model, the distribution of hospitalizations throughout the follow-up period impacts the risk of death. This result differs from prediction in the Poisson model, previously studied, where only the number of hospitalizations matters. We apply our methodology to a prospective, observational cohort study of 512 patients treated for COPD in one of six outpatient respiratory clinics run by the Respiratory Service of Galdakao University Hospital, with a median follow-up of 4.7 years. We find that more concentrated hospitalizations increase the risk of death.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.04849&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Telmo J. Pérez-Izquierdo, Irantzu Barrio, Cristobal Esteban</name></author><category term="stat.ME," /><category term="stat.AP" /><summary type="html">Predicting the risk of death for chronic patients is highly valuable for informed medical decision-making. This paper proposes a general framework for dynamic prediction of the risk of death of a patient given her hospitalization history, which is generally available to physicians. Predictions are based on a joint model for the death and hospitalization processes, thereby avoiding the potential bias arising from selection of survivors. The framework accommodates various submodels for the hospitalization process. In particular, we study prediction of the risk of death in a renewal model for hospitalizations, a common approach to recurrent event modelling. In the renewal model, the distribution of hospitalizations throughout the follow-up period impacts the risk of death. This result differs from prediction in the Poisson model, previously studied, where only the number of hospitalizations matters. We apply our methodology to a prospective, observational cohort study of 512 patients treated for COPD in one of six outpatient respiratory clinics run by the Respiratory Service of Galdakao University Hospital, with a median follow-up of 4.7 years. We find that more concentrated hospitalizations increase the risk of death.</summary></entry><entry><title type="html">ELBOing Stein: Variational Bayes with Stein Mixture Inference</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ELBOingSteinVariationalBayeswithSteinMixtureInference.html" rel="alternate" type="text/html" title="ELBOing Stein: Variational Bayes with Stein Mixture Inference" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ELBOingSteinVariationalBayeswithSteinMixtureInference</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ELBOingSteinVariationalBayeswithSteinMixtureInference.html">&lt;p&gt;Stein variational gradient descent (SVGD) [Liu and Wang, 2016] performs approximate Bayesian inference by representing the posterior with a set of particles. However, SVGD suffers from variance collapse, i.e. poor predictions due to underestimating uncertainty [Ba et al., 2021], even for moderately-dimensional models such as small Bayesian neural networks (BNNs). To address this issue, we generalize SVGD by letting each particle parameterize a component distribution in a mixture model. Our method, Stein Mixture Inference (SMI), optimizes a lower bound to the evidence (ELBO) and introduces user-specified guides parameterized by particles. SMI extends the Nonlinear SVGD framework [Wang and Liu, 2019] to the case of variational Bayes. SMI effectively avoids variance collapse, judging by a previously described test developed for this purpose, and performs well on standard data sets. In addition, SMI requires considerably fewer particles than SVGD to accurately estimate uncertainty for small BNNs. The synergistic combination of NSVGD, ELBO optimization and user-specified guides establishes a promising approach towards variational Bayesian inference in the case of tall and wide data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22948&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ola R{\o}nning, Eric Nalisnick, Christophe Ley, Padhraic Smyth, Thomas Hamelryck</name></author><category term="stat.ML" /><summary type="html">Stein variational gradient descent (SVGD) [Liu and Wang, 2016] performs approximate Bayesian inference by representing the posterior with a set of particles. However, SVGD suffers from variance collapse, i.e. poor predictions due to underestimating uncertainty [Ba et al., 2021], even for moderately-dimensional models such as small Bayesian neural networks (BNNs). To address this issue, we generalize SVGD by letting each particle parameterize a component distribution in a mixture model. Our method, Stein Mixture Inference (SMI), optimizes a lower bound to the evidence (ELBO) and introduces user-specified guides parameterized by particles. SMI extends the Nonlinear SVGD framework [Wang and Liu, 2019] to the case of variational Bayes. SMI effectively avoids variance collapse, judging by a previously described test developed for this purpose, and performs well on standard data sets. In addition, SMI requires considerably fewer particles than SVGD to accurately estimate uncertainty for small BNNs. The synergistic combination of NSVGD, ELBO optimization and user-specified guides establishes a promising approach towards variational Bayesian inference in the case of tall and wide data.</summary></entry><entry><title type="html">Efficient distributed representations with linear-time attention scores normalization</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Efficientdistributedrepresentationswithlineartimeattentionscoresnormalization.html" rel="alternate" type="text/html" title="Efficient distributed representations with linear-time attention scores normalization" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Efficientdistributedrepresentationswithlineartimeattentionscoresnormalization</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Efficientdistributedrepresentationswithlineartimeattentionscoresnormalization.html">&lt;p&gt;The attention score matrix ${\rm SoftMax}(XY^T)$ encodes relational similarity patterns between objects and is extremely popular in machine learning. However, the complexity required to calculate it runs quadratically with the problem size, making it a computationally heavy solution. In this article, we propose a linear-time approximation of the attention score normalization constants for embedding vectors with bounded norms. We show on several pre-trained embeddings that the accuracy of our estimation formula surpasses competing kernel methods by even orders of magnitude. From this result, we design a linear-time and task-agnostic embedding algorithm based on the optimization of the attention scores. The proposed algorithm is highly interpretable and easily adapted to an arbitrary embedding problem. We consider a few use-cases and observe similar or higher performances and a lower computational time with respect to comparable embedding algorithms.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2303.17475&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Lorenzo Dall&apos;Amico, Enrico Maria Belliardo</name></author><category term="stat.ML" /><summary type="html">The attention score matrix ${\rm SoftMax}(XY^T)$ encodes relational similarity patterns between objects and is extremely popular in machine learning. However, the complexity required to calculate it runs quadratically with the problem size, making it a computationally heavy solution. In this article, we propose a linear-time approximation of the attention score normalization constants for embedding vectors with bounded norms. We show on several pre-trained embeddings that the accuracy of our estimation formula surpasses competing kernel methods by even orders of magnitude. From this result, we design a linear-time and task-agnostic embedding algorithm based on the optimization of the attention scores. The proposed algorithm is highly interpretable and easily adapted to an arbitrary embedding problem. We consider a few use-cases and observe similar or higher performances and a lower computational time with respect to comparable embedding algorithms.</summary></entry><entry><title type="html">Enhancing Preference-based Linear Bandits via Human Response Time</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/EnhancingPreferencebasedLinearBanditsviaHumanResponseTime.html" rel="alternate" type="text/html" title="Enhancing Preference-based Linear Bandits via Human Response Time" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/EnhancingPreferencebasedLinearBanditsviaHumanResponseTime</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/EnhancingPreferencebasedLinearBanditsviaHumanResponseTime.html">&lt;p&gt;Interactive preference learning systems present humans with queries as pairs of options; humans then select their preferred choice, allowing the system to infer preferences from these binary choices. While binary choice feedback is simple and widely used, it offers limited information about preference strength. To address this, we leverage human response times, which inversely correlate with preference strength, as complementary information. We introduce a computationally efficient method based on the EZ-diffusion model, combining choices and response times to estimate the underlying human utility function. Theoretical and empirical comparisons with traditional choice-only estimators show that for queries where humans have strong preferences (i.e., “easy” queries), response times provide valuable complementary information and enhance utility estimates. We integrate this estimator into preference-based linear bandits for fixed-budget best-arm identification. Simulations on three real-world datasets demonstrate that incorporating response times significantly accelerates preference learning.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2409.05798&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Shen Li, Yuyang Zhang, Zhaolin Ren, Claire Liang, Na Li, Julie A. Shah</name></author><category term="stat.ML" /><summary type="html">Interactive preference learning systems present humans with queries as pairs of options; humans then select their preferred choice, allowing the system to infer preferences from these binary choices. While binary choice feedback is simple and widely used, it offers limited information about preference strength. To address this, we leverage human response times, which inversely correlate with preference strength, as complementary information. We introduce a computationally efficient method based on the EZ-diffusion model, combining choices and response times to estimate the underlying human utility function. Theoretical and empirical comparisons with traditional choice-only estimators show that for queries where humans have strong preferences (i.e., “easy” queries), response times provide valuable complementary information and enhance utility estimates. We integrate this estimator into preference-based linear bandits for fixed-budget best-arm identification. Simulations on three real-world datasets demonstrate that incorporating response times significantly accelerates preference learning.</summary></entry><entry><title type="html">Equivariant Machine Learning on Graphs with Nonlinear Spectral Filters</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/EquivariantMachineLearningonGraphswithNonlinearSpectralFilters.html" rel="alternate" type="text/html" title="Equivariant Machine Learning on Graphs with Nonlinear Spectral Filters" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/EquivariantMachineLearningonGraphswithNonlinearSpectralFilters</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/EquivariantMachineLearningonGraphswithNonlinearSpectralFilters.html">&lt;p&gt;Equivariant machine learning is an approach for designing deep learning models that respect the symmetries of the problem, with the aim of reducing model complexity and improving generalization. In this paper, we focus on an extension of shift equivariance, which is the basis of convolution networks on images, to general graphs. Unlike images, graphs do not have a natural notion of domain translation. Therefore, we consider the graph functional shifts as the symmetry group: the unitary operators that commute with the graph shift operator. Notably, such symmetries operate in the signal space rather than directly in the spatial space. We remark that each linear filter layer of a standard spectral graph neural network (GNN) commutes with graph functional shifts, but the activation function breaks this symmetry. Instead, we propose nonlinear spectral filters (NLSFs) that are fully equivariant to graph functional shifts and show that they have universal approximation properties. The proposed NLSFs are based on a new form of spectral domain that is transferable between graphs. We demonstrate the superior performance of NLSFs over existing spectral GNNs in node and graph classification benchmarks.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.01249&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ya-Wei Eileen Lin, Ronen Talmon, Ron Levie</name></author><category term="stat.ML" /><summary type="html">Equivariant machine learning is an approach for designing deep learning models that respect the symmetries of the problem, with the aim of reducing model complexity and improving generalization. In this paper, we focus on an extension of shift equivariance, which is the basis of convolution networks on images, to general graphs. Unlike images, graphs do not have a natural notion of domain translation. Therefore, we consider the graph functional shifts as the symmetry group: the unitary operators that commute with the graph shift operator. Notably, such symmetries operate in the signal space rather than directly in the spatial space. We remark that each linear filter layer of a standard spectral graph neural network (GNN) commutes with graph functional shifts, but the activation function breaks this symmetry. Instead, we propose nonlinear spectral filters (NLSFs) that are fully equivariant to graph functional shifts and show that they have universal approximation properties. The proposed NLSFs are based on a new form of spectral domain that is transferable between graphs. We demonstrate the superior performance of NLSFs over existing spectral GNNs in node and graph classification benchmarks.</summary></entry><entry><title type="html">Estimation of uncertainties in the density driven flow in fractured porous media using MLMC</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/EstimationofuncertaintiesinthedensitydrivenflowinfracturedporousmediausingMLMC.html" rel="alternate" type="text/html" title="Estimation of uncertainties in the density driven flow in fractured porous media using MLMC" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/EstimationofuncertaintiesinthedensitydrivenflowinfracturedporousmediausingMLMC</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/EstimationofuncertaintiesinthedensitydrivenflowinfracturedporousmediausingMLMC.html">&lt;p&gt;We use the Multi Level Monte Carlo method to estimate uncertainties in a Henry-like salt water intrusion problem with a fracture. The flow is induced by the variation of the density of the fluid phase, which depends on the mass fraction of salt. We assume that the fracture has a known fixed location but an uncertain aperture. Other input uncertainties are the porosity and permeability fields and the recharge. In our setting, porosity and permeability vary spatially and recharge is time-dependent. For each realisation of these uncertain parameters, the evolution of the mass fraction and pressure fields is modelled by a system of non-linear and time-dependent PDEs with a jump of the solution at the fracture. The uncertainties propagate into the distribution of the salt concentration, which is an important characteristic of the quality of water resources. We show that the multilevel Monte Carlo (MLMC) method is able to reduce the overall computational cost compared to classical Monte Carlo methods. This is achieved by balancing discretisation and statistical errors. Multiple scenarios are evaluated at different spatial and temporal mesh levels. The deterministic solver ug4 is run in parallel to calculate all stochastic scenarios.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2404.18003&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Dmitry Logashenko, Alexander Litvinenko, Raul Tempone, Gabriel Wittum</name></author><category term="stat.CO" /><summary type="html">We use the Multi Level Monte Carlo method to estimate uncertainties in a Henry-like salt water intrusion problem with a fracture. The flow is induced by the variation of the density of the fluid phase, which depends on the mass fraction of salt. We assume that the fracture has a known fixed location but an uncertain aperture. Other input uncertainties are the porosity and permeability fields and the recharge. In our setting, porosity and permeability vary spatially and recharge is time-dependent. For each realisation of these uncertain parameters, the evolution of the mass fraction and pressure fields is modelled by a system of non-linear and time-dependent PDEs with a jump of the solution at the fracture. The uncertainties propagate into the distribution of the salt concentration, which is an important characteristic of the quality of water resources. We show that the multilevel Monte Carlo (MLMC) method is able to reduce the overall computational cost compared to classical Monte Carlo methods. This is achieved by balancing discretisation and statistical errors. Multiple scenarios are evaluated at different spatial and temporal mesh levels. The deterministic solver ug4 is run in parallel to calculate all stochastic scenarios.</summary></entry><entry><title type="html">Evolution of global inequality in well-being: A copula-based approach</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/EvolutionofglobalinequalityinwellbeingAcopulabasedapproach.html" rel="alternate" type="text/html" title="Evolution of global inequality in well-being: A copula-based approach" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/EvolutionofglobalinequalityinwellbeingAcopulabasedapproach</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/EvolutionofglobalinequalityinwellbeingAcopulabasedapproach.html">&lt;p&gt;We employ a flexible parametric model to estimate global income, health, and education distributions from 1980 to 2015. Using these marginal distributions within a copula-based framework, we construct a global joint distribution of well-being. This approach allows us to specifically analyze the impact of dependency structures on global well-being inequality. While inequality decreased in each individual dimension, our findings suggest that multidimensional inequality does not necessarily follow this trend. Its evolution is influenced by the interdependence among dimensions and the chosen inequality aversion parameter.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22892&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Koen Decancq, Vanesa Jorda</name></author><category term="stat.AP" /><summary type="html">We employ a flexible parametric model to estimate global income, health, and education distributions from 1980 to 2015. Using these marginal distributions within a copula-based framework, we construct a global joint distribution of well-being. This approach allows us to specifically analyze the impact of dependency structures on global well-being inequality. While inequality decreased in each individual dimension, our findings suggest that multidimensional inequality does not necessarily follow this trend. Its evolution is influenced by the interdependence among dimensions and the chosen inequality aversion parameter.</summary></entry><entry><title type="html">Extracting Mechanisms from Heterogeneous Effects: An Identification Strategy for Mediation Analysis</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ExtractingMechanismsfromHeterogeneousEffectsAnIdentificationStrategyforMediationAnalysis.html" rel="alternate" type="text/html" title="Extracting Mechanisms from Heterogeneous Effects: An Identification Strategy for Mediation Analysis" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ExtractingMechanismsfromHeterogeneousEffectsAnIdentificationStrategyforMediationAnalysis</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ExtractingMechanismsfromHeterogeneousEffectsAnIdentificationStrategyforMediationAnalysis.html">&lt;p&gt;Understanding causal mechanisms is crucial for explaining and generalizing empirical phenomena. Causal mediation analysis offers statistical techniques to quantify the mediation effects. However, current methods often require multiple ignorability assumptions or sophisticated research designs. In this paper, we introduce a novel identification strategy that enables the simultaneous identification and estimation of treatment and mediation effects. By combining explicit and implicit mediation analysis, this strategy exploits heterogeneous treatment effects through a new decomposition of total treatment effects. Monte Carlo simulations demonstrate that the method is more accurate and precise across various scenarios. To illustrate the efficiency and efficacy of our method, we apply it to estimate the causal mediation effects in two studies with distinct data structures, focusing on common pool resource governance and voting information. Additionally, we have developed statistical software to facilitate the implementation of our method.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2403.04131&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jiawei Fu</name></author><category term="stat.ME" /><summary type="html">Understanding causal mechanisms is crucial for explaining and generalizing empirical phenomena. Causal mediation analysis offers statistical techniques to quantify the mediation effects. However, current methods often require multiple ignorability assumptions or sophisticated research designs. In this paper, we introduce a novel identification strategy that enables the simultaneous identification and estimation of treatment and mediation effects. By combining explicit and implicit mediation analysis, this strategy exploits heterogeneous treatment effects through a new decomposition of total treatment effects. Monte Carlo simulations demonstrate that the method is more accurate and precise across various scenarios. To illustrate the efficiency and efficacy of our method, we apply it to estimate the causal mediation effects in two studies with distinct data structures, focusing on common pool resource governance and voting information. Additionally, we have developed statistical software to facilitate the implementation of our method.</summary></entry><entry><title type="html">FGCE: Feasible Group Counterfactual Explanations for Auditing Fairness</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/FGCEFeasibleGroupCounterfactualExplanationsforAuditingFairness.html" rel="alternate" type="text/html" title="FGCE: Feasible Group Counterfactual Explanations for Auditing Fairness" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/FGCEFeasibleGroupCounterfactualExplanationsforAuditingFairness</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/FGCEFeasibleGroupCounterfactualExplanationsforAuditingFairness.html">&lt;p&gt;This paper introduces the first graph-based framework for generating group counterfactual explanations to audit model fairness, a crucial aspect of trustworthy machine learning. Counterfactual explanations are instrumental in understanding and mitigating unfairness by revealing how inputs should change to achieve a desired outcome. Our framework, named Feasible Group Counterfactual Explanations (FGCEs), captures real-world feasibility constraints and constructs subgroups with similar counterfactuals, setting it apart from existing methods. It also addresses key trade-offs in counterfactual generation, including the balance between the number of counterfactuals, their associated costs, and the breadth of coverage achieved. To evaluate these trade-offs and assess fairness, we propose measures tailored to group counterfactual generation. Our experimental results on benchmark datasets demonstrate the effectiveness of our approach in managing feasibility constraints and trade-offs, as well as the potential of our proposed metrics in identifying and quantifying fairness issues.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22591&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Christos Fragkathoulas, Vasiliki Papanikou, Evaggelia Pitoura, Evimaria Terzi</name></author><category term="stat.ME" /><summary type="html">This paper introduces the first graph-based framework for generating group counterfactual explanations to audit model fairness, a crucial aspect of trustworthy machine learning. Counterfactual explanations are instrumental in understanding and mitigating unfairness by revealing how inputs should change to achieve a desired outcome. Our framework, named Feasible Group Counterfactual Explanations (FGCEs), captures real-world feasibility constraints and constructs subgroups with similar counterfactuals, setting it apart from existing methods. It also addresses key trade-offs in counterfactual generation, including the balance between the number of counterfactuals, their associated costs, and the breadth of coverage achieved. To evaluate these trade-offs and assess fairness, we propose measures tailored to group counterfactual generation. Our experimental results on benchmark datasets demonstrate the effectiveness of our approach in managing feasibility constraints and trade-offs, as well as the potential of our proposed metrics in identifying and quantifying fairness issues.</summary></entry><entry><title type="html">Fair Wasserstein Coresets</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/FairWassersteinCoresets.html" rel="alternate" type="text/html" title="Fair Wasserstein Coresets" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/FairWassersteinCoresets</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/FairWassersteinCoresets.html">&lt;p&gt;Data distillation and coresets have emerged as popular approaches to generate a smaller representative set of samples for downstream learning tasks to handle large-scale datasets. At the same time, machine learning is being increasingly applied to decision-making processes at a societal level, making it imperative for modelers to address inherent biases towards subgroups present in the data. While current approaches focus on creating fair synthetic representative samples by optimizing local properties relative to the original samples, their impact on downstream learning processes has yet to be explored. In this work, we present fair Wasserstein coresets (FWC), a novel coreset approach which generates fair synthetic representative samples along with sample-level weights to be used in downstream learning tasks. FWC uses an efficient majority minimization algorithm to minimize the Wasserstein distance between the original dataset and the weighted synthetic samples while enforcing demographic parity. We show that an unconstrained version of FWC is equivalent to Lloyd’s algorithm for k-medians and k-means clustering. Experiments conducted on both synthetic and real datasets show that FWC: (i) achieves a competitive fairness-utility tradeoff in downstream models compared to existing approaches, (ii) improves downstream fairness when added to the existing training data and (iii) can be used to reduce biases in predictions from large language models (GPT-3.5 and GPT-4).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2311.05436&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Zikai Xiong, Niccolò Dalmasso, Shubham Sharma, Freddy Lecue, Daniele Magazzeni, Vamsi K. Potluru, Tucker Balch, Manuela Veloso</name></author><category term="stat.ML" /><summary type="html">Data distillation and coresets have emerged as popular approaches to generate a smaller representative set of samples for downstream learning tasks to handle large-scale datasets. At the same time, machine learning is being increasingly applied to decision-making processes at a societal level, making it imperative for modelers to address inherent biases towards subgroups present in the data. While current approaches focus on creating fair synthetic representative samples by optimizing local properties relative to the original samples, their impact on downstream learning processes has yet to be explored. In this work, we present fair Wasserstein coresets (FWC), a novel coreset approach which generates fair synthetic representative samples along with sample-level weights to be used in downstream learning tasks. FWC uses an efficient majority minimization algorithm to minimize the Wasserstein distance between the original dataset and the weighted synthetic samples while enforcing demographic parity. We show that an unconstrained version of FWC is equivalent to Lloyd’s algorithm for k-medians and k-means clustering. Experiments conducted on both synthetic and real datasets show that FWC: (i) achieves a competitive fairness-utility tradeoff in downstream models compared to existing approaches, (ii) improves downstream fairness when added to the existing training data and (iii) can be used to reduce biases in predictions from large language models (GPT-3.5 and GPT-4).</summary></entry><entry><title type="html">Fast Signal Region Detection with Application to Whole Genome Association Studies</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/FastSignalRegionDetectionwithApplicationtoWholeGenomeAssociationStudies.html" rel="alternate" type="text/html" title="Fast Signal Region Detection with Application to Whole Genome Association Studies" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/FastSignalRegionDetectionwithApplicationtoWholeGenomeAssociationStudies</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/FastSignalRegionDetectionwithApplicationtoWholeGenomeAssociationStudies.html">&lt;p&gt;Research on the localization of the genetic basis associated with diseases or traits has been widely conducted in the last a few decades. Scan methods have been developed for region-based analysis in whole-genome association studies, helping us better understand how genetics influences human diseases or traits, especially when the aggregated effects of multiple causal variants are present. In this paper, we propose a fast and effective algorithm coupling with high-dimensional test for simultaneously detecting multiple signal regions, which is distinct from existing methods using scan or knockoff statistics. The idea is to conduct binary splitting with re-search and arrangement based on a sequence of dynamic critical values to increase detection accuracy and reduce computation. Theoretical and empirical studies demonstrate that our approach enjoys favorable theoretical guarantees with fewer restrictions and exhibits superior numerical performance with faster computation. Utilizing the UK Biobank data to identify the genetic regions related to breast cancer, we confirm previous findings and meanwhile, identify a number of new regions which suggest strong association with risk of breast cancer and deserve further investigation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2305.08172&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Wei Zhang, Fan Wang, Fang Yao</name></author><category term="stat.ME" /><summary type="html">Research on the localization of the genetic basis associated with diseases or traits has been widely conducted in the last a few decades. Scan methods have been developed for region-based analysis in whole-genome association studies, helping us better understand how genetics influences human diseases or traits, especially when the aggregated effects of multiple causal variants are present. In this paper, we propose a fast and effective algorithm coupling with high-dimensional test for simultaneously detecting multiple signal regions, which is distinct from existing methods using scan or knockoff statistics. The idea is to conduct binary splitting with re-search and arrangement based on a sequence of dynamic critical values to increase detection accuracy and reduce computation. Theoretical and empirical studies demonstrate that our approach enjoys favorable theoretical guarantees with fewer restrictions and exhibits superior numerical performance with faster computation. Utilizing the UK Biobank data to identify the genetic regions related to breast cancer, we confirm previous findings and meanwhile, identify a number of new regions which suggest strong association with risk of breast cancer and deserve further investigation.</summary></entry><entry><title type="html">Feature Responsiveness Scores: Model-Agnostic Explanations for Recourse</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/FeatureResponsivenessScoresModelAgnosticExplanationsforRecourse.html" rel="alternate" type="text/html" title="Feature Responsiveness Scores: Model-Agnostic Explanations for Recourse" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/FeatureResponsivenessScoresModelAgnosticExplanationsforRecourse</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/FeatureResponsivenessScoresModelAgnosticExplanationsforRecourse.html">&lt;p&gt;Machine learning models are often used to automate or support decisions in applications such as lending and hiring. In such settings, consumer protection rules mandate that we provide a list of “principal reasons” to consumers who receive adverse decisions. In practice, lenders and employers identify principal reasons by returning the top-scoring features from a feature attribution method. In this work, we study how such practices align with one of the underlying goals of consumer protection - recourse - i.e., educating individuals on how they can attain a desired outcome. We show that standard attribution methods can mislead individuals by highlighting reasons without recourse - i.e., by presenting consumers with features that cannot be changed to achieve recourse. We propose to address these issues by scoring features on the basis of responsiveness - i.e., the probability that an individual can attain a desired outcome by changing a specific feature. We develop efficient methods to compute responsiveness scores for any model and any dataset under complex actionability constraints. We present an extensive empirical study on the responsiveness of explanations in lending and demonstrate how responsiveness scores can be used to construct feature-highlighting explanations that lead to recourse and mitigate harm by flagging instances with fixed predictions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22598&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Seung Hyun Cheon, Anneke Wernerfelt, Sorelle A. Friedler, Berk Ustun</name></author><category term="stat.ML" /><summary type="html">Machine learning models are often used to automate or support decisions in applications such as lending and hiring. In such settings, consumer protection rules mandate that we provide a list of “principal reasons” to consumers who receive adverse decisions. In practice, lenders and employers identify principal reasons by returning the top-scoring features from a feature attribution method. In this work, we study how such practices align with one of the underlying goals of consumer protection - recourse - i.e., educating individuals on how they can attain a desired outcome. We show that standard attribution methods can mislead individuals by highlighting reasons without recourse - i.e., by presenting consumers with features that cannot be changed to achieve recourse. We propose to address these issues by scoring features on the basis of responsiveness - i.e., the probability that an individual can attain a desired outcome by changing a specific feature. We develop efficient methods to compute responsiveness scores for any model and any dataset under complex actionability constraints. We present an extensive empirical study on the responsiveness of explanations in lending and demonstrate how responsiveness scores can be used to construct feature-highlighting explanations that lead to recourse and mitigate harm by flagging instances with fixed predictions.</summary></entry><entry><title type="html">Federated UCBVI: Communication-Efficient Federated Regret Minimization with Heterogeneous Agents</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/FederatedUCBVICommunicationEfficientFederatedRegretMinimizationwithHeterogeneousAgents.html" rel="alternate" type="text/html" title="Federated UCBVI: Communication-Efficient Federated Regret Minimization with Heterogeneous Agents" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/FederatedUCBVICommunicationEfficientFederatedRegretMinimizationwithHeterogeneousAgents</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/FederatedUCBVICommunicationEfficientFederatedRegretMinimizationwithHeterogeneousAgents.html">&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;In this paper, we present the Federated Upper Confidence Bound Value Iteration algorithm ($\texttt{Fed-UCBVI}$), a novel extension of the $\texttt{UCBVI}$ algorithm (Azar et al., 2017) tailored for the federated learning framework. We prove that the regret of $\texttt{Fed-UCBVI}$ scales as $\tilde{\mathcal{O}}(\sqrt{H^3&lt;/td&gt;
      &lt;td&gt;\mathcal{S}&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;\mathcal{A}&lt;/td&gt;
      &lt;td&gt;T / M})$, with a small additional term due to heterogeneity, where $&lt;/td&gt;
      &lt;td&gt;\mathcal{S}&lt;/td&gt;
      &lt;td&gt;$ is the number of states, $&lt;/td&gt;
      &lt;td&gt;\mathcal{A}&lt;/td&gt;
      &lt;td&gt;$ is the number of actions, $H$ is the episode length, $M$ is the number of agents, and $T$ is the number of episodes. Notably, in the single-agent setting, this upper bound matches the minimax lower bound up to polylogarithmic factors, while in the multi-agent scenario, $\texttt{Fed-UCBVI}$ has linear speed-up. To conduct our analysis, we introduce a new measure of heterogeneity, which may hold independent theoretical interest. Furthermore, we show that, unlike existing federated reinforcement learning approaches, $\texttt{Fed-UCBVI}$’s communication complexity only marginally increases with the number of agents.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22908&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Safwan Labbi, Daniil Tiapkin, Lorenzo Mancini, Paul Mangold, Eric Moulines</name></author><category term="stat.ML" /><summary type="html">In this paper, we present the Federated Upper Confidence Bound Value Iteration algorithm ($\texttt{Fed-UCBVI}$), a novel extension of the $\texttt{UCBVI}$ algorithm (Azar et al., 2017) tailored for the federated learning framework. We prove that the regret of $\texttt{Fed-UCBVI}$ scales as $\tilde{\mathcal{O}}(\sqrt{H^3 \mathcal{S}   \mathcal{A} T / M})$, with a small additional term due to heterogeneity, where $ \mathcal{S} $ is the number of states, $ \mathcal{A} $ is the number of actions, $H$ is the episode length, $M$ is the number of agents, and $T$ is the number of episodes. Notably, in the single-agent setting, this upper bound matches the minimax lower bound up to polylogarithmic factors, while in the multi-agent scenario, $\texttt{Fed-UCBVI}$ has linear speed-up. To conduct our analysis, we introduce a new measure of heterogeneity, which may hold independent theoretical interest. Furthermore, we show that, unlike existing federated reinforcement learning approaches, $\texttt{Fed-UCBVI}$’s communication complexity only marginally increases with the number of agents.</summary></entry><entry><title type="html">Flow Matching for Posterior Inference with Simulator Feedback</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/FlowMatchingforPosteriorInferencewithSimulatorFeedback.html" rel="alternate" type="text/html" title="Flow Matching for Posterior Inference with Simulator Feedback" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/FlowMatchingforPosteriorInferencewithSimulatorFeedback</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/FlowMatchingforPosteriorInferencewithSimulatorFeedback.html">&lt;p&gt;Flow-based generative modeling is a powerful tool for solving inverse problems in physical sciences that can be used for sampling and likelihood evaluation with much lower inference times than traditional methods. We propose to refine flows with additional control signals based on a simulator. Control signals can include gradients and a problem-specific cost function if the simulator is differentiable, or they can be fully learned from the simulator output. In our proposed method, we pretrain the flow network and include feedback from the simulator exclusively for finetuning, therefore requiring only a small amount of additional parameters and compute. We motivate our design choices on several benchmark problems for simulation-based inference and evaluate flow matching with simulator feedback against classical MCMC methods for modeling strong gravitational lens systems, a challenging inverse problem in astronomy. We demonstrate that including feedback from the simulator improves the accuracy by $53\%$, making it competitive with traditional techniques while being up to $67$x faster for inference.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22573&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Benjamin Holzschuh, Nils Thuerey</name></author><category term="stat.ML" /><summary type="html">Flow-based generative modeling is a powerful tool for solving inverse problems in physical sciences that can be used for sampling and likelihood evaluation with much lower inference times than traditional methods. We propose to refine flows with additional control signals based on a simulator. Control signals can include gradients and a problem-specific cost function if the simulator is differentiable, or they can be fully learned from the simulator output. In our proposed method, we pretrain the flow network and include feedback from the simulator exclusively for finetuning, therefore requiring only a small amount of additional parameters and compute. We motivate our design choices on several benchmark problems for simulation-based inference and evaluate flow matching with simulator feedback against classical MCMC methods for modeling strong gravitational lens systems, a challenging inverse problem in astronomy. We demonstrate that including feedback from the simulator improves the accuracy by $53\%$, making it competitive with traditional techniques while being up to $67$x faster for inference.</summary></entry><entry><title type="html">FoLDTree: A ULDA-Based Decision Tree Framework for Efficient Oblique Splits and Feature Selection</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/FoLDTreeAULDABasedDecisionTreeFrameworkforEfficientObliqueSplitsandFeatureSelection.html" rel="alternate" type="text/html" title="FoLDTree: A ULDA-Based Decision Tree Framework for Efficient Oblique Splits and Feature Selection" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/FoLDTreeAULDABasedDecisionTreeFrameworkforEfficientObliqueSplitsandFeatureSelection</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/FoLDTreeAULDABasedDecisionTreeFrameworkforEfficientObliqueSplitsandFeatureSelection.html">&lt;p&gt;Traditional decision trees are limited by axis-orthogonal splits, which can perform poorly when true decision boundaries are oblique. While oblique decision tree methods address this limitation, they often face high computational costs, difficulties with multi-class classification, and a lack of effective feature selection. In this paper, we introduce LDATree and FoLDTree, two novel frameworks that integrate Uncorrelated Linear Discriminant Analysis (ULDA) and Forward ULDA into a decision tree structure. These methods enable efficient oblique splits, handle missing values, support feature selection, and provide both class labels and probabilities as model outputs. Through evaluations on simulated and real-world datasets, LDATree and FoLDTree consistently outperform axis-orthogonal and other oblique decision tree methods, achieving accuracy levels comparable to the random forest. The results highlight the potential of these frameworks as robust alternatives to traditional single-tree methods.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23147&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Siyu Wang</name></author><category term="stat.ME," /><category term="stat.ML" /><summary type="html">Traditional decision trees are limited by axis-orthogonal splits, which can perform poorly when true decision boundaries are oblique. While oblique decision tree methods address this limitation, they often face high computational costs, difficulties with multi-class classification, and a lack of effective feature selection. In this paper, we introduce LDATree and FoLDTree, two novel frameworks that integrate Uncorrelated Linear Discriminant Analysis (ULDA) and Forward ULDA into a decision tree structure. These methods enable efficient oblique splits, handle missing values, support feature selection, and provide both class labels and probabilities as model outputs. Through evaluations on simulated and real-world datasets, LDATree and FoLDTree consistently outperform axis-orthogonal and other oblique decision tree methods, achieving accuracy levels comparable to the random forest. The results highlight the potential of these frameworks as robust alternatives to traditional single-tree methods.</summary></entry><entry><title type="html">Functional Gradient Flows for Constrained Sampling</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/FunctionalGradientFlowsforConstrainedSampling.html" rel="alternate" type="text/html" title="Functional Gradient Flows for Constrained Sampling" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/FunctionalGradientFlowsforConstrainedSampling</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/FunctionalGradientFlowsforConstrainedSampling.html">&lt;p&gt;Recently, through a unified gradient flow perspective of Markov chain Monte Carlo (MCMC) and variational inference (VI), particle-based variational inference methods (ParVIs) have been proposed that tend to combine the best of both worlds. While typical ParVIs such as Stein Variational Gradient Descent (SVGD) approximate the gradient flow within a reproducing kernel Hilbert space (RKHS), many attempts have been made recently to replace RKHS with more expressive function spaces, such as neural networks. While successful, these methods are mainly designed for sampling from unconstrained domains. In this paper, we offer a general solution to constrained sampling by introducing a boundary condition for the gradient flow which would confine the particles within the specific domain. This allows us to propose a new functional gradient ParVI method for constrained sampling, called constrained functional gradient flow (CFG), with provable continuous-time convergence in total variation (TV). We also present novel numerical strategies to handle the boundary integral term arising from the domain constraints. Our theory and experiments demonstrate the effectiveness of the proposed framework.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23170&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Shiyue Zhang, Longlin Yu, Ziheng Cheng, Cheng Zhang</name></author><category term="stat.ML" /><summary type="html">Recently, through a unified gradient flow perspective of Markov chain Monte Carlo (MCMC) and variational inference (VI), particle-based variational inference methods (ParVIs) have been proposed that tend to combine the best of both worlds. While typical ParVIs such as Stein Variational Gradient Descent (SVGD) approximate the gradient flow within a reproducing kernel Hilbert space (RKHS), many attempts have been made recently to replace RKHS with more expressive function spaces, such as neural networks. While successful, these methods are mainly designed for sampling from unconstrained domains. In this paper, we offer a general solution to constrained sampling by introducing a boundary condition for the gradient flow which would confine the particles within the specific domain. This allows us to propose a new functional gradient ParVI method for constrained sampling, called constrained functional gradient flow (CFG), with provable continuous-time convergence in total variation (TV). We also present novel numerical strategies to handle the boundary integral term arising from the domain constraints. Our theory and experiments demonstrate the effectiveness of the proposed framework.</summary></entry><entry><title type="html">Fundamental properties of linear factor models</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Fundamentalpropertiesoflinearfactormodels.html" rel="alternate" type="text/html" title="Fundamental properties of linear factor models" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Fundamentalpropertiesoflinearfactormodels</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Fundamentalpropertiesoflinearfactormodels.html">&lt;p&gt;We study conditional linear factor models in the context of asset pricing panels. Our analysis focuses on conditional means and covariances to characterize the cross-sectional and inter-temporal properties of returns and factors as well as their interrelationships. We also review the conditions outlined in Kozak and Nagel (2024) and show how the conditional mean-variance efficient portfolio of an unbalanced panel can be spanned by low-dimensional factor portfolios, even without assuming invertibility of the conditional covariance matrices. Our analysis provides a comprehensive foundation for the specification and estimation of conditional linear factor models.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2409.02521&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Damir Filipovic, Paul Schneider</name></author><category term="stat.AP" /><summary type="html">We study conditional linear factor models in the context of asset pricing panels. Our analysis focuses on conditional means and covariances to characterize the cross-sectional and inter-temporal properties of returns and factors as well as their interrelationships. We also review the conditions outlined in Kozak and Nagel (2024) and show how the conditional mean-variance efficient portfolio of an unbalanced panel can be spanned by low-dimensional factor portfolios, even without assuming invertibility of the conditional covariance matrices. Our analysis provides a comprehensive foundation for the specification and estimation of conditional linear factor models.</summary></entry><entry><title type="html">Fusion of Movement and Naive Predictions for Point Forecasting in Univariate Random Walks</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/FusionofMovementandNaivePredictionsforPointForecastinginUnivariateRandomWalks.html" rel="alternate" type="text/html" title="Fusion of Movement and Naive Predictions for Point Forecasting in Univariate Random Walks" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/FusionofMovementandNaivePredictionsforPointForecastinginUnivariateRandomWalks</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/FusionofMovementandNaivePredictionsforPointForecastinginUnivariateRandomWalks.html">&lt;p&gt;Point forecasting in univariate random walks is an important yet challenging research topic. Many attempts at this task often fail to surpass the na&quot;ive baseline because of the randomness of the data and the improper utilization of exogenous variables as features. In view of the limitations of existing random walk forecasting methods, this study introduces a variant definition of random walks, proposing that point forecasting can be improved beyond the na&quot;ive baseline through the fusion of movement and na&quot;ive predictions (FMNP). FMNP naturally bridges movement prediction and point forecasting. It employs an exogenous variable to provide a consistent movement prediction for the target variable and uses a linear regression to combine movement and na&quot;ive predictions. In forecasting five financial time series in the U.S. market with the FTSE opening price as the exogenous variable, FMNP consistently outperforms na&quot;ive baselines and is superior to baseline models such as ARIMA, MA, MLP, DNN, LSTM, and CNN-LSTM. FMNP is particularly advantageous when accurate point predictions are challenging but accurate movement predictions are attainable, translating movement predictions into point forecasts in random walk contexts.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.14469&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Cheng Zhang</name></author><category term="stat.ML" /><summary type="html">Point forecasting in univariate random walks is an important yet challenging research topic. Many attempts at this task often fail to surpass the na&quot;ive baseline because of the randomness of the data and the improper utilization of exogenous variables as features. In view of the limitations of existing random walk forecasting methods, this study introduces a variant definition of random walks, proposing that point forecasting can be improved beyond the na&quot;ive baseline through the fusion of movement and na&quot;ive predictions (FMNP). FMNP naturally bridges movement prediction and point forecasting. It employs an exogenous variable to provide a consistent movement prediction for the target variable and uses a linear regression to combine movement and na&quot;ive predictions. In forecasting five financial time series in the U.S. market with the FTSE opening price as the exogenous variable, FMNP consistently outperforms na&quot;ive baselines and is superior to baseline models such as ARIMA, MA, MLP, DNN, LSTM, and CNN-LSTM. FMNP is particularly advantageous when accurate point predictions are challenging but accurate movement predictions are attainable, translating movement predictions into point forecasts in random walk contexts.</summary></entry><entry><title type="html">Gaussian process-based online health monitoring and fault analysis of lithium-ion battery systems from field data</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Gaussianprocessbasedonlinehealthmonitoringandfaultanalysisoflithiumionbatterysystemsfromfielddata.html" rel="alternate" type="text/html" title="Gaussian process-based online health monitoring and fault analysis of lithium-ion battery systems from field data" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Gaussianprocessbasedonlinehealthmonitoringandfaultanalysisoflithiumionbatterysystemsfromfielddata</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Gaussianprocessbasedonlinehealthmonitoringandfaultanalysisoflithiumionbatterysystemsfromfielddata.html">&lt;p&gt;Health monitoring, fault analysis, and detection are critical for the safe and sustainable operation of battery systems. We apply Gaussian process resistance models on lithium iron phosphate battery field data to effectively separate the time-dependent and operating point-dependent resistance. The data set contains 29 battery systems returned to the manufacturer for warranty, each with eight cells in series, totaling 232 cells and 131 million data rows. We develop probabilistic fault detection rules using recursive spatiotemporal Gaussian processes. These processes allow the quick processing of over a million data points, enabling advanced online monitoring and furthering the understanding of battery pack failure in the field. The analysis underlines that often, only a single cell shows abnormal behavior or a knee point, consistent with weakest-link failure for cells connected in series, amplified by local resistive heating. The results further the understanding of how batteries degrade and fail in the field and demonstrate the potential of efficient online monitoring based on data. We open-source the code and publish the large data set upon completion of the review of this article.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.19015&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Joachim Schaeffer, Eric Lenz, Duncan Gulla, Martin Z. Bazant, Richard D. Braatz, Rolf Findeisen</name></author><category term="stat.AP" /><summary type="html">Health monitoring, fault analysis, and detection are critical for the safe and sustainable operation of battery systems. We apply Gaussian process resistance models on lithium iron phosphate battery field data to effectively separate the time-dependent and operating point-dependent resistance. The data set contains 29 battery systems returned to the manufacturer for warranty, each with eight cells in series, totaling 232 cells and 131 million data rows. We develop probabilistic fault detection rules using recursive spatiotemporal Gaussian processes. These processes allow the quick processing of over a million data points, enabling advanced online monitoring and furthering the understanding of battery pack failure in the field. The analysis underlines that often, only a single cell shows abnormal behavior or a knee point, consistent with weakest-link failure for cells connected in series, amplified by local resistive heating. The results further the understanding of how batteries degrade and fail in the field and demonstrate the potential of efficient online monitoring based on data. We open-source the code and publish the large data set upon completion of the review of this article.</summary></entry><entry><title type="html">Gender disparities in rehospitalisations after coronary artery bypass grafting: evidence from a functional causal mediation analysis of the MIMIC-IV data</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/GenderdisparitiesinrehospitalisationsaftercoronaryarterybypassgraftingevidencefromafunctionalcausalmediationanalysisoftheMIMICIVdata.html" rel="alternate" type="text/html" title="Gender disparities in rehospitalisations after coronary artery bypass grafting: evidence from a functional causal mediation analysis of the MIMIC-IV data" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/GenderdisparitiesinrehospitalisationsaftercoronaryarterybypassgraftingevidencefromafunctionalcausalmediationanalysisoftheMIMICIVdata</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/GenderdisparitiesinrehospitalisationsaftercoronaryarterybypassgraftingevidencefromafunctionalcausalmediationanalysisoftheMIMICIVdata.html">&lt;p&gt;Hospital readmissions following coronary artery bypass grafting (CABG) not only impose a substantial cost burden on healthcare systems but also serve as a potential indicator of the quality of medical care. Previous studies of gender effects on complications after CABG surgery have consistently revealed that women tend to suffer worse outcomes. To better understand the causal pathway from gender to the number of rehospitalisations, we study the postoperative central venous pressure (CVP), frequently recorded over patients’ intensive care unit (ICU) stay after the CABG surgery, as a functional mediator. Confronted with time-varying CVP measurements and zero-inflated rehospitalisation counts within 60 days following discharge, we propose a parameter-simulating quasi-Bayesian Monte Carlo approximation method that accommodates a functional mediator and a zero-inflated count outcome for causal mediation analysis. We find a causal relationship between the female gender and increased rehospitalisation counts after CABG, and that time-varying central venous pressure mediates this causal effect.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22502&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Henan Xu, Yeying Zhu, Donna L. Coffman</name></author><category term="stat.AP," /><category term="stat.ME" /><summary type="html">Hospital readmissions following coronary artery bypass grafting (CABG) not only impose a substantial cost burden on healthcare systems but also serve as a potential indicator of the quality of medical care. Previous studies of gender effects on complications after CABG surgery have consistently revealed that women tend to suffer worse outcomes. To better understand the causal pathway from gender to the number of rehospitalisations, we study the postoperative central venous pressure (CVP), frequently recorded over patients’ intensive care unit (ICU) stay after the CABG surgery, as a functional mediator. Confronted with time-varying CVP measurements and zero-inflated rehospitalisation counts within 60 days following discharge, we propose a parameter-simulating quasi-Bayesian Monte Carlo approximation method that accommodates a functional mediator and a zero-inflated count outcome for causal mediation analysis. We find a causal relationship between the female gender and increased rehospitalisation counts after CABG, and that time-varying central venous pressure mediates this causal effect.</summary></entry><entry><title type="html">General Bayesian quantile regression for counts via generative modeling</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/GeneralBayesianquantileregressionforcountsviagenerativemodeling.html" rel="alternate" type="text/html" title="General Bayesian quantile regression for counts via generative modeling" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/GeneralBayesianquantileregressionforcountsviagenerativemodeling</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/GeneralBayesianquantileregressionforcountsviagenerativemodeling.html">&lt;p&gt;Although quantile regression has emerged as a powerful tool for understanding various quantiles of a response variable conditioned on a set of covariates, the development of quantile regression for count responses has received far less attention. This paper proposes a new Bayesian approach to quantile regression for count data, which provides a more flexible and interpretable alternative to the existing approaches. The proposed approach associates the continuous latent variable with the discrete response and nonparametrically estimates the joint distribution of the latent variable and a set of covariates. Then, by regressing the estimated continuous conditional quantile on the covariates, the posterior distributions of the covariate effects on the conditional quantiles are obtained through general Bayesian updating via simple optimization. The simulation study and real data analysis demonstrate that the proposed method overcomes the existing limitations and enhances quantile estimation and interpretation of variable relationships, making it a valuable tool for practitioners handling count data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23081&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yuta Yamauchi, Genya Kobayashi, Shonosuke Sugasawa</name></author><category term="stat.ME" /><summary type="html">Although quantile regression has emerged as a powerful tool for understanding various quantiles of a response variable conditioned on a set of covariates, the development of quantile regression for count responses has received far less attention. This paper proposes a new Bayesian approach to quantile regression for count data, which provides a more flexible and interpretable alternative to the existing approaches. The proposed approach associates the continuous latent variable with the discrete response and nonparametrically estimates the joint distribution of the latent variable and a set of covariates. Then, by regressing the estimated continuous conditional quantile on the covariates, the posterior distributions of the covariate effects on the conditional quantiles are obtained through general Bayesian updating via simple optimization. The simulation study and real data analysis demonstrate that the proposed method overcomes the existing limitations and enhances quantile estimation and interpretation of variable relationships, making it a valuable tool for practitioners handling count data.</summary></entry><entry><title type="html">Generalization Bounds via Conditional $f$-Information</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/GeneralizationBoundsviaConditionalfInformation.html" rel="alternate" type="text/html" title="Generalization Bounds via Conditional $f$-Information" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/GeneralizationBoundsviaConditionalfInformation</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/GeneralizationBoundsviaConditionalfInformation.html">&lt;p&gt;In this work, we introduce novel information-theoretic generalization bounds using the conditional $f$-information framework, an extension of the traditional conditional mutual information (MI) framework. We provide a generic approach to derive generalization bounds via $f$-information in the supersample setting, applicable to both bounded and unbounded loss functions. Unlike previous MI-based bounds, our proof strategy does not rely on upper bounding the cumulant-generating function (CGF) in the variational formula of MI. Instead, we set the CGF or its upper bound to zero by carefully selecting the measurable function invoked in the variational formula. Although some of our techniques are partially inspired by recent advances in the coin-betting framework (e.g., Jang et al. (2023)), our results are independent of any previous findings from regret guarantees of online gambling algorithms. Additionally, our newly derived MI-based bound recovers many previous results and improves our understanding of their potential limitations. Finally, we empirically compare various $f$-information measures for generalization, demonstrating the improvement of our new bounds over the previous bounds.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22887&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ziqiao Wang, Yongyi Mao</name></author><category term="stat.ML" /><summary type="html">In this work, we introduce novel information-theoretic generalization bounds using the conditional $f$-information framework, an extension of the traditional conditional mutual information (MI) framework. We provide a generic approach to derive generalization bounds via $f$-information in the supersample setting, applicable to both bounded and unbounded loss functions. Unlike previous MI-based bounds, our proof strategy does not rely on upper bounding the cumulant-generating function (CGF) in the variational formula of MI. Instead, we set the CGF or its upper bound to zero by carefully selecting the measurable function invoked in the variational formula. Although some of our techniques are partially inspired by recent advances in the coin-betting framework (e.g., Jang et al. (2023)), our results are independent of any previous findings from regret guarantees of online gambling algorithms. Additionally, our newly derived MI-based bound recovers many previous results and improves our understanding of their potential limitations. Finally, we empirically compare various $f$-information measures for generalization, demonstrating the improvement of our new bounds over the previous bounds.</summary></entry><entry><title type="html">Graph Integration for Diffusion-Based Manifold Alignment</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/GraphIntegrationforDiffusionBasedManifoldAlignment.html" rel="alternate" type="text/html" title="Graph Integration for Diffusion-Based Manifold Alignment" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/GraphIntegrationforDiffusionBasedManifoldAlignment</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/GraphIntegrationforDiffusionBasedManifoldAlignment.html">&lt;p&gt;Data from individual observations can originate from various sources or modalities but are often intrinsically linked. Multimodal data integration can enrich information content compared to single-source data. Manifold alignment is a form of data integration that seeks a shared, underlying low-dimensional representation of multiple data sources that emphasizes similarities between alternative representations of the same entities. Semi-supervised manifold alignment relies on partially known correspondences between domains, either through shared features or through other known associations. In this paper, we introduce two semi-supervised manifold alignment methods. The first method, Shortest Paths on the Union of Domains (SPUD), forms a unified graph structure using known correspondences to establish graph edges. By learning inter-domain geodesic distances, SPUD creates a global, multi-domain structure. The second method, MASH (Manifold Alignment via Stochastic Hopping), learns local geometry within each domain and forms a joint diffusion operator using known correspondences to iteratively learn new inter-domain correspondences through a random-walk approach. Through the diffusion process, MASH forms a coupling matrix that links heterogeneous domains into a unified structure. We compare SPUD and MASH with existing semi-supervised manifold alignment methods and show that they outperform competing methods in aligning true correspondences and cross-domain classification. In addition, we show how these methods can be applied to transfer label information between domains.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22978&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jake S. Rhodes, Adam G. Rustad</name></author><category term="stat.ML" /><summary type="html">Data from individual observations can originate from various sources or modalities but are often intrinsically linked. Multimodal data integration can enrich information content compared to single-source data. Manifold alignment is a form of data integration that seeks a shared, underlying low-dimensional representation of multiple data sources that emphasizes similarities between alternative representations of the same entities. Semi-supervised manifold alignment relies on partially known correspondences between domains, either through shared features or through other known associations. In this paper, we introduce two semi-supervised manifold alignment methods. The first method, Shortest Paths on the Union of Domains (SPUD), forms a unified graph structure using known correspondences to establish graph edges. By learning inter-domain geodesic distances, SPUD creates a global, multi-domain structure. The second method, MASH (Manifold Alignment via Stochastic Hopping), learns local geometry within each domain and forms a joint diffusion operator using known correspondences to iteratively learn new inter-domain correspondences through a random-walk approach. Through the diffusion process, MASH forms a coupling matrix that links heterogeneous domains into a unified structure. We compare SPUD and MASH with existing semi-supervised manifold alignment methods and show that they outperform competing methods in aligning true correspondences and cross-domain classification. In addition, we show how these methods can be applied to transfer label information between domains.</summary></entry><entry><title type="html">Hyperparameter Optimization in Machine Learning</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/HyperparameterOptimizationinMachineLearning.html" rel="alternate" type="text/html" title="Hyperparameter Optimization in Machine Learning" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/HyperparameterOptimizationinMachineLearning</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/HyperparameterOptimizationinMachineLearning.html">&lt;p&gt;Hyperparameters are configuration variables controlling the behavior of machine learning algorithms. They are ubiquitous in machine learning and artificial intelligence and the choice of their values determine the effectiveness of systems based on these technologies. Manual hyperparameter search is often unsatisfactory and becomes unfeasible when the number of hyperparameters is large. Automating the search is an important step towards automating machine learning, freeing researchers and practitioners alike from the burden of finding a good set of hyperparameters by trial and error. In this survey, we present a unified treatment of hyperparameter optimization, providing the reader with examples and insights into the state-of-the-art. We cover the main families of techniques to automate hyperparameter search, often referred to as hyperparameter optimization or tuning, including random and quasi-random search, bandit-, model- and gradient- based approaches. We further discuss extensions, including online, constrained, and multi-objective formulations, touch upon connections with other fields such as meta-learning and neural architecture search, and conclude with open questions and future research directions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22854&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Luca Franceschi, Michele Donini, Valerio Perrone, Aaron Klein, Cédric Archambeau, Matthias Seeger, Massimiliano Pontil, Paolo Frasconi</name></author><category term="stat.ML" /><summary type="html">Hyperparameters are configuration variables controlling the behavior of machine learning algorithms. They are ubiquitous in machine learning and artificial intelligence and the choice of their values determine the effectiveness of systems based on these technologies. Manual hyperparameter search is often unsatisfactory and becomes unfeasible when the number of hyperparameters is large. Automating the search is an important step towards automating machine learning, freeing researchers and practitioners alike from the burden of finding a good set of hyperparameters by trial and error. In this survey, we present a unified treatment of hyperparameter optimization, providing the reader with examples and insights into the state-of-the-art. We cover the main families of techniques to automate hyperparameter search, often referred to as hyperparameter optimization or tuning, including random and quasi-random search, bandit-, model- and gradient- based approaches. We further discuss extensions, including online, constrained, and multi-objective formulations, touch upon connections with other fields such as meta-learning and neural architecture search, and conclude with open questions and future research directions.</summary></entry><entry><title type="html">Identifiability Analysis of Linear ODE Systems with Hidden Confounders</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/IdentifiabilityAnalysisofLinearODESystemswithHiddenConfounders.html" rel="alternate" type="text/html" title="Identifiability Analysis of Linear ODE Systems with Hidden Confounders" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/IdentifiabilityAnalysisofLinearODESystemswithHiddenConfounders</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/IdentifiabilityAnalysisofLinearODESystemswithHiddenConfounders.html">&lt;p&gt;The identifiability analysis of linear Ordinary Differential Equation (ODE) systems is a necessary prerequisite for making reliable causal inferences about these systems. While identifiability has been well studied in scenarios where the system is fully observable, the conditions for identifiability remain unexplored when latent variables interact with the system. This paper aims to address this gap by presenting a systematic analysis of identifiability in linear ODE systems incorporating hidden confounders. Specifically, we investigate two cases of such systems. In the first case, latent confounders exhibit no causal relationships, yet their evolution adheres to specific functional forms, such as polynomial functions of time $t$. Subsequently, we extend this analysis to encompass scenarios where hidden confounders exhibit causal dependencies, with the causal structure of latent variables described by a Directed Acyclic Graph (DAG). The second case represents a more intricate variation of the first case, prompting a more comprehensive identifiability analysis. Accordingly, we conduct detailed identifiability analyses of the second system under various observation conditions, including both continuous and discrete observations from single or multiple trajectories. To validate our theoretical results, we perform a series of simulations, which support and substantiate our findings.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21917&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yuanyuan Wang, Biwei Huang, Wei Huang, Xi Geng, Mingming Gong</name></author><category term="stat.ML" /><summary type="html">The identifiability analysis of linear Ordinary Differential Equation (ODE) systems is a necessary prerequisite for making reliable causal inferences about these systems. While identifiability has been well studied in scenarios where the system is fully observable, the conditions for identifiability remain unexplored when latent variables interact with the system. This paper aims to address this gap by presenting a systematic analysis of identifiability in linear ODE systems incorporating hidden confounders. Specifically, we investigate two cases of such systems. In the first case, latent confounders exhibit no causal relationships, yet their evolution adheres to specific functional forms, such as polynomial functions of time $t$. Subsequently, we extend this analysis to encompass scenarios where hidden confounders exhibit causal dependencies, with the causal structure of latent variables described by a Directed Acyclic Graph (DAG). The second case represents a more intricate variation of the first case, prompting a more comprehensive identifiability analysis. Accordingly, we conduct detailed identifiability analyses of the second system under various observation conditions, including both continuous and discrete observations from single or multiple trajectories. To validate our theoretical results, we perform a series of simulations, which support and substantiate our findings.</summary></entry><entry><title type="html">Identifying Drift, Diffusion, and Causal Structure from Temporal Snapshots</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/IdentifyingDriftDiffusionandCausalStructurefromTemporalSnapshots.html" rel="alternate" type="text/html" title="Identifying Drift, Diffusion, and Causal Structure from Temporal Snapshots" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/IdentifyingDriftDiffusionandCausalStructurefromTemporalSnapshots</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/IdentifyingDriftDiffusionandCausalStructurefromTemporalSnapshots.html">&lt;p&gt;Stochastic differential equations (SDEs) are a fundamental tool for modelling dynamic processes, including gene regulatory networks (GRNs), contaminant transport, financial markets, and image generation. However, learning the underlying SDE from observational data is a challenging task, especially when individual trajectories are not observable. Motivated by burgeoning research in single-cell datasets, we present the first comprehensive approach for jointly estimating the drift and diffusion of an SDE from its temporal marginals. Assuming linear drift and additive diffusion, we prove that these parameters are identifiable from marginals if and only if the initial distribution is not invariant to a class of generalized rotations, a condition that is satisfied by most distributions. We further prove that the causal graph of any SDE with additive diffusion can be recovered from the SDE parameters. To complement this theory, we adapt entropy-regularized optimal transport to handle anisotropic diffusion, and introduce APPEX (Alternating Projection Parameter Estimation from $X_0$), an iterative algorithm designed to estimate the drift, diffusion, and causal graph of an additive noise SDE, solely from temporal marginals. We show that each of these steps are asymptotically optimal with respect to the Kullback-Leibler divergence, and demonstrate APPEX’s effectiveness on simulated data from linear additive noise SDEs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22729&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Vincent Guan, Joseph Janssen, Hossein Rahmani, Andrew Warren, Stephen Zhang, Elina Robeva, Geoffrey Schiebinger</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">Stochastic differential equations (SDEs) are a fundamental tool for modelling dynamic processes, including gene regulatory networks (GRNs), contaminant transport, financial markets, and image generation. However, learning the underlying SDE from observational data is a challenging task, especially when individual trajectories are not observable. Motivated by burgeoning research in single-cell datasets, we present the first comprehensive approach for jointly estimating the drift and diffusion of an SDE from its temporal marginals. Assuming linear drift and additive diffusion, we prove that these parameters are identifiable from marginals if and only if the initial distribution is not invariant to a class of generalized rotations, a condition that is satisfied by most distributions. We further prove that the causal graph of any SDE with additive diffusion can be recovered from the SDE parameters. To complement this theory, we adapt entropy-regularized optimal transport to handle anisotropic diffusion, and introduce APPEX (Alternating Projection Parameter Estimation from $X_0$), an iterative algorithm designed to estimate the drift, diffusion, and causal graph of an additive noise SDE, solely from temporal marginals. We show that each of these steps are asymptotically optimal with respect to the Kullback-Leibler divergence, and demonstrate APPEX’s effectiveness on simulated data from linear additive noise SDEs.</summary></entry><entry><title type="html">Improved Particle Approximation Error for Mean Field Neural Networks</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ImprovedParticleApproximationErrorforMeanFieldNeuralNetworks.html" rel="alternate" type="text/html" title="Improved Particle Approximation Error for Mean Field Neural Networks" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ImprovedParticleApproximationErrorforMeanFieldNeuralNetworks</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ImprovedParticleApproximationErrorforMeanFieldNeuralNetworks.html">&lt;p&gt;Mean-field Langevin dynamics (MFLD) minimizes an entropy-regularized nonlinear convex functional defined over the space of probability distributions. MFLD has gained attention due to its connection with noisy gradient descent for mean-field two-layer neural networks. Unlike standard Langevin dynamics, the nonlinearity of the objective functional induces particle interactions, necessitating multiple particles to approximate the dynamics in a finite-particle setting. Recent works (Chen et al., 2022; Suzuki et al., 2023b) have demonstrated the uniform-in-time propagation of chaos for MFLD, showing that the gap between the particle system and its mean-field limit uniformly shrinks over time as the number of particles increases. In this work, we improve the dependence on logarithmic Sobolev inequality (LSI) constants in their particle approximation errors, which can exponentially deteriorate with the regularization coefficient. Specifically, we establish an LSI-constant-free particle approximation error concerning the objective gap by leveraging the problem structure in risk minimization. As the application, we demonstrate improved convergence of MFLD, sampling guarantee for the mean-field stationary distribution, and uniform-in-time Wasserstein propagation of chaos in terms of particle complexity.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.15767&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Atsushi Nitanda</name></author><category term="stat.ML" /><summary type="html">Mean-field Langevin dynamics (MFLD) minimizes an entropy-regularized nonlinear convex functional defined over the space of probability distributions. MFLD has gained attention due to its connection with noisy gradient descent for mean-field two-layer neural networks. Unlike standard Langevin dynamics, the nonlinearity of the objective functional induces particle interactions, necessitating multiple particles to approximate the dynamics in a finite-particle setting. Recent works (Chen et al., 2022; Suzuki et al., 2023b) have demonstrated the uniform-in-time propagation of chaos for MFLD, showing that the gap between the particle system and its mean-field limit uniformly shrinks over time as the number of particles increases. In this work, we improve the dependence on logarithmic Sobolev inequality (LSI) constants in their particle approximation errors, which can exponentially deteriorate with the regularization coefficient. Specifically, we establish an LSI-constant-free particle approximation error concerning the objective gap by leveraging the problem structure in risk minimization. As the application, we demonstrate improved convergence of MFLD, sampling guarantee for the mean-field stationary distribution, and uniform-in-time Wasserstein propagation of chaos in terms of particle complexity.</summary></entry><entry><title type="html">Improved convergence rate of kNN graph Laplacians</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ImprovedconvergencerateofkNNgraphLaplacians.html" rel="alternate" type="text/html" title="Improved convergence rate of kNN graph Laplacians" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ImprovedconvergencerateofkNNgraphLaplacians</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ImprovedconvergencerateofkNNgraphLaplacians.html">&lt;p&gt;In graph-based data analysis, $k$-nearest neighbor ($k$NN) graphs are widely used due to their adaptivity to local data densities. Allowing weighted edges in the graph, the kernelized graph affinity provides a more general type of $k$NN graph where the $k$NN distance is used to set the kernel bandwidth adaptively. In this work, we consider a general class of $k$NN graph where the graph affinity is $W_{ij} = \epsilon^{-d/2} \; k_0 ( | x_i - x_j |^2 / \epsilon \phi( \widehat{\rho}(x_i), \widehat{\rho}(x_j) )^2 ) $, with $\widehat{\rho}(x)$ being the (rescaled) $k$NN distance at the point $x$, $\phi$ a symmetric bi-variate function, and $k_0$ a non-negative function on $[0,\infty)$. Under the manifold data setting, where $N$ i.i.d. samples $x_i$ are drawn from a density $p$ on a $d$-dimensional unknown manifold embedded in a high dimensional Euclidean space, we prove the point-wise convergence of the $k$NN graph Laplacian to the limiting manifold operator (depending on $p$) at the rate of $O(N^{-2/(d+6)}\,)$, up to a log factor, when $k_0$ and $\phi$ have $C^3$ regularity and satisfy other technical conditions. This fast rate is obtained when $\epsilon \sim N^{-2/(d+6)}\,$ and $k \sim N^{6/(d+6)}\,$, both at the optimal order to balance the theoretical bias and variance errors. When $k_0$ and $\phi$ have lower regularities, including when $k_0$ is a compactly supported function as in the standard $k$NN graph, the convergence rate degenerates to $O(N^{-1/(d+4)}\,)$. Our improved convergence rate is based on a refined analysis of the $k$NN estimator, which can be of independent interest. We validate our theory by numerical experiments on simulated data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23212&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yixuan Tan, Xiuyuan Cheng</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">In graph-based data analysis, $k$-nearest neighbor ($k$NN) graphs are widely used due to their adaptivity to local data densities. Allowing weighted edges in the graph, the kernelized graph affinity provides a more general type of $k$NN graph where the $k$NN distance is used to set the kernel bandwidth adaptively. In this work, we consider a general class of $k$NN graph where the graph affinity is $W_{ij} = \epsilon^{-d/2} \; k_0 ( | x_i - x_j |^2 / \epsilon \phi( \widehat{\rho}(x_i), \widehat{\rho}(x_j) )^2 ) $, with $\widehat{\rho}(x)$ being the (rescaled) $k$NN distance at the point $x$, $\phi$ a symmetric bi-variate function, and $k_0$ a non-negative function on $[0,\infty)$. Under the manifold data setting, where $N$ i.i.d. samples $x_i$ are drawn from a density $p$ on a $d$-dimensional unknown manifold embedded in a high dimensional Euclidean space, we prove the point-wise convergence of the $k$NN graph Laplacian to the limiting manifold operator (depending on $p$) at the rate of $O(N^{-2/(d+6)}\,)$, up to a log factor, when $k_0$ and $\phi$ have $C^3$ regularity and satisfy other technical conditions. This fast rate is obtained when $\epsilon \sim N^{-2/(d+6)}\,$ and $k \sim N^{6/(d+6)}\,$, both at the optimal order to balance the theoretical bias and variance errors. When $k_0$ and $\phi$ have lower regularities, including when $k_0$ is a compactly supported function as in the standard $k$NN graph, the convergence rate degenerates to $O(N^{-1/(d+4)}\,)$. Our improved convergence rate is based on a refined analysis of the $k$NN estimator, which can be of independent interest. We validate our theory by numerical experiments on simulated data.</summary></entry><entry><title type="html">Improving Generalization and Convergence by Enhancing Implicit Regularization</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ImprovingGeneralizationandConvergencebyEnhancingImplicitRegularization.html" rel="alternate" type="text/html" title="Improving Generalization and Convergence by Enhancing Implicit Regularization" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ImprovingGeneralizationandConvergencebyEnhancingImplicitRegularization</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ImprovingGeneralizationandConvergencebyEnhancingImplicitRegularization.html">&lt;p&gt;In this work, we propose an Implicit Regularization Enhancement (IRE) framework to accelerate the discovery of flat solutions in deep learning, thereby improving generalization and convergence. Specifically, IRE decouples the dynamics of flat and sharp directions, which boosts the sharpness reduction along flat directions while maintaining the training stability in sharp directions. We show that IRE can be practically incorporated with {\em generic base optimizers} without introducing significant computational overload. Experiments show that IRE consistently improves the generalization performance for image classification tasks across a variety of benchmark datasets (CIFAR-10/100, ImageNet) and models (ResNets and ViTs). Surprisingly, IRE also achieves a $2\times$ {\em speed-up} compared to AdamW in the pre-training of Llama models (of sizes ranging from 60M to 229M) on datasets including Wikitext-103, Minipile, and Openwebtext. Moreover, we provide theoretical guarantees, showing that IRE can substantially accelerate the convergence towards flat minima in Sharpness-aware Minimization (SAM).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.20763&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Mingze Wang, Jinbo Wang, Haotian He, Zilin Wang, Guanhua Huang, Feiyu Xiong, Zhiyu Li, Weinan E, Lei Wu</name></author><category term="stat.ML" /><summary type="html">In this work, we propose an Implicit Regularization Enhancement (IRE) framework to accelerate the discovery of flat solutions in deep learning, thereby improving generalization and convergence. Specifically, IRE decouples the dynamics of flat and sharp directions, which boosts the sharpness reduction along flat directions while maintaining the training stability in sharp directions. We show that IRE can be practically incorporated with {\em generic base optimizers} without introducing significant computational overload. Experiments show that IRE consistently improves the generalization performance for image classification tasks across a variety of benchmark datasets (CIFAR-10/100, ImageNet) and models (ResNets and ViTs). Surprisingly, IRE also achieves a $2\times$ {\em speed-up} compared to AdamW in the pre-training of Llama models (of sizes ranging from 60M to 229M) on datasets including Wikitext-103, Minipile, and Openwebtext. Moreover, we provide theoretical guarantees, showing that IRE can substantially accelerate the convergence towards flat minima in Sharpness-aware Minimization (SAM).</summary></entry><entry><title type="html">Inaccuracy and divergence measures based on survival extropy, their properties, and applications in testing and image analysis</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Inaccuracyanddivergencemeasuresbasedonsurvivalextropytheirpropertiesandapplicationsintestingandimageanalysis.html" rel="alternate" type="text/html" title="Inaccuracy and divergence measures based on survival extropy, their properties, and applications in testing and image analysis" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Inaccuracyanddivergencemeasuresbasedonsurvivalextropytheirpropertiesandapplicationsintestingandimageanalysis</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Inaccuracyanddivergencemeasuresbasedonsurvivalextropytheirpropertiesandapplicationsintestingandimageanalysis.html">&lt;p&gt;This article introduces novel measures of inaccuracy and divergence based on survival extropy and their dynamic forms and explores their properties and applications. To address the drawbacks of asymmetry and range limitations, we introduce two measures: the survival extropy inaccuracy ratio and symmetric divergence measures. The inaccuracy ratio is utilized for the analysis and classification of images. A goodness-of-fit test for the uniform distribution is developed using the survival extropy divergence. Characterizations of the exponential distribution are derived using the dynamic survival extropy inaccuracy and divergence measures. The article also proposes non-parametric estimators for the divergence measures and conducts simulation studies to validate their performance. Finally, it demonstrates the application of symmetric survival extropy divergence in failure time data analysis.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22747&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Saranya P., Sunoj S. M</name></author><category term="stat.AP" /><summary type="html">This article introduces novel measures of inaccuracy and divergence based on survival extropy and their dynamic forms and explores their properties and applications. To address the drawbacks of asymmetry and range limitations, we introduce two measures: the survival extropy inaccuracy ratio and symmetric divergence measures. The inaccuracy ratio is utilized for the analysis and classification of images. A goodness-of-fit test for the uniform distribution is developed using the survival extropy divergence. Characterizations of the exponential distribution are derived using the dynamic survival extropy inaccuracy and divergence measures. The article also proposes non-parametric estimators for the divergence measures and conducts simulation studies to validate their performance. Finally, it demonstrates the application of symmetric survival extropy divergence in failure time data analysis.</summary></entry><entry><title type="html">Inference in Partially Linear Models under Dependent Data with Deep Neural Networks</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/InferenceinPartiallyLinearModelsunderDependentDatawithDeepNeuralNetworks.html" rel="alternate" type="text/html" title="Inference in Partially Linear Models under Dependent Data with Deep Neural Networks" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/InferenceinPartiallyLinearModelsunderDependentDatawithDeepNeuralNetworks</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/InferenceinPartiallyLinearModelsunderDependentDatawithDeepNeuralNetworks.html">&lt;p&gt;I consider inference in a partially linear regression model under stationary $\beta$-mixing data after first stage deep neural network (DNN) estimation. Using the DNN results of Brown (2024), I show that the estimator for the finite dimensional parameter, constructed using DNN-estimated nuisance components, achieves $\sqrt{n}$-consistency and asymptotic normality. By avoiding sample splitting, I address one of the key challenges in applying machine learning techniques to econometric models with dependent data. In a future version of this work, I plan to extend these results to obtain general conditions for semiparametric inference after DNN estimation of nuisance components, which will allow for considerations such as more efficient estimation procedures, and instrumental variable settings.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22574&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Chad Brown</name></author><category term="stat.ML" /><summary type="html">I consider inference in a partially linear regression model under stationary $\beta$-mixing data after first stage deep neural network (DNN) estimation. Using the DNN results of Brown (2024), I show that the estimator for the finite dimensional parameter, constructed using DNN-estimated nuisance components, achieves $\sqrt{n}$-consistency and asymptotic normality. By avoiding sample splitting, I address one of the key challenges in applying machine learning techniques to econometric models with dependent data. In a future version of this work, I plan to extend these results to obtain general conditions for semiparametric inference after DNN estimation of nuisance components, which will allow for considerations such as more efficient estimation procedures, and instrumental variable settings.</summary></entry><entry><title type="html">Is Transductive Learning Equivalent to PAC Learning?</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/IsTransductiveLearningEquivalenttoPACLearning.html" rel="alternate" type="text/html" title="Is Transductive Learning Equivalent to PAC Learning?" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/IsTransductiveLearningEquivalenttoPACLearning</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/IsTransductiveLearningEquivalenttoPACLearning.html">&lt;p&gt;Much of learning theory is concerned with the design and analysis of probably approximately correct (PAC) learners. The closely related transductive model of learning has recently seen more scrutiny, with its learners often used as precursors to PAC learners. Our goal in this work is to understand and quantify the exact relationship between these two models. First, we observe that modest extensions of existing results show the models to be essentially equivalent for realizable learning for most natural loss functions, up to low order terms in the error and sample complexity. The situation for agnostic learning appears less straightforward, with sample complexities potentially separated by a $\frac{1}{\epsilon}$ factor. This is therefore where our main contributions lie. Our results are two-fold:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;For agnostic learning with bounded losses (including, for example, multiclass classification), we show that PAC learning reduces to transductive learning at the cost of low-order terms in the error and sample complexity via an adaptation of the reduction of arXiv:2304.09167 to the agnostic setting.&lt;/li&gt;
  &lt;li&gt;For agnostic binary classification, we show the converse: transductive learning is essentially no more difficult than PAC learning. Together with our first result this implies that the PAC and transductive models are essentially equivalent for agnostic binary classification. This is our most technical result, and involves two steps: A symmetrization argument on the agnostic one-inclusion graph (OIG) of arXiv:2309.13692 to derive the worst-case agnostic transductive instance, and expressing the error of the agnostic OIG algorithm for this instance in terms of the empirical Rademacher complexity of the class.
  We leave as an intriguing open question whether our second result can be extended beyond binary classification to show the transductive and PAC models equivalent more broadly.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.05190&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Shaddin Dughmi, Yusuf Kalayci, Grayson York</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">Much of learning theory is concerned with the design and analysis of probably approximately correct (PAC) learners. The closely related transductive model of learning has recently seen more scrutiny, with its learners often used as precursors to PAC learners. Our goal in this work is to understand and quantify the exact relationship between these two models. First, we observe that modest extensions of existing results show the models to be essentially equivalent for realizable learning for most natural loss functions, up to low order terms in the error and sample complexity. The situation for agnostic learning appears less straightforward, with sample complexities potentially separated by a $\frac{1}{\epsilon}$ factor. This is therefore where our main contributions lie. Our results are two-fold: For agnostic learning with bounded losses (including, for example, multiclass classification), we show that PAC learning reduces to transductive learning at the cost of low-order terms in the error and sample complexity via an adaptation of the reduction of arXiv:2304.09167 to the agnostic setting. For agnostic binary classification, we show the converse: transductive learning is essentially no more difficult than PAC learning. Together with our first result this implies that the PAC and transductive models are essentially equivalent for agnostic binary classification. This is our most technical result, and involves two steps: A symmetrization argument on the agnostic one-inclusion graph (OIG) of arXiv:2309.13692 to derive the worst-case agnostic transductive instance, and expressing the error of the agnostic OIG algorithm for this instance in terms of the empirical Rademacher complexity of the class. We leave as an intriguing open question whether our second result can be extended beyond binary classification to show the transductive and PAC models equivalent more broadly.</summary></entry><entry><title type="html">Joint Estimation of Conditional Mean and Covariance for Unbalanced Panels</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/JointEstimationofConditionalMeanandCovarianceforUnbalancedPanels.html" rel="alternate" type="text/html" title="Joint Estimation of Conditional Mean and Covariance for Unbalanced Panels" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/JointEstimationofConditionalMeanandCovarianceforUnbalancedPanels</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/JointEstimationofConditionalMeanandCovarianceforUnbalancedPanels.html">&lt;p&gt;We propose a novel nonparametric kernel-based estimator of cross-sectional conditional mean and covariance matrices for large unbalanced panels. We show its consistency and provide finite-sample guarantees. In an empirical application, we estimate conditional mean and covariance matrices for a large unbalanced panel of monthly stock excess returns given macroeconomic and firm-specific covariates from 1962 to 2021.The estimator performs well with respect to statistical measures. It is informative for empirical asset pricing, generating conditional mean-variance efficient portfolios with substantial out-of-sample Sharpe ratios far beyond equal-weighted benchmarks.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21858&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Damir Filipovic, Paul Schneider</name></author><category term="stat.ME," /><category term="stat.ML" /><summary type="html">We propose a novel nonparametric kernel-based estimator of cross-sectional conditional mean and covariance matrices for large unbalanced panels. We show its consistency and provide finite-sample guarantees. In an empirical application, we estimate conditional mean and covariance matrices for a large unbalanced panel of monthly stock excess returns given macroeconomic and firm-specific covariates from 1962 to 2021.The estimator performs well with respect to statistical measures. It is informative for empirical asset pricing, generating conditional mean-variance efficient portfolios with substantial out-of-sample Sharpe ratios far beyond equal-weighted benchmarks.</summary></entry><entry><title type="html">Kernel Two-Sample Tests in High Dimension: Interplay Between Moment Discrepancy and Dimension-and-Sample Orders</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/KernelTwoSampleTestsinHighDimensionInterplayBetweenMomentDiscrepancyandDimensionandSampleOrders.html" rel="alternate" type="text/html" title="Kernel Two-Sample Tests in High Dimension: Interplay Between Moment Discrepancy and Dimension-and-Sample Orders" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/KernelTwoSampleTestsinHighDimensionInterplayBetweenMomentDiscrepancyandDimensionandSampleOrders</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/KernelTwoSampleTestsinHighDimensionInterplayBetweenMomentDiscrepancyandDimensionandSampleOrders.html">&lt;p&gt;Motivated by the increasing use of kernel-based metrics for high-dimensional and large-scale data, we study the asymptotic behavior of kernel two-sample tests when the dimension and sample sizes both diverge to infinity. We focus on the maximum mean discrepancy (MMD) using isotropic kernel, including MMD with the Gaussian kernel and the Laplace kernel, and the energy distance as special cases. We derive asymptotic expansions of the kernel two-sample statistics, based on which we establish the central limit theorem (CLT) under both the null hypothesis and the local and fixed alternatives. The new non-null CLT results allow us to perform asymptotic exact power analysis, which reveals a delicate interplay between the moment discrepancy that can be detected by the kernel two-sample tests and the dimension-and-sample orders. The asymptotic theory is further corroborated through numerical studies.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2201.00073&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jian Yan, Xianyang Zhang</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">Motivated by the increasing use of kernel-based metrics for high-dimensional and large-scale data, we study the asymptotic behavior of kernel two-sample tests when the dimension and sample sizes both diverge to infinity. We focus on the maximum mean discrepancy (MMD) using isotropic kernel, including MMD with the Gaussian kernel and the Laplace kernel, and the energy distance as special cases. We derive asymptotic expansions of the kernel two-sample statistics, based on which we establish the central limit theorem (CLT) under both the null hypothesis and the local and fixed alternatives. The new non-null CLT results allow us to perform asymptotic exact power analysis, which reveals a delicate interplay between the moment discrepancy that can be detected by the kernel two-sample tests and the dimension-and-sample orders. The asymptotic theory is further corroborated through numerical studies.</summary></entry><entry><title type="html">Lambda-Skip Connections: the architectural component that prevents Rank Collapse</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/LambdaSkipConnectionsthearchitecturalcomponentthatpreventsRankCollapse.html" rel="alternate" type="text/html" title="Lambda-Skip Connections: the architectural component that prevents Rank Collapse" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/LambdaSkipConnectionsthearchitecturalcomponentthatpreventsRankCollapse</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/LambdaSkipConnectionsthearchitecturalcomponentthatpreventsRankCollapse.html">&lt;p&gt;Rank collapse, a phenomenon where embedding vectors in sequence models rapidly converge to a uniform token or equilibrium state, has recently gained attention in the deep learning literature. This phenomenon leads to reduced expressivity and potential training instabilities due to vanishing gradients. Empirical evidence suggests that architectural components like skip connections, LayerNorm, and MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse. While this issue is well-documented for transformers, alternative sequence models, such as State Space Models (SSMs), which have recently gained prominence, have not been thoroughly examined for similar vulnerabilities. This paper extends the theory of rank collapse from transformers to SSMs using a unifying framework that captures both architectures. We study how a parametrized version of the classic skip connection component, which we call \emph{lambda-skip connections}, provides guarantees for rank collapse prevention. Through analytical results, we present a sufficient condition to guarantee prevention of rank collapse across all the aforementioned architectures. We also study the necessity of this condition via ablation studies and analytical examples. To our knowledge, this is the first study that provides a general guarantee to prevent rank collapse, and that investigates rank collapse in the context of SSMs, offering valuable understanding for both theoreticians and practitioners. Finally, we validate our findings with experiments demonstrating the crucial role of architectural components such as skip connections and gating mechanisms in preventing rank collapse.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.10609&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Federico Arangath Joseph, Jerome Sieber, Melanie N. Zeilinger, Carmen Amo Alonso</name></author><category term="stat.ML" /><summary type="html">Rank collapse, a phenomenon where embedding vectors in sequence models rapidly converge to a uniform token or equilibrium state, has recently gained attention in the deep learning literature. This phenomenon leads to reduced expressivity and potential training instabilities due to vanishing gradients. Empirical evidence suggests that architectural components like skip connections, LayerNorm, and MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse. While this issue is well-documented for transformers, alternative sequence models, such as State Space Models (SSMs), which have recently gained prominence, have not been thoroughly examined for similar vulnerabilities. This paper extends the theory of rank collapse from transformers to SSMs using a unifying framework that captures both architectures. We study how a parametrized version of the classic skip connection component, which we call \emph{lambda-skip connections}, provides guarantees for rank collapse prevention. Through analytical results, we present a sufficient condition to guarantee prevention of rank collapse across all the aforementioned architectures. We also study the necessity of this condition via ablation studies and analytical examples. To our knowledge, this is the first study that provides a general guarantee to prevent rank collapse, and that investigates rank collapse in the context of SSMs, offering valuable understanding for both theoreticians and practitioners. Finally, we validate our findings with experiments demonstrating the crucial role of architectural components such as skip connections and gating mechanisms in preventing rank collapse.</summary></entry><entry><title type="html">Log Heston Model for Monthly Average VIX</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/LogHestonModelforMonthlyAverageVIX.html" rel="alternate" type="text/html" title="Log Heston Model for Monthly Average VIX" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/LogHestonModelforMonthlyAverageVIX</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/LogHestonModelforMonthlyAverageVIX.html">&lt;p&gt;We model time series of VIX (monthly average) and monthly stock index returns. We use log-Heston model: logarithm of VIX is modeled as an autoregression of order 1. Our main insight is that normalizing monthly stock index returns (dividing them by VIX) makes them much closer to independent identically distributed Gaussian. The resulting model is mean-reverting, and the innovations are non-Gaussian. The combined stochastic volatility model fits well, and captures Pareto-like tails of real-world stock market returns. This works for small and large stock indices, for both price and total returns.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22471&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jihyun Park, Andrey Sarantsev</name></author><category term="stat.AP" /><summary type="html">We model time series of VIX (monthly average) and monthly stock index returns. We use log-Heston model: logarithm of VIX is modeled as an autoregression of order 1. Our main insight is that normalizing monthly stock index returns (dividing them by VIX) makes them much closer to independent identically distributed Gaussian. The resulting model is mean-reverting, and the innovations are non-Gaussian. The combined stochastic volatility model fits well, and captures Pareto-like tails of real-world stock market returns. This works for small and large stock indices, for both price and total returns.</summary></entry><entry><title type="html">Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/LorentzEquivariantGeometricAlgebraTransformersforHighEnergyPhysics.html" rel="alternate" type="text/html" title="Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/LorentzEquivariantGeometricAlgebraTransformersforHighEnergyPhysics</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/LorentzEquivariantGeometricAlgebraTransformersforHighEnergyPhysics.html">&lt;p&gt;Extracting scientific understanding from particle-physics experiments requires solving diverse learning problems with high precision and good data efficiency. We propose the Lorentz Geometric Algebra Transformer (L-GATr), a new multi-purpose architecture for high-energy physics. L-GATr represents high-energy data in a geometric algebra over four-dimensional space-time and is equivariant under Lorentz transformations, the symmetry group of relativistic kinematics. At the same time, the architecture is a Transformer, which makes it versatile and scalable to large systems. L-GATr is first demonstrated on regression and classification tasks from particle physics. We then construct the first Lorentz-equivariant generative model: a continuous normalizing flow based on an L-GATr network, trained with Riemannian flow matching. Across our experiments, L-GATr is on par with or outperforms strong domain-specific baselines.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.14806&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jonas Spinner, Victor Bresó, Pim de Haan, Tilman Plehn, Jesse Thaler, Johann Brehmer</name></author><category term="stat.ML" /><summary type="html">Extracting scientific understanding from particle-physics experiments requires solving diverse learning problems with high precision and good data efficiency. We propose the Lorentz Geometric Algebra Transformer (L-GATr), a new multi-purpose architecture for high-energy physics. L-GATr represents high-energy data in a geometric algebra over four-dimensional space-time and is equivariant under Lorentz transformations, the symmetry group of relativistic kinematics. At the same time, the architecture is a Transformer, which makes it versatile and scalable to large systems. L-GATr is first demonstrated on regression and classification tasks from particle physics. We then construct the first Lorentz-equivariant generative model: a continuous normalizing flow based on an L-GATr network, trained with Riemannian flow matching. Across our experiments, L-GATr is on par with or outperforms strong domain-specific baselines.</summary></entry><entry><title type="html">Low-rank longitudinal factor regression with application to chemical mixtures</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Lowranklongitudinalfactorregressionwithapplicationtochemicalmixtures.html" rel="alternate" type="text/html" title="Low-rank longitudinal factor regression with application to chemical mixtures" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Lowranklongitudinalfactorregressionwithapplicationtochemicalmixtures</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Lowranklongitudinalfactorregressionwithapplicationtochemicalmixtures.html">&lt;p&gt;Developmental epidemiology commonly focuses on assessing the association between multiple early life exposures and childhood health. Statistical analyses of data from such studies focus on inferring the contributions of individual exposures, while also characterizing time-varying and interacting effects. Such inferences are made more challenging by correlations among exposures, nonlinearity, and the curse of dimensionality. Motivated by studying the effects of prenatal bisphenol A (BPA) and phthalate exposures on glucose metabolism in adolescence using data from the ELEMENT study, we propose a low-rank longitudinal factor regression (LowFR) model for tractable inference on flexible longitudinal exposure effects. LowFR handles highly-correlated exposures using a Bayesian dynamic factor model, which is fit jointly with a health outcome via a novel factor regression approach. The model collapses on simpler and intuitive submodels when appropriate, while expanding to allow considerable flexibility in time-varying and interaction effects when supported by the data. After demonstrating LowFR’s effectiveness in simulations, we use it to analyze the ELEMENT data and find that diethyl and dibutyl phthalate metabolite levels in trimesters 1 and 2 are associated with altered glucose metabolism in adolescence.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2311.16470&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Glenn Palmer, Amy H. Herring, David B. Dunson</name></author><category term="stat.AP" /><summary type="html">Developmental epidemiology commonly focuses on assessing the association between multiple early life exposures and childhood health. Statistical analyses of data from such studies focus on inferring the contributions of individual exposures, while also characterizing time-varying and interacting effects. Such inferences are made more challenging by correlations among exposures, nonlinearity, and the curse of dimensionality. Motivated by studying the effects of prenatal bisphenol A (BPA) and phthalate exposures on glucose metabolism in adolescence using data from the ELEMENT study, we propose a low-rank longitudinal factor regression (LowFR) model for tractable inference on flexible longitudinal exposure effects. LowFR handles highly-correlated exposures using a Bayesian dynamic factor model, which is fit jointly with a health outcome via a novel factor regression approach. The model collapses on simpler and intuitive submodels when appropriate, while expanding to allow considerable flexibility in time-varying and interaction effects when supported by the data. After demonstrating LowFR’s effectiveness in simulations, we use it to analyze the ELEMENT data and find that diethyl and dibutyl phthalate metabolite levels in trimesters 1 and 2 are associated with altered glucose metabolism in adolescence.</summary></entry><entry><title type="html">Mixed Dynamics In Linear Networks: Unifying the Lazy and Active Regimes</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/MixedDynamicsInLinearNetworksUnifyingtheLazyandActiveRegimes.html" rel="alternate" type="text/html" title="Mixed Dynamics In Linear Networks: Unifying the Lazy and Active Regimes" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/MixedDynamicsInLinearNetworksUnifyingtheLazyandActiveRegimes</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/MixedDynamicsInLinearNetworksUnifyingtheLazyandActiveRegimes.html">&lt;p&gt;The training dynamics of linear networks are well studied in two distinct setups: the lazy regime and balanced/active regime, depending on the initialization and width of the network. We provide a surprisingly simple unifying formula for the evolution of the learned matrix that contains as special cases both lazy and balanced regimes but also a mixed regime in between the two. In the mixed regime, a part of the network is lazy while the other is balanced. More precisely the network is lazy along singular values that are below a certain threshold and balanced along those that are above the same threshold. At initialization, all singular values are lazy, allowing for the network to align itself with the task, so that later in time, when some of the singular value cross the threshold and become active they will converge rapidly (convergence in the balanced regime is notoriously difficult in the absence of alignment). The mixed regime is the `best of both worlds’: it converges from any random initialization (in contrast to balanced dynamics which require special initialization), and has a low rank bias (absent in the lazy dynamics). This allows us to prove an almost complete phase diagram of training behavior as a function of the variance at initialization and the width, for a MSE training task.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.17580&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Zhenfeng Tu, Santiago Aranguri, Arthur Jacot</name></author><category term="stat.ML" /><summary type="html">The training dynamics of linear networks are well studied in two distinct setups: the lazy regime and balanced/active regime, depending on the initialization and width of the network. We provide a surprisingly simple unifying formula for the evolution of the learned matrix that contains as special cases both lazy and balanced regimes but also a mixed regime in between the two. In the mixed regime, a part of the network is lazy while the other is balanced. More precisely the network is lazy along singular values that are below a certain threshold and balanced along those that are above the same threshold. At initialization, all singular values are lazy, allowing for the network to align itself with the task, so that later in time, when some of the singular value cross the threshold and become active they will converge rapidly (convergence in the balanced regime is notoriously difficult in the absence of alignment). The mixed regime is the `best of both worlds’: it converges from any random initialization (in contrast to balanced dynamics which require special initialization), and has a low rank bias (absent in the lazy dynamics). This allows us to prove an almost complete phase diagram of training behavior as a function of the variance at initialization and the width, for a MSE training task.</summary></entry><entry><title type="html">Multi-Model Subset Selection</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/MultiModelSubsetSelection.html" rel="alternate" type="text/html" title="Multi-Model Subset Selection" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/MultiModelSubsetSelection</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/MultiModelSubsetSelection.html">&lt;p&gt;The two primary approaches for high-dimensional regression problems are sparse methods (e.g., best subset selection, which uses the L0-norm in the penalty) and ensemble methods (e.g., random forests). Although sparse methods typically yield interpretable models, in terms of prediction accuracy they are often outperformed by “blackbox” multi-model ensemble methods. A regression ensemble is introduced which combines the interpretability of sparse methods with the high prediction accuracy of ensemble methods. An algorithm is proposed to solve the joint optimization of the corresponding L0-penalized regression models by extending recent developments in L0-optimization for sparse methods to multi-model regression ensembles. The sparse and diverse models in the ensemble are learned simultaneously from the data. Each of these models provides an explanation for the relationship between a subset of predictors and the response variable. Empirical studies and theoretical knowledge about ensembles are used to gain insight into the ensemble method’s performance, focusing on the interplay between bias, variance, covariance, and variable selection. In prediction tasks, the ensembles can outperform state-of-the-art competitors on both simulated and real data. Forward stepwise regression is also generalized to multi-model regression ensembles and used to obtain an initial solution for the algorithm. The optimization algorithms are implemented in publicly available software packages.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2204.08100&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Anthony-Alexander Christidis, Stefan Van Aelst, Ruben Zamar</name></author><category term="stat.ME" /><summary type="html">The two primary approaches for high-dimensional regression problems are sparse methods (e.g., best subset selection, which uses the L0-norm in the penalty) and ensemble methods (e.g., random forests). Although sparse methods typically yield interpretable models, in terms of prediction accuracy they are often outperformed by “blackbox” multi-model ensemble methods. A regression ensemble is introduced which combines the interpretability of sparse methods with the high prediction accuracy of ensemble methods. An algorithm is proposed to solve the joint optimization of the corresponding L0-penalized regression models by extending recent developments in L0-optimization for sparse methods to multi-model regression ensembles. The sparse and diverse models in the ensemble are learned simultaneously from the data. Each of these models provides an explanation for the relationship between a subset of predictors and the response variable. Empirical studies and theoretical knowledge about ensembles are used to gain insight into the ensemble method’s performance, focusing on the interplay between bias, variance, covariance, and variable selection. In prediction tasks, the ensembles can outperform state-of-the-art competitors on both simulated and real data. Forward stepwise regression is also generalized to multi-model regression ensembles and used to obtain an initial solution for the algorithm. The optimization algorithms are implemented in publicly available software packages.</summary></entry><entry><title type="html">Multicriteria Analysis of Decentralized Wastewater Treatment Technologies for the Philippines</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/MulticriteriaAnalysisofDecentralizedWastewaterTreatmentTechnologiesforthePhilippines.html" rel="alternate" type="text/html" title="Multicriteria Analysis of Decentralized Wastewater Treatment Technologies for the Philippines" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/MulticriteriaAnalysisofDecentralizedWastewaterTreatmentTechnologiesforthePhilippines</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/MulticriteriaAnalysisofDecentralizedWastewaterTreatmentTechnologiesforthePhilippines.html">&lt;p&gt;This research focuses on decentralized wastewater treatment (DEWAT) technologies for the Philippines that is motivated by the limited suitable wastewater treatment infrastructure in the country. A multi-criteria analysis (MCA), using the Analytic Hierarchy Process (AHP) and Delphi method, was employed to evaluate DEWAT technologies based on life cycle costs and wastewater treatment efficiency parameters such as CODt, BOD5, TSS, NH4-N, TP, and hydraulic retention time. A two-factor Analysis of Variance (ANOVA) without replication was used to assess statistical differences between technologies. The analysis revealed that the Downflow Hanging Sponge (DHS) filter, Multi-Soil Layering (MSL) systems, and Moving Bed Biofilm Reactors (MBBRs) are the top-performing technologies, with no statistically significant differences in their overall performance. The DHS filter ranked highest, excelling in energy efficiency and nutrient removal, making it ideal for resource-scarce environments. MSL systems were noted for their broad-spectrum contaminant removal, while MBBRs demonstrated flexibility and scalability for semi-urban areas. A thorough analysis is carried out for these DEWAT technologies and insights for applicability in the Philippine context are provided.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22484&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Egberto Selerio</name></author><category term="stat.AP" /><summary type="html">This research focuses on decentralized wastewater treatment (DEWAT) technologies for the Philippines that is motivated by the limited suitable wastewater treatment infrastructure in the country. A multi-criteria analysis (MCA), using the Analytic Hierarchy Process (AHP) and Delphi method, was employed to evaluate DEWAT technologies based on life cycle costs and wastewater treatment efficiency parameters such as CODt, BOD5, TSS, NH4-N, TP, and hydraulic retention time. A two-factor Analysis of Variance (ANOVA) without replication was used to assess statistical differences between technologies. The analysis revealed that the Downflow Hanging Sponge (DHS) filter, Multi-Soil Layering (MSL) systems, and Moving Bed Biofilm Reactors (MBBRs) are the top-performing technologies, with no statistically significant differences in their overall performance. The DHS filter ranked highest, excelling in energy efficiency and nutrient removal, making it ideal for resource-scarce environments. MSL systems were noted for their broad-spectrum contaminant removal, while MBBRs demonstrated flexibility and scalability for semi-urban areas. A thorough analysis is carried out for these DEWAT technologies and insights for applicability in the Philippine context are provided.</summary></entry><entry><title type="html">No imputation without representation</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Noimputationwithoutrepresentation.html" rel="alternate" type="text/html" title="No imputation without representation" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Noimputationwithoutrepresentation</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Noimputationwithoutrepresentation.html">&lt;p&gt;By filling in missing values in datasets, imputation allows these datasets to be used with algorithms that cannot handle missing values by themselves. However, missing values may in principle contribute useful information that is lost through imputation. The missing-indicator approach can be used in combination with imputation to instead represent this information as a part of the dataset. There are several theoretical considerations why missing-indicators may or may not be beneficial, but there has not been any large-scale practical experiment on real-life datasets to test this question for machine learning predictions. We perform this experiment for three imputation strategies and a range of different classification algorithms, on the basis of twenty real-life datasets. In a follow-up experiment, we determine attribute-specific missingness thresholds for each classifier above which missing-indicators are more likely than not to increase classification performance. And in a second follow-up experiment, we evaluate numerical imputation of one-hot encoded categorical attributes. We reach the following conclusions. Firstly, missing-indicators generally increase classification performance. Secondly, with missing-indicators, nearest neighbour and iterative imputation do not lead to better performance than simple mean/mode imputation. Thirdly, for decision trees, pruning is necessary to prevent overfitting. Fourthly, the thresholds above which missing-indicators are more likely than not to improve performance are lower for categorical attributes than for numerical attributes. Lastly, mean imputation of numerical attributes preserves some of the information from missing values. Consequently, when not using missing-indicators it can be advantageous to apply mean imputation to one-hot encoded categorical attributes instead of mode imputation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2206.14254&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Oliver Urs Lenz, Daniel Peralta, Chris Cornelis</name></author><category term="stat.ML" /><summary type="html">By filling in missing values in datasets, imputation allows these datasets to be used with algorithms that cannot handle missing values by themselves. However, missing values may in principle contribute useful information that is lost through imputation. The missing-indicator approach can be used in combination with imputation to instead represent this information as a part of the dataset. There are several theoretical considerations why missing-indicators may or may not be beneficial, but there has not been any large-scale practical experiment on real-life datasets to test this question for machine learning predictions. We perform this experiment for three imputation strategies and a range of different classification algorithms, on the basis of twenty real-life datasets. In a follow-up experiment, we determine attribute-specific missingness thresholds for each classifier above which missing-indicators are more likely than not to increase classification performance. And in a second follow-up experiment, we evaluate numerical imputation of one-hot encoded categorical attributes. We reach the following conclusions. Firstly, missing-indicators generally increase classification performance. Secondly, with missing-indicators, nearest neighbour and iterative imputation do not lead to better performance than simple mean/mode imputation. Thirdly, for decision trees, pruning is necessary to prevent overfitting. Fourthly, the thresholds above which missing-indicators are more likely than not to improve performance are lower for categorical attributes than for numerical attributes. Lastly, mean imputation of numerical attributes preserves some of the information from missing values. Consequently, when not using missing-indicators it can be advantageous to apply mean imputation to one-hot encoded categorical attributes instead of mode imputation.</summary></entry><entry><title type="html">Novel Subsampling Strategies for Heavily Censored Reliability Data</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/NovelSubsamplingStrategiesforHeavilyCensoredReliabilityData.html" rel="alternate" type="text/html" title="Novel Subsampling Strategies for Heavily Censored Reliability Data" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/NovelSubsamplingStrategiesforHeavilyCensoredReliabilityData</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/NovelSubsamplingStrategiesforHeavilyCensoredReliabilityData.html">&lt;p&gt;Computational capability often falls short when confronted with massive data, posing a common challenge in establishing a statistical model or statistical inference method dealing with big data. While subsampling techniques have been extensively developed to downsize the data volume, there is a notable gap in addressing the unique challenge of handling extensive reliability data, in which a common situation is that a large proportion of data is censored. In this article, we propose an efficient subsampling method for reliability analysis in the presence of censoring data, intending to estimate the parameters of lifetime distribution. Moreover, a novel subsampling method for subsampling from severely censored data is proposed, i.e., only a tiny proportion of data is complete. The subsampling-based estimators are given, and their asymptotic properties are derived. The optimal subsampling probabilities are derived through the L-optimality criterion, which minimizes the trace of the product of the asymptotic covariance matrix and a constant matrix. Efficient algorithms are proposed to implement the proposed subsampling methods to address the challenge that optimal subsampling strategy depends on unknown parameter estimation from full data. Real-world hard drive dataset case and simulative empirical studies are employed to demonstrate the superior performance of the proposed methods.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22751&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yixiao Ruan, Zan Li, Zhaohui Li, Dennis K. J. Lin, Qingpei Hu, Dan Yu</name></author><category term="stat.ME," /><category term="stat.CO" /><summary type="html">Computational capability often falls short when confronted with massive data, posing a common challenge in establishing a statistical model or statistical inference method dealing with big data. While subsampling techniques have been extensively developed to downsize the data volume, there is a notable gap in addressing the unique challenge of handling extensive reliability data, in which a common situation is that a large proportion of data is censored. In this article, we propose an efficient subsampling method for reliability analysis in the presence of censoring data, intending to estimate the parameters of lifetime distribution. Moreover, a novel subsampling method for subsampling from severely censored data is proposed, i.e., only a tiny proportion of data is complete. The subsampling-based estimators are given, and their asymptotic properties are derived. The optimal subsampling probabilities are derived through the L-optimality criterion, which minimizes the trace of the product of the asymptotic covariance matrix and a constant matrix. Efficient algorithms are proposed to implement the proposed subsampling methods to address the challenge that optimal subsampling strategy depends on unknown parameter estimation from full data. Real-world hard drive dataset case and simulative empirical studies are employed to demonstrate the superior performance of the proposed methods.</summary></entry><entry><title type="html">On tail inference in scale-free inhomogeneous random graphs</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Ontailinferenceinscalefreeinhomogeneousrandomgraphs.html" rel="alternate" type="text/html" title="On tail inference in scale-free inhomogeneous random graphs" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Ontailinferenceinscalefreeinhomogeneousrandomgraphs</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Ontailinferenceinscalefreeinhomogeneousrandomgraphs.html">&lt;p&gt;Both empirical and theoretical investigations of scale-free network models have found that large degrees in a network exert an outsized impact on its structure. However, the tools used to infer the tail behavior of degree distributions in scale-free networks often lack a strong theoretical foundation. In this paper, we introduce a new framework for analyzing the asymptotic distribution of estimators for degree tail indices in scale-free inhomogeneous random graphs. Our framework leverages the relationship between the large weights and large degrees of Norros-Reittu and Chung-Lu random graphs. In particular, we determine a rate for the number of nodes $k(n) \rightarrow \infty$ such that for all $i = 1, \dots, k(n)$, the node with the $i$-th largest weight will have the $i$-th largest degree with high probability. Such alignment of upper-order statistics is then employed to establish the asymptotic normality of three different tail index estimators based on the upper degrees. These results suggest potential applications of the framework to threshold selection and goodness-of-fit testing in scale-free networks, issues that have long challenged the network science community.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22703&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Daniel Cirkovic, Tiandong Wang, Daren B. H. Cline</name></author><category term="stat.ME," /><category term="stat.TH" /><summary type="html">Both empirical and theoretical investigations of scale-free network models have found that large degrees in a network exert an outsized impact on its structure. However, the tools used to infer the tail behavior of degree distributions in scale-free networks often lack a strong theoretical foundation. In this paper, we introduce a new framework for analyzing the asymptotic distribution of estimators for degree tail indices in scale-free inhomogeneous random graphs. Our framework leverages the relationship between the large weights and large degrees of Norros-Reittu and Chung-Lu random graphs. In particular, we determine a rate for the number of nodes $k(n) \rightarrow \infty$ such that for all $i = 1, \dots, k(n)$, the node with the $i$-th largest weight will have the $i$-th largest degree with high probability. Such alignment of upper-order statistics is then employed to establish the asymptotic normality of three different tail index estimators based on the upper degrees. These results suggest potential applications of the framework to threshold selection and goodness-of-fit testing in scale-free networks, issues that have long challenged the network science community.</summary></entry><entry><title type="html">On the fundamental limitations of multiproposal Markov chain Monte Carlo algorithms</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/OnthefundamentallimitationsofmultiproposalMarkovchainMonteCarloalgorithms.html" rel="alternate" type="text/html" title="On the fundamental limitations of multiproposal Markov chain Monte Carlo algorithms" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/OnthefundamentallimitationsofmultiproposalMarkovchainMonteCarloalgorithms</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/OnthefundamentallimitationsofmultiproposalMarkovchainMonteCarloalgorithms.html">&lt;p&gt;We study multiproposal Markov chain Monte Carlo algorithms, such as Multiple-try or generalised Metropolis-Hastings schemes, which have recently received renewed attention due to their amenability to parallel computing. First, we prove that no multiproposal scheme can speed-up convergence relative to the corresponding single proposal scheme by more than a factor of $K$, where $K$ denotes the number of proposals at each iteration. This result applies to arbitrary target distributions and it implies that serial multiproposal implementations are always less efficient than single proposal ones. Secondly, we consider log-concave distributions over Euclidean spaces, proving that, in this case, the speed-up is at most logarithmic in $K$, which implies that even parallel multiproposal implementations are fundamentally limited in the computational gain they can offer. Crucially, our results apply to arbitrary multiproposal schemes and purely rely on the two-step structure of the associated kernels (i.e. first generate $K$ candidate points, then select one among those). Our theoretical findings are validated through numerical simulations.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23174&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Francesco Pozza, Giacomo Zanella</name></author><category term="stat.CO," /><category term="stat.ME," /><category term="stat.TH" /><summary type="html">We study multiproposal Markov chain Monte Carlo algorithms, such as Multiple-try or generalised Metropolis-Hastings schemes, which have recently received renewed attention due to their amenability to parallel computing. First, we prove that no multiproposal scheme can speed-up convergence relative to the corresponding single proposal scheme by more than a factor of $K$, where $K$ denotes the number of proposals at each iteration. This result applies to arbitrary target distributions and it implies that serial multiproposal implementations are always less efficient than single proposal ones. Secondly, we consider log-concave distributions over Euclidean spaces, proving that, in this case, the speed-up is at most logarithmic in $K$, which implies that even parallel multiproposal implementations are fundamentally limited in the computational gain they can offer. Crucially, our results apply to arbitrary multiproposal schemes and purely rely on the two-step structure of the associated kernels (i.e. first generate $K$ candidate points, then select one among those). Our theoretical findings are validated through numerical simulations.</summary></entry><entry><title type="html">Optimal Linear Decay Learning Rate Schedules and Further Refinements</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/OptimalLinearDecayLearningRateSchedulesandFurtherRefinements.html" rel="alternate" type="text/html" title="Optimal Linear Decay Learning Rate Schedules and Further Refinements" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/OptimalLinearDecayLearningRateSchedulesandFurtherRefinements</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/OptimalLinearDecayLearningRateSchedulesandFurtherRefinements.html">&lt;p&gt;Learning rate schedules used in practice bear little resemblance to those recommended by theory. We close much of this theory/practice gap, and as a consequence are able to derive new problem-adaptive learning rate schedules. Our main technical contribution is a refined analysis of learning rate schedules for a wide class of optimization algorithms (including SGD). When considering only worst-case analysis, our theory predicts that the optimal choice is the linear decay schedule where the step-size is set proportional to 1 - t/T, where t is the current iteration and T is the total number of steps. To go beyond this worst-case analysis, we use the observed gradient norms to derive schedules refined for any particular task. These refined schedules exhibit learning rate warm-up and rapid learning rate annealing near the end of training. Ours is the first systematic approach to automatically yield both of these properties. We perform the most comprehensive evaluation of learning rate schedules to date, evaluating across 10 diverse deep learning problems, a series of LLMs, and a suite of logistic regression problems. We validate that overall, the linear-decay schedule outperforms all commonly used default schedules including cosine annealing. Our adaptive schedule refinement method gives further improvements.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2310.07831&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Aaron Defazio, Ashok Cutkosky, Harsh Mehta, Konstantin Mishchenko</name></author><category term="stat.ML" /><summary type="html">Learning rate schedules used in practice bear little resemblance to those recommended by theory. We close much of this theory/practice gap, and as a consequence are able to derive new problem-adaptive learning rate schedules. Our main technical contribution is a refined analysis of learning rate schedules for a wide class of optimization algorithms (including SGD). When considering only worst-case analysis, our theory predicts that the optimal choice is the linear decay schedule where the step-size is set proportional to 1 - t/T, where t is the current iteration and T is the total number of steps. To go beyond this worst-case analysis, we use the observed gradient norms to derive schedules refined for any particular task. These refined schedules exhibit learning rate warm-up and rapid learning rate annealing near the end of training. Ours is the first systematic approach to automatically yield both of these properties. We perform the most comprehensive evaluation of learning rate schedules to date, evaluating across 10 diverse deep learning problems, a series of LLMs, and a suite of logistic regression problems. We validate that overall, the linear-decay schedule outperforms all commonly used default schedules including cosine annealing. Our adaptive schedule refinement method gives further improvements.</summary></entry><entry><title type="html">Order of Addition in Orthogonally Blocked Mixture and Component-Amount Designs</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/OrderofAdditioninOrthogonallyBlockedMixtureandComponentAmountDesigns.html" rel="alternate" type="text/html" title="Order of Addition in Orthogonally Blocked Mixture and Component-Amount Designs" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/OrderofAdditioninOrthogonallyBlockedMixtureandComponentAmountDesigns</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/OrderofAdditioninOrthogonallyBlockedMixtureandComponentAmountDesigns.html">&lt;p&gt;Mixture experiments often involve process variables, such as different chemical reactors in a laboratory or varying mixing speeds in a production line. Organizing the runs in orthogonal blocks allows the mixture model to be fitted independently of the process effects, ensuring clearer insights into the role of each mixture component. Current literature on mixture designs in orthogonal blocks ignores the order of addition of mixture components in mixture blends. This paper considers the order of addition of components in mixture and mixture-amount experiments, using the variable total amount taken into orthogonal blocks. The response depends on both the mixture proportions or the amounts of the components and the order of their addition. Mixture designs in orthogonal blocks are constructed to enable the estimation of mixture or component-amount model parameters and the order-of-addition effects. The G-efficiency criterion is used to assess how well the design supports precise and unbiased estimation of the model parameters. The fraction of the Design Space plot is used to provide a visual assessment of the prediction capabilities of a design across the entire design space.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22501&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Taha Hasan, Touqeer Ahmad</name></author><category term="stat.ME," /><category term="stat.AP" /><summary type="html">Mixture experiments often involve process variables, such as different chemical reactors in a laboratory or varying mixing speeds in a production line. Organizing the runs in orthogonal blocks allows the mixture model to be fitted independently of the process effects, ensuring clearer insights into the role of each mixture component. Current literature on mixture designs in orthogonal blocks ignores the order of addition of mixture components in mixture blends. This paper considers the order of addition of components in mixture and mixture-amount experiments, using the variable total amount taken into orthogonal blocks. The response depends on both the mixture proportions or the amounts of the components and the order of their addition. Mixture designs in orthogonal blocks are constructed to enable the estimation of mixture or component-amount model parameters and the order-of-addition effects. The G-efficiency criterion is used to assess how well the design supports precise and unbiased estimation of the model parameters. The fraction of the Design Space plot is used to provide a visual assessment of the prediction capabilities of a design across the entire design space.</summary></entry><entry><title type="html">PAC-Bayes-Chernoff bounds for unbounded losses</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/PACBayesChernoffboundsforunboundedlosses.html" rel="alternate" type="text/html" title="PAC-Bayes-Chernoff bounds for unbounded losses" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/PACBayesChernoffboundsforunboundedlosses</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/PACBayesChernoffboundsforunboundedlosses.html">&lt;p&gt;We introduce a new PAC-Bayes oracle bound for unbounded losses that extends Cram&apos;er-Chernoff bounds to the PAC-Bayesian setting. The proof technique relies on controlling the tails of certain random variables involving the Cram&apos;er transform of the loss. Our approach naturally leverages properties of Cram&apos;er-Chernoff bounds, such as exact optimization of the free parameter in many PAC-Bayes bounds. We highlight several applications of the main theorem. Firstly, we show that our bound recovers and generalizes previous results. Additionally, our approach allows working with richer assumptions that result in more informative and potentially tighter bounds. In this direction, we provide a general bound under a new \textit{model-dependent} assumption from which we obtain bounds based on parameter norms and log-Sobolev inequalities. Notably, many of these bounds can be minimized to obtain distributions beyond the Gibbs posterior and provide novel theoretical coverage to existing regularization techniques.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2401.01148&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ioar Casado, Luis A. Ortega, Aritz Pérez, Andrés R. Masegosa</name></author><category term="stat.ML" /><summary type="html">We introduce a new PAC-Bayes oracle bound for unbounded losses that extends Cram&apos;er-Chernoff bounds to the PAC-Bayesian setting. The proof technique relies on controlling the tails of certain random variables involving the Cram&apos;er transform of the loss. Our approach naturally leverages properties of Cram&apos;er-Chernoff bounds, such as exact optimization of the free parameter in many PAC-Bayes bounds. We highlight several applications of the main theorem. Firstly, we show that our bound recovers and generalizes previous results. Additionally, our approach allows working with richer assumptions that result in more informative and potentially tighter bounds. In this direction, we provide a general bound under a new \textit{model-dependent} assumption from which we obtain bounds based on parameter norms and log-Sobolev inequalities. Notably, many of these bounds can be minimized to obtain distributions beyond the Gibbs posterior and provide novel theoretical coverage to existing regularization techniques.</summary></entry><entry><title type="html">Parameter uncertainties for imperfect surrogate models in the low-noise regime</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Parameteruncertaintiesforimperfectsurrogatemodelsinthelownoiseregime.html" rel="alternate" type="text/html" title="Parameter uncertainties for imperfect surrogate models in the low-noise regime" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Parameteruncertaintiesforimperfectsurrogatemodelsinthelownoiseregime</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Parameteruncertaintiesforimperfectsurrogatemodelsinthelownoiseregime.html">&lt;p&gt;Bayesian regression determines model parameters by minimizing the expected loss, an upper bound to the true generalization error. However, the loss ignores misspecification, where models are imperfect. Parameter uncertainties from Bayesian regression are thus significantly underestimated and vanish in the large data limit. This is particularly problematic when building models of low-noise, or near-deterministic, calculations, as the main source of uncertainty is neglected. We analyze the generalization error of misspecified, near-deterministic surrogate models, a regime of broad relevance in science and engineering. We show posterior distributions must cover every training point to avoid a divergent generalization error and design an ansatz that respects this constraint, which for linear models incurs minimal overhead. This is demonstrated on model problems before application to thousand dimensional datasets in atomistic machine learning. Our efficient misspecification-aware scheme gives accurate prediction and bounding of test errors where existing schemes fail, allowing this important source of uncertainty to be incorporated in computational workflows.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.01810&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Thomas D Swinburne, Danny Perez</name></author><category term="stat.ML" /><summary type="html">Bayesian regression determines model parameters by minimizing the expected loss, an upper bound to the true generalization error. However, the loss ignores misspecification, where models are imperfect. Parameter uncertainties from Bayesian regression are thus significantly underestimated and vanish in the large data limit. This is particularly problematic when building models of low-noise, or near-deterministic, calculations, as the main source of uncertainty is neglected. We analyze the generalization error of misspecified, near-deterministic surrogate models, a regime of broad relevance in science and engineering. We show posterior distributions must cover every training point to avoid a divergent generalization error and design an ansatz that respects this constraint, which for linear models incurs minimal overhead. This is demonstrated on model problems before application to thousand dimensional datasets in atomistic machine learning. Our efficient misspecification-aware scheme gives accurate prediction and bounding of test errors where existing schemes fail, allowing this important source of uncertainty to be incorporated in computational workflows.</summary></entry><entry><title type="html">Partial Channel Dependence with Channel Masks for Time Series Foundation Models</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/PartialChannelDependencewithChannelMasksforTimeSeriesFoundationModels.html" rel="alternate" type="text/html" title="Partial Channel Dependence with Channel Masks for Time Series Foundation Models" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/PartialChannelDependencewithChannelMasksforTimeSeriesFoundationModels</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/PartialChannelDependencewithChannelMasksforTimeSeriesFoundationModels.html">&lt;p&gt;Recent advancements in foundation models have been successfully extended to the time series (TS) domain, facilitated by the emergence of large-scale TS datasets. However, previous efforts have primarily focused on designing model architectures to address explicit heterogeneity among datasets such as various numbers of channels, while often overlooking implicit heterogeneity such as varying dependencies between channels. In this work, we introduce the concept of partial channel dependence (PCD), which enables a more sophisticated adjustment of channel dependencies based on dataset-specific information. To achieve PCD, we propose a channel mask that captures the relationships between channels within a dataset using two key components: 1) a correlation matrix that encodes relative dependencies between channels, and 2) domain parameters that learn the absolute dependencies specific to each dataset, refining the correlation matrix. We validate the effectiveness of PCD across four tasks in TS including forecasting, classification, imputation, and anomaly detection, under diverse settings, including few-shot and zero-shot scenarios with both TS foundation models and single-task models. Code is available at https://github.com/seunghan96/CM.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23222&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Seunghan Lee, Taeyoung Park, Kibok Lee</name></author><category term="stat.ML" /><summary type="html">Recent advancements in foundation models have been successfully extended to the time series (TS) domain, facilitated by the emergence of large-scale TS datasets. However, previous efforts have primarily focused on designing model architectures to address explicit heterogeneity among datasets such as various numbers of channels, while often overlooking implicit heterogeneity such as varying dependencies between channels. In this work, we introduce the concept of partial channel dependence (PCD), which enables a more sophisticated adjustment of channel dependencies based on dataset-specific information. To achieve PCD, we propose a channel mask that captures the relationships between channels within a dataset using two key components: 1) a correlation matrix that encodes relative dependencies between channels, and 2) domain parameters that learn the absolute dependencies specific to each dataset, refining the correlation matrix. We validate the effectiveness of PCD across four tasks in TS including forecasting, classification, imputation, and anomaly detection, under diverse settings, including few-shot and zero-shot scenarios with both TS foundation models and single-task models. Code is available at https://github.com/seunghan96/CM.</summary></entry><entry><title type="html">Particle Semi-Implicit Variational Inference</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ParticleSemiImplicitVariationalInference.html" rel="alternate" type="text/html" title="Particle Semi-Implicit Variational Inference" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ParticleSemiImplicitVariationalInference</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ParticleSemiImplicitVariationalInference.html">&lt;p&gt;Semi-implicit variational inference (SIVI) enriches the expressiveness of variational families by utilizing a kernel and a mixing distribution to hierarchically define the variational distribution. Existing SIVI methods parameterize the mixing distribution using implicit distributions, leading to intractable variational densities. As a result, directly maximizing the evidence lower bound (ELBO) is not possible, so they resort to one of the following: optimizing bounds on the ELBO, employing costly inner-loop Markov chain Monte Carlo runs, or solving minimax objectives. In this paper, we propose a novel method for SIVI called Particle Variational Inference (PVI) which employs empirical measures to approximate the optimal mixing distributions characterized as the minimizer of a free energy functional. PVI arises naturally as a particle approximation of a Euclidean–Wasserstein gradient flow and, unlike prior works, it directly optimizes the ELBO whilst making no parametric assumption about the mixing distribution. Our empirical results demonstrate that PVI performs favourably compared to other SIVI methods across various tasks. Moreover, we provide a theoretical analysis of the behaviour of the gradient flow of a related free energy functional: establishing the existence and uniqueness of solutions as well as propagation of chaos results.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2407.00649&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jen Ning Lim, Adam M. Johansen</name></author><category term="stat.ML" /><summary type="html">Semi-implicit variational inference (SIVI) enriches the expressiveness of variational families by utilizing a kernel and a mixing distribution to hierarchically define the variational distribution. Existing SIVI methods parameterize the mixing distribution using implicit distributions, leading to intractable variational densities. As a result, directly maximizing the evidence lower bound (ELBO) is not possible, so they resort to one of the following: optimizing bounds on the ELBO, employing costly inner-loop Markov chain Monte Carlo runs, or solving minimax objectives. In this paper, we propose a novel method for SIVI called Particle Variational Inference (PVI) which employs empirical measures to approximate the optimal mixing distributions characterized as the minimizer of a free energy functional. PVI arises naturally as a particle approximation of a Euclidean–Wasserstein gradient flow and, unlike prior works, it directly optimizes the ELBO whilst making no parametric assumption about the mixing distribution. Our empirical results demonstrate that PVI performs favourably compared to other SIVI methods across various tasks. Moreover, we provide a theoretical analysis of the behaviour of the gradient flow of a related free energy functional: establishing the existence and uniqueness of solutions as well as propagation of chaos results.</summary></entry><entry><title type="html">Pretraining and the Lasso</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/PretrainingandtheLasso.html" rel="alternate" type="text/html" title="Pretraining and the Lasso" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/PretrainingandtheLasso</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/PretrainingandtheLasso.html">&lt;p&gt;Pretraining is a popular and powerful paradigm in machine learning to pass information from one model to another. As an example, suppose one has a modest-sized dataset of images of cats and dogs, and plans to fit a deep neural network to classify them from the pixel features. With pretraining, we start with a neural network trained on a large corpus of images, consisting of not just cats and dogs but hundreds of other image types. Then we fix all of the network weights except for the top layer(s) (which makes the final classification) and train (or “fine tune”) those weights on our dataset. This often results in dramatically better performance than the network trained solely on our smaller dataset. In this paper, we ask the question “Can pretraining help the lasso?”.
  We develop a framework for the lasso in which a model is fit to a large dataset, and then fine-tuned using a smaller dataset. This latter dataset can be a subset of the original dataset, or it can be a dataset with a different but related outcome. This framework has a wide variety of applications, including stratified models, multinomial responses, multi-response models, conditional average treatment estimation and even gradient boosting.
  In the stratified model setting, the pretrained lasso pipeline estimates the coefficients common to all groups at the first stage, and then estimates the group-specific coefficients at the second “fine-tuning” stage. We show that under appropriate assumptions, the support recovery rate of the common coefficients is superior to that of the usual lasso trained only on individual groups. This separate identification of common and individual coefficients can also be useful for scientific understanding.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2401.12911&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Erin Craig, Mert Pilanci, Thomas Le Menestrel, Balasubramanian Narasimhan, Manuel Rivas, Stein-Erik Gullaksen, Roozbeh Dehghannasiri, Julia Salzman, Jonathan Taylor, Robert Tibshirani</name></author><category term="stat.ME" /><summary type="html">Pretraining is a popular and powerful paradigm in machine learning to pass information from one model to another. As an example, suppose one has a modest-sized dataset of images of cats and dogs, and plans to fit a deep neural network to classify them from the pixel features. With pretraining, we start with a neural network trained on a large corpus of images, consisting of not just cats and dogs but hundreds of other image types. Then we fix all of the network weights except for the top layer(s) (which makes the final classification) and train (or “fine tune”) those weights on our dataset. This often results in dramatically better performance than the network trained solely on our smaller dataset. In this paper, we ask the question “Can pretraining help the lasso?”. We develop a framework for the lasso in which a model is fit to a large dataset, and then fine-tuned using a smaller dataset. This latter dataset can be a subset of the original dataset, or it can be a dataset with a different but related outcome. This framework has a wide variety of applications, including stratified models, multinomial responses, multi-response models, conditional average treatment estimation and even gradient boosting. In the stratified model setting, the pretrained lasso pipeline estimates the coefficients common to all groups at the first stage, and then estimates the group-specific coefficients at the second “fine-tuning” stage. We show that under appropriate assumptions, the support recovery rate of the common coefficients is superior to that of the usual lasso trained only on individual groups. This separate identification of common and individual coefficients can also be useful for scientific understanding.</summary></entry><entry><title type="html">Prior Knowledge Accelerate Variance Computing</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/PriorKnowledgeAccelerateVarianceComputing.html" rel="alternate" type="text/html" title="Prior Knowledge Accelerate Variance Computing" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/PriorKnowledgeAccelerateVarianceComputing</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/PriorKnowledgeAccelerateVarianceComputing.html">&lt;p&gt;Variance is a basic metric to evaluate the degree of data dispersion, and it is also frequently used in the realm of statistics. However, due to the computing variance and the large dataset being time-consuming, there is an urge to accelerate this computing process. The paper suggests a new method to reduce the time of this computation, it assumes a scenario in which we already know the variance of the original dataset, and the whole variance of this merge dataset could be expressed in the form of addition between the original variance and a remainder term. When we want to calculate the total variance after this adds up, the method only needs to calculate the remainder to get the result instead of recalculating the total variance again, which we named this type of method as PKA(Prior Knowledge Acceleration). The paper mathematically proves the effectiveness of PKA in variance calculation, and the conditions for this method to accelerate properly.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21922&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jiawen Li</name></author><category term="stat.CO," /><category term="stat.TH" /><summary type="html">Variance is a basic metric to evaluate the degree of data dispersion, and it is also frequently used in the realm of statistics. However, due to the computing variance and the large dataset being time-consuming, there is an urge to accelerate this computing process. The paper suggests a new method to reduce the time of this computation, it assumes a scenario in which we already know the variance of the original dataset, and the whole variance of this merge dataset could be expressed in the form of addition between the original variance and a remainder term. When we want to calculate the total variance after this adds up, the method only needs to calculate the remainder to get the result instead of recalculating the total variance again, which we named this type of method as PKA(Prior Knowledge Acceleration). The paper mathematically proves the effectiveness of PKA in variance calculation, and the conditions for this method to accelerate properly.</summary></entry><entry><title type="html">Privacy-Preserving Dynamic Assortment Selection</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/PrivacyPreservingDynamicAssortmentSelection.html" rel="alternate" type="text/html" title="Privacy-Preserving Dynamic Assortment Selection" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/PrivacyPreservingDynamicAssortmentSelection</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/PrivacyPreservingDynamicAssortmentSelection.html">&lt;p&gt;With the growing demand for personalized assortment recommendations, concerns over data privacy have intensified, highlighting the urgent need for effective privacy-preserving strategies. This paper presents a novel framework for privacy-preserving dynamic assortment selection using the multinomial logit (MNL) bandits model. Our approach employs a perturbed upper confidence bound method, integrating calibrated noise into user utility estimates to balance between exploration and exploitation while ensuring robust privacy protection. We rigorously prove that our policy satisfies Joint Differential Privacy (JDP), which better suits dynamic environments than traditional differential privacy, effectively mitigating inference attack risks. This analysis is built upon a novel objective perturbation technique tailored for MNL bandits, which is also of independent interest. Theoretically, we derive a near-optimal regret bound of $\tilde{O}(\sqrt{T})$ for our policy and explicitly quantify how privacy protection impacts regret. Through extensive simulations and an application to the Expedia hotel dataset, we demonstrate substantial performance enhancements over the benchmark method.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22488&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Young Hyun Cho, Will Wei Sun</name></author><category term="stat.ML" /><summary type="html">With the growing demand for personalized assortment recommendations, concerns over data privacy have intensified, highlighting the urgent need for effective privacy-preserving strategies. This paper presents a novel framework for privacy-preserving dynamic assortment selection using the multinomial logit (MNL) bandits model. Our approach employs a perturbed upper confidence bound method, integrating calibrated noise into user utility estimates to balance between exploration and exploitation while ensuring robust privacy protection. We rigorously prove that our policy satisfies Joint Differential Privacy (JDP), which better suits dynamic environments than traditional differential privacy, effectively mitigating inference attack risks. This analysis is built upon a novel objective perturbation technique tailored for MNL bandits, which is also of independent interest. Theoretically, we derive a near-optimal regret bound of $\tilde{O}(\sqrt{T})$ for our policy and explicitly quantify how privacy protection impacts regret. Through extensive simulations and an application to the Expedia hotel dataset, we demonstrate substantial performance enhancements over the benchmark method.</summary></entry><entry><title type="html">Progression: an extrapolation principle for regression</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Progressionanextrapolationprincipleforregression.html" rel="alternate" type="text/html" title="Progression: an extrapolation principle for regression" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Progressionanextrapolationprincipleforregression</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Progressionanextrapolationprincipleforregression.html">&lt;p&gt;The problem of regression extrapolation, or out-of-distribution generalization, arises when predictions are required at test points outside the range of the training data. In such cases, the non-parametric guarantees for regression methods from both statistics and machine learning typically fail. Based on the theory of tail dependence, we propose a novel statistical extrapolation principle. After a suitable, data-adaptive marginal transformation, it assumes a simple relationship between predictors and the response at the boundary of the training predictor samples. This assumption holds for a wide range of models, including non-parametric regression functions with additive noise. Our semi-parametric method, progression, leverages this extrapolation principle and offers guarantees on the approximation error beyond the training data range. We demonstrate how this principle can be effectively integrated with existing approaches, such as random forests and additive models, to improve extrapolation performance on out-of-distribution samples.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23246&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Gloria Buriticá, Sebastian Engelke</name></author><category term="stat.ME," /><category term="stat.ML" /><summary type="html">The problem of regression extrapolation, or out-of-distribution generalization, arises when predictions are required at test points outside the range of the training data. In such cases, the non-parametric guarantees for regression methods from both statistics and machine learning typically fail. Based on the theory of tail dependence, we propose a novel statistical extrapolation principle. After a suitable, data-adaptive marginal transformation, it assumes a simple relationship between predictors and the response at the boundary of the training predictor samples. This assumption holds for a wide range of models, including non-parametric regression functions with additive noise. Our semi-parametric method, progression, leverages this extrapolation principle and offers guarantees on the approximation error beyond the training data range. We demonstrate how this principle can be effectively integrated with existing approaches, such as random forests and additive models, to improve extrapolation performance on out-of-distribution samples.</summary></entry><entry><title type="html">Propensity Score Methods for Local Test Score Equating: Stratification and Inverse Probability Weighting</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/PropensityScoreMethodsforLocalTestScoreEquatingStratificationandInverseProbabilityWeighting.html" rel="alternate" type="text/html" title="Propensity Score Methods for Local Test Score Equating: Stratification and Inverse Probability Weighting" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/PropensityScoreMethodsforLocalTestScoreEquatingStratificationandInverseProbabilityWeighting</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/PropensityScoreMethodsforLocalTestScoreEquatingStratificationandInverseProbabilityWeighting.html">&lt;p&gt;In test equating, ensuring score comparability across different test forms is crucial but particularly challenging when test groups are non-equivalent and no anchor test is available. Local test equating aims to satisfy Lord’s equity requirement by conditioning equating transformations on individual-level information, typically using anchor test scores as proxies for latent ability. However, anchor tests are not always available in practice. This paper introduces two novel propensity score-based methods for local equating: stratification and inverse probability weighting (IPW). These methods use covariates to account for group differences, with propensity scores serving as proxies for latent ability differences between test groups. The stratification method partitions examinees into comparable groups based on similar propensity scores, while IPW assigns weights inversely proportional to the probability of group membership. We evaluate these methods through empirical analysis and simulation studies. Results indicate both methods can effectively adjust for group differences, with their relative performance depending on the strength of covariate-ability correlations. The study extends local equating methodology to cases where only covariate information is available, providing testing programs with new tools for ensuring fair score comparability.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22989&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Gabriel Wallin, Marie Wiberg</name></author><category term="stat.ME," /><category term="stat.AP" /><summary type="html">In test equating, ensuring score comparability across different test forms is crucial but particularly challenging when test groups are non-equivalent and no anchor test is available. Local test equating aims to satisfy Lord’s equity requirement by conditioning equating transformations on individual-level information, typically using anchor test scores as proxies for latent ability. However, anchor tests are not always available in practice. This paper introduces two novel propensity score-based methods for local equating: stratification and inverse probability weighting (IPW). These methods use covariates to account for group differences, with propensity scores serving as proxies for latent ability differences between test groups. The stratification method partitions examinees into comparable groups based on similar propensity scores, while IPW assigns weights inversely proportional to the probability of group membership. We evaluate these methods through empirical analysis and simulation studies. Results indicate both methods can effectively adjust for group differences, with their relative performance depending on the strength of covariate-ability correlations. The study extends local equating methodology to cases where only covariate information is available, providing testing programs with new tools for ensuring fair score comparability.</summary></entry><entry><title type="html">Provable acceleration for diffusion models under minimal assumptions</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Provableaccelerationfordiffusionmodelsunderminimalassumptions.html" rel="alternate" type="text/html" title="Provable acceleration for diffusion models under minimal assumptions" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Provableaccelerationfordiffusionmodelsunderminimalassumptions</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Provableaccelerationfordiffusionmodelsunderminimalassumptions.html">&lt;p&gt;While score-based diffusion models have achieved exceptional sampling quality, their sampling speeds are often limited by the high computational burden of score function evaluations. Despite the recent remarkable empirical advances in speeding up the score-based samplers, theoretical understanding of acceleration techniques remains largely limited. To bridge this gap, we propose a novel training-free acceleration scheme for stochastic samplers. Under minimal assumptions – namely, $L^2$-accurate score estimates and a finite second-moment condition on the target distribution – our accelerated sampler provably achieves $\varepsilon$-accuracy in total variation within $\widetilde{O}(d^{5/4}/\sqrt{\varepsilon})$ iterations, thereby significantly improving upon the $\widetilde{O}(d/\varepsilon)$ iteration complexity of standard score-based samplers. Notably, our convergence theory does not rely on restrictive assumptions on the target distribution or higher-order score estimation guarantees.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23285&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Gen Li, Changxiao Cai</name></author><category term="stat.ML" /><summary type="html">While score-based diffusion models have achieved exceptional sampling quality, their sampling speeds are often limited by the high computational burden of score function evaluations. Despite the recent remarkable empirical advances in speeding up the score-based samplers, theoretical understanding of acceleration techniques remains largely limited. To bridge this gap, we propose a novel training-free acceleration scheme for stochastic samplers. Under minimal assumptions – namely, $L^2$-accurate score estimates and a finite second-moment condition on the target distribution – our accelerated sampler provably achieves $\varepsilon$-accuracy in total variation within $\widetilde{O}(d^{5/4}/\sqrt{\varepsilon})$ iterations, thereby significantly improving upon the $\widetilde{O}(d/\varepsilon)$ iteration complexity of standard score-based samplers. Notably, our convergence theory does not rely on restrictive assumptions on the target distribution or higher-order score estimation guarantees.</summary></entry><entry><title type="html">Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ProvablyOptimalMemoryCapacityforModernHopfieldModelsTransformerCompatibleDenseAssociativeMemoriesasSphericalCodes.html" rel="alternate" type="text/html" title="Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ProvablyOptimalMemoryCapacityforModernHopfieldModelsTransformerCompatibleDenseAssociativeMemoriesasSphericalCodes</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ProvablyOptimalMemoryCapacityforModernHopfieldModelsTransformerCompatibleDenseAssociativeMemoriesasSphericalCodes.html">&lt;p&gt;We study the optimal memorization capacity of modern Hopfield models and Kernelized Hopfield Models (KHMs), a transformer-compatible class of Dense Associative Memories. We present a tight analysis by establishing a connection between the memory configuration of KHMs and spherical codes from information theory. Specifically, we treat the stored memory set as a specialized spherical code. This enables us to cast the memorization problem in KHMs into a point arrangement problem on a hypersphere. We show that the optimal capacity of KHMs occurs when the feature space allows memories to form an optimal spherical code. This unique perspective leads to: (i) An analysis of how KHMs achieve optimal memory capacity, and identify corresponding necessary conditions. Importantly, we establish an upper capacity bound that matches the well-known exponential lower bound in the literature. This provides the first tight and optimal asymptotic memory capacity for modern Hopfield models. (ii) A sub-linear time algorithm $\mathtt{U}\text{-}\mathtt{Hop}$+ to reach KHMs’ optimal capacity. (iii) An analysis of the scaling behavior of the required feature dimension relative to the number of stored memories. These efforts improve both the retrieval capability of KHMs and the representation learning of corresponding transformers. Experimentally, we provide thorough numerical results to back up theoretical findings.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23126&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jerry Yao-Chieh Hu, Dennis Wu, Han Liu</name></author><category term="stat.ML" /><summary type="html">We study the optimal memorization capacity of modern Hopfield models and Kernelized Hopfield Models (KHMs), a transformer-compatible class of Dense Associative Memories. We present a tight analysis by establishing a connection between the memory configuration of KHMs and spherical codes from information theory. Specifically, we treat the stored memory set as a specialized spherical code. This enables us to cast the memorization problem in KHMs into a point arrangement problem on a hypersphere. We show that the optimal capacity of KHMs occurs when the feature space allows memories to form an optimal spherical code. This unique perspective leads to: (i) An analysis of how KHMs achieve optimal memory capacity, and identify corresponding necessary conditions. Importantly, we establish an upper capacity bound that matches the well-known exponential lower bound in the literature. This provides the first tight and optimal asymptotic memory capacity for modern Hopfield models. (ii) A sub-linear time algorithm $\mathtt{U}\text{-}\mathtt{Hop}$+ to reach KHMs’ optimal capacity. (iii) An analysis of the scaling behavior of the required feature dimension relative to the number of stored memories. These efforts improve both the retrieval capability of KHMs and the representation learning of corresponding transformers. Experimentally, we provide thorough numerical results to back up theoretical findings.</summary></entry><entry><title type="html">QWO: Speeding Up Permutation-Based Causal Discovery in LiGAMs</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/QWOSpeedingUpPermutationBasedCausalDiscoveryinLiGAMs.html" rel="alternate" type="text/html" title="QWO: Speeding Up Permutation-Based Causal Discovery in LiGAMs" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/QWOSpeedingUpPermutationBasedCausalDiscoveryinLiGAMs</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/QWOSpeedingUpPermutationBasedCausalDiscoveryinLiGAMs.html">&lt;p&gt;Causal discovery is essential for understanding relationships among variables of interest in many scientific domains. In this paper, we focus on permutation-based methods for learning causal graphs in Linear Gaussian Acyclic Models (LiGAMs), where the permutation encodes a causal ordering of the variables. Existing methods in this setting are not scalable due to their high computational complexity. These methods are comprised of two main components: (i) constructing a specific DAG, $\mathcal{G}^\pi$, for a given permutation $\pi$, which represents the best structure that can be learned from the available data while adhering to $\pi$, and (ii) searching over the space of permutations (i.e., causal orders) to minimize the number of edges in $\mathcal{G}^\pi$. We introduce QWO, a novel approach that significantly enhances the efficiency of computing $\mathcal{G}^\pi$ for a given permutation $\pi$. QWO has a speed-up of $O(n^2)$ ($n$ is the number of variables) compared to the state-of-the-art BIC-based method, making it highly scalable. We show that our method is theoretically sound and can be integrated into existing search strategies such as GRASP and hill-climbing-based methods to improve their performance.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23155&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Mohammad Shahverdikondori, Ehsan Mokhtarian, Negar Kiyavash</name></author><category term="stat.ME," /><category term="stat.ML" /><summary type="html">Causal discovery is essential for understanding relationships among variables of interest in many scientific domains. In this paper, we focus on permutation-based methods for learning causal graphs in Linear Gaussian Acyclic Models (LiGAMs), where the permutation encodes a causal ordering of the variables. Existing methods in this setting are not scalable due to their high computational complexity. These methods are comprised of two main components: (i) constructing a specific DAG, $\mathcal{G}^\pi$, for a given permutation $\pi$, which represents the best structure that can be learned from the available data while adhering to $\pi$, and (ii) searching over the space of permutations (i.e., causal orders) to minimize the number of edges in $\mathcal{G}^\pi$. We introduce QWO, a novel approach that significantly enhances the efficiency of computing $\mathcal{G}^\pi$ for a given permutation $\pi$. QWO has a speed-up of $O(n^2)$ ($n$ is the number of variables) compared to the state-of-the-art BIC-based method, making it highly scalable. We show that our method is theoretically sound and can be integrated into existing search strategies such as GRASP and hill-climbing-based methods to improve their performance.</summary></entry><entry><title type="html">Research frontiers in ambit stochastics: In memory of Ole E. Barndorff-Nielsen</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ResearchfrontiersinambitstochasticsInmemoryofOleEBarndorffNielsen.html" rel="alternate" type="text/html" title="Research frontiers in ambit stochastics: In memory of Ole E. Barndorff-Nielsen" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ResearchfrontiersinambitstochasticsInmemoryofOleEBarndorffNielsen</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ResearchfrontiersinambitstochasticsInmemoryofOleEBarndorffNielsen.html">&lt;p&gt;This article surveys key aspects of ambit stochastics and remembers Ole E. Barndorff-Nielsen’s important contributions to the foundation and advancement of this new research field over the last two decades. It also highlights some of the emerging trends in ambit stochastics.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.00566&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Fred Espen Benth, Almut E. D. Veraart</name></author><category term="stat.ME," /><category term="stat.AP," /><category term="stat.TH" /><summary type="html">This article surveys key aspects of ambit stochastics and remembers Ole E. Barndorff-Nielsen’s important contributions to the foundation and advancement of this new research field over the last two decades. It also highlights some of the emerging trends in ambit stochastics.</summary></entry><entry><title type="html">Robustifying automatic speech recognition by extracting slowly varying features</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Robustifyingautomaticspeechrecognitionbyextractingslowlyvaryingfeatures.html" rel="alternate" type="text/html" title="Robustifying automatic speech recognition by extracting slowly varying features" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Robustifyingautomaticspeechrecognitionbyextractingslowlyvaryingfeatures</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Robustifyingautomaticspeechrecognitionbyextractingslowlyvaryingfeatures.html">&lt;p&gt;In the past few years, it has been shown that deep learning systems are highly vulnerable under attacks with adversarial examples. Neural-network-based automatic speech recognition (ASR) systems are no exception. Targeted and untargeted attacks can modify an audio input signal in such a way that humans still recognise the same words, while ASR systems are steered to predict a different transcription. In this paper, we propose a defense mechanism against targeted adversarial attacks consisting in removing fast-changing features from the audio signals, either by applying slow feature analysis, a low-pass filter, or both, before feeding the input to the ASR system. We perform an empirical analysis of hybrid ASR models trained on data pre-processed in such a way. While the resulting models perform quite well on benign data, they are significantly more robust against targeted adversarial attacks: Our final, proposed model shows a performance on clean data similar to the baseline model, while being more than four times more robust.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2112.07400&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Matías Pizarro, Dorothea Kolossa, Asja Fischer</name></author><category term="stat.ML" /><summary type="html">In the past few years, it has been shown that deep learning systems are highly vulnerable under attacks with adversarial examples. Neural-network-based automatic speech recognition (ASR) systems are no exception. Targeted and untargeted attacks can modify an audio input signal in such a way that humans still recognise the same words, while ASR systems are steered to predict a different transcription. In this paper, we propose a defense mechanism against targeted adversarial attacks consisting in removing fast-changing features from the audio signals, either by applying slow feature analysis, a low-pass filter, or both, before feeding the input to the ASR system. We perform an empirical analysis of hybrid ASR models trained on data pre-processed in such a way. While the resulting models perform quite well on benign data, they are significantly more robust against targeted adversarial attacks: Our final, proposed model shows a performance on clean data similar to the baseline model, while being more than four times more robust.</summary></entry><entry><title type="html">Robust training of implicit generative models for multivariate and heavy-tailed distributions with an invariant statistical loss</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Robusttrainingofimplicitgenerativemodelsformultivariateandheavytaileddistributionswithaninvariantstatisticalloss.html" rel="alternate" type="text/html" title="Robust training of implicit generative models for multivariate and heavy-tailed distributions with an invariant statistical loss" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Robusttrainingofimplicitgenerativemodelsformultivariateandheavytaileddistributionswithaninvariantstatisticalloss</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Robusttrainingofimplicitgenerativemodelsformultivariateandheavytaileddistributionswithaninvariantstatisticalloss.html">&lt;p&gt;Traditional implicit generative models are capable of learning highly complex data distributions. However, their training involves distinguishing real data from synthetically generated data using adversarial discriminators, which can lead to unstable training dynamics and mode dropping issues. In this work, we build on the \textit{invariant statistical loss} (ISL) method introduced in \cite{de2024training}, and extend it to handle heavy-tailed and multivariate data distributions.
  The data generated by many real-world phenomena can only be properly characterised using heavy-tailed probability distributions, and traditional implicit methods struggle to effectively capture their asymptotic behavior. To address this problem, we introduce a generator trained with ISL, that uses input noise from a generalised Pareto distribution (GPD). We refer to this generative scheme as Pareto-ISL for conciseness. Our experiments demonstrate that Pareto-ISL accurately models the tails of the distributions while still effectively capturing their central characteristics.
  The original ISL function was conceived for 1D data sets. When the actual data is $n$-dimensional, a straightforward extension of the method was obtained by targeting the $n$ marginal distributions of the data. This approach is computationally infeasible and ineffective in high-dimensional spaces. To overcome this, we extend the 1D approach using random projections and define a new loss function suited for multivariate data, keeping problems tractable by adjusting the number of projections. We assess its performance in multidimensional generative modeling and explore its potential as a pretraining technique for generative adversarial networks (GANs) to prevent mode collapse, reporting promising results and highlighting its robustness across various hyperparameter settings.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22381&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>José Manuel de Frutos, Manuel A. Vázquez, Pablo Olmos, Joaquín Míguez</name></author><category term="stat.CO," /><category term="stat.ML" /><summary type="html">Traditional implicit generative models are capable of learning highly complex data distributions. However, their training involves distinguishing real data from synthetically generated data using adversarial discriminators, which can lead to unstable training dynamics and mode dropping issues. In this work, we build on the \textit{invariant statistical loss} (ISL) method introduced in \cite{de2024training}, and extend it to handle heavy-tailed and multivariate data distributions. The data generated by many real-world phenomena can only be properly characterised using heavy-tailed probability distributions, and traditional implicit methods struggle to effectively capture their asymptotic behavior. To address this problem, we introduce a generator trained with ISL, that uses input noise from a generalised Pareto distribution (GPD). We refer to this generative scheme as Pareto-ISL for conciseness. Our experiments demonstrate that Pareto-ISL accurately models the tails of the distributions while still effectively capturing their central characteristics. The original ISL function was conceived for 1D data sets. When the actual data is $n$-dimensional, a straightforward extension of the method was obtained by targeting the $n$ marginal distributions of the data. This approach is computationally infeasible and ineffective in high-dimensional spaces. To overcome this, we extend the 1D approach using random projections and define a new loss function suited for multivariate data, keeping problems tractable by adjusting the number of projections. We assess its performance in multidimensional generative modeling and explore its potential as a pretraining technique for generative adversarial networks (GANs) to prevent mode collapse, reporting promising results and highlighting its robustness across various hyperparameter settings.</summary></entry><entry><title type="html">Scaling Laws in Linear Regression: Compute, Parameters, and Data</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ScalingLawsinLinearRegressionComputeParametersandData.html" rel="alternate" type="text/html" title="Scaling Laws in Linear Regression: Compute, Parameters, and Data" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ScalingLawsinLinearRegressionComputeParametersandData</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ScalingLawsinLinearRegressionComputeParametersandData.html">&lt;p&gt;Empirically, large-scale deep learning models often satisfy a neural scaling law: the test error of the trained model improves polynomially as the model size and data size grow. However, conventional wisdom suggests the test error consists of approximation, bias, and variance errors, where the variance error increases with model size. This disagrees with the general form of neural scaling laws, which predict that increasing model size monotonically improves performance.
  We study the theory of scaling laws in an infinite dimensional linear regression setup. Specifically, we consider a model with $M$ parameters as a linear function of sketched covariates. The model is trained by one-pass stochastic gradient descent (SGD) using $N$ data. Assuming the optimal parameter satisfies a Gaussian prior and the data covariance matrix has a power-law spectrum of degree $a&amp;gt;1$, we show that the reducible part of the test error is $\Theta(M^{-(a-1)} + N^{-(a-1)/a})$. The variance error, which increases with $M$, is dominated by the other errors due to the implicit regularization of SGD, thus disappearing from the bound. Our theory is consistent with the empirical neural scaling laws and verified by numerical simulation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.08466&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Licong Lin, Jingfeng Wu, Sham M. Kakade, Peter L. Bartlett, Jason D. Lee</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">Empirically, large-scale deep learning models often satisfy a neural scaling law: the test error of the trained model improves polynomially as the model size and data size grow. However, conventional wisdom suggests the test error consists of approximation, bias, and variance errors, where the variance error increases with model size. This disagrees with the general form of neural scaling laws, which predict that increasing model size monotonically improves performance. We study the theory of scaling laws in an infinite dimensional linear regression setup. Specifically, we consider a model with $M$ parameters as a linear function of sketched covariates. The model is trained by one-pass stochastic gradient descent (SGD) using $N$ data. Assuming the optimal parameter satisfies a Gaussian prior and the data covariance matrix has a power-law spectrum of degree $a&amp;gt;1$, we show that the reducible part of the test error is $\Theta(M^{-(a-1)} + N^{-(a-1)/a})$. The variance error, which increases with $M$, is dominated by the other errors due to the implicit regularization of SGD, thus disappearing from the bound. Our theory is consistent with the empirical neural scaling laws and verified by numerical simulation.</summary></entry><entry><title type="html">Schur’s Positive-Definite Network: Deep Learning in the SPD cone with structure</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/SchursPositiveDefiniteNetworkDeepLearningintheSPDconewithstructure.html" rel="alternate" type="text/html" title="Schur’s Positive-Definite Network: Deep Learning in the SPD cone with structure" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/SchursPositiveDefiniteNetworkDeepLearningintheSPDconewithstructure</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/SchursPositiveDefiniteNetworkDeepLearningintheSPDconewithstructure.html">&lt;p&gt;Estimating matrices in the symmetric positive-definite (SPD) cone is of interest for many applications ranging from computer vision to graph learning. While there exist various convex optimization-based estimators, they remain limited in expressivity due to their model-based approach. The success of deep learning motivates the use of learning-based approaches to estimate SPD matrices with neural networks in a data-driven fashion. However, designing effective neural architectures for SPD learning is challenging, particularly when the task requires additional structural constraints, such as element-wise sparsity. Current approaches either do not ensure that the output meets all desired properties or lack expressivity. In this paper, we introduce SpodNet, a novel and generic learning module that guarantees SPD outputs and supports additional structural constraints. Notably, it solves the challenging task of learning jointly SPD and sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.09023&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Can Pouliquen, Mathurin Massias, Titouan Vayer</name></author><category term="stat.ML" /><summary type="html">Estimating matrices in the symmetric positive-definite (SPD) cone is of interest for many applications ranging from computer vision to graph learning. While there exist various convex optimization-based estimators, they remain limited in expressivity due to their model-based approach. The success of deep learning motivates the use of learning-based approaches to estimate SPD matrices with neural networks in a data-driven fashion. However, designing effective neural architectures for SPD learning is challenging, particularly when the task requires additional structural constraints, such as element-wise sparsity. Current approaches either do not ensure that the output meets all desired properties or lack expressivity. In this paper, we introduce SpodNet, a novel and generic learning module that guarantees SPD outputs and supports additional structural constraints. Notably, it solves the challenging task of learning jointly SPD and sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.</summary></entry><entry><title type="html">Score-based Causal Representation Learning: Linear and General Transformations</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ScorebasedCausalRepresentationLearningLinearandGeneralTransformations.html" rel="alternate" type="text/html" title="Score-based Causal Representation Learning: Linear and General Transformations" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ScorebasedCausalRepresentationLearningLinearandGeneralTransformations</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ScorebasedCausalRepresentationLearningLinearandGeneralTransformations.html">&lt;p&gt;This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to ancestors for general causal models and perfect latent graph recovery for sufficiently non-linear causal models. Secondly, it focuses on general transformations and shows that two stochastic hard interventions per node suffice for identifiability. Notably, one does not need to know which pair of interventional environments have the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.00849&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Burak Var{\i}c{\i}, Emre Acartürk, Karthikeyan Shanmugam, Abhishek Kumar, Ali Tajer</name></author><category term="stat.ML" /><summary type="html">This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to ancestors for general causal models and perfect latent graph recovery for sufficiently non-linear causal models. Secondly, it focuses on general transformations and shows that two stochastic hard interventions per node suffice for identifiability. Notably, one does not need to know which pair of interventional environments have the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data.</summary></entry><entry><title type="html">Sketchy Moment Matching: Toward Fast and Provable Data Selection for Finetuning</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/SketchyMomentMatchingTowardFastandProvableDataSelectionforFinetuning.html" rel="alternate" type="text/html" title="Sketchy Moment Matching: Toward Fast and Provable Data Selection for Finetuning" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/SketchyMomentMatchingTowardFastandProvableDataSelectionforFinetuning</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/SketchyMomentMatchingTowardFastandProvableDataSelectionforFinetuning.html">&lt;p&gt;We revisit data selection in a modern context of finetuning from a fundamental perspective. Extending the classical wisdom of variance minimization in low dimensions to high-dimensional finetuning, our generalization analysis unveils the importance of additionally reducing bias induced by low-rank approximation. Inspired by the variance-bias tradeoff in high dimensions from the theory, we introduce Sketchy Moment Matching (SkMM), a scalable data selection scheme with two stages. (i) First, the bias is controlled using gradient sketching that explores the finetuning parameter space for an informative low-dimensional subspace $\mathcal{S}$; (ii) then the variance is reduced over $\mathcal{S}$ via moment matching between the original and selected datasets. Theoretically, we show that gradient sketching is fast and provably accurate: selecting $n$ samples by reducing variance over $\mathcal{S}$ preserves the fast-rate generalization $O(\dim(\mathcal{S})/n)$, independent of the parameter dimension. Empirically, we concretize the variance-bias balance via synthetic experiments and demonstrate the effectiveness of SkMM for finetuning in real vision tasks.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2407.06120&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yijun Dong, Hoang Phan, Xiang Pan, Qi Lei</name></author><category term="stat.ML" /><summary type="html">We revisit data selection in a modern context of finetuning from a fundamental perspective. Extending the classical wisdom of variance minimization in low dimensions to high-dimensional finetuning, our generalization analysis unveils the importance of additionally reducing bias induced by low-rank approximation. Inspired by the variance-bias tradeoff in high dimensions from the theory, we introduce Sketchy Moment Matching (SkMM), a scalable data selection scheme with two stages. (i) First, the bias is controlled using gradient sketching that explores the finetuning parameter space for an informative low-dimensional subspace $\mathcal{S}$; (ii) then the variance is reduced over $\mathcal{S}$ via moment matching between the original and selected datasets. Theoretically, we show that gradient sketching is fast and provably accurate: selecting $n$ samples by reducing variance over $\mathcal{S}$ preserves the fast-rate generalization $O(\dim(\mathcal{S})/n)$, independent of the parameter dimension. Empirically, we concretize the variance-bias balance via synthetic experiments and demonstrate the effectiveness of SkMM for finetuning in real vision tasks.</summary></entry><entry><title type="html">Solving Quadratic Systems with Full-Rank Matrices Using Sparse or Generative Priors</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/SolvingQuadraticSystemswithFullRankMatricesUsingSparseorGenerativePriors.html" rel="alternate" type="text/html" title="Solving Quadratic Systems with Full-Rank Matrices Using Sparse or Generative Priors" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/SolvingQuadraticSystemswithFullRankMatricesUsingSparseorGenerativePriors</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/SolvingQuadraticSystemswithFullRankMatricesUsingSparseorGenerativePriors.html">&lt;p&gt;The problem of recovering a signal $\boldsymbol x\in \mathbb{R}^n$ from a quadratic system ${y_i=\boldsymbol x^\top\boldsymbol A_i\boldsymbol x,\ i=1,\ldots,m}$ with full-rank matrices $\boldsymbol A_i$ frequently arises in applications such as unassigned distance geometry and sub-wavelength imaging. With i.i.d. standard Gaussian matrices $\boldsymbol A_i$, this paper addresses the high-dimensional case where $m\ll n$ by incorporating prior knowledge of $\boldsymbol x$. First, we consider a $k$-sparse $\boldsymbol x$ and introduce the thresholded Wirtinger flow (TWF) algorithm that does not require the sparsity level $k$. TWF comprises two steps: the spectral initialization that identifies a point sufficiently close to $\boldsymbol x$ (up to a sign flip) when $m=O(k^2\log n)$, and the thresholded gradient descent which, when provided a good initialization, produces a sequence linearly converging to $\boldsymbol x$ with $m=O(k\log n)$ measurements. Second, we explore the generative prior, assuming that $x$ lies in the range of an $L$-Lipschitz continuous generative model with $k$-dimensional inputs in an $\ell_2$-ball of radius $r$. With an estimate correlated with the signal, we develop the projected gradient descent (PGD) algorithm that also comprises two steps: the projected power method that provides an initial vector with $O\big(\sqrt{\frac{k \log L}{m}}\big)$ $\ell_2$-error given $m=O(k\log(Lnr))$ measurements, and the projected gradient descent that refines the $\ell_2$-error to $O(\delta)$ at a geometric rate when $m=O(k\log\frac{Lrn}{\delta^2})$. Experimental results corroborate our theoretical findings and show that: (i) our approach for the sparse case notably outperforms the existing provable algorithm sparse power factorization; (ii) leveraging the generative prior allows for precise image recovery in the MNIST dataset from a small number of quadratic measurements.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2309.09032&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Junren Chen, Michael K. Ng, Zhaoqiang Liu</name></author><category term="stat.ML" /><summary type="html">The problem of recovering a signal $\boldsymbol x\in \mathbb{R}^n$ from a quadratic system ${y_i=\boldsymbol x^\top\boldsymbol A_i\boldsymbol x,\ i=1,\ldots,m}$ with full-rank matrices $\boldsymbol A_i$ frequently arises in applications such as unassigned distance geometry and sub-wavelength imaging. With i.i.d. standard Gaussian matrices $\boldsymbol A_i$, this paper addresses the high-dimensional case where $m\ll n$ by incorporating prior knowledge of $\boldsymbol x$. First, we consider a $k$-sparse $\boldsymbol x$ and introduce the thresholded Wirtinger flow (TWF) algorithm that does not require the sparsity level $k$. TWF comprises two steps: the spectral initialization that identifies a point sufficiently close to $\boldsymbol x$ (up to a sign flip) when $m=O(k^2\log n)$, and the thresholded gradient descent which, when provided a good initialization, produces a sequence linearly converging to $\boldsymbol x$ with $m=O(k\log n)$ measurements. Second, we explore the generative prior, assuming that $x$ lies in the range of an $L$-Lipschitz continuous generative model with $k$-dimensional inputs in an $\ell_2$-ball of radius $r$. With an estimate correlated with the signal, we develop the projected gradient descent (PGD) algorithm that also comprises two steps: the projected power method that provides an initial vector with $O\big(\sqrt{\frac{k \log L}{m}}\big)$ $\ell_2$-error given $m=O(k\log(Lnr))$ measurements, and the projected gradient descent that refines the $\ell_2$-error to $O(\delta)$ at a geometric rate when $m=O(k\log\frac{Lrn}{\delta^2})$. Experimental results corroborate our theoretical findings and show that: (i) our approach for the sparse case notably outperforms the existing provable algorithm sparse power factorization; (ii) leveraging the generative prior allows for precise image recovery in the MNIST dataset from a small number of quadratic measurements.</summary></entry><entry><title type="html">Spatial Interference Detection in Treatment Effect Model</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/SpatialInterferenceDetectioninTreatmentEffectModel.html" rel="alternate" type="text/html" title="Spatial Interference Detection in Treatment Effect Model" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/SpatialInterferenceDetectioninTreatmentEffectModel</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/SpatialInterferenceDetectioninTreatmentEffectModel.html">&lt;p&gt;Modeling the interference effect is an important issue in the field of causal inference. Existing studies rely on explicit and often homogeneous assumptions regarding interference structures. In this paper, we introduce a low-rank and sparse treatment effect model that leverages data-driven techniques to identify the locations of interference effects. A profiling algorithm is proposed to estimate the model coefficients, and based on these estimates, global test and local detection methods are established to detect the existence of interference and the interference neighbor locations for each unit. We derive the non-asymptotic bound of the estimation error, and establish theoretical guarantees for the global test and the accuracy of the detection method in terms of Jaccard index. Simulations and real data examples are provided to demonstrate the usefulness of the proposed method.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2409.04836&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Wei Zhang, Ying Yang, Fang Yao</name></author><category term="stat.ME" /><summary type="html">Modeling the interference effect is an important issue in the field of causal inference. Existing studies rely on explicit and often homogeneous assumptions regarding interference structures. In this paper, we introduce a low-rank and sparse treatment effect model that leverages data-driven techniques to identify the locations of interference effects. A profiling algorithm is proposed to estimate the model coefficients, and based on these estimates, global test and local detection methods are established to detect the existence of interference and the interference neighbor locations for each unit. We derive the non-asymptotic bound of the estimation error, and establish theoretical guarantees for the global test and the accuracy of the detection method in terms of Jaccard index. Simulations and real data examples are provided to demonstrate the usefulness of the proposed method.</summary></entry><entry><title type="html">Spatial Proportional Hazards Model with Differential Regularization</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/SpatialProportionalHazardsModelwithDifferentialRegularization.html" rel="alternate" type="text/html" title="Spatial Proportional Hazards Model with Differential Regularization" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/SpatialProportionalHazardsModelwithDifferentialRegularization</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/SpatialProportionalHazardsModelwithDifferentialRegularization.html">&lt;p&gt;This paper presents a semiparametric proportional hazards model designed to handle spatially varying covariate functions, applicable to both geostatistical and areal data observed on irregular spatial domains. The model is estimated through the maximization of a penalized partial likelihood, with a roughness penalty term based on a differential of the spatial field over the target domain. The finite element method is employed for efficient estimation, enabling a piecewise polynomial surface representation of the spatial field. We apply this method to analyze response time data from the London Fire Brigade.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.13420&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Lorenzo Tedesco</name></author><category term="stat.ME," /><category term="stat.TH" /><summary type="html">This paper presents a semiparametric proportional hazards model designed to handle spatially varying covariate functions, applicable to both geostatistical and areal data observed on irregular spatial domains. The model is estimated through the maximization of a penalized partial likelihood, with a roughness penalty term based on a differential of the spatial field over the target domain. The finite element method is employed for efficient estimation, enabling a piecewise polynomial surface representation of the spatial field. We apply this method to analyze response time data from the London Fire Brigade.</summary></entry><entry><title type="html">Spectral Graph Pruning Against Over-Squashing and Over-Smoothing</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/SpectralGraphPruningAgainstOverSquashingandOverSmoothing.html" rel="alternate" type="text/html" title="Spectral Graph Pruning Against Over-Squashing and Over-Smoothing" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/SpectralGraphPruningAgainstOverSquashingandOverSmoothing</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/SpectralGraphPruningAgainstOverSquashingandOverSmoothing.html">&lt;p&gt;Message Passing Graph Neural Networks are known to suffer from two problems that are sometimes believed to be diametrically opposed: over-squashing and over-smoothing. The former results from topological bottlenecks that hamper the information flow from distant nodes and are mitigated by spectral gap maximization, primarily, by means of edge additions. However, such additions often promote over-smoothing that renders nodes of different classes less distinguishable. Inspired by the Braess phenomenon, we argue that deleting edges can address over-squashing and over-smoothing simultaneously. This insight explains how edge deletions can improve generalization, thus connecting spectral gap optimization to a seemingly disconnected objective of reducing computational resources by pruning graphs for lottery tickets. To this end, we propose a more effective spectral gap optimization framework to add or delete edges and demonstrate its effectiveness on large heterophilic datasets.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2404.04612&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Adarsh Jamadandi, Celia Rubio-Madrigal, Rebekka Burkholz</name></author><category term="stat.ML" /><summary type="html">Message Passing Graph Neural Networks are known to suffer from two problems that are sometimes believed to be diametrically opposed: over-squashing and over-smoothing. The former results from topological bottlenecks that hamper the information flow from distant nodes and are mitigated by spectral gap maximization, primarily, by means of edge additions. However, such additions often promote over-smoothing that renders nodes of different classes less distinguishable. Inspired by the Braess phenomenon, we argue that deleting edges can address over-squashing and over-smoothing simultaneously. This insight explains how edge deletions can improve generalization, thus connecting spectral gap optimization to a seemingly disconnected objective of reducing computational resources by pruning graphs for lottery tickets. To this end, we propose a more effective spectral gap optimization framework to add or delete edges and demonstrate its effectiveness on large heterophilic datasets.</summary></entry><entry><title type="html">Statistical-Computational Trade-offs for Density Estimation</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/StatisticalComputationalTradeoffsforDensityEstimation.html" rel="alternate" type="text/html" title="Statistical-Computational Trade-offs for Density Estimation" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/StatisticalComputationalTradeoffsforDensityEstimation</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/StatisticalComputationalTradeoffsforDensityEstimation.html">&lt;p&gt;We study the density estimation problem defined as follows: given $k$ distributions $p_1, \ldots, p_k$ over a discrete domain $[n]$, as well as a collection of samples chosen from a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&apos;&apos; distribution $q$ over $[n]$, output $p_i$ that is&lt;/code&gt;close’’ to $q$. Recently~\cite{aamand2023data} gave the first and only known result that achieves sublinear bounds in {\em both} the sampling complexity and the query time while preserving polynomial data structure space. However, their improvement over linear samples and time is only by subpolynomial factors.
  Our main result is a lower bound showing that, for a broad class of data structures, their bounds cannot be significantly improved. In particular, if an algorithm uses $O(n/\log^c k)$ samples for some constant $c&amp;gt;0$ and polynomial space, then the query time of the data structure must be at least $k^{1-O(1)/\log \log k}$, i.e., close to linear in the number of distributions $k$. This is a novel \emph{statistical-computational} trade-off for density estimation, demonstrating that any data structure must use close to a linear number of samples or take close to linear query time. The lower bound holds even in the realizable case where $q=p_i$ for some $i$, and when the distributions are flat (specifically, all distributions are uniform over half of the domain $[n]$). We also give a simple data structure for our lower bound instance with asymptotically matching upper bounds. Experiments show that the data structure is quite efficient in practice.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23087&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Anders Aamand, Alexandr Andoni, Justin Y. Chen, Piotr Indyk, Shyam Narayanan, Sandeep Silwal, Haike Xu</name></author><category term="stat.ML" /><summary type="html">We study the density estimation problem defined as follows: given $k$ distributions $p_1, \ldots, p_k$ over a discrete domain $[n]$, as well as a collection of samples chosen from a query&apos;&apos; distribution $q$ over $[n]$, output $p_i$ that isclose’’ to $q$. Recently~\cite{aamand2023data} gave the first and only known result that achieves sublinear bounds in {\em both} the sampling complexity and the query time while preserving polynomial data structure space. However, their improvement over linear samples and time is only by subpolynomial factors. Our main result is a lower bound showing that, for a broad class of data structures, their bounds cannot be significantly improved. In particular, if an algorithm uses $O(n/\log^c k)$ samples for some constant $c&amp;gt;0$ and polynomial space, then the query time of the data structure must be at least $k^{1-O(1)/\log \log k}$, i.e., close to linear in the number of distributions $k$. This is a novel \emph{statistical-computational} trade-off for density estimation, demonstrating that any data structure must use close to a linear number of samples or take close to linear query time. The lower bound holds even in the realizable case where $q=p_i$ for some $i$, and when the distributions are flat (specifically, all distributions are uniform over half of the domain $[n]$). We also give a simple data structure for our lower bound instance with asymptotically matching upper bounds. Experiments show that the data structure is quite efficient in practice.</summary></entry><entry><title type="html">Structure and inference in hypergraphs with node attributes</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Structureandinferenceinhypergraphswithnodeattributes.html" rel="alternate" type="text/html" title="Structure and inference in hypergraphs with node attributes" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Structureandinferenceinhypergraphswithnodeattributes</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Structureandinferenceinhypergraphswithnodeattributes.html">&lt;p&gt;Many networked datasets with units interacting in groups of two or more, encoded with hypergraphs, are accompanied by extra information about nodes, such as the role of an individual in a workplace. Here we show how these node attributes can be used to improve our understanding of the structure resulting from higher-order interactions. We consider the problem of community detection in hypergraphs and develop a principled model that combines higher-order interactions and node attributes to better represent the observed interactions and to detect communities more accurately than using either of these types of information alone. The method learns automatically from the input data the extent to which structure and attributes contribute to explain the data, down weighing or discarding attributes if not informative. Our algorithmic implementation is efficient and scales to large hypergraphs and interactions of large numbers of units. We apply our method to a variety of systems, showing strong performance in hyperedge prediction tasks and in selecting community divisions that correlate with attributes when these are informative, but discarding them otherwise. Our approach illustrates the advantage of using informative node attributes when available with higher-order data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2311.03857&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Anna Badalyan, Nicolò Ruggeri, Caterina De Bacco</name></author><category term="stat.ML" /><summary type="html">Many networked datasets with units interacting in groups of two or more, encoded with hypergraphs, are accompanied by extra information about nodes, such as the role of an individual in a workplace. Here we show how these node attributes can be used to improve our understanding of the structure resulting from higher-order interactions. We consider the problem of community detection in hypergraphs and develop a principled model that combines higher-order interactions and node attributes to better represent the observed interactions and to detect communities more accurately than using either of these types of information alone. The method learns automatically from the input data the extent to which structure and attributes contribute to explain the data, down weighing or discarding attributes if not informative. Our algorithmic implementation is efficient and scales to large hypergraphs and interactions of large numbers of units. We apply our method to a variety of systems, showing strong performance in hyperedge prediction tasks and in selecting community divisions that correlate with attributes when these are informative, but discarding them otherwise. Our approach illustrates the advantage of using informative node attributes when available with higher-order data.</summary></entry><entry><title type="html">Structured Learning of Compositional Sequential Interventions</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/StructuredLearningofCompositionalSequentialInterventions.html" rel="alternate" type="text/html" title="Structured Learning of Compositional Sequential Interventions" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/StructuredLearningofCompositionalSequentialInterventions</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/StructuredLearningofCompositionalSequentialInterventions.html">&lt;p&gt;We consider sequential treatment regimes where each unit is exposed to combinations of interventions over time. When interventions are described by qualitative labels, such as “close schools for a month due to a pandemic” or “promote this podcast to this user during this week”, it is unclear which appropriate structural assumptions allow us to generalize behavioral predictions to previously unseen combinations of interventions. Standard black-box approaches mapping sequences of categorical variables to outputs are applicable, but they rely on poorly understood assumptions on how reliable generalization can be obtained, and may underperform under sparse sequences, temporal variability, and large action spaces. To approach that, we pose an explicit model for composition, that is, how the effect of sequential interventions can be isolated into modules, clarifying which data conditions allow for the identification of their combined effect at different units and time steps. We show the identification properties of our compositional model, inspired by advances in causal matrix factorization methods. Our focus is on predictive models for novel compositions of interventions instead of matrix completion tasks and causal effect estimation. We compare our approach to flexible but generic black-box models to illustrate how structure aids prediction in sparse data conditions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.05745&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jialin Yu, Andreas Koukorinis, Nicolò Colombo, Yuchen Zhu, Ricardo Silva</name></author><category term="stat.ML" /><summary type="html">We consider sequential treatment regimes where each unit is exposed to combinations of interventions over time. When interventions are described by qualitative labels, such as “close schools for a month due to a pandemic” or “promote this podcast to this user during this week”, it is unclear which appropriate structural assumptions allow us to generalize behavioral predictions to previously unseen combinations of interventions. Standard black-box approaches mapping sequences of categorical variables to outputs are applicable, but they rely on poorly understood assumptions on how reliable generalization can be obtained, and may underperform under sparse sequences, temporal variability, and large action spaces. To approach that, we pose an explicit model for composition, that is, how the effect of sequential interventions can be isolated into modules, clarifying which data conditions allow for the identification of their combined effect at different units and time steps. We show the identification properties of our compositional model, inspired by advances in causal matrix factorization methods. Our focus is on predictive models for novel compositions of interventions instead of matrix completion tasks and causal effect estimation. We compare our approach to flexible but generic black-box models to illustrate how structure aids prediction in sparse data conditions.</summary></entry><entry><title type="html">Surface data imputation with stochastic processes</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Surfacedataimputationwithstochasticprocesses.html" rel="alternate" type="text/html" title="Surface data imputation with stochastic processes" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Surfacedataimputationwithstochasticprocesses</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Surfacedataimputationwithstochasticprocesses.html">&lt;p&gt;Spurious measurements in surface data are common in technical surfaces. Excluding or ignoring these spurious points may lead to incorrect surface characterization if these points inherit features of the surface. Therefore, data imputation must be applied to ensure that the estimated data points at spurious measurements do not strongly deviate from the true surface and its characteristics. Traditional surface data imputation methods rely on simple assumptions and ignore existing knowledge of the surface, yielding in suboptimal estimates. In this paper, we propose using stochastic processes for data imputation. This approach, which originates from surface simulation, allows for the straightforward integration of a priori knowledge. We employ Gaussian processes for surface data imputation with artificially generated missing features. Both the surfaces and the missing features are generated artificially. Our results demonstrate that the proposed method fills the missing values and interpolates data points with better alignment to the measured surface compared to traditional approaches, particularly when surface features are missing.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22824&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Arsalan Jawaid, Samuel Schmidt, Jörg Seewig</name></author><category term="stat.ME" /><summary type="html">Spurious measurements in surface data are common in technical surfaces. Excluding or ignoring these spurious points may lead to incorrect surface characterization if these points inherit features of the surface. Therefore, data imputation must be applied to ensure that the estimated data points at spurious measurements do not strongly deviate from the true surface and its characteristics. Traditional surface data imputation methods rely on simple assumptions and ignore existing knowledge of the surface, yielding in suboptimal estimates. In this paper, we propose using stochastic processes for data imputation. This approach, which originates from surface simulation, allows for the straightforward integration of a priori knowledge. We employ Gaussian processes for surface data imputation with artificially generated missing features. Both the surfaces and the missing features are generated artificially. Our results demonstrate that the proposed method fills the missing values and interpolates data points with better alignment to the measured surface compared to traditional approaches, particularly when surface features are missing.</summary></entry><entry><title type="html">The DeepJoint algorithm: An innovative approach for studying the longitudinal evolution of quantitative mammographic density and its association with screen-detected breast cancer risk</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/TheDeepJointalgorithmAninnovativeapproachforstudyingthelongitudinalevolutionofquantitativemammographicdensityanditsassociationwithscreendetectedbreastcancerrisk.html" rel="alternate" type="text/html" title="The DeepJoint algorithm: An innovative approach for studying the longitudinal evolution of quantitative mammographic density and its association with screen-detected breast cancer risk" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/TheDeepJointalgorithmAninnovativeapproachforstudyingthelongitudinalevolutionofquantitativemammographicdensityanditsassociationwithscreendetectedbreastcancerrisk</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/TheDeepJointalgorithmAninnovativeapproachforstudyingthelongitudinalevolutionofquantitativemammographicdensityanditsassociationwithscreendetectedbreastcancerrisk.html">&lt;p&gt;Mammographic density is a dynamic risk factor for breast cancer and affects the sensitivity of mammography-based screening. While automated machine and deep learning-based methods provide more consistent and precise measurements compared to subjective BI-RADS assessments, they often fail to account for the longitudinal evolution of density. Many of these methods assess mammographic density in a cross-sectional manner, overlooking correlations in repeated measures, irregular visit intervals, missing data, and informative dropouts. Joint models, however, are well-suited for capturing the longitudinal relationship between biomarkers and survival outcomes. We present the DeepJoint algorithm, an open-source solution that integrates deep learning for quantitative mammographic density estimation with joint modeling to assess the longitudinal relationship between mammographic density and breast cancer risk. Our method efficiently analyzes processed mammograms from various manufacturers, estimating both dense area and percent density–established risk factors for breast cancer. We utilize a joint model to explore their association with breast cancer risk and provide individualized risk predictions. Bayesian inference and the Monte Carlo consensus algorithm make the approach reliable for large screening datasets. Our method allows for accurate analysis of processed mammograms from multiple manufacturers, offering a comprehensive view of breast cancer risk based on individual longitudinal density profiles. The complete pipeline is publicly available, promoting broader application and comparison with other methods.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2403.13488&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Manel Rakez, Julien Guillaumin, Aurelien Chick, Gaelle Coureau, Foucauld Chamming&apos;s, Pierre Fillard, Brice Amadeo, Virginie Rondeau</name></author><category term="stat.AP" /><summary type="html">Mammographic density is a dynamic risk factor for breast cancer and affects the sensitivity of mammography-based screening. While automated machine and deep learning-based methods provide more consistent and precise measurements compared to subjective BI-RADS assessments, they often fail to account for the longitudinal evolution of density. Many of these methods assess mammographic density in a cross-sectional manner, overlooking correlations in repeated measures, irregular visit intervals, missing data, and informative dropouts. Joint models, however, are well-suited for capturing the longitudinal relationship between biomarkers and survival outcomes. We present the DeepJoint algorithm, an open-source solution that integrates deep learning for quantitative mammographic density estimation with joint modeling to assess the longitudinal relationship between mammographic density and breast cancer risk. Our method efficiently analyzes processed mammograms from various manufacturers, estimating both dense area and percent density–established risk factors for breast cancer. We utilize a joint model to explore their association with breast cancer risk and provide individualized risk predictions. Bayesian inference and the Monte Carlo consensus algorithm make the approach reliable for large screening datasets. Our method allows for accurate analysis of processed mammograms from multiple manufacturers, offering a comprehensive view of breast cancer risk based on individual longitudinal density profiles. The complete pipeline is publicly available, promoting broader application and comparison with other methods.</summary></entry><entry><title type="html">The Road Less Scheduled</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/TheRoadLessScheduled.html" rel="alternate" type="text/html" title="The Road Less Scheduled" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/TheRoadLessScheduled</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/TheRoadLessScheduled.html">&lt;p&gt;Existing learning rate schedules that do not require specification of the optimization stopping step T are greatly out-performed by learning rate schedules that depend on T. We propose an approach that avoids the need for this stopping time by eschewing the use of schedules entirely, while exhibiting state-of-the-art performance compared to schedules across a wide family of problems ranging from convex problems to large-scale deep learning problems. Our Schedule-Free approach introduces no additional hyper-parameters over standard optimizers with momentum. Our method is a direct consequence of a new theory we develop that unifies scheduling and iterate averaging. An open source implementation of our method is available at https://github.com/facebookresearch/schedule_free. Schedule-Free AdamW is the core algorithm behind our winning entry to the MLCommons 2024 AlgoPerf Algorithmic Efficiency Challenge Self-Tuning track.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.15682&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Aaron Defazio, Xingyu Alice Yang, Harsh Mehta, Konstantin Mishchenko, Ahmed Khaled, Ashok Cutkosky</name></author><category term="stat.ML" /><summary type="html">Existing learning rate schedules that do not require specification of the optimization stopping step T are greatly out-performed by learning rate schedules that depend on T. We propose an approach that avoids the need for this stopping time by eschewing the use of schedules entirely, while exhibiting state-of-the-art performance compared to schedules across a wide family of problems ranging from convex problems to large-scale deep learning problems. Our Schedule-Free approach introduces no additional hyper-parameters over standard optimizers with momentum. Our method is a direct consequence of a new theory we develop that unifies scheduling and iterate averaging. An open source implementation of our method is available at https://github.com/facebookresearch/schedule_free. Schedule-Free AdamW is the core algorithm behind our winning entry to the MLCommons 2024 AlgoPerf Algorithmic Efficiency Challenge Self-Tuning track.</summary></entry><entry><title type="html">The Sample-Communication Complexity Trade-off in Federated Q-Learning</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/TheSampleCommunicationComplexityTradeoffinFederatedQLearning.html" rel="alternate" type="text/html" title="The Sample-Communication Complexity Trade-off in Federated Q-Learning" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/TheSampleCommunicationComplexityTradeoffinFederatedQLearning</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/TheSampleCommunicationComplexityTradeoffinFederatedQLearning.html">&lt;p&gt;We consider the problem of federated Q-learning, where $M$ agents aim to collaboratively learn the optimal Q-function of an unknown infinite-horizon Markov decision process with finite state and action spaces. We investigate the trade-off between sample and communication complexities for the widely used class of intermittent communication algorithms. We first establish the converse result, where it is shown that a federated Q-learning algorithm that offers any speedup with respect to the number of agents in the per-agent sample complexity needs to incur a communication cost of at least an order of $\frac{1}{1-\gamma}$ up to logarithmic factors, where $\gamma$ is the discount factor. We also propose a new algorithm, called Fed-DVR-Q, which is the first federated Q-learning algorithm to simultaneously achieve order-optimal sample and communication complexities. Thus, together these results provide a complete characterization of the sample-communication complexity trade-off in federated Q-learning.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2408.16981&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Sudeep Salgia, Yuejie Chi</name></author><category term="stat.ML" /><summary type="html">We consider the problem of federated Q-learning, where $M$ agents aim to collaboratively learn the optimal Q-function of an unknown infinite-horizon Markov decision process with finite state and action spaces. We investigate the trade-off between sample and communication complexities for the widely used class of intermittent communication algorithms. We first establish the converse result, where it is shown that a federated Q-learning algorithm that offers any speedup with respect to the number of agents in the per-agent sample complexity needs to incur a communication cost of at least an order of $\frac{1}{1-\gamma}$ up to logarithmic factors, where $\gamma$ is the discount factor. We also propose a new algorithm, called Fed-DVR-Q, which is the first federated Q-learning algorithm to simultaneously achieve order-optimal sample and communication complexities. Thus, together these results provide a complete characterization of the sample-communication complexity trade-off in federated Q-learning.</summary></entry><entry><title type="html">The VIX as Stochastic Volatility for Corporate Bonds</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/TheVIXasStochasticVolatilityforCorporateBonds.html" rel="alternate" type="text/html" title="The VIX as Stochastic Volatility for Corporate Bonds" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/TheVIXasStochasticVolatilityforCorporateBonds</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/TheVIXasStochasticVolatilityforCorporateBonds.html">&lt;p&gt;Classic stochastic volatility models assume volatility is unobservable. We use the VIX for consider it observable, and use the Volatility Index: S\&amp;amp;P 500 VIX. This index was designed to measure volatility of S\&amp;amp;P 500. We apply it to a different segment: Corporate bond markets. We fit time series models for spreads between corporate and 10-year Treasury bonds. Next, we divide residuals by VIX. Our main idea is such division makes residuals closer to the ideal case of a Gaussian white noise. This is remarkable, since these residuals and VIX come from separate market segments. We conclude with the analysis of long-term behavior of these models.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22498&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jihyun Park, Andrey Sarantsev</name></author><category term="stat.AP" /><summary type="html">Classic stochastic volatility models assume volatility is unobservable. We use the VIX for consider it observable, and use the Volatility Index: S\&amp;amp;P 500 VIX. This index was designed to measure volatility of S\&amp;amp;P 500. We apply it to a different segment: Corporate bond markets. We fit time series models for spreads between corporate and 10-year Treasury bonds. Next, we divide residuals by VIX. Our main idea is such division makes residuals closer to the ideal case of a Gaussian white noise. This is remarkable, since these residuals and VIX come from separate market segments. We conclude with the analysis of long-term behavior of these models.</summary></entry><entry><title type="html">Theoretical and Practical Limits of Kolmogorov-Zurbenko Periodograms with DiRienzo-Zurbenko Algorithm Smoothing in the Spectral Analysis of Time Series Data</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/TheoreticalandPracticalLimitsofKolmogorovZurbenkoPeriodogramswithDiRienzoZurbenkoAlgorithmSmoothingintheSpectralAnalysisofTimeSeriesData.html" rel="alternate" type="text/html" title="Theoretical and Practical Limits of Kolmogorov-Zurbenko Periodograms with DiRienzo-Zurbenko Algorithm Smoothing in the Spectral Analysis of Time Series Data" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/TheoreticalandPracticalLimitsofKolmogorovZurbenkoPeriodogramswithDiRienzoZurbenkoAlgorithmSmoothingintheSpectralAnalysisofTimeSeriesData</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/TheoreticalandPracticalLimitsofKolmogorovZurbenkoPeriodogramswithDiRienzoZurbenkoAlgorithmSmoothingintheSpectralAnalysisofTimeSeriesData.html">&lt;p&gt;This investigation establishes the theoretical and practical limits of the Kolmogorov-Zurbenko periodogram with DiRienzo-Zurbenko algorithm smoothing with respect to sensitivity (i.e., ability to detect weak signals), accuracy (i.e., ability to correctly identify signal frequencies), resolution (i.e., ability to separate signals with close frequencies), and robustness (i.e., sensitivity, accuracy, and resolution despite high levels of missing data). Compared to standard periodograms that utilize static smoothing with a fixed window width, Kolmogorov-Zurbenko periodograms with DiRienzo-Zurbenko algorithm smoothing utilize dynamic smoothing with a variable window width. This article begins with a summary of its statistical derivation and development followed by instructions for accessing and utilizing this approach within the R statistical program platform. Brief definitions, importance, statistical bases, theoretical and practical limits, and demonstrations are provided for its sensitivity, accuracy, resolution, and robustness. Next using a simulated time series in which two signals close in frequency are embedded in a significant level of random noise, the predictive power of this approach is compared to an autoregressive integral moving average (ARIMA), with support also garnered for its being robust even in the face of a high level of missing data. The article concludes with brief descriptions of studies across a range of scientific disciplines that have capitalized on the power of the Kolmogorov-Zurbenko periodogram with DiRienzo-Zurbenko algorithm smoothing.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2007.03031&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Barry Loneck, Igor Zurbenko, Edward Valachovic</name></author><category term="stat.AP," /><category term="stat.CO" /><summary type="html">This investigation establishes the theoretical and practical limits of the Kolmogorov-Zurbenko periodogram with DiRienzo-Zurbenko algorithm smoothing with respect to sensitivity (i.e., ability to detect weak signals), accuracy (i.e., ability to correctly identify signal frequencies), resolution (i.e., ability to separate signals with close frequencies), and robustness (i.e., sensitivity, accuracy, and resolution despite high levels of missing data). Compared to standard periodograms that utilize static smoothing with a fixed window width, Kolmogorov-Zurbenko periodograms with DiRienzo-Zurbenko algorithm smoothing utilize dynamic smoothing with a variable window width. This article begins with a summary of its statistical derivation and development followed by instructions for accessing and utilizing this approach within the R statistical program platform. Brief definitions, importance, statistical bases, theoretical and practical limits, and demonstrations are provided for its sensitivity, accuracy, resolution, and robustness. Next using a simulated time series in which two signals close in frequency are embedded in a significant level of random noise, the predictive power of this approach is compared to an autoregressive integral moving average (ARIMA), with support also garnered for its being robust even in the face of a high level of missing data. The article concludes with brief descriptions of studies across a range of scientific disciplines that have capitalized on the power of the Kolmogorov-Zurbenko periodogram with DiRienzo-Zurbenko algorithm smoothing.</summary></entry><entry><title type="html">Trade-Offs of Diagonal Fisher Information Matrix Estimators</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/TradeOffsofDiagonalFisherInformationMatrixEstimators.html" rel="alternate" type="text/html" title="Trade-Offs of Diagonal Fisher Information Matrix Estimators" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/TradeOffsofDiagonalFisherInformationMatrixEstimators</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/TradeOffsofDiagonalFisherInformationMatrixEstimators.html">&lt;p&gt;The Fisher information matrix can be used to characterize the local geometry of the parameter space of neural networks. It elucidates insightful theories and useful tools to understand and optimize neural networks. Given its high computational cost, practitioners often use random estimators and evaluate only the diagonal entries. We examine two popular estimators whose accuracy and sample complexity depend on their associated variances. We derive bounds of the variances and instantiate them in neural networks for regression and classification. We navigate trade-offs for both estimators based on analytical and numerical studies. We find that the variance quantities depend on the non-linearity wrt different parameter groups and should not be neglected when estimating the Fisher information.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.05379&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Alexander Soen, Ke Sun</name></author><category term="stat.ML" /><summary type="html">The Fisher information matrix can be used to characterize the local geometry of the parameter space of neural networks. It elucidates insightful theories and useful tools to understand and optimize neural networks. Given its high computational cost, practitioners often use random estimators and evaluate only the diagonal entries. We examine two popular estimators whose accuracy and sample complexity depend on their associated variances. We derive bounds of the variances and instantiate them in neural networks for regression and classification. We navigate trade-offs for both estimators based on analytical and numerical studies. We find that the variance quantities depend on the non-linearity wrt different parameter groups and should not be neglected when estimating the Fisher information.</summary></entry><entry><title type="html">Transductive Learning Is Compact</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/TransductiveLearningIsCompact.html" rel="alternate" type="text/html" title="Transductive Learning Is Compact" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/TransductiveLearningIsCompact</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/TransductiveLearningIsCompact.html">&lt;p&gt;We demonstrate a compactness result holding broadly across supervised learning with a general class of loss functions: Any hypothesis class $H$ is learnable with transductive sample complexity $m$ precisely when all of its finite projections are learnable with sample complexity $m$. We prove that this exact form of compactness holds for realizable and agnostic learning with respect to any proper metric loss function (e.g., any norm on $\mathbb{R}^d$) and any continuous loss on a compact space (e.g., cross-entropy, squared loss). For realizable learning with improper metric losses, we show that exact compactness of sample complexity can fail, and provide matching upper and lower bounds of a factor of 2 on the extent to which such sample complexities can differ. We conjecture that larger gaps are possible for the agnostic case. Furthermore, invoking the equivalence between sample complexities in the PAC and transductive models (up to lower order factors, in the realizable case) permits us to directly port our results to the PAC model, revealing an almost-exact form of compactness holding broadly in PAC learning.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.10360&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Julian Asilis, Siddartha Devic, Shaddin Dughmi, Vatsal Sharan, Shang-Hua Teng</name></author><category term="stat.ML" /><summary type="html">We demonstrate a compactness result holding broadly across supervised learning with a general class of loss functions: Any hypothesis class $H$ is learnable with transductive sample complexity $m$ precisely when all of its finite projections are learnable with sample complexity $m$. We prove that this exact form of compactness holds for realizable and agnostic learning with respect to any proper metric loss function (e.g., any norm on $\mathbb{R}^d$) and any continuous loss on a compact space (e.g., cross-entropy, squared loss). For realizable learning with improper metric losses, we show that exact compactness of sample complexity can fail, and provide matching upper and lower bounds of a factor of 2 on the extent to which such sample complexities can differ. We conjecture that larger gaps are possible for the agnostic case. Furthermore, invoking the equivalence between sample complexities in the PAC and transductive models (up to lower order factors, in the realizable case) permits us to directly port our results to the PAC model, revealing an almost-exact form of compactness holding broadly in PAC learning.</summary></entry><entry><title type="html">Understanding Aggregations of Proper Learners in Multiclass Classification</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/UnderstandingAggregationsofProperLearnersinMulticlassClassification.html" rel="alternate" type="text/html" title="Understanding Aggregations of Proper Learners in Multiclass Classification" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/UnderstandingAggregationsofProperLearnersinMulticlassClassification</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/UnderstandingAggregationsofProperLearnersinMulticlassClassification.html">&lt;p&gt;Multiclass learnability is known to exhibit a properness barrier: there are learnable classes which cannot be learned by any proper learner. Binary classification faces no such barrier for learnability, but a similar one for optimal learning, which can in general only be achieved by improper learners. Fortunately, recent advances in binary classification have demonstrated that this requirement can be satisfied using aggregations of proper learners, some of which are strikingly simple. This raises a natural question: to what extent can simple aggregations of proper learners overcome the properness barrier in multiclass classification?
  We give a positive answer to this question for classes which have finite Graph dimension, $d_G$. Namely, we demonstrate that the optimal binary learners of Hanneke, Larsen, and Aden-Ali et al. (appropriately generalized to the multiclass setting) achieve sample complexity $O\left(\frac{d_G + \ln(1 / \delta)}{\epsilon}\right)$. This forms a strict improvement upon the sample complexity of ERM. We complement this with a lower bound demonstrating that for certain classes of Graph dimension $d_G$, majorities of ERM learners require $\Omega \left( \frac{d_G + \ln(1 / \delta)}{\epsilon}\right)$ samples. Furthermore, we show that a single ERM requires $\Omega \left(\frac{d_G \ln(1 / \epsilon) + \ln(1 / \delta)}{\epsilon}\right)$ samples on such classes, exceeding the lower bound of Daniely et al. (2015) by a factor of $\ln(1 / \epsilon)$. For multiclass learning in full generality – i.e., for classes of finite DS dimension but possibly infinite Graph dimension – we give a strong refutation to these learning strategies, by exhibiting a learnable class which cannot be learned to constant error by any aggregation of a finite number of proper learners.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22749&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Julian Asilis, Mikael M{\o}ller H{\o}gsgaard, Grigoris Velegkas</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">Multiclass learnability is known to exhibit a properness barrier: there are learnable classes which cannot be learned by any proper learner. Binary classification faces no such barrier for learnability, but a similar one for optimal learning, which can in general only be achieved by improper learners. Fortunately, recent advances in binary classification have demonstrated that this requirement can be satisfied using aggregations of proper learners, some of which are strikingly simple. This raises a natural question: to what extent can simple aggregations of proper learners overcome the properness barrier in multiclass classification? We give a positive answer to this question for classes which have finite Graph dimension, $d_G$. Namely, we demonstrate that the optimal binary learners of Hanneke, Larsen, and Aden-Ali et al. (appropriately generalized to the multiclass setting) achieve sample complexity $O\left(\frac{d_G + \ln(1 / \delta)}{\epsilon}\right)$. This forms a strict improvement upon the sample complexity of ERM. We complement this with a lower bound demonstrating that for certain classes of Graph dimension $d_G$, majorities of ERM learners require $\Omega \left( \frac{d_G + \ln(1 / \delta)}{\epsilon}\right)$ samples. Furthermore, we show that a single ERM requires $\Omega \left(\frac{d_G \ln(1 / \epsilon) + \ln(1 / \delta)}{\epsilon}\right)$ samples on such classes, exceeding the lower bound of Daniely et al. (2015) by a factor of $\ln(1 / \epsilon)$. For multiclass learning in full generality – i.e., for classes of finite DS dimension but possibly infinite Graph dimension – we give a strong refutation to these learning strategies, by exhibiting a learnable class which cannot be learned to constant error by any aggregation of a finite number of proper learners.</summary></entry><entry><title type="html">Universality of the $\pi^2/6$ Pathway in Avoiding Model Collapse</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/Universalityofthepi26PathwayinAvoidingModelCollapse.html" rel="alternate" type="text/html" title="Universality of the $\pi^2/6$ Pathway in Avoiding Model Collapse" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/Universalityofthepi26PathwayinAvoidingModelCollapse</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/Universalityofthepi26PathwayinAvoidingModelCollapse.html">&lt;p&gt;Researchers in empirical machine learning recently spotlighted their fears of so-called Model Collapse. They imagined a discard workflow, where an initial generative model is trained with real data, after which the real data are discarded, and subsequently, the model generates synthetic data on which a new model is trained. They came to the conclusion that models degenerate as model-fitting generations proceed. However, other researchers considered an augment workflow, where the original real data continue to be used in each generation of training, augmented by synthetic data from models fit in all earlier generations. Empirical results on canonical datasets and learning procedures confirmed the occurrence of model collapse under the discard workflow and avoidance of model collapse under the augment workflow. Under the augment workflow, theoretical evidence also confirmed avoidance in particular instances; specifically, Gerstgrasser et al. (2024) found that for classical Linear Regression, test risk at any later generation is bounded by a moderate multiple, viz. pi-squared-over-6 of the test risk of training with the original real data alone. Some commentators questioned the generality of theoretical conclusions based on the generative model assumed in Gerstgrasser et al. (2024): could similar conclusions be reached for other task/model pairings? In this work, we demonstrate the universality of the pi-squared-over-6 augment risk bound across a large family of canonical statistical models, offering key insights into exactly why collapse happens under the discard workflow and is avoided under the augment workflow. In the process, we provide a framework that is able to accommodate a large variety of workflows (beyond discard and augment), thereby enabling an experimenter to judge the comparative merits of multiple different workflows by simulating a simple Gaussian process.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22812&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Apratim Dey, David Donoho</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">Researchers in empirical machine learning recently spotlighted their fears of so-called Model Collapse. They imagined a discard workflow, where an initial generative model is trained with real data, after which the real data are discarded, and subsequently, the model generates synthetic data on which a new model is trained. They came to the conclusion that models degenerate as model-fitting generations proceed. However, other researchers considered an augment workflow, where the original real data continue to be used in each generation of training, augmented by synthetic data from models fit in all earlier generations. Empirical results on canonical datasets and learning procedures confirmed the occurrence of model collapse under the discard workflow and avoidance of model collapse under the augment workflow. Under the augment workflow, theoretical evidence also confirmed avoidance in particular instances; specifically, Gerstgrasser et al. (2024) found that for classical Linear Regression, test risk at any later generation is bounded by a moderate multiple, viz. pi-squared-over-6 of the test risk of training with the original real data alone. Some commentators questioned the generality of theoretical conclusions based on the generative model assumed in Gerstgrasser et al. (2024): could similar conclusions be reached for other task/model pairings? In this work, we demonstrate the universality of the pi-squared-over-6 augment risk bound across a large family of canonical statistical models, offering key insights into exactly why collapse happens under the discard workflow and is avoided under the augment workflow. In the process, we provide a framework that is able to accommodate a large variety of workflows (beyond discard and augment), thereby enabling an experimenter to judge the comparative merits of multiple different workflows by simulating a simple Gaussian process.</summary></entry><entry><title type="html">Unlocking Point Processes through Point Set Diffusion</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/UnlockingPointProcessesthroughPointSetDiffusion.html" rel="alternate" type="text/html" title="Unlocking Point Processes through Point Set Diffusion" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/UnlockingPointProcessesthroughPointSetDiffusion</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/UnlockingPointProcessesthroughPointSetDiffusion.html">&lt;p&gt;Point processes model the distribution of random point sets in mathematical spaces, such as spatial and temporal domains, with applications in fields like seismology, neuroscience, and economics. Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function, introducing an inherent trade-off between efficiency and flexibility. In this paper, we introduce Point Set Diffusion, a diffusion-based latent variable model that can represent arbitrary point processes on general metric spaces without relying on the intensity function. By directly learning to stochastically interpolate between noise and data point sets, our approach enables efficient, parallel sampling and flexible generation for complex conditional tasks defined on the metric space. Experiments on synthetic and real-world datasets demonstrate that Point Set Diffusion achieves state-of-the-art performance in unconditional and conditional generation of spatial and spatiotemporal point processes while providing up to orders of magnitude faster sampling than autoregressive baselines.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22493&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>David Lüdke, Enric Rabasseda Raventós, Marcel Kollovieh, Stephan Günnemann</name></author><category term="stat.ML" /><summary type="html">Point processes model the distribution of random point sets in mathematical spaces, such as spatial and temporal domains, with applications in fields like seismology, neuroscience, and economics. Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function, introducing an inherent trade-off between efficiency and flexibility. In this paper, we introduce Point Set Diffusion, a diffusion-based latent variable model that can represent arbitrary point processes on general metric spaces without relying on the intensity function. By directly learning to stochastically interpolate between noise and data point sets, our approach enables efficient, parallel sampling and flexible generation for complex conditional tasks defined on the metric space. Experiments on synthetic and real-world datasets demonstrate that Point Set Diffusion achieves state-of-the-art performance in unconditional and conditional generation of spatial and spatiotemporal point processes while providing up to orders of magnitude faster sampling than autoregressive baselines.</summary></entry><entry><title type="html">Unlocking the Power of Multi-institutional Data: Integrating and Harmonizing Genomic Data Across Institutions</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/UnlockingthePowerofMultiinstitutionalDataIntegratingandHarmonizingGenomicDataAcrossInstitutions.html" rel="alternate" type="text/html" title="Unlocking the Power of Multi-institutional Data: Integrating and Harmonizing Genomic Data Across Institutions" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/UnlockingthePowerofMultiinstitutionalDataIntegratingandHarmonizingGenomicDataAcrossInstitutions</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/UnlockingthePowerofMultiinstitutionalDataIntegratingandHarmonizingGenomicDataAcrossInstitutions.html">&lt;p&gt;Cancer is a complex disease driven by genomic alterations, and tumor sequencing is becoming a mainstay of clinical care for cancer patients. The emergence of multi-institution sequencing data presents a powerful resource for learning real-world evidence to enhance precision oncology. GENIE BPC, led by the American Association for Cancer Research, establishes a unique database linking genomic data with clinical information for patients treated at multiple cancer centers. However, leveraging such multi-institutional sequencing data presents significant challenges. Variations in gene panels result in loss of information when the analysis is conducted on common gene sets. Additionally, differences in sequencing techniques and patient heterogeneity across institutions add complexity. High data dimensionality, sparse gene mutation patterns, and weak signals at the individual gene level further complicate matters. Motivated by these real-world challenges, we introduce the Bridge model. It uses a quantile-matched latent variable approach to derive integrated features to preserve information beyond common genes and maximize the utilization of all available data while leveraging information sharing to enhance both learning efficiency and the model’s capacity to generalize. By extracting harmonized and noise-reduced lower-dimensional latent variables, the true mutation pattern unique to each individual is captured. We assess the model’s performance and parameter estimation through extensive simulation studies. The extracted latent features from the Bridge model consistently excel in predicting patient survival across six cancer types in GENIE BPC data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.00077&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yuan Chen, Ronglai Shen, Xiwen Feng, Katherine Panageas</name></author><category term="stat.ME" /><summary type="html">Cancer is a complex disease driven by genomic alterations, and tumor sequencing is becoming a mainstay of clinical care for cancer patients. The emergence of multi-institution sequencing data presents a powerful resource for learning real-world evidence to enhance precision oncology. GENIE BPC, led by the American Association for Cancer Research, establishes a unique database linking genomic data with clinical information for patients treated at multiple cancer centers. However, leveraging such multi-institutional sequencing data presents significant challenges. Variations in gene panels result in loss of information when the analysis is conducted on common gene sets. Additionally, differences in sequencing techniques and patient heterogeneity across institutions add complexity. High data dimensionality, sparse gene mutation patterns, and weak signals at the individual gene level further complicate matters. Motivated by these real-world challenges, we introduce the Bridge model. It uses a quantile-matched latent variable approach to derive integrated features to preserve information beyond common genes and maximize the utilization of all available data while leveraging information sharing to enhance both learning efficiency and the model’s capacity to generalize. By extracting harmonized and noise-reduced lower-dimensional latent variables, the true mutation pattern unique to each individual is captured. We assess the model’s performance and parameter estimation through extensive simulation studies. The extracted latent features from the Bridge model consistently excel in predicting patient survival across six cancer types in GENIE BPC data.</summary></entry><entry><title type="html">Unpicking Data at the Seams: VAEs, Disentanglement and Independent Components</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/UnpickingDataattheSeamsVAEsDisentanglementandIndependentComponents.html" rel="alternate" type="text/html" title="Unpicking Data at the Seams: VAEs, Disentanglement and Independent Components" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/UnpickingDataattheSeamsVAEsDisentanglementandIndependentComponents</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/UnpickingDataattheSeamsVAEsDisentanglementandIndependentComponents.html">&lt;p&gt;Disentanglement, or identifying salient statistically independent factors of the data, is of interest in many areas of machine learning and statistics, with relevance to synthetic data generation with controlled properties, robust classification of features, parsimonious encoding, and a greater understanding of the generative process underlying the data. Disentanglement arises in several generative paradigms, including Variational Autoencoders (VAEs), Generative Adversarial Networks and diffusion models. Particular progress has recently been made in understanding disentanglement in VAEs, where the choice of diagonal posterior covariance matrices is shown to promote mutual orthogonality between columns of the decoder’s Jacobian. We continue this thread to show how this linear independence translates to statistical independence, completing the chain in understanding how the VAE’s objective identifies independent components of, or disentangles, the data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22559&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Carl Allen</name></author><category term="stat.ML" /><summary type="html">Disentanglement, or identifying salient statistically independent factors of the data, is of interest in many areas of machine learning and statistics, with relevance to synthetic data generation with controlled properties, robust classification of features, parsimonious encoding, and a greater understanding of the generative process underlying the data. Disentanglement arises in several generative paradigms, including Variational Autoencoders (VAEs), Generative Adversarial Networks and diffusion models. Particular progress has recently been made in understanding disentanglement in VAEs, where the choice of diagonal posterior covariance matrices is shown to promote mutual orthogonality between columns of the decoder’s Jacobian. We continue this thread to show how this linear independence translates to statistical independence, completing the chain in understanding how the VAE’s objective identifies independent components of, or disentangles, the data.</summary></entry><entry><title type="html">Very fast Bayesian Additive Regression Trees on GPU</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/VeryfastBayesianAdditiveRegressionTreesonGPU.html" rel="alternate" type="text/html" title="Very fast Bayesian Additive Regression Trees on GPU" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/VeryfastBayesianAdditiveRegressionTreesonGPU</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/VeryfastBayesianAdditiveRegressionTreesonGPU.html">&lt;p&gt;Bayesian Additive Regression Trees (BART) is a nonparametric Bayesian regression technique based on an ensemble of decision trees. It is part of the toolbox of many statisticians. The overall statistical quality of the regression is typically higher than other generic alternatives, and it requires less manual tuning, making it a good default choice. However, it is a niche method compared to its natural competitor XGBoost, due to the longer running time, making sample sizes above 10,000-100,000 a nuisance. I present a GPU-enabled implementation of BART, faster by up to 200x relative to a single CPU core, making BART competitive in running time with XGBoost. This implementation is available in the Python package bartz.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23244&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Giacomo Petrillo</name></author><category term="stat.ML" /><summary type="html">Bayesian Additive Regression Trees (BART) is a nonparametric Bayesian regression technique based on an ensemble of decision trees. It is part of the toolbox of many statisticians. The overall statistical quality of the regression is typically higher than other generic alternatives, and it requires less manual tuning, making it a good default choice. However, it is a niche method compared to its natural competitor XGBoost, due to the longer running time, making sample sizes above 10,000-100,000 a nuisance. I present a GPU-enabled implementation of BART, faster by up to 200x relative to a single CPU core, making BART competitive in running time with XGBoost. This implementation is available in the Python package bartz.</summary></entry><entry><title type="html">Why Fine-grained Labels in Pretraining Benefit Generalization?</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/WhyFinegrainedLabelsinPretrainingBenefitGeneralization.html" rel="alternate" type="text/html" title="Why Fine-grained Labels in Pretraining Benefit Generalization?" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/WhyFinegrainedLabelsinPretrainingBenefitGeneralization</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/WhyFinegrainedLabelsinPretrainingBenefitGeneralization.html">&lt;p&gt;Recent studies show that pretraining a deep neural network with fine-grained labeled data, followed by fine-tuning on coarse-labeled data for downstream tasks, often yields better generalization than pretraining with coarse-labeled data. While there is ample empirical evidence supporting this, the theoretical justification remains an open problem. This paper addresses this gap by introducing a “hierarchical multi-view” structure to confine the input data distribution. Under this framework, we prove that: 1) coarse-grained pretraining only allows a neural network to learn the common features well, while 2) fine-grained pretraining helps the network learn the rare features in addition to the common ones, leading to improved accuracy on hard downstream test samples.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23129&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Guan Zhe Hong, Yin Cui, Ariel Fuxman, Stanely Chan, Enming Luo</name></author><category term="stat.ML" /><summary type="html">Recent studies show that pretraining a deep neural network with fine-grained labeled data, followed by fine-tuning on coarse-labeled data for downstream tasks, often yields better generalization than pretraining with coarse-labeled data. While there is ample empirical evidence supporting this, the theoretical justification remains an open problem. This paper addresses this gap by introducing a “hierarchical multi-view” structure to confine the input data distribution. Under this framework, we prove that: 1) coarse-grained pretraining only allows a neural network to learn the common features well, while 2) fine-grained pretraining helps the network learn the rare features in addition to the common ones, leading to improved accuracy on hard downstream test samples.</summary></entry><entry><title type="html">Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/ZerothOrderSamplingMethodsforNonLogConcaveDistributionsAlleviatingMetastabilitybyDenoisingDiffusion.html" rel="alternate" type="text/html" title="Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/ZerothOrderSamplingMethodsforNonLogConcaveDistributionsAlleviatingMetastabilitybyDenoisingDiffusion</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/ZerothOrderSamplingMethodsforNonLogConcaveDistributionsAlleviatingMetastabilitybyDenoisingDiffusion.html">&lt;p&gt;This paper considers the problem of sampling from non-logconcave distribution, based on queries of its unnormalized density. It first describes a framework, Denoising Diffusion Monte Carlo (DDMC), based on the simulation of a denoising diffusion process with its score function approximated by a generic Monte Carlo estimator. DDMC is an oracle-based meta-algorithm, where its oracle is the assumed access to samples that generate a Monte Carlo score estimator. Then we provide an implementation of this oracle, based on rejection sampling, and this turns DDMC into a true algorithm, termed Zeroth-Order Diffusion Monte Carlo (ZOD-MC). We provide convergence analyses by first constructing a general framework, i.e. a performance guarantee for DDMC, without assuming the target distribution to be log-concave or satisfying any isoperimetric inequality. Then we prove that ZOD-MC admits an inverse polynomial dependence on the desired sampling accuracy, albeit still suffering from the curse of dimensionality. Consequently, for low dimensional distributions, ZOD-MC is a very efficient sampler, with performance exceeding latest samplers, including also-denoising-diffusion-based RDMC and RSDMC. Last, we experimentally demonstrate the insensitivity of ZOD-MC to increasingly higher barriers between modes or discontinuity in non-convex potential.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.17886&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ye He, Kevin Rojas, Molei Tao</name></author><category term="stat.ML," /><category term="stat.ME," /><category term="stat.TH" /><summary type="html">This paper considers the problem of sampling from non-logconcave distribution, based on queries of its unnormalized density. It first describes a framework, Denoising Diffusion Monte Carlo (DDMC), based on the simulation of a denoising diffusion process with its score function approximated by a generic Monte Carlo estimator. DDMC is an oracle-based meta-algorithm, where its oracle is the assumed access to samples that generate a Monte Carlo score estimator. Then we provide an implementation of this oracle, based on rejection sampling, and this turns DDMC into a true algorithm, termed Zeroth-Order Diffusion Monte Carlo (ZOD-MC). We provide convergence analyses by first constructing a general framework, i.e. a performance guarantee for DDMC, without assuming the target distribution to be log-concave or satisfying any isoperimetric inequality. Then we prove that ZOD-MC admits an inverse polynomial dependence on the desired sampling accuracy, albeit still suffering from the curse of dimensionality. Consequently, for low dimensional distributions, ZOD-MC is a very efficient sampler, with performance exceeding latest samplers, including also-denoising-diffusion-based RDMC and RSDMC. Last, we experimentally demonstrate the insensitivity of ZOD-MC to increasingly higher barriers between modes or discontinuity in non-convex potential.</summary></entry><entry><title type="html">einspace: Searching for Neural Architectures from Fundamental Operations</title><link href="https://dedzago.github.io/arxiv_rss/2024/10/31/einspaceSearchingforNeuralArchitecturesfromFundamentalOperations.html" rel="alternate" type="text/html" title="einspace: Searching for Neural Architectures from Fundamental Operations" /><published>2024-10-31T00:00:00+00:00</published><updated>2024-10-31T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/10/31/einspaceSearchingforNeuralArchitecturesfromFundamentalOperations</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/10/31/einspaceSearchingforNeuralArchitecturesfromFundamentalOperations.html">&lt;p&gt;Neural architecture search (NAS) finds high performing networks for a given task. Yet the results of NAS are fairly prosaic; they did not e.g. create a shift from convolutional structures to transformers. This is not least because the search spaces in NAS often aren’t diverse enough to include such transformations a priori. Instead, for NAS to provide greater potential for fundamental design shifts, we need a novel expressive search space design which is built from more fundamental operations. To this end, we introduce einspace, a search space based on a parameterised probabilistic context-free grammar. Our space is versatile, supporting architectures of various sizes and complexities, while also containing diverse network operations which allow it to model convolutions, attention components and more. It contains many existing competitive architectures, and provides flexibility for discovering new ones. Using this search space, we perform experiments to find novel architectures as well as improvements on existing ones on the diverse Unseen NAS datasets. We show that competitive architectures can be obtained by searching from scratch, and we consistently find large improvements when initialising the search with strong baselines. We believe that this work is an important advancement towards a transformative NAS paradigm where search space expressivity and strategic search initialisation play key roles.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.20838&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Linus Ericsson, Miguel Espinosa, Chenhongyi Yang, Antreas Antoniou, Amos Storkey, Shay B. Cohen, Steven McDonagh, Elliot J. Crowley</name></author><category term="stat.ML" /><summary type="html">Neural architecture search (NAS) finds high performing networks for a given task. Yet the results of NAS are fairly prosaic; they did not e.g. create a shift from convolutional structures to transformers. This is not least because the search spaces in NAS often aren’t diverse enough to include such transformations a priori. Instead, for NAS to provide greater potential for fundamental design shifts, we need a novel expressive search space design which is built from more fundamental operations. To this end, we introduce einspace, a search space based on a parameterised probabilistic context-free grammar. Our space is versatile, supporting architectures of various sizes and complexities, while also containing diverse network operations which allow it to model convolutions, attention components and more. It contains many existing competitive architectures, and provides flexibility for discovering new ones. Using this search space, we perform experiments to find novel architectures as well as improvements on existing ones on the diverse Unseen NAS datasets. We show that competitive architectures can be obtained by searching from scratch, and we consistently find large improvements when initialising the search with strong baselines. We believe that this work is an important advancement towards a transformative NAS paradigm where search space expressivity and strategic search initialisation play key roles.</summary></entry></feed>