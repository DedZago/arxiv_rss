<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="https://emanuelealiverti.github.io/arxiv_rss/feed.xml" rel="self" type="application/atom+xml" /><link href="https://emanuelealiverti.github.io/arxiv_rss/" rel="alternate" type="text/html" /><updated>2024-10-29T12:58:19+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/feed.xml</id><title type="html">Stat Arxiv of Today</title><subtitle></subtitle><author><name>Emanuele Aliverti</name></author><entry><title type="html"></title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/2024-10-29-FedECAAFederatedExternalControlArmMethodforCausalInferencewithTimeToEventDatainDistributedSettings.html" rel="alternate" type="text/html" title="" /><published>2024-10-29T12:58:19+00:00</published><updated>2024-10-29T12:58:19+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/2024-10-29-FedECAAFederatedExternalControlArmMethodforCausalInferencewithTimeToEventDatainDistributedSettings</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/2024-10-29-FedECAAFederatedExternalControlArmMethodforCausalInferencewithTimeToEventDatainDistributedSettings.html">&lt;p&gt;External control arms (ECA) can inform the early clinical development of experimental drugs and provide efficacy evidence for regulatory approval. However, the main challenge in implementing ECA lies in accessing real-world or historical clinical trials data. Indeed, regulations protecting patients’ rights by strictly controlling data processing make pooling data from multiple sources in a central server often difficult. To address these limitations, we develop a new method, ‘FedECA’ that leverages federated learning (FL) to enable inverse probability of treatment weighting (IPTW) for time-to-event outcomes on separate cohorts without needing to pool data. To showcase the potential of FedECA, we apply it in different settings of increasing complexity culminating with a real-world use-case in which FedECA provides evidence for a differential effect between two drugs that would have otherwise gone unnoticed. By sharing our code, we hope FedECA will foster the creation of federated research networks and thus accelerate drug development.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2311.16984&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Emanuele Aliverti</name></author></entry><entry><title type="html">A Bayesian Generalized Bridge Regression Approach to Covariance Estimation in the Presence of Covariates</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ABayesianGeneralizedBridgeRegressionApproachtoCovarianceEstimationinthePresenceofCovariates.html" rel="alternate" type="text/html" title="A Bayesian Generalized Bridge Regression Approach to Covariance Estimation in the Presence of Covariates" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ABayesianGeneralizedBridgeRegressionApproachtoCovarianceEstimationinthePresenceofCovariates</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ABayesianGeneralizedBridgeRegressionApproachtoCovarianceEstimationinthePresenceofCovariates.html">&lt;p&gt;A hierarchical Bayesian approach that permits simultaneous inference for the regression coefficient matrix and the error precision (inverse covariance) matrix in the multivariate linear model is proposed. Assuming a natural ordering of the elements of the response, the precision matrix is reparameterized so it can be estimated with univariate-response linear regression techniques. A novel generalized bridge regression prior that accommodates both sparse and dense settings and is competitive with alternative methods for univariate-response regression is proposed and used in this framework. Two component-wise Markov chain Monte Carlo algorithms are developed for sampling, including a data augmentation algorithm based on a scale mixture of normals representation. Numerical examples demonstrate that the proposed method is competitive with comparable joint mean-covariance models, particularly in estimation of the precision matrix. The method is also used to estimate the 253 by 253 precision matrix of 90,670 spectra extracted from images taken by the Hubble Space Telescope, demonstrating its computational feasibility for problems with large n and q.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.00906&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Christina Zhao , Ding Xiang , Galin L. Jones , Adam J. Rothman</name></author><category term="stat.ME" /><summary type="html">A hierarchical Bayesian approach that permits simultaneous inference for the regression coefficient matrix and the error precision (inverse covariance) matrix in the multivariate linear model is proposed. Assuming a natural ordering of the elements of the response, the precision matrix is reparameterized so it can be estimated with univariate-response linear regression techniques. A novel generalized bridge regression prior that accommodates both sparse and dense settings and is competitive with alternative methods for univariate-response regression is proposed and used in this framework. Two component-wise Markov chain Monte Carlo algorithms are developed for sampling, including a data augmentation algorithm based on a scale mixture of normals representation. Numerical examples demonstrate that the proposed method is competitive with comparable joint mean-covariance models, particularly in estimation of the precision matrix. The method is also used to estimate the 253 by 253 precision matrix of 90,670 spectra extracted from images taken by the Hubble Space Telescope, demonstrating its computational feasibility for problems with large n and q.</summary></entry><entry><title type="html">A Componentwise Estimation Procedure for Multivariate Location and Scatter: Robustness, Efficiency and Scalability</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AComponentwiseEstimationProcedureforMultivariateLocationandScatterRobustnessEfficiencyandScalability.html" rel="alternate" type="text/html" title="A Componentwise Estimation Procedure for Multivariate Location and Scatter: Robustness, Efficiency and Scalability" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AComponentwiseEstimationProcedureforMultivariateLocationandScatterRobustnessEfficiencyandScalability</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AComponentwiseEstimationProcedureforMultivariateLocationandScatterRobustnessEfficiencyandScalability.html">&lt;p&gt;Covariance matrix estimation is an important problem in multivariate data analysis, both from theoretical as well as applied points of view. Many simple and popular covariance matrix estimators are known to be severely affected by model misspecification and the presence of outliers in the data; on the other hand robust estimators with reasonably high efficiency are often computationally challenging for modern large and complex datasets. In this work, we propose a new, simple, robust and highly efficient method for estimation of the location vector and the scatter matrix for elliptically symmetric distributions. The proposed estimation procedure is designed in the spirit of the minimum density power divergence (DPD) estimation approach with appropriate modifications which makes our proposal (sequential minimum DPD estimation) computationally very economical and scalable to large as well as higher dimensional datasets. Consistency and asymptotic normality of the proposed sequential estimators of the multivariate location and scatter are established along with asymptotic positive definiteness of the estimated scatter matrix. Robustness of our estimators are studied by means of influence functions. All theoretical results are illustrated further under multivariate normality. A large-scale simulation study is presented to assess finite sample performances and scalability of our method in comparison to the usual maximum likelihood estimator (MLE), the ordinary minimum DPD estimator (MDPDE) and other popular non-parametric methods. The applicability of our method is further illustrated with a real dataset on credit card transactions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21166&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Soumya Chakraborty, Ayanendranath Basu, Abhik Ghosh</name></author><category term="stat.ME" /><summary type="html">Covariance matrix estimation is an important problem in multivariate data analysis, both from theoretical as well as applied points of view. Many simple and popular covariance matrix estimators are known to be severely affected by model misspecification and the presence of outliers in the data; on the other hand robust estimators with reasonably high efficiency are often computationally challenging for modern large and complex datasets. In this work, we propose a new, simple, robust and highly efficient method for estimation of the location vector and the scatter matrix for elliptically symmetric distributions. The proposed estimation procedure is designed in the spirit of the minimum density power divergence (DPD) estimation approach with appropriate modifications which makes our proposal (sequential minimum DPD estimation) computationally very economical and scalable to large as well as higher dimensional datasets. Consistency and asymptotic normality of the proposed sequential estimators of the multivariate location and scatter are established along with asymptotic positive definiteness of the estimated scatter matrix. Robustness of our estimators are studied by means of influence functions. All theoretical results are illustrated further under multivariate normality. A large-scale simulation study is presented to assess finite sample performances and scalability of our method in comparison to the usual maximum likelihood estimator (MLE), the ordinary minimum DPD estimator (MDPDE) and other popular non-parametric methods. The applicability of our method is further illustrated with a real dataset on credit card transactions.</summary></entry><entry><title type="html">A Distributed Lag Approach to the Generalised Dynamic Factor Model (GDFM)</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ADistributedLagApproachtotheGeneralisedDynamicFactorModelGDFM.html" rel="alternate" type="text/html" title="A Distributed Lag Approach to the Generalised Dynamic Factor Model (GDFM)" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ADistributedLagApproachtotheGeneralisedDynamicFactorModelGDFM</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ADistributedLagApproachtotheGeneralisedDynamicFactorModelGDFM.html">&lt;p&gt;We provide estimation and inference for the Generalised Dynamic Factor Model (GDFM) under the assumption that the dynamic common component can be expressed in terms of a finite number of lags of contemporaneously pervasive factors. The proposed estimator is simply an OLS regression of the observed variables on factors extracted via static principal components and therefore avoids frequency domain techniques entirely.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20885&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Philipp Gersing</name></author><category term="stat.ME" /><summary type="html">We provide estimation and inference for the Generalised Dynamic Factor Model (GDFM) under the assumption that the dynamic common component can be expressed in terms of a finite number of lags of contemporaneously pervasive factors. The proposed estimator is simply an OLS regression of the observed variables on factors extracted via static principal components and therefore avoids frequency domain techniques entirely.</summary></entry><entry><title type="html">A Fast Coordinate Descent Method for High-Dimensional Non-Negative Least Squares using a Unified Sparse Regression Framework</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AFastCoordinateDescentMethodforHighDimensionalNonNegativeLeastSquaresusingaUnifiedSparseRegressionFramework.html" rel="alternate" type="text/html" title="A Fast Coordinate Descent Method for High-Dimensional Non-Negative Least Squares using a Unified Sparse Regression Framework" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AFastCoordinateDescentMethodforHighDimensionalNonNegativeLeastSquaresusingaUnifiedSparseRegressionFramework</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AFastCoordinateDescentMethodforHighDimensionalNonNegativeLeastSquaresusingaUnifiedSparseRegressionFramework.html">&lt;p&gt;We develop theoretical results that establish a connection across various regression methods such as the non-negative least squares, bounded variable least squares, simplex constrained least squares, and lasso. In particular, we show in general that a polyhedron constrained least squares problem admits a locally unique sparse solution in high dimensions. We demonstrate the power of our result by concretely quantifying the sparsity level for the aforementioned methods. Furthermore, we propose a novel coordinate descent based solver for NNLS in high dimensions using our theoretical result as motivation. We show through simulated data and a real data example that our solver achieves at least a 5x speed-up from the state-of-the-art solvers.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.03014&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>James Yang, Trevor Hastie</name></author><category term="stat.CO," /><category term="stat.TH" /><summary type="html">We develop theoretical results that establish a connection across various regression methods such as the non-negative least squares, bounded variable least squares, simplex constrained least squares, and lasso. In particular, we show in general that a polyhedron constrained least squares problem admits a locally unique sparse solution in high dimensions. We demonstrate the power of our result by concretely quantifying the sparsity level for the aforementioned methods. Furthermore, we propose a novel coordinate descent based solver for NNLS in high dimensions using our theoretical result as motivation. We show through simulated data and a real data example that our solver achieves at least a 5x speed-up from the state-of-the-art solvers.</summary></entry><entry><title type="html">A General Framework for Cutting Feedback within Modularised Bayesian Inference</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AGeneralFrameworkforCuttingFeedbackwithinModularisedBayesianInference.html" rel="alternate" type="text/html" title="A General Framework for Cutting Feedback within Modularised Bayesian Inference" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AGeneralFrameworkforCuttingFeedbackwithinModularisedBayesianInference</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AGeneralFrameworkforCuttingFeedbackwithinModularisedBayesianInference.html">&lt;p&gt;Standard Bayesian inference can build models that combine information from various sources, but this inference may not be reliable if components of a model are misspecified. Cut inference, as a particular type of modularized Bayesian inference, is an alternative which splits a model into modules and cuts the feedback from the suspect module. Previous studies have focused on a two-module case, but a more general definition of a “module” remains unclear. We present a formal definition of a “module” and discuss its properties. We formulate methods for identifying modules; determining the order of modules; and building the cut distribution that should be used for cut inference within an arbitrary directed acyclic graph structure. We justify the cut distribution by showing that it not only cuts the feedback but also is the best approximation satisfying this condition to the joint distribution in the Kullback-Leibler divergence. We also extend cut inference for the two-module case to a general multiple-module case via a sequential splitting technique and demonstrate this via illustrative applications.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2211.03274&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yang Liu, Robert J. B. Goudie</name></author><category term="stat.ME," /><category term="stat.TH" /><summary type="html">Standard Bayesian inference can build models that combine information from various sources, but this inference may not be reliable if components of a model are misspecified. Cut inference, as a particular type of modularized Bayesian inference, is an alternative which splits a model into modules and cuts the feedback from the suspect module. Previous studies have focused on a two-module case, but a more general definition of a “module” remains unclear. We present a formal definition of a “module” and discuss its properties. We formulate methods for identifying modules; determining the order of modules; and building the cut distribution that should be used for cut inference within an arbitrary directed acyclic graph structure. We justify the cut distribution by showing that it not only cuts the feedback but also is the best approximation satisfying this condition to the joint distribution in the Kullback-Leibler divergence. We also extend cut inference for the two-module case to a general multiple-module case via a sequential splitting technique and demonstrate this via illustrative applications.</summary></entry><entry><title type="html">A Robust Topological Framework for Detecting Regime Changes in Multi-Trial Experiments with Application to Predictive Maintenance</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ARobustTopologicalFrameworkforDetectingRegimeChangesinMultiTrialExperimentswithApplicationtoPredictiveMaintenance.html" rel="alternate" type="text/html" title="A Robust Topological Framework for Detecting Regime Changes in Multi-Trial Experiments with Application to Predictive Maintenance" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ARobustTopologicalFrameworkforDetectingRegimeChangesinMultiTrialExperimentswithApplicationtoPredictiveMaintenance</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ARobustTopologicalFrameworkforDetectingRegimeChangesinMultiTrialExperimentswithApplicationtoPredictiveMaintenance.html">&lt;p&gt;We present a general and flexible framework for detecting regime changes in complex, non-stationary data across multi-trial experiments. Traditional change point detection methods focus on identifying abrupt changes within a single time series (single trial), targeting shifts in statistical properties such as the mean, variance, and spectrum over time within that sole trial. In contrast, our approach considers changes occurring across trials, accommodating changes that may arise within individual trials due to experimental inconsistencies, such as varying delays or event duration. By leveraging diverse metrics to analyze time-frequency characteristics specifically topological changes in the spectrum and spectrograms, our approach offers a comprehensive framework for detecting such variations. Our approach can handle different scenarios with various statistical assumptions, including varying levels of stationarity within and across trials, making our framework highly adaptable. We validate our approach through simulations using time-varying autoregressive processes that exhibit different regime changes. Our results demonstrate the effectiveness of detecting changes across trials under diverse conditions. Furthermore, we illustrate the effectiveness of our method by applying it to predictive maintenance using the NASA bearing dataset. By analyzing the time-frequency characteristics of vibration signals recorded by accelerometers, our approach accurately identifies bearing failures, showcasing its strong potential for early fault detection in mechanical systems.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20443&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Anass B. El-Yaagoubi, Jean-Marc Freyermuth, Hernando Ombao</name></author><category term="stat.ME" /><summary type="html">We present a general and flexible framework for detecting regime changes in complex, non-stationary data across multi-trial experiments. Traditional change point detection methods focus on identifying abrupt changes within a single time series (single trial), targeting shifts in statistical properties such as the mean, variance, and spectrum over time within that sole trial. In contrast, our approach considers changes occurring across trials, accommodating changes that may arise within individual trials due to experimental inconsistencies, such as varying delays or event duration. By leveraging diverse metrics to analyze time-frequency characteristics specifically topological changes in the spectrum and spectrograms, our approach offers a comprehensive framework for detecting such variations. Our approach can handle different scenarios with various statistical assumptions, including varying levels of stationarity within and across trials, making our framework highly adaptable. We validate our approach through simulations using time-varying autoregressive processes that exhibit different regime changes. Our results demonstrate the effectiveness of detecting changes across trials under diverse conditions. Furthermore, we illustrate the effectiveness of our method by applying it to predictive maintenance using the NASA bearing dataset. By analyzing the time-frequency characteristics of vibration signals recorded by accelerometers, our approach accurately identifies bearing failures, showcasing its strong potential for early fault detection in mechanical systems.</summary></entry><entry><title type="html">A Short Note on the Efficiency of Markov Chains for Bayesian Linear Regression Models with Heavy-Tailed Errors</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AShortNoteontheEfficiencyofMarkovChainsforBayesianLinearRegressionModelswithHeavyTailedErrors.html" rel="alternate" type="text/html" title="A Short Note on the Efficiency of Markov Chains for Bayesian Linear Regression Models with Heavy-Tailed Errors" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AShortNoteontheEfficiencyofMarkovChainsforBayesianLinearRegressionModelswithHeavyTailedErrors</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AShortNoteontheEfficiencyofMarkovChainsforBayesianLinearRegressionModelswithHeavyTailedErrors.html">&lt;p&gt;In this short note, we consider posterior simulation for a linear regression model when the error distribution is given by a scale mixture of multivariate normals. We first show that the sampler of Backlund and Hobert (2020) for the case of the conditionally conjugate normal-inverse Wishart prior continues to be geometrically ergodic even when the error density is heavier-tailed. Moreover, we prove that the ergodicity is uniform by verifying the minorization condition. In the second half of this note, we treat an improper case and show that the sampler of Section 4 of Roy and Hobert (2010) is geometrically ergodic under significantly milder conditions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.17070&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yasuyuki Hamura</name></author><category term="stat.CO," /><category term="stat.TH" /><summary type="html">In this short note, we consider posterior simulation for a linear regression model when the error distribution is given by a scale mixture of multivariate normals. We first show that the sampler of Backlund and Hobert (2020) for the case of the conditionally conjugate normal-inverse Wishart prior continues to be geometrically ergodic even when the error density is heavier-tailed. Moreover, we prove that the ergodicity is uniform by verifying the minorization condition. In the second half of this note, we treat an improper case and show that the sampler of Section 4 of Roy and Hobert (2010) is geometrically ergodic under significantly milder conditions.</summary></entry><entry><title type="html">A Statistical Analysis of Deep Federated Learning for Intrinsically Low-dimensional Data</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AStatisticalAnalysisofDeepFederatedLearningforIntrinsicallyLowdimensionalData.html" rel="alternate" type="text/html" title="A Statistical Analysis of Deep Federated Learning for Intrinsically Low-dimensional Data" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AStatisticalAnalysisofDeepFederatedLearningforIntrinsicallyLowdimensionalData</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AStatisticalAnalysisofDeepFederatedLearningforIntrinsicallyLowdimensionalData.html">&lt;p&gt;Federated Learning (FL) has emerged as a groundbreaking paradigm in collaborative machine learning, emphasizing decentralized model training to address data privacy concerns. While significant progress has been made in optimizing federated learning, the exploration of generalization error, particularly in heterogeneous settings, has been limited, focusing mainly on parametric cases. This paper investigates the generalization properties of deep federated regression within a two-stage sampling model. Our findings highlight that the intrinsic dimension, defined by the entropic dimension, is crucial for determining convergence rates when appropriate network sizes are used. Specifically, if the true relationship between response and explanatory variables is charecterized by a $\beta$-H&quot;older function and there are $n$ independent and identically distributed (i.i.d.) samples from $m$ participating clients, the error rate for participating clients scales at most as $\tilde{O}\left((mn)^{-2\beta/(2\beta + \bar{d}&lt;em&gt;{2\beta}(\lambda))}\right)$, and for non-participating clients, it scales as $\tilde{O}\left(\Delta \cdot m^{-2\beta/(2\beta + \bar{d}&lt;/em&gt;{2\beta}(\lambda))} + (mn)^{-2\beta/(2\beta + \bar{d}&lt;em&gt;{2\beta}(\lambda))}\right)$. Here, $\bar{d}&lt;/em&gt;{2\beta}(\lambda)$ represents the $2\beta$-entropic dimension of $\lambda$, the marginal distribution of the explanatory variables, and $\Delta$ characterizes the dependence between the sampling stages. Our results explicitly account for the “closeness” of clients, demonstrating that the convergence rates of deep federated learners depend on intrinsic rather than nominal high-dimensionality.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20659&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Saptarshi Chakraborty, Peter L. Bartlett</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">Federated Learning (FL) has emerged as a groundbreaking paradigm in collaborative machine learning, emphasizing decentralized model training to address data privacy concerns. While significant progress has been made in optimizing federated learning, the exploration of generalization error, particularly in heterogeneous settings, has been limited, focusing mainly on parametric cases. This paper investigates the generalization properties of deep federated regression within a two-stage sampling model. Our findings highlight that the intrinsic dimension, defined by the entropic dimension, is crucial for determining convergence rates when appropriate network sizes are used. Specifically, if the true relationship between response and explanatory variables is charecterized by a $\beta$-H&quot;older function and there are $n$ independent and identically distributed (i.i.d.) samples from $m$ participating clients, the error rate for participating clients scales at most as $\tilde{O}\left((mn)^{-2\beta/(2\beta + \bar{d}{2\beta}(\lambda))}\right)$, and for non-participating clients, it scales as $\tilde{O}\left(\Delta \cdot m^{-2\beta/(2\beta + \bar{d}{2\beta}(\lambda))} + (mn)^{-2\beta/(2\beta + \bar{d}{2\beta}(\lambda))}\right)$. Here, $\bar{d}{2\beta}(\lambda)$ represents the $2\beta$-entropic dimension of $\lambda$, the marginal distribution of the explanatory variables, and $\Delta$ characterizes the dependence between the sampling stages. Our results explicitly account for the “closeness” of clients, demonstrating that the convergence rates of deep federated learners depend on intrinsic rather than nominal high-dimensionality.</summary></entry><entry><title type="html">A Stein Gradient Descent Approach for Doubly Intractable Distributions</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ASteinGradientDescentApproachforDoublyIntractableDistributions.html" rel="alternate" type="text/html" title="A Stein Gradient Descent Approach for Doubly Intractable Distributions" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ASteinGradientDescentApproachforDoublyIntractableDistributions</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ASteinGradientDescentApproachforDoublyIntractableDistributions.html">&lt;p&gt;Bayesian inference for doubly intractable distributions is challenging because they include intractable terms, which are functions of parameters of interest. Although several alternatives have been developed for such models, they are computationally intensive due to repeated auxiliary variable simulations. We propose a novel Monte Carlo Stein variational gradient descent (MC-SVGD) approach for inference for doubly intractable distributions. Through an efficient gradient approximation, our MC-SVGD approach rapidly transforms an arbitrary reference distribution to approximate the posterior distribution of interest, without necessitating any predefined variational distribution class for the posterior. Such a transport map is obtained by minimizing Kullback-Leibler divergence between the transformed and posterior distributions in a reproducing kernel Hilbert space (RKHS). We also investigate the convergence rate of the proposed method. We illustrate the application of the method to challenging examples, including a Potts model, an exponential random graph model, and a Conway–Maxwell–Poisson regression model. The proposed method achieves substantial computational gains over existing algorithms, while providing comparable inferential performance for the posterior distributions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21021&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Heesang Lee, Songhee Kim, Bokgyeong Kang, Jaewoo Park</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">Bayesian inference for doubly intractable distributions is challenging because they include intractable terms, which are functions of parameters of interest. Although several alternatives have been developed for such models, they are computationally intensive due to repeated auxiliary variable simulations. We propose a novel Monte Carlo Stein variational gradient descent (MC-SVGD) approach for inference for doubly intractable distributions. Through an efficient gradient approximation, our MC-SVGD approach rapidly transforms an arbitrary reference distribution to approximate the posterior distribution of interest, without necessitating any predefined variational distribution class for the posterior. Such a transport map is obtained by minimizing Kullback-Leibler divergence between the transformed and posterior distributions in a reproducing kernel Hilbert space (RKHS). We also investigate the convergence rate of the proposed method. We illustrate the application of the method to challenging examples, including a Potts model, an exponential random graph model, and a Conway–Maxwell–Poisson regression model. The proposed method achieves substantial computational gains over existing algorithms, while providing comparable inferential performance for the posterior distributions.</summary></entry><entry><title type="html">A Systematic Review of Machine Learning Approaches for Detecting Deceptive Activities on Social Media: Methods, Challenges, and Biases</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ASystematicReviewofMachineLearningApproachesforDetectingDeceptiveActivitiesonSocialMediaMethodsChallengesandBiases.html" rel="alternate" type="text/html" title="A Systematic Review of Machine Learning Approaches for Detecting Deceptive Activities on Social Media: Methods, Challenges, and Biases" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ASystematicReviewofMachineLearningApproachesforDetectingDeceptiveActivitiesonSocialMediaMethodsChallengesandBiases</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ASystematicReviewofMachineLearningApproachesforDetectingDeceptiveActivitiesonSocialMediaMethodsChallengesandBiases.html">&lt;p&gt;Social media platforms like Twitter, Facebook, and Instagram have facilitated the spread of misinformation, necessitating automated detection systems. This systematic review evaluates 36 studies that apply machine learning (ML) and deep learning (DL) models to detect fake news, spam, and fake accounts on social media. Using the Prediction model Risk Of Bias ASsessment Tool (PROBAST), the review identified key biases across the ML lifecycle: selection bias due to non-representative sampling, inadequate handling of class imbalance, insufficient linguistic preprocessing (e.g., negations), and inconsistent hyperparameter tuning. Although models such as Support Vector Machines (SVM), Random Forests, and Long Short-Term Memory (LSTM) networks showed strong potential, over-reliance on accuracy as an evaluation metric in imbalanced data settings was a common flaw. The review highlights the need for improved data preprocessing (e.g., resampling techniques), consistent hyperparameter tuning, and the use of appropriate metrics like precision, recall, F1 score, and AUROC. Addressing these limitations can lead to more reliable and generalizable ML/DL models for detecting deceptive content, ultimately contributing to the reduction of misinformation on social media.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20293&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yunchong Liu, Xiaorui Shen, Yeyubei Zhang, Zhongyan Wang, Yexin Tian, Jianglai Dai, Yuchen Cao</name></author><category term="stat.ML" /><summary type="html">Social media platforms like Twitter, Facebook, and Instagram have facilitated the spread of misinformation, necessitating automated detection systems. This systematic review evaluates 36 studies that apply machine learning (ML) and deep learning (DL) models to detect fake news, spam, and fake accounts on social media. Using the Prediction model Risk Of Bias ASsessment Tool (PROBAST), the review identified key biases across the ML lifecycle: selection bias due to non-representative sampling, inadequate handling of class imbalance, insufficient linguistic preprocessing (e.g., negations), and inconsistent hyperparameter tuning. Although models such as Support Vector Machines (SVM), Random Forests, and Long Short-Term Memory (LSTM) networks showed strong potential, over-reliance on accuracy as an evaluation metric in imbalanced data settings was a common flaw. The review highlights the need for improved data preprocessing (e.g., resampling techniques), consistent hyperparameter tuning, and the use of appropriate metrics like precision, recall, F1 score, and AUROC. Addressing these limitations can lead to more reliable and generalizable ML/DL models for detecting deceptive content, ultimately contributing to the reduction of misinformation on social media.</summary></entry><entry><title type="html">A Taxonomy of Loss Functions for Stochastic Optimal Control</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ATaxonomyofLossFunctionsforStochasticOptimalControl.html" rel="alternate" type="text/html" title="A Taxonomy of Loss Functions for Stochastic Optimal Control" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ATaxonomyofLossFunctionsforStochasticOptimalControl</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ATaxonomyofLossFunctionsforStochasticOptimalControl.html">&lt;p&gt;Stochastic optimal control (SOC) aims to direct the behavior of noisy systems and has widespread applications in science, engineering, and artificial intelligence. In particular, reward fine-tuning of diffusion and flow matching models and sampling from unnormalized methods can be recast as SOC problems. A recent work has introduced Adjoint Matching (Domingo-Enrich et al., 2024), a loss function for SOC problems that vastly outperforms existing loss functions in the reward fine-tuning setup. The goal of this work is to clarify the connections between all the existing (and some new) SOC loss functions. Namely, we show that SOC loss functions can be grouped into classes that share the same gradient in expectation, which means that their optimization landscape is the same; they only differ in their gradient variance. We perform simple SOC experiments to understand the strengths and weaknesses of different loss functions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.00345&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Carles Domingo-Enrich</name></author><category term="stat.ML" /><summary type="html">Stochastic optimal control (SOC) aims to direct the behavior of noisy systems and has widespread applications in science, engineering, and artificial intelligence. In particular, reward fine-tuning of diffusion and flow matching models and sampling from unnormalized methods can be recast as SOC problems. A recent work has introduced Adjoint Matching (Domingo-Enrich et al., 2024), a loss function for SOC problems that vastly outperforms existing loss functions in the reward fine-tuning setup. The goal of this work is to clarify the connections between all the existing (and some new) SOC loss functions. Namely, we show that SOC loss functions can be grouped into classes that share the same gradient in expectation, which means that their optimization landscape is the same; they only differ in their gradient variance. We perform simple SOC experiments to understand the strengths and weaknesses of different loss functions.</summary></entry><entry><title type="html">Accurate Inference for Penalized Logistic Regression</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AccurateInferenceforPenalizedLogisticRegression.html" rel="alternate" type="text/html" title="Accurate Inference for Penalized Logistic Regression" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AccurateInferenceforPenalizedLogisticRegression</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AccurateInferenceforPenalizedLogisticRegression.html">&lt;p&gt;Inference for high-dimensional logistic regression models using penalized methods has been a challenging research problem. As an illustration, a major difficulty is the significant bias of the Lasso estimator, which limits its direct application in inference. Although various bias corrected Lasso estimators have been proposed, they often still exhibit substantial biases in finite samples, undermining their inference performance. These finite sample biases become particularly problematic in one-sided inference problems, such as one-sided hypothesis testing. This paper proposes a novel two-step procedure for accurate inference in high-dimensional logistic regression models. In the first step, we propose a Lasso-based variable selection method to select a suitable submodel of moderate size for subsequent inference. In the second step, we introduce a bias corrected estimator to fit the selected submodel. We demonstrate that the resulting estimator from this two-step procedure has a small bias order and enables accurate inference. Numerical studies and an analysis of alcohol consumption data are included, where our proposed method is compared to alternative approaches. Our results indicate that the proposed method exhibits significantly smaller biases than alternative methods in finite samples, thereby leading to improved inference performance.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20045&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yuming Zhang, Stéphane Guerrier, Runze Li</name></author><category term="stat.ME" /><summary type="html">Inference for high-dimensional logistic regression models using penalized methods has been a challenging research problem. As an illustration, a major difficulty is the significant bias of the Lasso estimator, which limits its direct application in inference. Although various bias corrected Lasso estimators have been proposed, they often still exhibit substantial biases in finite samples, undermining their inference performance. These finite sample biases become particularly problematic in one-sided inference problems, such as one-sided hypothesis testing. This paper proposes a novel two-step procedure for accurate inference in high-dimensional logistic regression models. In the first step, we propose a Lasso-based variable selection method to select a suitable submodel of moderate size for subsequent inference. In the second step, we introduce a bias corrected estimator to fit the selected submodel. We demonstrate that the resulting estimator from this two-step procedure has a small bias order and enables accurate inference. Numerical studies and an analysis of alcohol consumption data are included, where our proposed method is compared to alternative approaches. Our results indicate that the proposed method exhibits significantly smaller biases than alternative methods in finite samples, thereby leading to improved inference performance.</summary></entry><entry><title type="html">Active Preference Learning for Ordering Items In- and Out-of-sample</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ActivePreferenceLearningforOrderingItemsInandOutofsample.html" rel="alternate" type="text/html" title="Active Preference Learning for Ordering Items In- and Out-of-sample" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ActivePreferenceLearningforOrderingItemsInandOutofsample</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ActivePreferenceLearningforOrderingItemsInandOutofsample.html">&lt;p&gt;Learning an ordering of items based on pairwise comparisons is useful when items are difficult to rate consistently on an absolute scale, for example, when annotators have to make subjective assessments. When exhaustive comparison is infeasible, actively sampling item pairs can reduce the number of annotations necessary for learning an accurate ordering. However, many algorithms ignore shared structure between items, limiting their sample efficiency and precluding generalization to new items. It is also common to disregard how noise in comparisons varies between item pairs, despite it being informative of item similarity. In this work, we study active preference learning for ordering items with contextual attributes, both in- and out-of-sample. We give an upper bound on the expected ordering error of a logistic preference model as a function of which items have been compared. Next, we propose an active learning strategy that samples items to minimize this bound by accounting for aleatoric and epistemic uncertainty in comparisons. We evaluate the resulting algorithm, and a variant aimed at reducing model misspecification, in multiple realistic ordering tasks with comparisons made by human annotators. Our results demonstrate superior sample efficiency and generalization compared to non-contextual ranking approaches and active preference learning baselines.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.03059&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Herman Bergström, Emil Carlsson, Devdatt Dubhashi, Fredrik D. Johansson</name></author><category term="stat.ML" /><summary type="html">Learning an ordering of items based on pairwise comparisons is useful when items are difficult to rate consistently on an absolute scale, for example, when annotators have to make subjective assessments. When exhaustive comparison is infeasible, actively sampling item pairs can reduce the number of annotations necessary for learning an accurate ordering. However, many algorithms ignore shared structure between items, limiting their sample efficiency and precluding generalization to new items. It is also common to disregard how noise in comparisons varies between item pairs, despite it being informative of item similarity. In this work, we study active preference learning for ordering items with contextual attributes, both in- and out-of-sample. We give an upper bound on the expected ordering error of a logistic preference model as a function of which items have been compared. Next, we propose an active learning strategy that samples items to minimize this bound by accounting for aleatoric and epistemic uncertainty in comparisons. We evaluate the resulting algorithm, and a variant aimed at reducing model misspecification, in multiple realistic ordering tasks with comparisons made by human annotators. Our results demonstrate superior sample efficiency and generalization compared to non-contextual ranking approaches and active preference learning baselines.</summary></entry><entry><title type="html">Adaptive Transfer Clustering: A Unified Framework</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AdaptiveTransferClusteringAUnifiedFramework.html" rel="alternate" type="text/html" title="Adaptive Transfer Clustering: A Unified Framework" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AdaptiveTransferClusteringAUnifiedFramework</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AdaptiveTransferClusteringAUnifiedFramework.html">&lt;p&gt;We propose a general transfer learning framework for clustering given a main dataset and an auxiliary one about the same subjects. The two datasets may reflect similar but different latent grouping structures of the subjects. We propose an adaptive transfer clustering (ATC) algorithm that automatically leverages the commonality in the presence of unknown discrepancy, by optimizing an estimated bias-variance decomposition. It applies to a broad class of statistical models including Gaussian mixture models, stochastic block models, and latent class models. A theoretical analysis proves the optimality of ATC under the Gaussian mixture model and explicitly quantifies the benefit of transfer. Extensive simulations and real data experiments confirm our method’s effectiveness in various scenarios.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21263&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yuqi Gu, Zhongyuan Lyu, Kaizheng Wang</name></author><category term="stat.ME," /><category term="stat.ML," /><category term="stat.TH" /><summary type="html">We propose a general transfer learning framework for clustering given a main dataset and an auxiliary one about the same subjects. The two datasets may reflect similar but different latent grouping structures of the subjects. We propose an adaptive transfer clustering (ATC) algorithm that automatically leverages the commonality in the presence of unknown discrepancy, by optimizing an estimated bias-variance decomposition. It applies to a broad class of statistical models including Gaussian mixture models, stochastic block models, and latent class models. A theoretical analysis proves the optimality of ATC under the Gaussian mixture model and explicitly quantifies the benefit of transfer. Extensive simulations and real data experiments confirm our method’s effectiveness in various scenarios.</summary></entry><entry><title type="html">Adjoint Matching: Fine-tuning Flow and Diffusion Generative Models with Memoryless Stochastic Optimal Control</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AdjointMatchingFinetuningFlowandDiffusionGenerativeModelswithMemorylessStochasticOptimalControl.html" rel="alternate" type="text/html" title="Adjoint Matching: Fine-tuning Flow and Diffusion Generative Models with Memoryless Stochastic Optimal Control" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AdjointMatchingFinetuningFlowandDiffusionGenerativeModelswithMemorylessStochasticOptimalControl</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AdjointMatchingFinetuningFlowandDiffusionGenerativeModelswithMemorylessStochasticOptimalControl.html">&lt;p&gt;Dynamical generative models that produce samples through an iterative process, such as Flow Matching and denoising diffusion models, have seen widespread use, but there have not been many theoretically-sound methods for improving these models with reward fine-tuning. In this work, we cast reward fine-tuning as stochastic optimal control (SOC). Critically, we prove that a very specific memoryless noise schedule must be enforced during fine-tuning, in order to account for the dependency between the noise variable and the generated samples. We also propose a new algorithm named Adjoint Matching which outperforms existing SOC algorithms, by casting SOC problems as a regression problem. We find that our approach significantly improves over existing methods for reward fine-tuning, achieving better consistency, realism, and generalization to unseen human preference reward models, while retaining sample diversity.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2409.08861&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Carles Domingo-Enrich, Michal Drozdzal, Brian Karrer, Ricky T. Q. Chen</name></author><category term="stat.ML" /><summary type="html">Dynamical generative models that produce samples through an iterative process, such as Flow Matching and denoising diffusion models, have seen widespread use, but there have not been many theoretically-sound methods for improving these models with reward fine-tuning. In this work, we cast reward fine-tuning as stochastic optimal control (SOC). Critically, we prove that a very specific memoryless noise schedule must be enforced during fine-tuning, in order to account for the dependency between the noise variable and the generated samples. We also propose a new algorithm named Adjoint Matching which outperforms existing SOC algorithms, by casting SOC problems as a regression problem. We find that our approach significantly improves over existing methods for reward fine-tuning, achieving better consistency, realism, and generalization to unseen human preference reward models, while retaining sample diversity.</summary></entry><entry><title type="html">A first-order augmented Lagrangian method for constrained minimax optimization</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AfirstorderaugmentedLagrangianmethodforconstrainedminimaxoptimization.html" rel="alternate" type="text/html" title="A first-order augmented Lagrangian method for constrained minimax optimization" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AfirstorderaugmentedLagrangianmethodforconstrainedminimaxoptimization</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AfirstorderaugmentedLagrangianmethodforconstrainedminimaxoptimization.html">&lt;p&gt;In this paper we study a class of constrained minimax problems. In particular, we propose a first-order augmented Lagrangian method for solving them, whose subproblems turn out to be a much simpler structured minimax problem and are suitably solved by a first-order method developed in this paper. Under some suitable assumptions, an \emph{operation complexity} of $O(\varepsilon^{-4}\log\varepsilon^{-1})$, measured by its fundamental operations, is established for the first-order augmented Lagrangian method for finding an $\varepsilon$-KKT solution of the constrained minimax problems.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2301.02060&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Zhaosong Lu, Sanyou Mei</name></author><category term="stat.ML" /><summary type="html">In this paper we study a class of constrained minimax problems. In particular, we propose a first-order augmented Lagrangian method for solving them, whose subproblems turn out to be a much simpler structured minimax problem and are suitably solved by a first-order method developed in this paper. Under some suitable assumptions, an \emph{operation complexity} of $O(\varepsilon^{-4}\log\varepsilon^{-1})$, measured by its fundamental operations, is established for the first-order augmented Lagrangian method for finding an $\varepsilon$-KKT solution of the constrained minimax problems.</summary></entry><entry><title type="html">Almost goodness-of-fit tests</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Almostgoodnessoffittests.html" rel="alternate" type="text/html" title="Almost goodness-of-fit tests" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Almostgoodnessoffittests</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Almostgoodnessoffittests.html">&lt;p&gt;We introduce the almost goodness-of-fit test, a procedure to decide if a (parametric) model provides a good representation of the probability distribution generating the observed sample. We consider the approximate model determined by an M-estimator of the parameters as the best representative of the unknown distribution within the parametric class. The objective is the approximate validation of a distribution or an entire parametric family up to a pre-specified threshold value, the margin of error. The methodology also allows quantifying the percentage improvement of the proposed model compared to a non-informative (constant) one. The test statistic is the $\mathrm{L}^p$-distance between the empirical distribution function and the corresponding one of the estimated (parametric) model. The value of the parameter $p$ allows modulating the impact of the tails of the distribution in the validation of the model. By deriving the asymptotic distribution of the test statistic, as well as proving the consistency of its bootstrap approximation, we present an easy-to-implement and flexible method. The performance of the proposal is illustrated with a simulation study and the analysis of a real dataset.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20918&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Amparo Baíllo, Javier Cárcamo</name></author><category term="stat.ME," /><category term="stat.AP," /><category term="stat.TH" /><summary type="html">We introduce the almost goodness-of-fit test, a procedure to decide if a (parametric) model provides a good representation of the probability distribution generating the observed sample. We consider the approximate model determined by an M-estimator of the parameters as the best representative of the unknown distribution within the parametric class. The objective is the approximate validation of a distribution or an entire parametric family up to a pre-specified threshold value, the margin of error. The methodology also allows quantifying the percentage improvement of the proposed model compared to a non-informative (constant) one. The test statistic is the $\mathrm{L}^p$-distance between the empirical distribution function and the corresponding one of the estimated (parametric) model. The value of the parameter $p$ allows modulating the impact of the tails of the distribution in the validation of the model. By deriving the asymptotic distribution of the test statistic, as well as proving the consistency of its bootstrap approximation, we present an easy-to-implement and flexible method. The performance of the proposal is illustrated with a simulation study and the analysis of a real dataset.</summary></entry><entry><title type="html">A model and method for analyzing the precision of binary measurement methods based on beta-binomial distributions, and related statistical tests</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Amodelandmethodforanalyzingtheprecisionofbinarymeasurementmethodsbasedonbetabinomialdistributionsandrelatedstatisticaltests.html" rel="alternate" type="text/html" title="A model and method for analyzing the precision of binary measurement methods based on beta-binomial distributions, and related statistical tests" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Amodelandmethodforanalyzingtheprecisionofbinarymeasurementmethodsbasedonbetabinomialdistributionsandrelatedstatisticaltests</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Amodelandmethodforanalyzingtheprecisionofbinarymeasurementmethodsbasedonbetabinomialdistributionsandrelatedstatisticaltests.html">&lt;p&gt;This study developed a new statistical model and method for analyzing the precision of binary measurement methods from collaborative studies. The model is based on beta-binomial distributions. In other words, it assumes that the sensitivity of each laboratory obeys a beta distribution, and the binary measured values under a given sensitivity follow a binomial distribution. We propose the key precision measures of repeatability and reproducibility for the model, and provide their unbiased estimates. Further, through consideration of a number of statistical test methods for homogeneity of proportions, we propose appropriate methods for determining laboratory effects in the new model. Finally, we apply the results to real-world examples in the fields of food safety and chemical risk assessment and management.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2008.13619&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jun-ichi Takeshita, Tomomichi Suzuki</name></author><category term="stat.AP," /><category term="stat.ME" /><summary type="html">This study developed a new statistical model and method for analyzing the precision of binary measurement methods from collaborative studies. The model is based on beta-binomial distributions. In other words, it assumes that the sensitivity of each laboratory obeys a beta distribution, and the binary measured values under a given sensitivity follow a binomial distribution. We propose the key precision measures of repeatability and reproducibility for the model, and provide their unbiased estimates. Further, through consideration of a number of statistical test methods for homogeneity of proportions, we propose appropriate methods for determining laboratory effects in the new model. Finally, we apply the results to real-world examples in the fields of food safety and chemical risk assessment and management.</summary></entry><entry><title type="html">An Adaptive Multivariate Functional EWMA Control Chart</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AnAdaptiveMultivariateFunctionalEWMAControlChart.html" rel="alternate" type="text/html" title="An Adaptive Multivariate Functional EWMA Control Chart" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AnAdaptiveMultivariateFunctionalEWMAControlChart</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AnAdaptiveMultivariateFunctionalEWMAControlChart.html">&lt;p&gt;In many modern industrial scenarios, the measurements of the quality characteristics of interest are often required to be represented as functional data or profiles. This motivates the growing interest in extending traditional univariate statistical process monitoring (SPM) schemes to the functional data setting. This article proposes a new SPM scheme, which is referred to as adaptive multivariate functional EWMA (AMFEWMA), to extend the well-known exponentially weighted moving average (EWMA) control chart from the univariate scalar to the multivariate functional setting. The favorable performance of the AMFEWMA control chart over existing methods is assessed via an extensive Monte Carlo simulation. Its practical applicability is demonstrated through a case study in the monitoring of the quality of a resistance spot welding process in the automotive industry through the online observations of dynamic resistance curves, which are associated with multiple spot welds on the same car body and recognized as the full technological signature of the process.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2403.03837&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Christian Capezza, Giovanna Capizzi, Fabio Centofanti, Antonio Lepore, Biagio Palumbo</name></author><category term="stat.ME," /><category term="stat.AP" /><summary type="html">In many modern industrial scenarios, the measurements of the quality characteristics of interest are often required to be represented as functional data or profiles. This motivates the growing interest in extending traditional univariate statistical process monitoring (SPM) schemes to the functional data setting. This article proposes a new SPM scheme, which is referred to as adaptive multivariate functional EWMA (AMFEWMA), to extend the well-known exponentially weighted moving average (EWMA) control chart from the univariate scalar to the multivariate functional setting. The favorable performance of the AMFEWMA control chart over existing methods is assessed via an extensive Monte Carlo simulation. Its practical applicability is demonstrated through a case study in the monitoring of the quality of a resistance spot welding process in the automotive industry through the online observations of dynamic resistance curves, which are associated with multiple spot welds on the same car body and recognized as the full technological signature of the process.</summary></entry><entry><title type="html">An Effective Theory of Bias Amplification</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AnEffectiveTheoryofBiasAmplification.html" rel="alternate" type="text/html" title="An Effective Theory of Bias Amplification" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AnEffectiveTheoryofBiasAmplification</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AnEffectiveTheoryofBiasAmplification.html">&lt;p&gt;Machine learning models may capture and amplify biases present in data, leading to disparate test performance across social groups. To better understand, evaluate, and mitigate these possible biases, a deeper theoretical understanding of how model design choices and data distribution properties could contribute to bias is needed. In this work, we contribute a precise analytical theory in the context of ridge regression, both with and without random projections, where the former models neural networks in a simplified regime. Our theory offers a unified and rigorous explanation of machine learning bias, providing insights into phenomena such as bias amplification and minority-group bias in various feature and parameter regimes. For example, we demonstrate that there may be an optimal regularization penalty or training time to avoid bias amplification, and there can be fundamental differences in test error between groups that do not vanish with increased parameterization. Importantly, our theoretical predictions align with several empirical observations reported in the literature. We extensively empirically validate our theory on diverse synthetic and semi-synthetic datasets.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.17263&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Arjun Subramonian, Sam Bell, Levent Sagun, Elvis Dohmatob</name></author><category term="stat.ML" /><summary type="html">Machine learning models may capture and amplify biases present in data, leading to disparate test performance across social groups. To better understand, evaluate, and mitigate these possible biases, a deeper theoretical understanding of how model design choices and data distribution properties could contribute to bias is needed. In this work, we contribute a precise analytical theory in the context of ridge regression, both with and without random projections, where the former models neural networks in a simplified regime. Our theory offers a unified and rigorous explanation of machine learning bias, providing insights into phenomena such as bias amplification and minority-group bias in various feature and parameter regimes. For example, we demonstrate that there may be an optimal regularization penalty or training time to avoid bias amplification, and there can be fundamental differences in test error between groups that do not vanish with increased parameterization. Importantly, our theoretical predictions align with several empirical observations reported in the literature. We extensively empirically validate our theory on diverse synthetic and semi-synthetic datasets.</summary></entry><entry><title type="html">Analysis of Diurnal Air Temperature Trends and Pattern Similarities in Highland and Lowland Stations of Italy and UK</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AnalysisofDiurnalAirTemperatureTrendsandPatternSimilaritiesinHighlandandLowlandStationsofItalyandUK.html" rel="alternate" type="text/html" title="Analysis of Diurnal Air Temperature Trends and Pattern Similarities in Highland and Lowland Stations of Italy and UK" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AnalysisofDiurnalAirTemperatureTrendsandPatternSimilaritiesinHighlandandLowlandStationsofItalyandUK</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/AnalysisofDiurnalAirTemperatureTrendsandPatternSimilaritiesinHighlandandLowlandStationsofItalyandUK.html">&lt;p&gt;In this paper, an analysis of hourly air temperatures in four groups of 32 stations of the UK highland (five stations), UK lowland (four stations), Italian highland (eleven stations), and Italian lowland (twelve stations) at various altitudes was conducted over the period from 2002 to 2021. The study aimed to examine the trends of each hour of the day in that period, over different averaging time windows (-10 day, -30 day, and -60 day). The trends were computed using the Mann-Kendall trend test and Sen’s slope estimator. The similarity of trends within and across the groups of stations was assessed using the hierarchical clustering with dynamic time warping technique. An additional analysis was conducted to show the correlation of trends among the group of stations using the correlation distance matrix. Hierarchical clustering and distance correlation analysis show trend similarities and correlations, also indicating dissimilarities among different groups. Using 30 day averages, significant warming trends in specific months at the Italian stations are evident, especially in February, July, August, and December. The UK highland stations did not show statistically significant trends, but clear pattern similarities were found within the groups, especially in certain months. The ultimate goal of this paper is to provide insights into temperature dynamics and climate change characteristics on regional and diurnal scales.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20726&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Chalachew Muluken Liyew. Rosa Meo, Stefano Ferraris, Elvira Di Nardo</name></author><category term="stat.AP" /><summary type="html">In this paper, an analysis of hourly air temperatures in four groups of 32 stations of the UK highland (five stations), UK lowland (four stations), Italian highland (eleven stations), and Italian lowland (twelve stations) at various altitudes was conducted over the period from 2002 to 2021. The study aimed to examine the trends of each hour of the day in that period, over different averaging time windows (-10 day, -30 day, and -60 day). The trends were computed using the Mann-Kendall trend test and Sen’s slope estimator. The similarity of trends within and across the groups of stations was assessed using the hierarchical clustering with dynamic time warping technique. An additional analysis was conducted to show the correlation of trends among the group of stations using the correlation distance matrix. Hierarchical clustering and distance correlation analysis show trend similarities and correlations, also indicating dissimilarities among different groups. Using 30 day averages, significant warming trends in specific months at the Italian stations are evident, especially in February, July, August, and December. The UK highland stations did not show statistically significant trends, but clear pattern similarities were found within the groups, especially in certain months. The ultimate goal of this paper is to provide insights into temperature dynamics and climate change characteristics on regional and diurnal scales.</summary></entry><entry><title type="html">A novel decomposition to explain heterogeneity in observational and randomized studies of causality</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Anoveldecompositiontoexplainheterogeneityinobservationalandrandomizedstudiesofcausality.html" rel="alternate" type="text/html" title="A novel decomposition to explain heterogeneity in observational and randomized studies of causality" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Anoveldecompositiontoexplainheterogeneityinobservationalandrandomizedstudiesofcausality</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Anoveldecompositiontoexplainheterogeneityinobservationalandrandomizedstudiesofcausality.html">&lt;p&gt;This paper introduces a novel decomposition framework to explain heterogeneity in causal effects observed across different studies, considering both observational and randomized settings. We present a formal decomposition of between-study heterogeneity, identifying sources of variability in treatment effects across studies. The proposed methodology allows for robust estimation of causal parameters under various assumptions, addressing differences in pre-treatment covariate distributions, mediating variables, and the outcome mechanism. Our approach is validated through a simulation study and applied to data from the Moving to Opportunity (MTO) study, demonstrating its practical relevance. This work contributes to the broader understanding of causal inference in multi-study environments, with potential applications in evidence synthesis and policy-making.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2208.05543&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Brian Gilbert, Ivan D{\i}az, Kara E. Rudolph, Tat-Thang Vo</name></author><category term="stat.ME" /><summary type="html">This paper introduces a novel decomposition framework to explain heterogeneity in causal effects observed across different studies, considering both observational and randomized settings. We present a formal decomposition of between-study heterogeneity, identifying sources of variability in treatment effects across studies. The proposed methodology allows for robust estimation of causal parameters under various assumptions, addressing differences in pre-treatment covariate distributions, mediating variables, and the outcome mechanism. Our approach is validated through a simulation study and applied to data from the Moving to Opportunity (MTO) study, demonstrating its practical relevance. This work contributes to the broader understanding of causal inference in multi-study environments, with potential applications in evidence synthesis and policy-making.</summary></entry><entry><title type="html">A successive approximation method in functional spaces for hierarchical optimal control problems and its application to learning</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Asuccessiveapproximationmethodinfunctionalspacesforhierarchicaloptimalcontrolproblemsanditsapplicationtolearning.html" rel="alternate" type="text/html" title="A successive approximation method in functional spaces for hierarchical optimal control problems and its application to learning" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Asuccessiveapproximationmethodinfunctionalspacesforhierarchicaloptimalcontrolproblemsanditsapplicationtolearning</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Asuccessiveapproximationmethodinfunctionalspacesforhierarchicaloptimalcontrolproblemsanditsapplicationtolearning.html">&lt;p&gt;We consider a class of learning problem of point estimation for modeling high-dimensional nonlinear functions, whose learning dynamics is guided by model training dataset, while the estimated parameter in due course provides an acceptable prediction accuracy on a different model validation dataset. Here, we establish an evidential connection between such a learning problem and a hierarchical optimal control problem that provides a framework how to account appropriately for both generalization and regularization at the optimization stage. In particular, we consider the following two objectives: (i) The first one is a controllability-type problem, i.e., generalization, which consists of guaranteeing the estimated parameter to reach a certain target set at some fixed final time, where such a target set is associated with model validation dataset. (ii) The second one is a regularization-type problem ensuring the estimated parameter trajectory to satisfy some regularization property over a certain finite time interval. First, we partition the control into two control strategies that are compatible with two abstract agents, namely, a leader, which is responsible for the controllability-type problem and that of a follower, which is associated with the regularization-type problem. Using the notion of Stackelberg’s optimization, we provide conditions on the existence of admissible optimal controls for such a hierarchical optimal control problem under which the follower is required to respond optimally to the strategy of the leader, so as to achieve the overall objectives that ultimately leading to an optimal parameter estimate. Moreover, we provide a nested algorithm, arranged in a hierarchical structure-based on successive approximation methods, for solving the corresponding optimal control problem. Finally, we present some numerical results for a typical nonlinear regression problem.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20617&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Getachew K. Befekadu</name></author><category term="stat.ML" /><summary type="html">We consider a class of learning problem of point estimation for modeling high-dimensional nonlinear functions, whose learning dynamics is guided by model training dataset, while the estimated parameter in due course provides an acceptable prediction accuracy on a different model validation dataset. Here, we establish an evidential connection between such a learning problem and a hierarchical optimal control problem that provides a framework how to account appropriately for both generalization and regularization at the optimization stage. In particular, we consider the following two objectives: (i) The first one is a controllability-type problem, i.e., generalization, which consists of guaranteeing the estimated parameter to reach a certain target set at some fixed final time, where such a target set is associated with model validation dataset. (ii) The second one is a regularization-type problem ensuring the estimated parameter trajectory to satisfy some regularization property over a certain finite time interval. First, we partition the control into two control strategies that are compatible with two abstract agents, namely, a leader, which is responsible for the controllability-type problem and that of a follower, which is associated with the regularization-type problem. Using the notion of Stackelberg’s optimization, we provide conditions on the existence of admissible optimal controls for such a hierarchical optimal control problem under which the follower is required to respond optimally to the strategy of the leader, so as to achieve the overall objectives that ultimately leading to an optimal parameter estimate. Moreover, we provide a nested algorithm, arranged in a hierarchical structure-based on successive approximation methods, for solving the corresponding optimal control problem. Finally, we present some numerical results for a typical nonlinear regression problem.</summary></entry><entry><title type="html">BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BLASTBlockLevelAdaptiveStructuredMatricesforEfficientDeepNeuralNetworkInference.html" rel="alternate" type="text/html" title="BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BLASTBlockLevelAdaptiveStructuredMatricesforEfficientDeepNeuralNetworkInference</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BLASTBlockLevelAdaptiveStructuredMatricesforEfficientDeepNeuralNetworkInference.html">&lt;p&gt;Large-scale foundation models have demonstrated exceptional performance in language and vision tasks. However, the numerous dense matrix-vector operations involved in these large networks pose significant computational challenges during inference. To address these challenges, we introduce the Block-Level Adaptive STructured (BLAST) matrix, designed to learn and leverage efficient structures prevalent in the weight matrices of linear layers within deep learning models. Compared to existing structured matrices, the BLAST matrix offers substantial flexibility, as it can represent various types of structures that are either learned from data or computed from pre-existing weight matrices. We demonstrate the efficiency of using the BLAST matrix for compressing both language and vision tasks, showing that (i) for medium-sized models such as ViT and GPT-2, training with BLAST weights boosts performance while reducing complexity by 70\% and 40\%, respectively; and (ii) for large foundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2x compression while exhibiting the lowest performance degradation among all tested structured matrices. Our code is available at \url{https://github.com/changwoolee/BLAST}.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21262&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Changwoo Lee, Soo Min Kwon, Qing Qu, Hun-Seok Kim</name></author><category term="stat.ML" /><summary type="html">Large-scale foundation models have demonstrated exceptional performance in language and vision tasks. However, the numerous dense matrix-vector operations involved in these large networks pose significant computational challenges during inference. To address these challenges, we introduce the Block-Level Adaptive STructured (BLAST) matrix, designed to learn and leverage efficient structures prevalent in the weight matrices of linear layers within deep learning models. Compared to existing structured matrices, the BLAST matrix offers substantial flexibility, as it can represent various types of structures that are either learned from data or computed from pre-existing weight matrices. We demonstrate the efficiency of using the BLAST matrix for compressing both language and vision tasks, showing that (i) for medium-sized models such as ViT and GPT-2, training with BLAST weights boosts performance while reducing complexity by 70\% and 40\%, respectively; and (ii) for large foundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2x compression while exhibiting the lowest performance degradation among all tested structured matrices. Our code is available at \url{https://github.com/changwoolee/BLAST}.</summary></entry><entry><title type="html">BSD: a Bayesian framework for parametric models of neural spectra</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BSDaBayesianframeworkforparametricmodelsofneuralspectra.html" rel="alternate" type="text/html" title="BSD: a Bayesian framework for parametric models of neural spectra" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BSDaBayesianframeworkforparametricmodelsofneuralspectra</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BSDaBayesianframeworkforparametricmodelsofneuralspectra.html">&lt;p&gt;The analysis of neural power spectra plays a crucial role in understanding brain function and dysfunction. While recent efforts have led to the development of methods for decomposing spectral data, challenges remain in performing statistical analysis and group-level comparisons. Here, we introduce Bayesian Spectral Decomposition (BSD), a Bayesian framework for analysing neural spectral power. BSD allows for the specification, inversion, comparison, and analysis of parametric models of neural spectra, addressing limitations of existing methods. We first establish the face validity of BSD on simulated data and show how it outperforms an established method (\fooof{}) for peak detection on artificial spectral data. We then demonstrate the efficacy of BSD on a group-level study of EEG spectra in 204 healthy subjects from the LEMON dataset. Our results not only highlight the effectiveness of BSD in model selection and parameter estimation, but also illustrate how BSD enables straightforward group-level regression of the effect of continuous covariates such as age. By using Bayesian inference techniques, BSD provides a robust framework for studying neural spectral data and their relationship to brain function and dysfunction.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20896&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Johan Medrano, Nicholas A. Alexander, Robert A. Seymour, Peter Zeidman</name></author><category term="stat.AP," /><category term="stat.ME," /><category term="stat.ML" /><summary type="html">The analysis of neural power spectra plays a crucial role in understanding brain function and dysfunction. While recent efforts have led to the development of methods for decomposing spectral data, challenges remain in performing statistical analysis and group-level comparisons. Here, we introduce Bayesian Spectral Decomposition (BSD), a Bayesian framework for analysing neural spectral power. BSD allows for the specification, inversion, comparison, and analysis of parametric models of neural spectra, addressing limitations of existing methods. We first establish the face validity of BSD on simulated data and show how it outperforms an established method (\fooof{}) for peak detection on artificial spectral data. We then demonstrate the efficacy of BSD on a group-level study of EEG spectra in 204 healthy subjects from the LEMON dataset. Our results not only highlight the effectiveness of BSD in model selection and parameter estimation, but also illustrate how BSD enables straightforward group-level regression of the effect of continuous covariates such as age. By using Bayesian inference techniques, BSD provides a robust framework for studying neural spectral data and their relationship to brain function and dysfunction.</summary></entry><entry><title type="html">BUNDL: Bayesian Uncertainty-aware Deep Learning with Noisy training Labels for Seizure Detection in EEG</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BUNDLBayesianUncertaintyawareDeepLearningwithNoisytrainingLabelsforSeizureDetectioninEEG.html" rel="alternate" type="text/html" title="BUNDL: Bayesian Uncertainty-aware Deep Learning with Noisy training Labels for Seizure Detection in EEG" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BUNDLBayesianUncertaintyawareDeepLearningwithNoisytrainingLabelsforSeizureDetectioninEEG</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BUNDLBayesianUncertaintyawareDeepLearningwithNoisytrainingLabelsforSeizureDetectioninEEG.html">&lt;p&gt;Deep learning methods are at the forefront of automated epileptic seizure detection and onset zone localization using scalp-EEG. However, the performance of deep learning methods rely heavily on the quality of annotated training datasets. Scalp EEG is susceptible to high noise levels, which in turn leads to imprecise annotations of the seizure timing and characteristics. This label noise presents a significant challenge in model training and generalization. In this paper, we introduce a novel statistical framework that informs a deep learning model of label ambiguity, thereby enhancing the overall seizure detection performance. Our Bayesian UncertaiNty-aware Deep Learning, BUNDL, strategy offers a straightforward and model-agnostic method for training deep neural networks with noisy training labels that does not add any parameters to existing architectures. By integrating domain knowledge into the statistical framework, we derive a novel KL-divergence-based loss function that capitalizes on uncertainty to better learn seizure characteristics from scalp EEG. Additionally, we explore the impact of improved seizure detection on the task of automated onset zone localization. We validate BUNDL using a comprehensive simulated EEG dataset and two publicly available datasets, TUH and CHB-MIT. BUNDL consistently improves the performance of three base models on simulated data under seven types of label noise and three EEG signal-to-noise ratios. Similar improvements were observed in the real-world TUH and CHB-MIT datasets. Finally, we demonstrate that BUNDL improves the accuracy of seizure onset zone localization. BUNDL is specifically designed to address label ambiguities, enabling the training of reliable and trustworthy models for epilepsy evaluation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.19815&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Deeksha M Shama, Archana Venkataraman</name></author><category term="stat.ML" /><summary type="html">Deep learning methods are at the forefront of automated epileptic seizure detection and onset zone localization using scalp-EEG. However, the performance of deep learning methods rely heavily on the quality of annotated training datasets. Scalp EEG is susceptible to high noise levels, which in turn leads to imprecise annotations of the seizure timing and characteristics. This label noise presents a significant challenge in model training and generalization. In this paper, we introduce a novel statistical framework that informs a deep learning model of label ambiguity, thereby enhancing the overall seizure detection performance. Our Bayesian UncertaiNty-aware Deep Learning, BUNDL, strategy offers a straightforward and model-agnostic method for training deep neural networks with noisy training labels that does not add any parameters to existing architectures. By integrating domain knowledge into the statistical framework, we derive a novel KL-divergence-based loss function that capitalizes on uncertainty to better learn seizure characteristics from scalp EEG. Additionally, we explore the impact of improved seizure detection on the task of automated onset zone localization. We validate BUNDL using a comprehensive simulated EEG dataset and two publicly available datasets, TUH and CHB-MIT. BUNDL consistently improves the performance of three base models on simulated data under seven types of label noise and three EEG signal-to-noise ratios. Similar improvements were observed in the real-world TUH and CHB-MIT datasets. Finally, we demonstrate that BUNDL improves the accuracy of seizure onset zone localization. BUNDL is specifically designed to address label ambiguities, enabling the training of reliable and trustworthy models for epilepsy evaluation.</summary></entry><entry><title type="html">BanditCAT and AutoIRT: Machine Learning Approaches to Computerized Adaptive Testing and Item Calibration</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BanditCATandAutoIRTMachineLearningApproachestoComputerizedAdaptiveTestingandItemCalibration.html" rel="alternate" type="text/html" title="BanditCAT and AutoIRT: Machine Learning Approaches to Computerized Adaptive Testing and Item Calibration" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BanditCATandAutoIRTMachineLearningApproachestoComputerizedAdaptiveTestingandItemCalibration</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BanditCATandAutoIRTMachineLearningApproachestoComputerizedAdaptiveTestingandItemCalibration.html">&lt;p&gt;In this paper, we present a complete framework for quickly calibrating and administering a robust large-scale computerized adaptive test (CAT) with a small number of responses. Calibration - learning item parameters in a test - is done using AutoIRT, a new method that uses automated machine learning (AutoML) in combination with item response theory (IRT), originally proposed in [Sharpnack et al., 2024]. AutoIRT trains a non-parametric AutoML grading model using item features, followed by an item-specific parametric model, which results in an explanatory IRT model. In our work, we use tabular AutoML tools (AutoGluon.tabular, [Erickson et al., 2020]) along with BERT embeddings and linguistically motivated NLP features. In this framework, we use Bayesian updating to obtain test taker ability posterior distributions for administration and scoring.
  For administration of our adaptive test, we propose the BanditCAT framework, a methodology motivated by casting the problem in the contextual bandit framework and utilizing item response theory (IRT). The key insight lies in defining the bandit reward as the Fisher information for the selected item, given the latent test taker ability from IRT assumptions. We use Thompson sampling to balance between exploring items with different psychometric characteristics and selecting highly discriminative items that give more precise information about ability. To control item exposure, we inject noise through an additional randomization step before computing the Fisher information. This framework was used to initially launch two new item types on the DET practice test using limited training data. We outline some reliability and exposure metrics for the 5 practice test experiments that utilized this framework.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21033&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>James Sharpnack, Kevin Hao, Phoebe Mulcaire, Klinton Bicknell, Geoff LaFlair, Kevin Yancey, Alina A. von Davier</name></author><category term="stat.ML," /><category term="stat.AP" /><summary type="html">In this paper, we present a complete framework for quickly calibrating and administering a robust large-scale computerized adaptive test (CAT) with a small number of responses. Calibration - learning item parameters in a test - is done using AutoIRT, a new method that uses automated machine learning (AutoML) in combination with item response theory (IRT), originally proposed in [Sharpnack et al., 2024]. AutoIRT trains a non-parametric AutoML grading model using item features, followed by an item-specific parametric model, which results in an explanatory IRT model. In our work, we use tabular AutoML tools (AutoGluon.tabular, [Erickson et al., 2020]) along with BERT embeddings and linguistically motivated NLP features. In this framework, we use Bayesian updating to obtain test taker ability posterior distributions for administration and scoring. For administration of our adaptive test, we propose the BanditCAT framework, a methodology motivated by casting the problem in the contextual bandit framework and utilizing item response theory (IRT). The key insight lies in defining the bandit reward as the Fisher information for the selected item, given the latent test taker ability from IRT assumptions. We use Thompson sampling to balance between exploring items with different psychometric characteristics and selecting highly discriminative items that give more precise information about ability. To control item exposure, we inject noise through an additional randomization step before computing the Fisher information. This framework was used to initially launch two new item types on the DET practice test using limited training data. We outline some reliability and exposure metrics for the 5 practice test experiments that utilized this framework.</summary></entry><entry><title type="html">Bandits with Mean Bounds</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BanditswithMeanBounds.html" rel="alternate" type="text/html" title="Bandits with Mean Bounds" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BanditswithMeanBounds</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BanditswithMeanBounds.html">&lt;p&gt;We study a variant of the bandit problem where side information in the form of bounds on the mean of each arm is provided. We prove that these translate to tighter estimates of subgaussian factors and develop novel algorithms that exploit these estimates. In the linear setting, we present the Restricted-set OFUL (R-OFUL) algorithm that additionally uses the geometric properties of the problem to (potentially) restrict the set of arms being played and reduce exploration rates for suboptimal arms. In the stochastic case, we propose the non-optimistic Global Under-Explore (GLUE) algorithm which employs the inferred subgaussian estimates to adapt the rate of exploration for the arms. We analyze the regret of R-OFUL and GLUE, showing that our regret upper bounds are never worse than that of the standard OFUL and UCB algorithms respectively. Further, we also consider a practically motivated setting of learning from confounded logs where mean bounds appear naturally.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2002.08405&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Nihal Sharma, Soumya Basu, Karthikeyan Shanmugam, Sanjay Shakkottai</name></author><category term="stat.ML" /><summary type="html">We study a variant of the bandit problem where side information in the form of bounds on the mean of each arm is provided. We prove that these translate to tighter estimates of subgaussian factors and develop novel algorithms that exploit these estimates. In the linear setting, we present the Restricted-set OFUL (R-OFUL) algorithm that additionally uses the geometric properties of the problem to (potentially) restrict the set of arms being played and reduce exploration rates for suboptimal arms. In the stochastic case, we propose the non-optimistic Global Under-Explore (GLUE) algorithm which employs the inferred subgaussian estimates to adapt the rate of exploration for the arms. We analyze the regret of R-OFUL and GLUE, showing that our regret upper bounds are never worse than that of the standard OFUL and UCB algorithms respectively. Further, we also consider a practically motivated setting of learning from confounded logs where mean bounds appear naturally.</summary></entry><entry><title type="html">Bayesian Bandit Algorithms with Approximate Inference in Stochastic Linear Bandits</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BayesianBanditAlgorithmswithApproximateInferenceinStochasticLinearBandits.html" rel="alternate" type="text/html" title="Bayesian Bandit Algorithms with Approximate Inference in Stochastic Linear Bandits" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BayesianBanditAlgorithmswithApproximateInferenceinStochasticLinearBandits</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BayesianBanditAlgorithmswithApproximateInferenceinStochasticLinearBandits.html">&lt;p&gt;Bayesian bandit algorithms with approximate Bayesian inference have been widely used in real-world applications. Despite the superior practical performance, their theoretical justification is less investigated in the literature, especially for contextual bandit problems. To fill this gap, we propose a theoretical framework to analyze the impact of approximate inference in stochastic linear bandits and conduct regret analysis on two Bayesian bandit algorithms, Linear Thompson sampling (LinTS) and the extension of Bayesian Upper Confidence Bound, namely Linear Bayesian Upper Confidence Bound (LinBUCB). We demonstrate that when applied in the presence of approximate inference, LinTS and LinBUCB can preserve their original rates of regret upper bound but with a sacrifice of larger constant terms. These results hold for general Bayesian inference approaches, assuming the inference error measured by two different $\alpha$-divergences is bounded. Additionally, by introducing a new definition of well-behaved distributions, we show that LinBUCB expedites the regret rate of LinTS from $\tilde{O}(d^{3/2}\sqrt{T})$ to $\tilde{O}(d\sqrt{T})$, matching the minimax optimal rate. To our knowledge, this work provides the first regret bounds in the setting of stochastic linear bandits with bounded approximate inference errors.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.14071&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ziyi Huang, Henry Lam, Haofeng Zhang</name></author><category term="stat.ML" /><summary type="html">Bayesian bandit algorithms with approximate Bayesian inference have been widely used in real-world applications. Despite the superior practical performance, their theoretical justification is less investigated in the literature, especially for contextual bandit problems. To fill this gap, we propose a theoretical framework to analyze the impact of approximate inference in stochastic linear bandits and conduct regret analysis on two Bayesian bandit algorithms, Linear Thompson sampling (LinTS) and the extension of Bayesian Upper Confidence Bound, namely Linear Bayesian Upper Confidence Bound (LinBUCB). We demonstrate that when applied in the presence of approximate inference, LinTS and LinBUCB can preserve their original rates of regret upper bound but with a sacrifice of larger constant terms. These results hold for general Bayesian inference approaches, assuming the inference error measured by two different $\alpha$-divergences is bounded. Additionally, by introducing a new definition of well-behaved distributions, we show that LinBUCB expedites the regret rate of LinTS from $\tilde{O}(d^{3/2}\sqrt{T})$ to $\tilde{O}(d\sqrt{T})$, matching the minimax optimal rate. To our knowledge, this work provides the first regret bounds in the setting of stochastic linear bandits with bounded approximate inference errors.</summary></entry><entry><title type="html">Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BeyondConceptBottleneckModelsHowtoMakeBlackBoxesIntervenable.html" rel="alternate" type="text/html" title="Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BeyondConceptBottleneckModelsHowtoMakeBlackBoxesIntervenable</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/BeyondConceptBottleneckModelsHowtoMakeBlackBoxesIntervenable.html">&lt;p&gt;Recently, interpretable machine learning has re-explored concept bottleneck models (CBM). An advantage of this model class is the user’s ability to intervene on predicted concept values, affecting the downstream output. In this work, we introduce a method to perform such concept-based interventions on pretrained neural networks, which are not interpretable by design, only given a small validation set with concept labels. Furthermore, we formalise the notion of intervenability as a measure of the effectiveness of concept-based interventions and leverage this definition to fine-tune black boxes. Empirically, we explore the intervenability of black-box classifiers on synthetic tabular and natural image benchmarks. We focus on backbone architectures of varying complexity, from simple, fully connected neural nets to Stable Diffusion. We demonstrate that the proposed fine-tuning improves intervention effectiveness and often yields better-calibrated predictions. To showcase the practical utility of our techniques, we apply them to deep chest X-ray classifiers and show that fine-tuned black boxes are more intervenable than CBMs. Lastly, we establish that our methods are still effective under vision-language-model-based concept annotations, alleviating the need for a human-annotated validation set.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2401.13544&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Sonia Laguna, Ričards Marcinkevičs, Moritz Vandenhirtz, Julia E. Vogt</name></author><category term="stat.ML" /><summary type="html">Recently, interpretable machine learning has re-explored concept bottleneck models (CBM). An advantage of this model class is the user’s ability to intervene on predicted concept values, affecting the downstream output. In this work, we introduce a method to perform such concept-based interventions on pretrained neural networks, which are not interpretable by design, only given a small validation set with concept labels. Furthermore, we formalise the notion of intervenability as a measure of the effectiveness of concept-based interventions and leverage this definition to fine-tune black boxes. Empirically, we explore the intervenability of black-box classifiers on synthetic tabular and natural image benchmarks. We focus on backbone architectures of varying complexity, from simple, fully connected neural nets to Stable Diffusion. We demonstrate that the proposed fine-tuning improves intervention effectiveness and often yields better-calibrated predictions. To showcase the practical utility of our techniques, we apply them to deep chest X-ray classifiers and show that fine-tuned black boxes are more intervenable than CBMs. Lastly, we establish that our methods are still effective under vision-language-model-based concept annotations, alleviating the need for a human-annotated validation set.</summary></entry><entry><title type="html">CDsampling: an R Package for Constrained D-optimal Sampling in Paid Research Study</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CDsamplinganRPackageforConstrainedDoptimalSamplinginPaidResearchStudy.html" rel="alternate" type="text/html" title="CDsampling: an R Package for Constrained D-optimal Sampling in Paid Research Study" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CDsamplinganRPackageforConstrainedDoptimalSamplinginPaidResearchStudy</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CDsamplinganRPackageforConstrainedDoptimalSamplinginPaidResearchStudy.html">&lt;p&gt;In the context of paid research studies and clinical trials, budget considerations and patient sampling from available populations are subject to inherent constraints. We introduce the R package CDsampling, which is the first to our knowledge to integrate optimal design theories within the framework of constrained sampling. This package offers the possibility to find both D-optimal approximate and exact allocations for samplings with or without constraints. Additionally, it provides functions to find constrained uniform sampling as a robust sampling strategy when the model information is limited. To demonstrate its efficacy, we provide simulated examples and a real-data example with datasets embedded in the package and compare them with classical sampling methods. Furthermore, it revisits the theoretical results of the Fisher information matrix for generalized linear models (including regular linear regression model) and multinomial logistic models, offering functions for its computation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20606&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yifei Huang, Liping Tong, Jie Yang</name></author><category term="stat.CO," /><category term="stat.AP" /><summary type="html">In the context of paid research studies and clinical trials, budget considerations and patient sampling from available populations are subject to inherent constraints. We introduce the R package CDsampling, which is the first to our knowledge to integrate optimal design theories within the framework of constrained sampling. This package offers the possibility to find both D-optimal approximate and exact allocations for samplings with or without constraints. Additionally, it provides functions to find constrained uniform sampling as a robust sampling strategy when the model information is limited. To demonstrate its efficacy, we provide simulated examples and a real-data example with datasets embedded in the package and compare them with classical sampling methods. Furthermore, it revisits the theoretical results of the Fisher information matrix for generalized linear models (including regular linear regression model) and multinomial logistic models, offering functions for its computation.</summary></entry><entry><title type="html">CaTs and DAGs: Integrating Directed Acyclic Graphs with Transformers and Fully-Connected Neural Networks for Causally Constrained Predictions</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CaTsandDAGsIntegratingDirectedAcyclicGraphswithTransformersandFullyConnectedNeuralNetworksforCausallyConstrainedPredictions.html" rel="alternate" type="text/html" title="CaTs and DAGs: Integrating Directed Acyclic Graphs with Transformers and Fully-Connected Neural Networks for Causally Constrained Predictions" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CaTsandDAGsIntegratingDirectedAcyclicGraphswithTransformersandFullyConnectedNeuralNetworksforCausallyConstrainedPredictions</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CaTsandDAGsIntegratingDirectedAcyclicGraphswithTransformersandFullyConnectedNeuralNetworksforCausallyConstrainedPredictions.html">&lt;p&gt;Artificial Neural Networks (ANNs), including fully-connected networks and transformers, are highly flexible and powerful function approximators, widely applied in fields like computer vision and natural language processing. However, their inability to inherently respect causal structures can limit their robustness, making them vulnerable to covariate shift and difficult to interpret/explain. This poses significant challenges for their reliability in real-world applications. In this paper, we introduce Causal Fully-Connected Neural Networks (CFCNs) and Causal Transformers (CaTs), two general model families designed to operate under predefined causal constraints, as specified by a Directed Acyclic Graph (DAG). These models retain the powerful function approximation abilities of traditional neural networks while adhering to the underlying structural constraints, improving robustness, reliability, and interpretability at inference time. This approach opens new avenues for deploying neural networks in more demanding, real-world scenarios where robustness and explainability is critical.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.14485&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Matthew J. Vowels, Mathieu Rochat, Sina Akbari</name></author><category term="stat.ML" /><summary type="html">Artificial Neural Networks (ANNs), including fully-connected networks and transformers, are highly flexible and powerful function approximators, widely applied in fields like computer vision and natural language processing. However, their inability to inherently respect causal structures can limit their robustness, making them vulnerable to covariate shift and difficult to interpret/explain. This poses significant challenges for their reliability in real-world applications. In this paper, we introduce Causal Fully-Connected Neural Networks (CFCNs) and Causal Transformers (CaTs), two general model families designed to operate under predefined causal constraints, as specified by a Directed Acyclic Graph (DAG). These models retain the powerful function approximation abilities of traditional neural networks while adhering to the underlying structural constraints, improving robustness, reliability, and interpretability at inference time. This approach opens new avenues for deploying neural networks in more demanding, real-world scenarios where robustness and explainability is critical.</summary></entry><entry><title type="html">Causal Inference for Genomic Data with Multiple Heterogeneous Outcomes</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CausalInferenceforGenomicDatawithMultipleHeterogeneousOutcomes.html" rel="alternate" type="text/html" title="Causal Inference for Genomic Data with Multiple Heterogeneous Outcomes" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CausalInferenceforGenomicDatawithMultipleHeterogeneousOutcomes</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CausalInferenceforGenomicDatawithMultipleHeterogeneousOutcomes.html">&lt;p&gt;With the evolution of single-cell RNA sequencing techniques into a standard approach in genomics, it has become possible to conduct cohort-level causal inferences based on single-cell-level measurements. However, the individual gene expression levels of interest are not directly observable; instead, only repeated proxy measurements from each individual’s cells are available, providing a derived outcome to estimate the underlying outcome for each of many genes. In this paper, we propose a generic semiparametric inference framework for doubly robust estimation with multiple derived outcomes, which also encompasses the usual setting of multiple outcomes when the response of each unit is available. To reliably quantify the causal effects of heterogeneous outcomes, we specialize the analysis to standardized average treatment effects and quantile treatment effects. Through this, we demonstrate the use of the semiparametric inferential results for doubly robust estimators derived from both Von Mises expansions and estimating equations. A multiple testing procedure based on Gaussian multiplier bootstrap is tailored for doubly robust estimators to control the false discovery exceedance rate. Applications in single-cell CRISPR perturbation analysis and individual-level differential expression analysis demonstrate the utility of the proposed methods and offer insights into the usage of different estimands for causal inference in genomics.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2404.09119&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jin-Hong Du, Zhenghao Zeng, Edward H. Kennedy, Larry Wasserman, Kathryn Roeder</name></author><category term="stat.ME," /><category term="stat.AP," /><category term="stat.ML" /><summary type="html">With the evolution of single-cell RNA sequencing techniques into a standard approach in genomics, it has become possible to conduct cohort-level causal inferences based on single-cell-level measurements. However, the individual gene expression levels of interest are not directly observable; instead, only repeated proxy measurements from each individual’s cells are available, providing a derived outcome to estimate the underlying outcome for each of many genes. In this paper, we propose a generic semiparametric inference framework for doubly robust estimation with multiple derived outcomes, which also encompasses the usual setting of multiple outcomes when the response of each unit is available. To reliably quantify the causal effects of heterogeneous outcomes, we specialize the analysis to standardized average treatment effects and quantile treatment effects. Through this, we demonstrate the use of the semiparametric inferential results for doubly robust estimators derived from both Von Mises expansions and estimating equations. A multiple testing procedure based on Gaussian multiplier bootstrap is tailored for doubly robust estimators to control the false discovery exceedance rate. Applications in single-cell CRISPR perturbation analysis and individual-level differential expression analysis demonstrate the utility of the proposed methods and offer insights into the usage of different estimands for causal inference in genomics.</summary></entry><entry><title type="html">Causal Order Discovery based on Monotonic SCMs</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CausalOrderDiscoverybasedonMonotonicSCMs.html" rel="alternate" type="text/html" title="Causal Order Discovery based on Monotonic SCMs" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CausalOrderDiscoverybasedonMonotonicSCMs</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CausalOrderDiscoverybasedonMonotonicSCMs.html">&lt;p&gt;In this paper, we consider the problem of causal order discovery within the framework of monotonic Structural Causal Models (SCMs), which have gained attention for their potential to enable causal inference and causal discovery from observational data. While existing approaches either assume prior knowledge about the causal order or use complex optimization techniques to impose sparsity in the Jacobian of Triangular Monotonic Increasing maps, our work introduces a novel sequential procedure that directly identifies the causal order by iteratively detecting the root variable. This method eliminates the need for sparsity assumptions and the associated optimization challenges, enabling the identification of a unique SCM without the need for multiple independence tests to break the Markov equivalence class. We demonstrate the effectiveness of our approach in sequentially finding the root variable, comparing it to methods that maximize Jacobian sparsity.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.19870&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ali Izadi, Martin Ester</name></author><category term="stat.ML" /><summary type="html">In this paper, we consider the problem of causal order discovery within the framework of monotonic Structural Causal Models (SCMs), which have gained attention for their potential to enable causal inference and causal discovery from observational data. While existing approaches either assume prior knowledge about the causal order or use complex optimization techniques to impose sparsity in the Jacobian of Triangular Monotonic Increasing maps, our work introduces a novel sequential procedure that directly identifies the causal order by iteratively detecting the root variable. This method eliminates the need for sparsity assumptions and the associated optimization challenges, enabling the identification of a unique SCM without the need for multiple independence tests to break the Markov equivalence class. We demonstrate the effectiveness of our approach in sequentially finding the root variable, comparing it to methods that maximize Jacobian sparsity.</summary></entry><entry><title type="html">Computable Lipschitz Bounds for Deep Neural Networks</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ComputableLipschitzBoundsforDeepNeuralNetworks.html" rel="alternate" type="text/html" title="Computable Lipschitz Bounds for Deep Neural Networks" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ComputableLipschitzBoundsforDeepNeuralNetworks</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ComputableLipschitzBoundsforDeepNeuralNetworks.html">&lt;p&gt;Deriving sharp and computable upper bounds of the Lipschitz constant of deep neural networks is crucial to formally guarantee the robustness of neural-network based models. We analyse three existing upper bounds written for the $l^2$ norm. We highlight the importance of working with the $l^1$ and $l^\infty$ norms and we propose two novel bounds for both feed-forward fully-connected neural networks and convolutional neural networks. We treat the technical difficulties related to convolutional neural networks with two different methods, called explicit and implicit. Several numerical tests empirically confirm the theoretical results, help to quantify the relationship between the presented bounds and establish the better accuracy of the new bounds. Four numerical tests are studied: two where the output is derived from an analytical closed form are proposed; another one with random matrices; and the last one for convolutional neural networks trained on the MNIST dataset. We observe that one of our bound is optimal in the sense that it is exact for the first test with the simplest analytical form and it is better than other bounds for the other tests.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21053&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Moreno Pintore, Bruno Després</name></author><category term="stat.ML" /><summary type="html">Deriving sharp and computable upper bounds of the Lipschitz constant of deep neural networks is crucial to formally guarantee the robustness of neural-network based models. We analyse three existing upper bounds written for the $l^2$ norm. We highlight the importance of working with the $l^1$ and $l^\infty$ norms and we propose two novel bounds for both feed-forward fully-connected neural networks and convolutional neural networks. We treat the technical difficulties related to convolutional neural networks with two different methods, called explicit and implicit. Several numerical tests empirically confirm the theoretical results, help to quantify the relationship between the presented bounds and establish the better accuracy of the new bounds. Four numerical tests are studied: two where the output is derived from an analytical closed form are proposed; another one with random matrices; and the last one for convolutional neural networks trained on the MNIST dataset. We observe that one of our bound is optimal in the sense that it is exact for the first test with the simplest analytical form and it is better than other bounds for the other tests.</summary></entry><entry><title type="html">Conformal Prediction in Dynamic Biological Systems</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ConformalPredictioninDynamicBiologicalSystems.html" rel="alternate" type="text/html" title="Conformal Prediction in Dynamic Biological Systems" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ConformalPredictioninDynamicBiologicalSystems</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ConformalPredictioninDynamicBiologicalSystems.html">&lt;p&gt;Uncertainty quantification (UQ) is the process of systematically determining and characterizing the degree of confidence in computational model predictions. In the context of systems biology, especially with dynamic models, UQ is crucial because it addresses the challenges posed by nonlinearity and parameter sensitivity, allowing us to properly understand and extrapolate the behavior of complex biological systems. Here, we focus on dynamic models represented by deterministic nonlinear ordinary differential equations. Many current UQ approaches in this field rely on Bayesian statistical methods. While powerful, these methods often require strong prior specifications and make parametric assumptions that may not always hold in biological systems. Additionally, these methods face challenges in domains where sample sizes are limited, and statistical inference becomes constrained, with computational speed being a bottleneck in large models of biological systems. As an alternative, we propose the use of conformal inference methods, introducing two novel algorithms that, in some instances, offer non-asymptotic guarantees, enhancing robustness and scalability across various applications. We demonstrate the efficacy of our proposed algorithms through several scenarios, highlighting their advantages over traditional Bayesian approaches. The proposed methods show promising results for diverse biological data structures and scenarios, offering a general framework to quantify uncertainty for dynamic models of biological systems.The software for the methodology and the reproduction of the results is available at https://zenodo.org/doi/10.5281/zenodo.13644870.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2409.02644&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Alberto Portela, Julio R. Banga, Marcos Matabuena</name></author><category term="stat.ML" /><summary type="html">Uncertainty quantification (UQ) is the process of systematically determining and characterizing the degree of confidence in computational model predictions. In the context of systems biology, especially with dynamic models, UQ is crucial because it addresses the challenges posed by nonlinearity and parameter sensitivity, allowing us to properly understand and extrapolate the behavior of complex biological systems. Here, we focus on dynamic models represented by deterministic nonlinear ordinary differential equations. Many current UQ approaches in this field rely on Bayesian statistical methods. While powerful, these methods often require strong prior specifications and make parametric assumptions that may not always hold in biological systems. Additionally, these methods face challenges in domains where sample sizes are limited, and statistical inference becomes constrained, with computational speed being a bottleneck in large models of biological systems. As an alternative, we propose the use of conformal inference methods, introducing two novel algorithms that, in some instances, offer non-asymptotic guarantees, enhancing robustness and scalability across various applications. We demonstrate the efficacy of our proposed algorithms through several scenarios, highlighting their advantages over traditional Bayesian approaches. The proposed methods show promising results for diverse biological data structures and scenarios, offering a general framework to quantify uncertainty for dynamic models of biological systems.The software for the methodology and the reproduction of the results is available at https://zenodo.org/doi/10.5281/zenodo.13644870.</summary></entry><entry><title type="html">Conformalized Selective Regression</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ConformalizedSelectiveRegression.html" rel="alternate" type="text/html" title="Conformalized Selective Regression" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ConformalizedSelectiveRegression</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ConformalizedSelectiveRegression.html">&lt;p&gt;Should prediction models always deliver a prediction? In the pursuit of maximum predictive performance, critical considerations of reliability and fairness are often overshadowed, particularly when it comes to the role of uncertainty. Selective regression, also known as the “reject option,” allows models to abstain from predictions in cases of considerable uncertainty. Initially proposed seven decades ago, approaches to selective regression have mostly focused on distribution-based proxies for measuring uncertainty, particularly conditional variance. However, this focus neglects the significant influence of model-specific biases on a model’s performance. In this paper, we propose a novel approach to selective regression by leveraging conformal prediction, which provides grounded confidence measures for individual predictions based on model-specific biases. In addition, we propose a standardized evaluation framework to allow proper comparison of selective regression approaches. Via an extensive experimental approach, we demonstrate how our proposed approach, conformalized selective regression, demonstrates an advantage over multiple state-of-the-art baselines.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.16300&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Anna Sokol, Nuno Moniz, Nitesh Chawla</name></author><category term="stat.ML" /><summary type="html">Should prediction models always deliver a prediction? In the pursuit of maximum predictive performance, critical considerations of reliability and fairness are often overshadowed, particularly when it comes to the role of uncertainty. Selective regression, also known as the “reject option,” allows models to abstain from predictions in cases of considerable uncertainty. Initially proposed seven decades ago, approaches to selective regression have mostly focused on distribution-based proxies for measuring uncertainty, particularly conditional variance. However, this focus neglects the significant influence of model-specific biases on a model’s performance. In this paper, we propose a novel approach to selective regression by leveraging conformal prediction, which provides grounded confidence measures for individual predictions based on model-specific biases. In addition, we propose a standardized evaluation framework to allow proper comparison of selective regression approaches. Via an extensive experimental approach, we demonstrate how our proposed approach, conformalized selective regression, demonstrates an advantage over multiple state-of-the-art baselines.</summary></entry><entry><title type="html">Conformal prediction with local weights: randomization enables local guarantees</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Conformalpredictionwithlocalweightsrandomizationenableslocalguarantees.html" rel="alternate" type="text/html" title="Conformal prediction with local weights: randomization enables local guarantees" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Conformalpredictionwithlocalweightsrandomizationenableslocalguarantees</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Conformalpredictionwithlocalweightsrandomizationenableslocalguarantees.html">&lt;p&gt;In this work, we consider the problem of building distribution-free prediction intervals with finite-sample conditional coverage guarantees. Conformal prediction (CP) is an increasingly popular framework for building such intervals with distribution-free guarantees, but these guarantees only ensure marginal coverage: the probability of coverage is averaged over both the training and test data, meaning that there might be substantial undercoverage within certain subpopulations. Instead, ideally we would want to have local coverage guarantees that hold for each possible value of the test point’s features. While the impossibility of achieving pointwise local coverage is well established in the literature, many variants of conformal prediction algorithm show favourable local coverage properties empirically. Relaxing the definition of local coverage can allow for a theoretical understanding of this empirical phenomenon. We propose randomly localized conformal prediction (RLCP), a method that builds on localized CP and weighted CP techniques to return prediction intervals that are not only marginally valid but also offer relaxed local coverage guarantees and validity under covariate shift. Through a series of simulations and real data experiments, we validate these coverage guarantees of RLCP while comparing it with the other local conformal prediction methods.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2310.07850&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Rohan Hore, Rina Foygel Barber</name></author><category term="stat.ME" /><summary type="html">In this work, we consider the problem of building distribution-free prediction intervals with finite-sample conditional coverage guarantees. Conformal prediction (CP) is an increasingly popular framework for building such intervals with distribution-free guarantees, but these guarantees only ensure marginal coverage: the probability of coverage is averaged over both the training and test data, meaning that there might be substantial undercoverage within certain subpopulations. Instead, ideally we would want to have local coverage guarantees that hold for each possible value of the test point’s features. While the impossibility of achieving pointwise local coverage is well established in the literature, many variants of conformal prediction algorithm show favourable local coverage properties empirically. Relaxing the definition of local coverage can allow for a theoretical understanding of this empirical phenomenon. We propose randomly localized conformal prediction (RLCP), a method that builds on localized CP and weighted CP techniques to return prediction intervals that are not only marginally valid but also offer relaxed local coverage guarantees and validity under covariate shift. Through a series of simulations and real data experiments, we validate these coverage guarantees of RLCP while comparing it with the other local conformal prediction methods.</summary></entry><entry><title type="html">Convergence Guarantees for the DeepWalk Embedding on Block Models</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ConvergenceGuaranteesfortheDeepWalkEmbeddingonBlockModels.html" rel="alternate" type="text/html" title="Convergence Guarantees for the DeepWalk Embedding on Block Models" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ConvergenceGuaranteesfortheDeepWalkEmbeddingonBlockModels</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ConvergenceGuaranteesfortheDeepWalkEmbeddingonBlockModels.html">&lt;p&gt;Graph embeddings have emerged as a powerful tool for understanding the structure of graphs. Unlike classical spectral methods, recent methods such as DeepWalk, Node2Vec, etc. are based on solving nonlinear optimization problems on the graph, using local information obtained by performing random walks. These techniques have empirically been shown to produce ‘‘better’’ embeddings than their classical counterparts. However, due to their reliance on solving a nonconvex optimization problem, obtaining theoretical guarantees on the properties of the solution has remained a challenge, even for simple classes of graphs. In this work, we show convergence properties for the DeepWalk algorithm on graphs obtained from the Stochastic Block Model (SBM). Despite being simplistic, the SBM has proved to be a classic model for analyzing the behavior of algorithms on large graphs. Our results mirror the existing ones for spectral embeddings on SBMs, showing that even in the case of one-dimensional embeddings, the output of the DeepWalk algorithm provably recovers the cluster structure with high probability.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20248&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Christopher Harker, Aditya Bhaskara</name></author><category term="stat.ML" /><summary type="html">Graph embeddings have emerged as a powerful tool for understanding the structure of graphs. Unlike classical spectral methods, recent methods such as DeepWalk, Node2Vec, etc. are based on solving nonlinear optimization problems on the graph, using local information obtained by performing random walks. These techniques have empirically been shown to produce ‘‘better’’ embeddings than their classical counterparts. However, due to their reliance on solving a nonconvex optimization problem, obtaining theoretical guarantees on the properties of the solution has remained a challenge, even for simple classes of graphs. In this work, we show convergence properties for the DeepWalk algorithm on graphs obtained from the Stochastic Block Model (SBM). Despite being simplistic, the SBM has proved to be a classic model for analyzing the behavior of algorithms on large graphs. Our results mirror the existing ones for spectral embeddings on SBMs, showing that even in the case of one-dimensional embeddings, the output of the DeepWalk algorithm provably recovers the cluster structure with high probability.</summary></entry><entry><title type="html">Copula-Linked Parallel ICA: A Method for Coupling Structural and Functional MRI brain Networks</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CopulaLinkedParallelICAAMethodforCouplingStructuralandFunctionalMRIbrainNetworks.html" rel="alternate" type="text/html" title="Copula-Linked Parallel ICA: A Method for Coupling Structural and Functional MRI brain Networks" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CopulaLinkedParallelICAAMethodforCouplingStructuralandFunctionalMRIbrainNetworks</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/CopulaLinkedParallelICAAMethodforCouplingStructuralandFunctionalMRIbrainNetworks.html">&lt;p&gt;Different brain imaging modalities offer unique insights into brain function and structure. Combining them enhances our understanding of neural mechanisms. Prior multimodal studies fusing functional MRI (fMRI) and structural MRI (sMRI) have shown the benefits of this approach. Since sMRI lacks temporal data, existing fusion methods often compress fMRI temporal information into summary measures, sacrificing rich temporal dynamics. Motivated by the observation that covarying networks are identified in both sMRI and resting-state fMRI, we developed a novel fusion method, by combining deep learning frameworks, copulas and independent component analysis (ICA), named copula linked parallel ICA (CLiP-ICA). This method estimates independent sources for each modality and links the spatial sources of fMRI and sMRI using a copula-based model for more flexible integration of temporal and spatial data. We tested CLiP-ICA using data from the Alzheimer’s Disease Neuroimaging Initiative (ADNI). Our results showed that CLiP-ICA effectively captures both strongly and weakly linked sMRI and fMRI networks, including the cerebellum, sensorimotor, visual, cognitive control, and default mode networks. It revealed more meaningful components and fewer artifacts, addressing the long-standing issue of optimal model order in ICA. CLiP-ICA also detected complex functional connectivity patterns across stages of cognitive decline, with cognitively normal subjects generally showing higher connectivity in sensorimotor and visual networks compared to patients with Alzheimer, along with patterns suggesting potential compensatory mechanisms.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.19774&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Oktay Agcaoglu , Rogers F. Silva , Deniz Alacam , Sergey Plis , Tulay Adali , Vince Calhoun</name></author><category term="stat.CO" /><summary type="html">Different brain imaging modalities offer unique insights into brain function and structure. Combining them enhances our understanding of neural mechanisms. Prior multimodal studies fusing functional MRI (fMRI) and structural MRI (sMRI) have shown the benefits of this approach. Since sMRI lacks temporal data, existing fusion methods often compress fMRI temporal information into summary measures, sacrificing rich temporal dynamics. Motivated by the observation that covarying networks are identified in both sMRI and resting-state fMRI, we developed a novel fusion method, by combining deep learning frameworks, copulas and independent component analysis (ICA), named copula linked parallel ICA (CLiP-ICA). This method estimates independent sources for each modality and links the spatial sources of fMRI and sMRI using a copula-based model for more flexible integration of temporal and spatial data. We tested CLiP-ICA using data from the Alzheimer’s Disease Neuroimaging Initiative (ADNI). Our results showed that CLiP-ICA effectively captures both strongly and weakly linked sMRI and fMRI networks, including the cerebellum, sensorimotor, visual, cognitive control, and default mode networks. It revealed more meaningful components and fewer artifacts, addressing the long-standing issue of optimal model order in ICA. CLiP-ICA also detected complex functional connectivity patterns across stages of cognitive decline, with cognitively normal subjects generally showing higher connectivity in sensorimotor and visual networks compared to patients with Alzheimer, along with patterns suggesting potential compensatory mechanisms.</summary></entry><entry><title type="html">Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DataEfficientOperatorLearningviaUnsupervisedPretrainingandInContextLearning.html" rel="alternate" type="text/html" title="Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DataEfficientOperatorLearningviaUnsupervisedPretrainingandInContextLearning</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DataEfficientOperatorLearningviaUnsupervisedPretrainingandInContextLearning.html">&lt;p&gt;Recent years have witnessed the promise of coupling machine learning methods and physical domain-specific insights for solving scientific problems based on partial differential equations (PDEs). However, being data-intensive, these methods still require a large amount of PDE data. This reintroduces the need for expensive numerical PDE solutions, partially undermining the original goal of avoiding these expensive simulations. In this work, seeking data efficiency, we design unsupervised pretraining for PDE operator learning. To reduce the need for training data with heavy simulation costs, we mine unlabeled PDE data without simulated solutions, and we pretrain neural operators with physics-inspired reconstruction-based proxy tasks. To improve out-of-distribution performance, we further assist neural operators in flexibly leveraging a similarity-based method that learns in-context examples, without incurring extra training costs or designs. Extensive empirical evaluations on a diverse set of PDEs demonstrate that our method is highly data-efficient, more generalizable, and even outperforms conventional vision-pretrained models. We provide our code at https://github.com/delta-lab-ai/data_efficient_nopt.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.15734&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Wuyang Chen, Jialin Song, Pu Ren, Shashank Subramanian, Dmitriy Morozov, Michael W. Mahoney</name></author><category term="stat.ML" /><summary type="html">Recent years have witnessed the promise of coupling machine learning methods and physical domain-specific insights for solving scientific problems based on partial differential equations (PDEs). However, being data-intensive, these methods still require a large amount of PDE data. This reintroduces the need for expensive numerical PDE solutions, partially undermining the original goal of avoiding these expensive simulations. In this work, seeking data efficiency, we design unsupervised pretraining for PDE operator learning. To reduce the need for training data with heavy simulation costs, we mine unlabeled PDE data without simulated solutions, and we pretrain neural operators with physics-inspired reconstruction-based proxy tasks. To improve out-of-distribution performance, we further assist neural operators in flexibly leveraging a similarity-based method that learns in-context examples, without incurring extra training costs or designs. Extensive empirical evaluations on a diverse set of PDEs demonstrate that our method is highly data-efficient, more generalizable, and even outperforms conventional vision-pretrained models. We provide our code at https://github.com/delta-lab-ai/data_efficient_nopt.</summary></entry><entry><title type="html">DeepMIDE: A Multivariate Spatio-Temporal Method for Ultra-Scale Offshore Wind Energy Forecasting</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DeepMIDEAMultivariateSpatioTemporalMethodforUltraScaleOffshoreWindEnergyForecasting.html" rel="alternate" type="text/html" title="DeepMIDE: A Multivariate Spatio-Temporal Method for Ultra-Scale Offshore Wind Energy Forecasting" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DeepMIDEAMultivariateSpatioTemporalMethodforUltraScaleOffshoreWindEnergyForecasting</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DeepMIDEAMultivariateSpatioTemporalMethodforUltraScaleOffshoreWindEnergyForecasting.html">&lt;p&gt;To unlock access to stronger winds, the offshore wind industry is advancing with significantly larger and taller wind turbines. This massive upscaling motivates a departure from univariate wind forecasting methods that traditionally focused on a single representative height. To fill this gap, we propose DeepMIDE–a statistical deep learning method which jointly models the offshore wind speeds across space, time, and height. DeepMIDE is formulated as a multi-output integro-difference equation model with a multivariate, nonstationary, and state-dependent kernel characterized by a set of advection vectors that encode the physics of wind field formation and propagation. Embedded within DeepMIDE, an advanced deep learning architecture learns these advection vectors from high dimensional streams of exogenous weather information, which, along with other parameters, are plugged back into the statistical model for probabilistic multi-height space-time forecasting. Tested on real-world data from future offshore wind energy sites in the Northeastern United States, the wind speed and power forecasts from DeepMIDE are shown to outperform those from prevalent time series, spatio-temporal, and deep learning methods.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20166&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Feng Ye, Xinxi Zhang, Michael Stein, Ahmed Aziz Ezzat</name></author><category term="stat.AP," /><category term="stat.ML" /><summary type="html">To unlock access to stronger winds, the offshore wind industry is advancing with significantly larger and taller wind turbines. This massive upscaling motivates a departure from univariate wind forecasting methods that traditionally focused on a single representative height. To fill this gap, we propose DeepMIDE–a statistical deep learning method which jointly models the offshore wind speeds across space, time, and height. DeepMIDE is formulated as a multi-output integro-difference equation model with a multivariate, nonstationary, and state-dependent kernel characterized by a set of advection vectors that encode the physics of wind field formation and propagation. Embedded within DeepMIDE, an advanced deep learning architecture learns these advection vectors from high dimensional streams of exogenous weather information, which, along with other parameters, are plugged back into the statistical model for probabilistic multi-height space-time forecasting. Tested on real-world data from future offshore wind energy sites in the Northeastern United States, the wind speed and power forecasts from DeepMIDE are shown to outperform those from prevalent time series, spatio-temporal, and deep learning methods.</summary></entry><entry><title type="html">Deep Recurrent Stochastic Configuration Networks for Modelling Nonlinear Dynamic Systems</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DeepRecurrentStochasticConfigurationNetworksforModellingNonlinearDynamicSystems.html" rel="alternate" type="text/html" title="Deep Recurrent Stochastic Configuration Networks for Modelling Nonlinear Dynamic Systems" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DeepRecurrentStochasticConfigurationNetworksforModellingNonlinearDynamicSystems</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DeepRecurrentStochasticConfigurationNetworksforModellingNonlinearDynamicSystems.html">&lt;p&gt;Deep learning techniques have shown promise in many domain applications. This paper proposes a novel deep reservoir computing framework, termed deep recurrent stochastic configuration network (DeepRSCN) for modelling nonlinear dynamic systems. DeepRSCNs are incrementally constructed, with all reservoir nodes directly linked to the final output. The random parameters are assigned in the light of a supervisory mechanism, ensuring the universal approximation property of the built model. The output weights are updated online using the projection algorithm to handle the unknown dynamics. Given a set of training samples, DeepRSCNs can quickly generate learning representations, which consist of random basis functions with cascaded input and readout weights. Experimental results over a time series prediction, a nonlinear system identification problem, and two industrial data predictive analyses demonstrate that the proposed DeepRSCN outperforms the single-layer network in terms of modelling efficiency, learning capability, and generalization performance.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20904&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Gang Dang, Dianhui Wang</name></author><category term="stat.ML" /><summary type="html">Deep learning techniques have shown promise in many domain applications. This paper proposes a novel deep reservoir computing framework, termed deep recurrent stochastic configuration network (DeepRSCN) for modelling nonlinear dynamic systems. DeepRSCNs are incrementally constructed, with all reservoir nodes directly linked to the final output. The random parameters are assigned in the light of a supervisory mechanism, ensuring the universal approximation property of the built model. The output weights are updated online using the projection algorithm to handle the unknown dynamics. Given a set of training samples, DeepRSCNs can quickly generate learning representations, which consist of random basis functions with cascaded input and readout weights. Experimental results over a time series prediction, a nonlinear system identification problem, and two industrial data predictive analyses demonstrate that the proposed DeepRSCN outperforms the single-layer network in terms of modelling efficiency, learning capability, and generalization performance.</summary></entry><entry><title type="html">Deep linear networks for regression are implicitly regularized towards flat minima</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Deeplinearnetworksforregressionareimplicitlyregularizedtowardsflatminima.html" rel="alternate" type="text/html" title="Deep linear networks for regression are implicitly regularized towards flat minima" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Deeplinearnetworksforregressionareimplicitlyregularizedtowardsflatminima</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Deeplinearnetworksforregressionareimplicitlyregularizedtowardsflatminima.html">&lt;p&gt;The largest eigenvalue of the Hessian, or sharpness, of neural networks is a key quantity to understand their optimization dynamics. In this paper, we study the sharpness of deep linear networks for univariate regression. Minimizers can have arbitrarily large sharpness, but not an arbitrarily small one. Indeed, we show a lower bound on the sharpness of minimizers, which grows linearly with depth. We then study the properties of the minimizer found by gradient flow, which is the limit of gradient descent with vanishing learning rate. We show an implicit regularization towards flat minima: the sharpness of the minimizer is no more than a constant times the lower bound. The constant depends on the condition number of the data covariance matrix, but not on width or depth. This result is proven both for a small-scale initialization and a residual initialization. Results of independent interest are shown in both cases. For small-scale initialization, we show that the learned weight matrices are approximately rank-one and that their singular vectors align. For residual initialization, convergence of the gradient flow for a Gaussian initialization of the residual network is proven. Numerical experiments illustrate our results and connect them to gradient descent with non-vanishing learning rate.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.13456&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Pierre Marion, Lénaïc Chizat</name></author><category term="stat.ML" /><summary type="html">The largest eigenvalue of the Hessian, or sharpness, of neural networks is a key quantity to understand their optimization dynamics. In this paper, we study the sharpness of deep linear networks for univariate regression. Minimizers can have arbitrarily large sharpness, but not an arbitrarily small one. Indeed, we show a lower bound on the sharpness of minimizers, which grows linearly with depth. We then study the properties of the minimizer found by gradient flow, which is the limit of gradient descent with vanishing learning rate. We show an implicit regularization towards flat minima: the sharpness of the minimizer is no more than a constant times the lower bound. The constant depends on the condition number of the data covariance matrix, but not on width or depth. This result is proven both for a small-scale initialization and a residual initialization. Results of independent interest are shown in both cases. For small-scale initialization, we show that the learned weight matrices are approximately rank-one and that their singular vectors align. For residual initialization, convergence of the gradient flow for a Gaussian initialization of the residual network is proven. Numerical experiments illustrate our results and connect them to gradient descent with non-vanishing learning rate.</summary></entry><entry><title type="html">Denoising Diffusion Variational Inference: Diffusion Models as Expressive Variational Posteriors</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DenoisingDiffusionVariationalInferenceDiffusionModelsasExpressiveVariationalPosteriors.html" rel="alternate" type="text/html" title="Denoising Diffusion Variational Inference: Diffusion Models as Expressive Variational Posteriors" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DenoisingDiffusionVariationalInferenceDiffusionModelsasExpressiveVariationalPosteriors</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DenoisingDiffusionVariationalInferenceDiffusionModelsasExpressiveVariationalPosteriors.html">&lt;p&gt;We propose denoising diffusion variational inference (DDVI), a black-box variational inference algorithm for latent variable models which relies on diffusion models as flexible approximate posteriors. Specifically, our method introduces an expressive class of diffusion-based variational posteriors that perform iterative refinement in latent space; we train these posteriors with a novel regularized evidence lower bound (ELBO) on the marginal likelihood inspired by the wake-sleep algorithm. Our method is easy to implement (it fits a regularized extension of the ELBO), is compatible with black-box variational inference, and outperforms alternative classes of approximate posteriors based on normalizing flows or adversarial networks. We find that DDVI improves inference and learning in deep latent variable models across common benchmarks as well as on a motivating task in biology – inferring latent ancestry from human genomes – where it outperforms strong baselines on the Thousand Genomes dataset.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2401.02739&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Top Piriyakulkij, Yingheng Wang, Volodymyr Kuleshov</name></author><category term="stat.ML" /><summary type="html">We propose denoising diffusion variational inference (DDVI), a black-box variational inference algorithm for latent variable models which relies on diffusion models as flexible approximate posteriors. Specifically, our method introduces an expressive class of diffusion-based variational posteriors that perform iterative refinement in latent space; we train these posteriors with a novel regularized evidence lower bound (ELBO) on the marginal likelihood inspired by the wake-sleep algorithm. Our method is easy to implement (it fits a regularized extension of the ELBO), is compatible with black-box variational inference, and outperforms alternative classes of approximate posteriors based on normalizing flows or adversarial networks. We find that DDVI improves inference and learning in deep latent variable models across common benchmarks as well as on a motivating task in biology – inferring latent ancestry from human genomes – where it outperforms strong baselines on the Thousand Genomes dataset.</summary></entry><entry><title type="html">Difference-in-Differences with Time-varying Continuous Treatments using Double/Debiased Machine Learning</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DifferenceinDifferenceswithTimevaryingContinuousTreatmentsusingDoubleDebiasedMachineLearning.html" rel="alternate" type="text/html" title="Difference-in-Differences with Time-varying Continuous Treatments using Double/Debiased Machine Learning" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DifferenceinDifferenceswithTimevaryingContinuousTreatmentsusingDoubleDebiasedMachineLearning</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DifferenceinDifferenceswithTimevaryingContinuousTreatmentsusingDoubleDebiasedMachineLearning.html">&lt;p&gt;We propose a difference-in-differences (DiD) method for a time-varying continuous treatment and multiple time periods. Our framework assesses the average treatment effect on the treated (ATET) when comparing two non-zero treatment doses. The identification is based on a conditional parallel trend assumption imposed on the mean potential outcome under the lower dose, given observed covariates and past treatment histories. We employ kernel-based ATET estimators for repeated cross-sections and panel data adopting the double/debiased machine learning framework to control for covariates and past treatment histories in a data-adaptive manner. We also demonstrate the asymptotic normality of our estimation approach under specific regularity conditions. In a simulation study, we find a compelling finite sample performance of undersmoothed versions of our estimators in setups with several thousand observations.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21105&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Michel F. C. Haddad, Martin Huber, Lucas Z. Zhang</name></author><category term="stat.ML" /><summary type="html">We propose a difference-in-differences (DiD) method for a time-varying continuous treatment and multiple time periods. Our framework assesses the average treatment effect on the treated (ATET) when comparing two non-zero treatment doses. The identification is based on a conditional parallel trend assumption imposed on the mean potential outcome under the lower dose, given observed covariates and past treatment histories. We employ kernel-based ATET estimators for repeated cross-sections and panel data adopting the double/debiased machine learning framework to control for covariates and past treatment histories in a data-adaptive manner. We also demonstrate the asymptotic normality of our estimation approach under specific regularity conditions. In a simulation study, we find a compelling finite sample performance of undersmoothed versions of our estimators in setups with several thousand observations.</summary></entry><entry><title type="html">Dimension reduction via score ratio matching</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Dimensionreductionviascoreratiomatching.html" rel="alternate" type="text/html" title="Dimension reduction via score ratio matching" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Dimensionreductionviascoreratiomatching</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Dimensionreductionviascoreratiomatching.html">&lt;p&gt;Gradient-based dimension reduction decreases the cost of Bayesian inference and probabilistic modeling by identifying maximally informative (and informed) low-dimensional projections of the data and parameters, allowing high-dimensional problems to be reformulated as cheaper low-dimensional problems. A broad family of such techniques identify these projections and provide error bounds on the resulting posterior approximations, via eigendecompositions of certain diagnostic matrices. Yet these matrices require gradients or even Hessians of the log-likelihood, excluding the purely data-driven setting and many problems of simulation-based inference. We propose a framework, derived from score-matching, to extend gradient-based dimension reduction to problems where gradients are unavailable. Specifically, we formulate an objective function to directly learn the score ratio function needed to compute the diagnostic matrices, propose a tailored parameterization for the score ratio network, and introduce regularization methods that capitalize on the hypothesized low-dimensional structure. We also introduce a novel algorithm to iteratively identify the low-dimensional reduced basis vectors more accurately with limited data based on eigenvalue deflation methods. We show that our approach outperforms standard score-matching for problems with low-dimensional structure, and demonstrate its effectiveness for PDE-constrained Bayesian inverse problems and conditional generative modeling.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.19990&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ricardo Baptista, Michael Brennan, Youssef Marzouk</name></author><category term="stat.CO," /><category term="stat.ML" /><summary type="html">Gradient-based dimension reduction decreases the cost of Bayesian inference and probabilistic modeling by identifying maximally informative (and informed) low-dimensional projections of the data and parameters, allowing high-dimensional problems to be reformulated as cheaper low-dimensional problems. A broad family of such techniques identify these projections and provide error bounds on the resulting posterior approximations, via eigendecompositions of certain diagnostic matrices. Yet these matrices require gradients or even Hessians of the log-likelihood, excluding the purely data-driven setting and many problems of simulation-based inference. We propose a framework, derived from score-matching, to extend gradient-based dimension reduction to problems where gradients are unavailable. Specifically, we formulate an objective function to directly learn the score ratio function needed to compute the diagnostic matrices, propose a tailored parameterization for the score ratio network, and introduce regularization methods that capitalize on the hypothesized low-dimensional structure. We also introduce a novel algorithm to iteratively identify the low-dimensional reduced basis vectors more accurately with limited data based on eigenvalue deflation methods. We show that our approach outperforms standard score-matching for problems with low-dimensional structure, and demonstrate its effectiveness for PDE-constrained Bayesian inverse problems and conditional generative modeling.</summary></entry><entry><title type="html">Directional data analysis using the spherical Cauchy and the Poisson kernel-based distribution</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DirectionaldataanalysisusingthesphericalCauchyandthePoissonkernelbaseddistribution.html" rel="alternate" type="text/html" title="Directional data analysis using the spherical Cauchy and the Poisson kernel-based distribution" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DirectionaldataanalysisusingthesphericalCauchyandthePoissonkernelbaseddistribution</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DirectionaldataanalysisusingthesphericalCauchyandthePoissonkernelbaseddistribution.html">&lt;p&gt;In 2020, two novel distributions for the analysis of directional data were introduced: the spherical Cauchy distribution and the Poisson kernel-based distribution. This paper provides a detailed exploration of both distributions within various analytical frameworks. To enhance the practical utility of these distributions, alternative parametrizations that offer advantages in numerical stability and parameter estimation are presented, such as implementation of the Newton-Raphson algorithm for parameter estimation, while facilitating a more efficient and simplified approach in the regression framework. Additionally, a two-sample location test based on the log-likelihood ratio test is introduced. This test is designed to assess whether the location parameters of two populations can be assumed equal. The maximum likelihood discriminant analysis framework is developed for classification purposes, and finally, the problem of clustering directional data is addressed, by fitting finite mixtures of Spherical Cauchy or Poisson kernel-based distributions. Empirical validation is conducted through comprehensive simulation studies and real data applications, wherein the performance of the spherical Cauchy and Poisson kernel-based distributions is systematically compared.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2409.03292&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Michail Tsagris</name></author><category term="stat.ME" /><summary type="html">In 2020, two novel distributions for the analysis of directional data were introduced: the spherical Cauchy distribution and the Poisson kernel-based distribution. This paper provides a detailed exploration of both distributions within various analytical frameworks. To enhance the practical utility of these distributions, alternative parametrizations that offer advantages in numerical stability and parameter estimation are presented, such as implementation of the Newton-Raphson algorithm for parameter estimation, while facilitating a more efficient and simplified approach in the regression framework. Additionally, a two-sample location test based on the log-likelihood ratio test is introduced. This test is designed to assess whether the location parameters of two populations can be assumed equal. The maximum likelihood discriminant analysis framework is developed for classification purposes, and finally, the problem of clustering directional data is addressed, by fitting finite mixtures of Spherical Cauchy or Poisson kernel-based distributions. Empirical validation is conducted through comprehensive simulation studies and real data applications, wherein the performance of the spherical Cauchy and Poisson kernel-based distributions is systematically compared.</summary></entry><entry><title type="html">Disentangled and Self-Explainable Node Representation Learning</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DisentangledandSelfExplainableNodeRepresentationLearning.html" rel="alternate" type="text/html" title="Disentangled and Self-Explainable Node Representation Learning" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DisentangledandSelfExplainableNodeRepresentationLearning</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DisentangledandSelfExplainableNodeRepresentationLearning.html">&lt;p&gt;Node representations, or embeddings, are low-dimensional vectors that capture node properties, typically learned through unsupervised structural similarity objectives or supervised tasks. While recent efforts have focused on explaining graph model decisions, the interpretability of unsupervised node embeddings remains underexplored. To bridge this gap, we introduce DiSeNE (Disentangled and Self-Explainable Node Embedding), a framework that generates self-explainable embeddings in an unsupervised manner. Our method employs disentangled representation learning to produce dimension-wise interpretable embeddings, where each dimension is aligned with distinct topological structure of the graph. We formalize novel desiderata for disentangled and interpretable embeddings, which drive our new objective functions, optimizing simultaneously for both interpretability and disentanglement. Additionally, we propose several new metrics to evaluate representation quality and human interpretability. Extensive experiments across multiple benchmark datasets demonstrate the effectiveness of our approach.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21043&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Simone Piaggesi, André Panisson, Megha Khosla</name></author><category term="stat.ML" /><summary type="html">Node representations, or embeddings, are low-dimensional vectors that capture node properties, typically learned through unsupervised structural similarity objectives or supervised tasks. While recent efforts have focused on explaining graph model decisions, the interpretability of unsupervised node embeddings remains underexplored. To bridge this gap, we introduce DiSeNE (Disentangled and Self-Explainable Node Embedding), a framework that generates self-explainable embeddings in an unsupervised manner. Our method employs disentangled representation learning to produce dimension-wise interpretable embeddings, where each dimension is aligned with distinct topological structure of the graph. We formalize novel desiderata for disentangled and interpretable embeddings, which drive our new objective functions, optimizing simultaneously for both interpretability and disentanglement. Additionally, we propose several new metrics to evaluate representation quality and human interpretability. Extensive experiments across multiple benchmark datasets demonstrate the effectiveness of our approach.</summary></entry><entry><title type="html">Distribution of lowest eigenvalue in $k$-body bosonic random matrix ensembles</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Distributionoflowesteigenvalueinkbodybosonicrandommatrixensembles.html" rel="alternate" type="text/html" title="Distribution of lowest eigenvalue in $k$-body bosonic random matrix ensembles" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Distributionoflowesteigenvalueinkbodybosonicrandommatrixensembles</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Distributionoflowesteigenvalueinkbodybosonicrandommatrixensembles.html">&lt;p&gt;We numerically study the distribution of the lowest eigenvalue of finite many-boson systems with $k$-body interactions modeled by Bosonic Embedded Gaussian Orthogonal [BEGOE($k$)] and Unitary [BEGUE($k$)] random matrix Ensembles. Following the recently published result that the $q$-normal describes the smooth form of the eigenvalue density of the $k$-body embedded ensembles, the first four moments of the distribution of lowest eigenvalues have been analyzed as a function of the $q$ parameter, with $q \sim 1$ for $k = 1$ and $q = 0$ for $k = m$; $m$ being the number of bosons. Analytics are difficult as we are dealing with highly correlated variables, however we provide ansatzs for centroids and variances of these distributions. These match very well with the numerical results obtained. Our results show the distribution exhibits a smooth transition from Gaussian like for $q$ close to 1 to a modified Gumbel like for intermediate values of $q$ to the well-known Tracy-Widom distribution for $q=0$. It should be emphasized that this is a new result which numerically demonstrates that the distribution of the lowest eigenvalue of finite many-boson systems with $k$-body interactions exhibits a smooth transition from Gaussian like (for $q$ close to 1) to a modified Gumbel like (for intermediate values of $q$) to the well-known Tracy-Widom distribution (for $q=0$). In addition, we have also studied the distribution of normalized spacing between the lowest and next lowest eigenvalues and it is seen that this distribution exhibits a transition from Wigner’s surmise (for $k=1$) to Poisson (for intermediate $k$ values with $k \le m/2$) to Wigner’s surmise (starting from $k = m/2$ to $k = m$) with decreasing $q$ value. Thus, the spacings at the spectrum edge behave differently from the spacings inside the spectrum bulk.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.00190&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>N. D. Chavda, Priyanka Rao, V. K. B. Kota, Manan Vyas</name></author><category term="stat.AP" /><summary type="html">We numerically study the distribution of the lowest eigenvalue of finite many-boson systems with $k$-body interactions modeled by Bosonic Embedded Gaussian Orthogonal [BEGOE($k$)] and Unitary [BEGUE($k$)] random matrix Ensembles. Following the recently published result that the $q$-normal describes the smooth form of the eigenvalue density of the $k$-body embedded ensembles, the first four moments of the distribution of lowest eigenvalues have been analyzed as a function of the $q$ parameter, with $q \sim 1$ for $k = 1$ and $q = 0$ for $k = m$; $m$ being the number of bosons. Analytics are difficult as we are dealing with highly correlated variables, however we provide ansatzs for centroids and variances of these distributions. These match very well with the numerical results obtained. Our results show the distribution exhibits a smooth transition from Gaussian like for $q$ close to 1 to a modified Gumbel like for intermediate values of $q$ to the well-known Tracy-Widom distribution for $q=0$. It should be emphasized that this is a new result which numerically demonstrates that the distribution of the lowest eigenvalue of finite many-boson systems with $k$-body interactions exhibits a smooth transition from Gaussian like (for $q$ close to 1) to a modified Gumbel like (for intermediate values of $q$) to the well-known Tracy-Widom distribution (for $q=0$). In addition, we have also studied the distribution of normalized spacing between the lowest and next lowest eigenvalues and it is seen that this distribution exhibits a transition from Wigner’s surmise (for $k=1$) to Poisson (for intermediate $k$ values with $k \le m/2$) to Wigner’s surmise (starting from $k = m/2$ to $k = m$) with decreasing $q$ value. Thus, the spacings at the spectrum edge behave differently from the spacings inside the spectrum bulk.</summary></entry><entry><title type="html">Double Debiased Covariate Shift Adaptation Robust to Density-Ratio Estimation</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DoubleDebiasedCovariateShiftAdaptationRobusttoDensityRatioEstimation.html" rel="alternate" type="text/html" title="Double Debiased Covariate Shift Adaptation Robust to Density-Ratio Estimation" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DoubleDebiasedCovariateShiftAdaptationRobusttoDensityRatioEstimation</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/DoubleDebiasedCovariateShiftAdaptationRobusttoDensityRatioEstimation.html">&lt;p&gt;Consider a scenario where we have access to train data with both covariates and outcomes while test data only contains covariates. In this scenario, our primary aim is to predict the missing outcomes of the test data. With this objective in mind, we train parametric regression models under a covariate shift, where covariate distributions are different between the train and test data. For this problem, existing studies have proposed covariate shift adaptation via importance weighting using the density ratio. This approach averages the train data losses, each weighted by an estimated ratio of the covariate densities between the train and test data, to approximate the test-data risk. Although it allows us to obtain a test-data risk minimizer, its performance heavily relies on the accuracy of the density ratio estimation. Moreover, even if the density ratio can be consistently estimated, the estimation errors of the density ratio also yield bias in the estimators of the regression model’s parameters of interest. To mitigate these challenges, we introduce a doubly robust estimator for covariate shift adaptation via importance weighting, which incorporates an additional estimator for the regression function. Leveraging double machine learning techniques, our estimator reduces the bias arising from the density ratio estimation errors. We demonstrate the asymptotic distribution of the regression parameter estimator. Notably, our estimator remains consistent if either the density ratio estimator or the regression function is consistent, showcasing its robustness against potential errors in density ratio estimation. Finally, we confirm the soundness of our proposed method via simulation studies.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2310.16638&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Masahiro Kato, Kota Matsui, Ryo Inokuchi</name></author><category term="stat.ME," /><category term="stat.ML" /><summary type="html">Consider a scenario where we have access to train data with both covariates and outcomes while test data only contains covariates. In this scenario, our primary aim is to predict the missing outcomes of the test data. With this objective in mind, we train parametric regression models under a covariate shift, where covariate distributions are different between the train and test data. For this problem, existing studies have proposed covariate shift adaptation via importance weighting using the density ratio. This approach averages the train data losses, each weighted by an estimated ratio of the covariate densities between the train and test data, to approximate the test-data risk. Although it allows us to obtain a test-data risk minimizer, its performance heavily relies on the accuracy of the density ratio estimation. Moreover, even if the density ratio can be consistently estimated, the estimation errors of the density ratio also yield bias in the estimators of the regression model’s parameters of interest. To mitigate these challenges, we introduce a doubly robust estimator for covariate shift adaptation via importance weighting, which incorporates an additional estimator for the regression function. Leveraging double machine learning techniques, our estimator reduces the bias arising from the density ratio estimation errors. We demonstrate the asymptotic distribution of the regression parameter estimator. Notably, our estimator remains consistent if either the density ratio estimator or the regression function is consistent, showcasing its robustness against potential errors in density ratio estimation. Finally, we confirm the soundness of our proposed method via simulation studies.</summary></entry><entry><title type="html">Efficient Certificates of Anti-Concentration Beyond Gaussians</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/EfficientCertificatesofAntiConcentrationBeyondGaussians.html" rel="alternate" type="text/html" title="Efficient Certificates of Anti-Concentration Beyond Gaussians" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/EfficientCertificatesofAntiConcentrationBeyondGaussians</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/EfficientCertificatesofAntiConcentrationBeyondGaussians.html">&lt;p&gt;A set of high dimensional points $X={x_1, x_2,\ldots, x_n} \subset R^d$ in isotropic position is said to be $\delta$-anti concentrated if for every direction $v$, the fraction of points in $X$ satisfying $|\langle x_i,v \rangle |\leq \delta$ is at most $O(\delta)$. Motivated by applications to list-decodable learning and clustering, recent works have considered the problem of constructing efficient certificates of anti-concentration in the average case, when the set of points $X$ corresponds to samples from a Gaussian distribution. Their certificates played a crucial role in several subsequent works in algorithmic robust statistics on list-decodable learning and settling the robust learnability of arbitrary Gaussian mixtures, yet remain limited to rotationally invariant distributions.
  This work presents a new (and arguably the most natural) formulation for anti-concentration. Using this formulation, we give quasi-polynomial time verifiable sum-of-squares certificates of anti-concentration that hold for a wide class of non-Gaussian distributions including anti-concentrated bounded product distributions and uniform distributions over $L_p$ balls (and their affine transformations). Consequently, our method upgrades and extends results in algorithmic robust statistics e.g., list-decodable learning and clustering, to such distributions. Our approach constructs a canonical integer program for anti-concentration and analysis a sum-of-squares relaxation of it, independent of the intended application. We rely on duality and analyze a pseudo-expectation on large subsets of the input points that take a small value in some direction. Our analysis uses the method of polynomial reweightings to reduce the problem to analyzing only analytically dense or sparse directions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.15084&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ainesh Bakshi, Pravesh Kothari, Goutham Rajendran, Madhur Tulsiani, Aravindan Vijayaraghavan</name></author><category term="stat.ML" /><summary type="html">A set of high dimensional points $X={x_1, x_2,\ldots, x_n} \subset R^d$ in isotropic position is said to be $\delta$-anti concentrated if for every direction $v$, the fraction of points in $X$ satisfying $|\langle x_i,v \rangle |\leq \delta$ is at most $O(\delta)$. Motivated by applications to list-decodable learning and clustering, recent works have considered the problem of constructing efficient certificates of anti-concentration in the average case, when the set of points $X$ corresponds to samples from a Gaussian distribution. Their certificates played a crucial role in several subsequent works in algorithmic robust statistics on list-decodable learning and settling the robust learnability of arbitrary Gaussian mixtures, yet remain limited to rotationally invariant distributions. This work presents a new (and arguably the most natural) formulation for anti-concentration. Using this formulation, we give quasi-polynomial time verifiable sum-of-squares certificates of anti-concentration that hold for a wide class of non-Gaussian distributions including anti-concentrated bounded product distributions and uniform distributions over $L_p$ balls (and their affine transformations). Consequently, our method upgrades and extends results in algorithmic robust statistics e.g., list-decodable learning and clustering, to such distributions. Our approach constructs a canonical integer program for anti-concentration and analysis a sum-of-squares relaxation of it, independent of the intended application. We rely on duality and analyze a pseudo-expectation on large subsets of the input points that take a small value in some direction. Our analysis uses the method of polynomial reweightings to reduce the problem to analyzing only analytically dense or sparse directions.</summary></entry><entry><title type="html">Emergence of Globally Attracting Fixed Points in Deep Neural Networks With Nonlinear Activations</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/EmergenceofGloballyAttractingFixedPointsinDeepNeuralNetworksWithNonlinearActivations.html" rel="alternate" type="text/html" title="Emergence of Globally Attracting Fixed Points in Deep Neural Networks With Nonlinear Activations" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/EmergenceofGloballyAttractingFixedPointsinDeepNeuralNetworksWithNonlinearActivations</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/EmergenceofGloballyAttractingFixedPointsinDeepNeuralNetworksWithNonlinearActivations.html">&lt;p&gt;Understanding how neural networks transform input data across layers is fundamental to unraveling their learning and generalization capabilities. Although prior work has used insights from kernel methods to study neural networks, a global analysis of how the similarity between hidden representations evolves across layers remains underexplored. In this paper, we introduce a theoretical framework for the evolution of the kernel sequence, which measures the similarity between the hidden representation for two different inputs. Operating under the mean-field regime, we show that the kernel sequence evolves deterministically via a kernel map, which only depends on the activation function. By expanding activation using Hermite polynomials and using their algebraic properties, we derive an explicit form for kernel map and fully characterize its fixed points. Our analysis reveals that for nonlinear activations, the kernel sequence converges globally to a unique fixed point, which can correspond to orthogonal or similar representations depending on the activation and network architecture. We further extend our results to networks with residual connections and normalization layers, demonstrating similar convergence behaviors. This work provides new insights into the implicit biases of deep neural networks and how architectural choices influence the evolution of representations across layers.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20107&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Amir Joudaki, Thomas Hofmann</name></author><category term="stat.ML" /><summary type="html">Understanding how neural networks transform input data across layers is fundamental to unraveling their learning and generalization capabilities. Although prior work has used insights from kernel methods to study neural networks, a global analysis of how the similarity between hidden representations evolves across layers remains underexplored. In this paper, we introduce a theoretical framework for the evolution of the kernel sequence, which measures the similarity between the hidden representation for two different inputs. Operating under the mean-field regime, we show that the kernel sequence evolves deterministically via a kernel map, which only depends on the activation function. By expanding activation using Hermite polynomials and using their algebraic properties, we derive an explicit form for kernel map and fully characterize its fixed points. Our analysis reveals that for nonlinear activations, the kernel sequence converges globally to a unique fixed point, which can correspond to orthogonal or similar representations depending on the activation and network architecture. We further extend our results to networks with residual connections and normalization layers, demonstrating similar convergence behaviors. This work provides new insights into the implicit biases of deep neural networks and how architectural choices influence the evolution of representations across layers.</summary></entry><entry><title type="html">End-To-End Causal Effect Estimation from Unstructured Natural Language Data</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/EndToEndCausalEffectEstimationfromUnstructuredNaturalLanguageData.html" rel="alternate" type="text/html" title="End-To-End Causal Effect Estimation from Unstructured Natural Language Data" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/EndToEndCausalEffectEstimationfromUnstructuredNaturalLanguageData</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/EndToEndCausalEffectEstimationfromUnstructuredNaturalLanguageData.html">&lt;p&gt;Knowing the effect of an intervention is critical for human decision-making, but current approaches for causal effect estimation rely on manual data collection and structuring, regardless of the causal assumptions. This increases both the cost and time-to-completion for studies. We show how large, diverse observational text data can be mined with large language models (LLMs) to produce inexpensive causal effect estimates under appropriate causal assumptions. We introduce NATURAL, a novel family of causal effect estimators built with LLMs that operate over datasets of unstructured text. Our estimators use LLM conditional distributions (over variables of interest, given the text data) to assist in the computation of classical estimators of causal effect. We overcome a number of technical challenges to realize this idea, such as automating data curation and using LLMs to impute missing information. We prepare six (two synthetic and four real) observational datasets, paired with corresponding ground truth in the form of randomized trials, which we used to systematically evaluate each step of our pipeline. NATURAL estimators demonstrate remarkable performance, yielding causal effect estimates that fall within 3 percentage points of their ground truth counterparts, including on real-world Phase 3/4 clinical trials. Our results suggest that unstructured text data is a rich source of causal effect information, and NATURAL is a first step towards an automated pipeline to tap this resource.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2407.07018&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Nikita Dhawan, Leonardo Cotta, Karen Ullrich, Rahul G. Krishnan, Chris J. Maddison</name></author><category term="stat.ME" /><summary type="html">Knowing the effect of an intervention is critical for human decision-making, but current approaches for causal effect estimation rely on manual data collection and structuring, regardless of the causal assumptions. This increases both the cost and time-to-completion for studies. We show how large, diverse observational text data can be mined with large language models (LLMs) to produce inexpensive causal effect estimates under appropriate causal assumptions. We introduce NATURAL, a novel family of causal effect estimators built with LLMs that operate over datasets of unstructured text. Our estimators use LLM conditional distributions (over variables of interest, given the text data) to assist in the computation of classical estimators of causal effect. We overcome a number of technical challenges to realize this idea, such as automating data curation and using LLMs to impute missing information. We prepare six (two synthetic and four real) observational datasets, paired with corresponding ground truth in the form of randomized trials, which we used to systematically evaluate each step of our pipeline. NATURAL estimators demonstrate remarkable performance, yielding causal effect estimates that fall within 3 percentage points of their ground truth counterparts, including on real-world Phase 3/4 clinical trials. Our results suggest that unstructured text data is a rich source of causal effect information, and NATURAL is a first step towards an automated pipeline to tap this resource.</summary></entry><entry><title type="html">Establishing Nationwide Power System Vulnerability Index across US Counties Using Interpretable Machine Learning</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/EstablishingNationwidePowerSystemVulnerabilityIndexacrossUSCountiesUsingInterpretableMachineLearning.html" rel="alternate" type="text/html" title="Establishing Nationwide Power System Vulnerability Index across US Counties Using Interpretable Machine Learning" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/EstablishingNationwidePowerSystemVulnerabilityIndexacrossUSCountiesUsingInterpretableMachineLearning</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/EstablishingNationwidePowerSystemVulnerabilityIndexacrossUSCountiesUsingInterpretableMachineLearning.html">&lt;p&gt;Power outages have become increasingly frequent, intense, and prolonged in the US due to climate change, aging electrical grids, and rising energy demand. However, largely due to the absence of granular spatiotemporal outage data, we lack data-driven evidence and analytics-based metrics to quantify power system vulnerability. This limitation has hindered the ability to effectively evaluate and address vulnerability to power outages in US communities. Here, we collected ~179 million power outage records at 15-minute intervals across 3022 US contiguous counties (96.15% of the area) from 2014 to 2023. We developed a power system vulnerability assessment framework based on three dimensions (intensity, frequency, and duration) and applied interpretable machine learning models (XGBoost and SHAP) to compute Power System Vulnerability Index (PSVI) at the county level. Our analysis reveals a consistent increase in power system vulnerability over the past decade. We identified 318 counties across 45 states as hotspots for high power system vulnerability, particularly in the West Coast (California and Washington), the East Coast (Florida and the Northeast area), the Great Lakes megalopolis (Chicago-Detroit metropolitan areas), and the Gulf of Mexico (Texas). Heterogeneity analysis indicates that urban counties, counties with interconnected grids, and states with high solar generation exhibit significantly higher vulnerability. Our results highlight the significance of the proposed PSVI for evaluating the vulnerability of communities to power outages. The findings underscore the widespread and pervasive impact of power outages across the country and offer crucial insights to support infrastructure operators, policymakers, and emergency managers in formulating policies and programs aimed at enhancing the resilience of the US power infrastructure.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.19754&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Junwei Ma, Bo Li, Olufemi A. Omitaomu, Ali Mostafavi</name></author><category term="stat.AP" /><summary type="html">Power outages have become increasingly frequent, intense, and prolonged in the US due to climate change, aging electrical grids, and rising energy demand. However, largely due to the absence of granular spatiotemporal outage data, we lack data-driven evidence and analytics-based metrics to quantify power system vulnerability. This limitation has hindered the ability to effectively evaluate and address vulnerability to power outages in US communities. Here, we collected ~179 million power outage records at 15-minute intervals across 3022 US contiguous counties (96.15% of the area) from 2014 to 2023. We developed a power system vulnerability assessment framework based on three dimensions (intensity, frequency, and duration) and applied interpretable machine learning models (XGBoost and SHAP) to compute Power System Vulnerability Index (PSVI) at the county level. Our analysis reveals a consistent increase in power system vulnerability over the past decade. We identified 318 counties across 45 states as hotspots for high power system vulnerability, particularly in the West Coast (California and Washington), the East Coast (Florida and the Northeast area), the Great Lakes megalopolis (Chicago-Detroit metropolitan areas), and the Gulf of Mexico (Texas). Heterogeneity analysis indicates that urban counties, counties with interconnected grids, and states with high solar generation exhibit significantly higher vulnerability. Our results highlight the significance of the proposed PSVI for evaluating the vulnerability of communities to power outages. The findings underscore the widespread and pervasive impact of power outages across the country and offer crucial insights to support infrastructure operators, policymakers, and emergency managers in formulating policies and programs aimed at enhancing the resilience of the US power infrastructure.</summary></entry><entry><title type="html">Evaluating the design space of diffusion-based generative models</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Evaluatingthedesignspaceofdiffusionbasedgenerativemodels.html" rel="alternate" type="text/html" title="Evaluating the design space of diffusion-based generative models" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Evaluatingthedesignspaceofdiffusionbasedgenerativemodels</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Evaluatingthedesignspaceofdiffusionbasedgenerativemodels.html">&lt;p&gt;Most existing theoretical investigations of the accuracy of diffusion models, albeit significant, assume the score function has been approximated to a certain accuracy, and then use this a priori bound to control the error of generation. This article instead provides a first quantitative understanding of the whole generation process, i.e., both training and sampling. More precisely, it conducts a non-asymptotic convergence analysis of denoising score matching under gradient descent. In addition, a refined sampling error analysis for variance exploding models is also provided. The combination of these two results yields a full error analysis, which elucidates (again, but this time theoretically) how to design the training and sampling processes for effective generation. For instance, our theory implies a preference toward noise distribution and loss weighting in training that qualitatively agree with the ones used in [Karras et al., 2022]. It also provides perspectives on the choices of time and variance schedules in sampling: when the score is well trained, the design in [Song et al., 2021] is more preferable, but when it is less trained, the design in [Karras et al., 2022] becomes more preferable.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.12839&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yuqing Wang, Ye He, Molei Tao</name></author><category term="stat.ML" /><summary type="html">Most existing theoretical investigations of the accuracy of diffusion models, albeit significant, assume the score function has been approximated to a certain accuracy, and then use this a priori bound to control the error of generation. This article instead provides a first quantitative understanding of the whole generation process, i.e., both training and sampling. More precisely, it conducts a non-asymptotic convergence analysis of denoising score matching under gradient descent. In addition, a refined sampling error analysis for variance exploding models is also provided. The combination of these two results yields a full error analysis, which elucidates (again, but this time theoretically) how to design the training and sampling processes for effective generation. For instance, our theory implies a preference toward noise distribution and loss weighting in training that qualitatively agree with the ones used in [Karras et al., 2022]. It also provides perspectives on the choices of time and variance schedules in sampling: when the score is well trained, the design in [Song et al., 2021] is more preferable, but when it is less trained, the design in [Karras et al., 2022] becomes more preferable.</summary></entry><entry><title type="html">Exogenous Matching: Learning Good Proposals for Tractable Counterfactual Estimation</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ExogenousMatchingLearningGoodProposalsforTractableCounterfactualEstimation.html" rel="alternate" type="text/html" title="Exogenous Matching: Learning Good Proposals for Tractable Counterfactual Estimation" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ExogenousMatchingLearningGoodProposalsforTractableCounterfactualEstimation</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ExogenousMatchingLearningGoodProposalsforTractableCounterfactualEstimation.html">&lt;p&gt;We propose an importance sampling method for tractable and efficient estimation of counterfactual expressions in general settings, named Exogenous Matching. By minimizing a common upper bound of counterfactual estimators, we transform the variance minimization problem into a conditional distribution learning problem, enabling its integration with existing conditional distribution modeling approaches. We validate the theoretical results through experiments under various types and settings of Structural Causal Models (SCMs) and demonstrate the outperformance on counterfactual estimation tasks compared to other existing importance sampling methods. We also explore the impact of injecting structural prior knowledge (counterfactual Markov boundaries) on the results. Finally, we apply this method to identifiable proxy SCMs and demonstrate the unbiasedness of the estimates, empirically illustrating the applicability of the method to practical scenarios.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.13914&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yikang Chen, Dehui Du, Lili Tian</name></author><category term="stat.ML" /><summary type="html">We propose an importance sampling method for tractable and efficient estimation of counterfactual expressions in general settings, named Exogenous Matching. By minimizing a common upper bound of counterfactual estimators, we transform the variance minimization problem into a conditional distribution learning problem, enabling its integration with existing conditional distribution modeling approaches. We validate the theoretical results through experiments under various types and settings of Structural Causal Models (SCMs) and demonstrate the outperformance on counterfactual estimation tasks compared to other existing importance sampling methods. We also explore the impact of injecting structural prior knowledge (counterfactual Markov boundaries) on the results. Finally, we apply this method to identifiable proxy SCMs and demonstrate the unbiasedness of the estimates, empirically illustrating the applicability of the method to practical scenarios.</summary></entry><entry><title type="html">Faster WIND: Accelerating Iterative Best-of-$N$ Distillation for LLM Alignment</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/FasterWINDAcceleratingIterativeBestofNDistillationforLLMAlignment.html" rel="alternate" type="text/html" title="Faster WIND: Accelerating Iterative Best-of-$N$ Distillation for LLM Alignment" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/FasterWINDAcceleratingIterativeBestofNDistillationforLLMAlignment</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/FasterWINDAcceleratingIterativeBestofNDistillationforLLMAlignment.html">&lt;p&gt;Recent advances in aligning large language models with human preferences have corroborated the growing importance of best-of-N distillation (BOND). However, the iterative BOND algorithm is prohibitively expensive in practice due to the sample and computation inefficiency. This paper addresses the problem by revealing a unified game-theoretic connection between iterative BOND and self-play alignment, which unifies seemingly disparate algorithmic paradigms. Based on the connection, we establish a novel framework, WIN rate Dominance (WIND), with a series of efficient algorithms for regularized win rate dominance optimization that approximates iterative BOND in the parameter space. We provides provable sample efficiency guarantee for one of the WIND variant with the square loss objective. The experimental results confirm that our algorithm not only accelerates the computation, but also achieves superior sample efficiency compared to existing methods.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20727&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Tong Yang, Jincheng Mei, Hanjun Dai, Zixin Wen, Shicong Cen, Dale Schuurmans, Yuejie Chi, Bo Dai</name></author><category term="stat.ML" /><summary type="html">Recent advances in aligning large language models with human preferences have corroborated the growing importance of best-of-N distillation (BOND). However, the iterative BOND algorithm is prohibitively expensive in practice due to the sample and computation inefficiency. This paper addresses the problem by revealing a unified game-theoretic connection between iterative BOND and self-play alignment, which unifies seemingly disparate algorithmic paradigms. Based on the connection, we establish a novel framework, WIN rate Dominance (WIND), with a series of efficient algorithms for regularized win rate dominance optimization that approximates iterative BOND in the parameter space. We provides provable sample efficiency guarantee for one of the WIND variant with the square loss objective. The experimental results confirm that our algorithm not only accelerates the computation, but also achieves superior sample efficiency compared to existing methods.</summary></entry><entry><title type="html">Functional Mixture Regression Control Chart</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/FunctionalMixtureRegressionControlChart.html" rel="alternate" type="text/html" title="Functional Mixture Regression Control Chart" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/FunctionalMixtureRegressionControlChart</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/FunctionalMixtureRegressionControlChart.html">&lt;p&gt;Industrial applications often exhibit multiple in-control patterns due to varying operating conditions, which makes a single functional linear model (FLM) inadequate to capture the complexity of the true relationship between a functional quality characteristic and covariates, which gives rise to the multimode profile monitoring problem. This issue is clearly illustrated in the resistance spot welding (RSW) process in the automotive industry, where different operating conditions lead to multiple in-control states. In these states, factors such as electrode tip wear and dressing may influence the functional quality characteristic differently, resulting in distinct FLMs across subpopulations. To address this problem, this article introduces the functional mixture regression control chart (FMRCC) to monitor functional quality characteristics with multiple in-control patterns and covariate information, modeled using a mixture of FLMs. A monitoring strategy based on the likelihood ratio test is proposed to monitor any deviation from the estimated in-control heterogeneous population. An extensive Monte Carlo simulation study is performed to compare the FMRCC with competing monitoring schemes that have already appeared in the literature, and a case study in the monitoring of an RSW process in the automotive industry, which motivated this research, illustrates its practical applicability.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20138&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Christian Capezza, Fabio Centofanti, Davide Forcina, Antonio Lepore, Biagio Palumbo</name></author><category term="stat.ME," /><category term="stat.AP" /><summary type="html">Industrial applications often exhibit multiple in-control patterns due to varying operating conditions, which makes a single functional linear model (FLM) inadequate to capture the complexity of the true relationship between a functional quality characteristic and covariates, which gives rise to the multimode profile monitoring problem. This issue is clearly illustrated in the resistance spot welding (RSW) process in the automotive industry, where different operating conditions lead to multiple in-control states. In these states, factors such as electrode tip wear and dressing may influence the functional quality characteristic differently, resulting in distinct FLMs across subpopulations. To address this problem, this article introduces the functional mixture regression control chart (FMRCC) to monitor functional quality characteristics with multiple in-control patterns and covariate information, modeled using a mixture of FLMs. A monitoring strategy based on the likelihood ratio test is proposed to monitor any deviation from the estimated in-control heterogeneous population. An extensive Monte Carlo simulation study is performed to compare the FMRCC with competing monitoring schemes that have already appeared in the literature, and a case study in the monitoring of an RSW process in the automotive industry, which motivated this research, illustrates its practical applicability.</summary></entry><entry><title type="html">Fused Extended Two-Way Fixed Effects for Difference-in-Differences With Staggered Adoptions</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/FusedExtendedTwoWayFixedEffectsforDifferenceinDifferencesWithStaggeredAdoptions.html" rel="alternate" type="text/html" title="Fused Extended Two-Way Fixed Effects for Difference-in-Differences With Staggered Adoptions" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/FusedExtendedTwoWayFixedEffectsforDifferenceinDifferencesWithStaggeredAdoptions</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/FusedExtendedTwoWayFixedEffectsforDifferenceinDifferencesWithStaggeredAdoptions.html">&lt;p&gt;To address the bias of the canonical two-way fixed effects estimator for difference-in-differences under staggered adoptions, Wooldridge (2021) proposed the extended two-way fixed effects estimator, which adds many parameters. However, this reduces efficiency. Restricting some of these parameters to be equal (for example, subsequent treatment effects within a cohort) helps, but ad hoc restrictions may reintroduce bias. We propose a machine learning estimator with a single tuning parameter, fused extended two-way fixed effects (FETWFE), that enables automatic data-driven selection of these restrictions. We prove that under an appropriate sparsity assumption FETWFE identifies the correct restrictions with probability tending to one, which improves efficiency. We also prove the consistency, oracle property, and asymptotic normality of FETWFE for several classes of heterogeneous marginal treatment effect estimators under either conditional or marginal parallel trends, and we prove the same results for conditional average treatment effects under conditional parallel trends. We demonstrate FETWFE in simulation studies and an empirical application.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2312.05985&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Gregory Faletto</name></author><category term="stat.ME," /><category term="stat.ML," /><category term="stat.TH" /><summary type="html">To address the bias of the canonical two-way fixed effects estimator for difference-in-differences under staggered adoptions, Wooldridge (2021) proposed the extended two-way fixed effects estimator, which adds many parameters. However, this reduces efficiency. Restricting some of these parameters to be equal (for example, subsequent treatment effects within a cohort) helps, but ad hoc restrictions may reintroduce bias. We propose a machine learning estimator with a single tuning parameter, fused extended two-way fixed effects (FETWFE), that enables automatic data-driven selection of these restrictions. We prove that under an appropriate sparsity assumption FETWFE identifies the correct restrictions with probability tending to one, which improves efficiency. We also prove the consistency, oracle property, and asymptotic normality of FETWFE for several classes of heterogeneous marginal treatment effect estimators under either conditional or marginal parallel trends, and we prove the same results for conditional average treatment effects under conditional parallel trends. We demonstrate FETWFE in simulation studies and an empirical application.</summary></entry><entry><title type="html">General Causal Imputation via Synthetic Interventions</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/GeneralCausalImputationviaSyntheticInterventions.html" rel="alternate" type="text/html" title="General Causal Imputation via Synthetic Interventions" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/GeneralCausalImputationviaSyntheticInterventions</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/GeneralCausalImputationviaSyntheticInterventions.html">&lt;p&gt;Given two sets of elements (such as cell types and drug compounds), researchers typically only have access to a limited subset of their interactions. The task of causal imputation involves using this subset to predict unobserved interactions. Squires et al. (2022) have proposed two estimators for this task based on the synthetic interventions (SI) estimator: SI-A (for actions) and SI-C (for contexts). We extend their work and introduce a novel causal imputation estimator, generalized synthetic interventions (GSI). We prove the identifiability of this estimator for data generated from a more complex latent factor model. On synthetic and real data we show empirically that it recovers or outperforms their estimators.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20647&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Marco Jiralerspong, Thomas Jiralerspong, Vedant Shah, Dhanya Sridhar, Gauthier Gidel</name></author><category term="stat.ML" /><summary type="html">Given two sets of elements (such as cell types and drug compounds), researchers typically only have access to a limited subset of their interactions. The task of causal imputation involves using this subset to predict unobserved interactions. Squires et al. (2022) have proposed two estimators for this task based on the synthetic interventions (SI) estimator: SI-A (for actions) and SI-C (for contexts). We extend their work and introduce a novel causal imputation estimator, generalized synthetic interventions (GSI). We prove the identifiability of this estimator for data generated from a more complex latent factor model. On synthetic and real data we show empirically that it recovers or outperforms their estimators.</summary></entry><entry><title type="html">Generative Example-Based Explanations: Bridging the Gap between Generative Modeling and Explainability</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/GenerativeExampleBasedExplanationsBridgingtheGapbetweenGenerativeModelingandExplainability.html" rel="alternate" type="text/html" title="Generative Example-Based Explanations: Bridging the Gap between Generative Modeling and Explainability" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/GenerativeExampleBasedExplanationsBridgingtheGapbetweenGenerativeModelingandExplainability</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/GenerativeExampleBasedExplanationsBridgingtheGapbetweenGenerativeModelingandExplainability.html">&lt;p&gt;Recently, several methods have leveraged deep generative modeling to produce example-based explanations of decision algorithms for high-dimensional input data. Despite promising results, a disconnect exists between these methods and the classical explainability literature, which focuses on lower-dimensional data with semantically meaningful features. This conceptual and communication gap leads to misunderstandings and misalignments in goals and expectations. In this paper, we bridge this gap by proposing a novel probabilistic framework for local example-based explanations. Our framework integrates the critical characteristics of classical local explanation desiderata while being amenable to high-dimensional data and their modeling through deep generative models. Our aim is to facilitate communication, foster rigor and transparency, and improve the quality of peer discussion and research progress.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20890&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Philipp Vaeth, Alexander M. Fruehwald, Benjamin Paassen, Magda Gregorova</name></author><category term="stat.ML" /><summary type="html">Recently, several methods have leveraged deep generative modeling to produce example-based explanations of decision algorithms for high-dimensional input data. Despite promising results, a disconnect exists between these methods and the classical explainability literature, which focuses on lower-dimensional data with semantically meaningful features. This conceptual and communication gap leads to misunderstandings and misalignments in goals and expectations. In this paper, we bridge this gap by proposing a novel probabilistic framework for local example-based explanations. Our framework integrates the critical characteristics of classical local explanation desiderata while being amenable to high-dimensional data and their modeling through deep generative models. Our aim is to facilitate communication, foster rigor and transparency, and improve the quality of peer discussion and research progress.</summary></entry><entry><title type="html">Hamiltonian Score Matching and Generative Flows</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/HamiltonianScoreMatchingandGenerativeFlows.html" rel="alternate" type="text/html" title="Hamiltonian Score Matching and Generative Flows" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/HamiltonianScoreMatchingandGenerativeFlows</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/HamiltonianScoreMatchingandGenerativeFlows.html">&lt;p&gt;Classical Hamiltonian mechanics has been widely used in machine learning in the form of Hamiltonian Monte Carlo for applications with predetermined force fields. In this work, we explore the potential of deliberately designing force fields for Hamiltonian ODEs, introducing Hamiltonian velocity predictors (HVPs) as a tool for score matching and generative models. We present two innovations constructed with HVPs: Hamiltonian Score Matching (HSM), which estimates score functions by augmenting data via Hamiltonian trajectories, and Hamiltonian Generative Flows (HGFs), a novel generative model that encompasses diffusion models and flow matching as HGFs with zero force fields. We showcase the extended design space of force fields by introducing Oscillation HGFs, a generative model inspired by harmonic oscillators. Our experiments validate our theoretical insights about HSM as a novel score matching metric and demonstrate that HGFs rival leading generative modeling techniques.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20470&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Peter Holderrieth, Yilun Xu, Tommi Jaakkola</name></author><category term="stat.ML" /><summary type="html">Classical Hamiltonian mechanics has been widely used in machine learning in the form of Hamiltonian Monte Carlo for applications with predetermined force fields. In this work, we explore the potential of deliberately designing force fields for Hamiltonian ODEs, introducing Hamiltonian velocity predictors (HVPs) as a tool for score matching and generative models. We present two innovations constructed with HVPs: Hamiltonian Score Matching (HSM), which estimates score functions by augmenting data via Hamiltonian trajectories, and Hamiltonian Generative Flows (HGFs), a novel generative model that encompasses diffusion models and flow matching as HGFs with zero force fields. We showcase the extended design space of force fields by introducing Oscillation HGFs, a generative model inspired by harmonic oscillators. Our experiments validate our theoretical insights about HSM as a novel score matching metric and demonstrate that HGFs rival leading generative modeling techniques.</summary></entry><entry><title type="html">Hazard and Beyond: Exploring Five Distributional Representations of Accelerometry Data for Disability Discrimination in Multiple Sclerosis</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/HazardandBeyondExploringFiveDistributionalRepresentationsofAccelerometryDataforDisabilityDiscriminationinMultipleSclerosis.html" rel="alternate" type="text/html" title="Hazard and Beyond: Exploring Five Distributional Representations of Accelerometry Data for Disability Discrimination in Multiple Sclerosis" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/HazardandBeyondExploringFiveDistributionalRepresentationsofAccelerometryDataforDisabilityDiscriminationinMultipleSclerosis</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/HazardandBeyondExploringFiveDistributionalRepresentationsofAccelerometryDataforDisabilityDiscriminationinMultipleSclerosis.html">&lt;p&gt;Research on modeling the distributional aspects in sensor-based digital health (sDHT) data has grown significantly in recent years. Most existing approaches focus on using individual-specific density or quantile functions. However, there has been limited exploration to assess the practical utility of alternative distributional representations in clinical contexts collecting sDHT data. This study is motivated by accelerometry data collected on 246 individuals with multiple sclerosis (MS) representing a wide range of disability (Expanded Disability Status Scale, EDSS: 0-7). We consider five different individual-level distributional representations of minute-level activity counts: density, survival, hazard, quantile, and total time on test functions. For each of the five distributional representations, scalar-on-function regression fits linear discriminators for binary and continuously measured MS disability, and cross-validated discriminatory performance of these linear discriminators is compared across. The results show that individual-level hazard functions provide the highest discriminatory accuracy, more than double the accuracy compared to density functions. Individual-level quantile functions provided the second-highest discriminatory accuracy. These findings highlight the importance of focusing on distributional representations that capture the tail behavior of distributions when analyzing digital health data, especially in clinical contexts.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20620&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Pratim Guha Niyogi, Muraleetharan Sanjayan, Kathryn C. Fitzgerald, Ellen M. Mowry, Vadim Zipunnikov</name></author><category term="stat.AP" /><summary type="html">Research on modeling the distributional aspects in sensor-based digital health (sDHT) data has grown significantly in recent years. Most existing approaches focus on using individual-specific density or quantile functions. However, there has been limited exploration to assess the practical utility of alternative distributional representations in clinical contexts collecting sDHT data. This study is motivated by accelerometry data collected on 246 individuals with multiple sclerosis (MS) representing a wide range of disability (Expanded Disability Status Scale, EDSS: 0-7). We consider five different individual-level distributional representations of minute-level activity counts: density, survival, hazard, quantile, and total time on test functions. For each of the five distributional representations, scalar-on-function regression fits linear discriminators for binary and continuously measured MS disability, and cross-validated discriminatory performance of these linear discriminators is compared across. The results show that individual-level hazard functions provide the highest discriminatory accuracy, more than double the accuracy compared to density functions. Individual-level quantile functions provided the second-highest discriminatory accuracy. These findings highlight the importance of focusing on distributional representations that capture the tail behavior of distributions when analyzing digital health data, especially in clinical contexts.</summary></entry><entry><title type="html">Hierarchical Universal Value Function Approximators</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/HierarchicalUniversalValueFunctionApproximators.html" rel="alternate" type="text/html" title="Hierarchical Universal Value Function Approximators" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/HierarchicalUniversalValueFunctionApproximators</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/HierarchicalUniversalValueFunctionApproximators.html">&lt;p&gt;There have been key advancements to building universal approximators for multi-goal collections of reinforcement learning value functions – key elements in estimating long-term returns of states in a parameterized manner. We extend this to hierarchical reinforcement learning, using the options framework, by introducing hierarchical universal value function approximators (H-UVFAs). This allows us to leverage the added benefits of scaling, planning, and generalization expected in temporal abstraction settings. We develop supervised and reinforcement learning methods for learning embeddings of the states, goals, options, and actions in the two hierarchical value functions: $Q(s, g, o; \theta)$ and $Q(s, g, o, a; \theta)$. Finally we demonstrate generalization of the HUVFAs and show they outperform corresponding UVFAs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.08997&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Rushiv Arora</name></author><category term="stat.ML" /><summary type="html">There have been key advancements to building universal approximators for multi-goal collections of reinforcement learning value functions – key elements in estimating long-term returns of states in a parameterized manner. We extend this to hierarchical reinforcement learning, using the options framework, by introducing hierarchical universal value function approximators (H-UVFAs). This allows us to leverage the added benefits of scaling, planning, and generalization expected in temporal abstraction settings. We develop supervised and reinforcement learning methods for learning embeddings of the states, goals, options, and actions in the two hierarchical value functions: $Q(s, g, o; \theta)$ and $Q(s, g, o, a; \theta)$. Finally we demonstrate generalization of the HUVFAs and show they outperform corresponding UVFAs.</summary></entry><entry><title type="html">High-dimensional partial linear model with trend filtering</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Highdimensionalpartiallinearmodelwithtrendfiltering.html" rel="alternate" type="text/html" title="High-dimensional partial linear model with trend filtering" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Highdimensionalpartiallinearmodelwithtrendfiltering</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Highdimensionalpartiallinearmodelwithtrendfiltering.html">&lt;p&gt;We study the high-dimensional partial linear model, where the linear part has a high-dimensional sparse regression coefficient and the nonparametric part includes a function whose derivatives are of bounded total variation. We expand upon the univariate trend filtering to develop partial linear trend filtering–a doubly penalized least square estimation approach based on $\ell_1$ penalty and total variation penalty. Analogous to the advantages of trend filtering in univariate nonparametric regression, partial linear trend filtering not only can be efficiently computed, but also achieves the optimal error rate for estimating the nonparametric function. This in turn leads to the oracle rate for the linear part as if the underlying nonparametric function were known. We compare the proposed approach with a standard smoothing spline based method, and show both empirically and theoretically that the former outperforms the latter when the underlying function possesses heterogeneous smoothness. We apply our approach to the IDATA study to investigate the relationship between metabolomic profiles and ultra-processed food (UPF) intake, efficiently identifying key metabolites associated with UPF consumption and demonstrating strong predictive performance.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20319&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Sang Kyu Lee, Hyokyoung G. Hong, Haolei Weng, Erikka Loftfield</name></author><category term="stat.ME" /><summary type="html">We study the high-dimensional partial linear model, where the linear part has a high-dimensional sparse regression coefficient and the nonparametric part includes a function whose derivatives are of bounded total variation. We expand upon the univariate trend filtering to develop partial linear trend filtering–a doubly penalized least square estimation approach based on $\ell_1$ penalty and total variation penalty. Analogous to the advantages of trend filtering in univariate nonparametric regression, partial linear trend filtering not only can be efficiently computed, but also achieves the optimal error rate for estimating the nonparametric function. This in turn leads to the oracle rate for the linear part as if the underlying nonparametric function were known. We compare the proposed approach with a standard smoothing spline based method, and show both empirically and theoretically that the former outperforms the latter when the underlying function possesses heterogeneous smoothness. We apply our approach to the IDATA study to investigate the relationship between metabolomic profiles and ultra-processed food (UPF) intake, efficiently identifying key metabolites associated with UPF consumption and demonstrating strong predictive performance.</summary></entry><entry><title type="html">Improving Neural Additive Models with Bayesian Principles</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ImprovingNeuralAdditiveModelswithBayesianPrinciples.html" rel="alternate" type="text/html" title="Improving Neural Additive Models with Bayesian Principles" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ImprovingNeuralAdditiveModelswithBayesianPrinciples</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ImprovingNeuralAdditiveModelswithBayesianPrinciples.html">&lt;p&gt;Neural additive models (NAMs) enhance the transparency of deep neural networks by handling input features in separate additive sub-networks. However, they lack inherent mechanisms that provide calibrated uncertainties and enable selection of relevant features and interactions. Approaching NAMs from a Bayesian perspective, we augment them in three primary ways, namely by a) providing credible intervals for the individual additive sub-networks; b) estimating the marginal likelihood to perform an implicit selection of features via an empirical Bayes procedure; and c) facilitating the ranking of feature pairs as candidates for second-order interaction in fine-tuned models. In particular, we develop Laplace-approximated NAMs (LA-NAMs), which show improved empirical performance on tabular datasets and challenging real-world medical tasks.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2305.16905&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Kouroche Bouchiat, Alexander Immer, Hugo Yèche, Gunnar Rätsch, Vincent Fortuin</name></author><category term="stat.ML" /><summary type="html">Neural additive models (NAMs) enhance the transparency of deep neural networks by handling input features in separate additive sub-networks. However, they lack inherent mechanisms that provide calibrated uncertainties and enable selection of relevant features and interactions. Approaching NAMs from a Bayesian perspective, we augment them in three primary ways, namely by a) providing credible intervals for the individual additive sub-networks; b) estimating the marginal likelihood to perform an implicit selection of features via an empirical Bayes procedure; and c) facilitating the ranking of feature pairs as candidates for second-order interaction in fine-tuned models. In particular, we develop Laplace-approximated NAMs (LA-NAMs), which show improved empirical performance on tabular datasets and challenging real-world medical tasks.</summary></entry><entry><title type="html">IncomeSCM: From tabular data set to time-series simulator and causal estimation benchmark</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/IncomeSCMFromtabulardatasettotimeseriessimulatorandcausalestimationbenchmark.html" rel="alternate" type="text/html" title="IncomeSCM: From tabular data set to time-series simulator and causal estimation benchmark" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/IncomeSCMFromtabulardatasettotimeseriessimulatorandcausalestimationbenchmark</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/IncomeSCMFromtabulardatasettotimeseriessimulatorandcausalestimationbenchmark.html">&lt;p&gt;Evaluating observational estimators of causal effects demands information that is rarely available: unconfounded interventions and outcomes from the population of interest, created either by randomization or adjustment. As a result, it is customary to fall back on simulators when creating benchmark tasks. Simulators offer great control but are often too simplistic to make challenging tasks, either because they are hand-designed and lack the nuances of real-world data, or because they are fit to observational data without structural constraints. In this work, we propose a general, repeatable strategy for turning observational data into sequential structural causal models and challenging estimation tasks by following two simple principles: 1) fitting real-world data where possible, and 2) creating complexity by composing simple, hand-designed mechanisms. We implement these ideas in a highly configurable software package and apply it to the well-known Adult income data set to construct the IncomeSCM simulator. From this, we devise multiple estimation tasks and sample data sets to compare established estimators of causal effects. The tasks present a suitable challenge, with effect estimates varying greatly in quality between methods, despite similar performance in the modeling of factual outcomes, highlighting the need for dedicated causal estimators and model selection criteria.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.16069&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Fredrik D. Johansson</name></author><category term="stat.ME" /><summary type="html">Evaluating observational estimators of causal effects demands information that is rarely available: unconfounded interventions and outcomes from the population of interest, created either by randomization or adjustment. As a result, it is customary to fall back on simulators when creating benchmark tasks. Simulators offer great control but are often too simplistic to make challenging tasks, either because they are hand-designed and lack the nuances of real-world data, or because they are fit to observational data without structural constraints. In this work, we propose a general, repeatable strategy for turning observational data into sequential structural causal models and challenging estimation tasks by following two simple principles: 1) fitting real-world data where possible, and 2) creating complexity by composing simple, hand-designed mechanisms. We implement these ideas in a highly configurable software package and apply it to the well-known Adult income data set to construct the IncomeSCM simulator. From this, we devise multiple estimation tasks and sample data sets to compare established estimators of causal effects. The tasks present a suitable challenge, with effect estimates varying greatly in quality between methods, despite similar performance in the modeling of factual outcomes, highlighting the need for dedicated causal estimators and model selection criteria.</summary></entry><entry><title type="html">Info-CELS: Informative Saliency Map Guided Counterfactual Explanation</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/InfoCELSInformativeSaliencyMapGuidedCounterfactualExplanation.html" rel="alternate" type="text/html" title="Info-CELS: Informative Saliency Map Guided Counterfactual Explanation" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/InfoCELSInformativeSaliencyMapGuidedCounterfactualExplanation</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/InfoCELSInformativeSaliencyMapGuidedCounterfactualExplanation.html">&lt;p&gt;As the demand for interpretable machine learning approaches continues to grow, there is an increasing necessity for human involvement in providing informative explanations for model decisions. This is necessary for building trust and transparency in AI-based systems, leading to the emergence of the Explainable Artificial Intelligence (XAI) field. Recently, a novel counterfactual explanation model, CELS, has been introduced. CELS learns a saliency map for the interest of an instance and generates a counterfactual explanation guided by the learned saliency map. While CELS represents the first attempt to exploit learned saliency maps not only to provide intuitive explanations for the reason behind the decision made by the time series classifier but also to explore post hoc counterfactual explanations, it exhibits limitations in terms of high validity for the sake of ensuring high proximity and sparsity. In this paper, we present an enhanced approach that builds upon CELS. While the original model achieved promising results in terms of sparsity and proximity, it faced limitations in validity. Our proposed method addresses this limitation by removing mask normalization to provide more informative and valid counterfactual explanations. Through extensive experimentation on datasets from various domains, we demonstrate that our approach outperforms the CELS model, achieving higher validity and producing more informative explanations.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20539&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Peiyu Li, Omar Bahri, Pouya Hosseinzadeh, Soukaïna Filali Boubrahimi, Shah Muhammad Hamdi</name></author><category term="stat.ML" /><summary type="html">As the demand for interpretable machine learning approaches continues to grow, there is an increasing necessity for human involvement in providing informative explanations for model decisions. This is necessary for building trust and transparency in AI-based systems, leading to the emergence of the Explainable Artificial Intelligence (XAI) field. Recently, a novel counterfactual explanation model, CELS, has been introduced. CELS learns a saliency map for the interest of an instance and generates a counterfactual explanation guided by the learned saliency map. While CELS represents the first attempt to exploit learned saliency maps not only to provide intuitive explanations for the reason behind the decision made by the time series classifier but also to explore post hoc counterfactual explanations, it exhibits limitations in terms of high validity for the sake of ensuring high proximity and sparsity. In this paper, we present an enhanced approach that builds upon CELS. While the original model achieved promising results in terms of sparsity and proximity, it faced limitations in validity. Our proposed method addresses this limitation by removing mask normalization to provide more informative and valid counterfactual explanations. Through extensive experimentation on datasets from various domains, we demonstrate that our approach outperforms the CELS model, achieving higher validity and producing more informative explanations.</summary></entry><entry><title type="html">Injectivity capacity of ReLU gates</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/InjectivitycapacityofReLUgates.html" rel="alternate" type="text/html" title="Injectivity capacity of ReLU gates" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/InjectivitycapacityofReLUgates</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/InjectivitycapacityofReLUgates.html">&lt;p&gt;We consider the injectivity property of the ReLU networks layers. Determining the ReLU injectivity capacity (ratio of the number of layer’s inputs and outputs) is established as isomorphic to determining the capacity of the so-called $\ell_0$ spherical perceptron. Employing \emph{fully lifted random duality theory} (fl RDT) a powerful program is developed and utilized to handle the $\ell_0$ spherical perceptron and implicitly the ReLU layers injectivity. To put the entire fl RDT machinery in practical use, a sizeable set of numerical evaluations is conducted as well. The lifting mechanism is observed to converge remarkably fast with relative corrections in the estimated quantities not exceeding $\sim 0.1\%$ already on the third level of lifting. Closed form explicit analytical relations among key lifting parameters are uncovered as well. In addition to being of incredible importance in handling all the required numerical work, these relations also shed a new light on beautiful parametric interconnections within the lifting structure. Finally, the obtained results are also shown to fairly closely match the replica predictions from [40].&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20646&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Mihailo Stojnic</name></author><category term="stat.ML" /><summary type="html">We consider the injectivity property of the ReLU networks layers. Determining the ReLU injectivity capacity (ratio of the number of layer’s inputs and outputs) is established as isomorphic to determining the capacity of the so-called $\ell_0$ spherical perceptron. Employing \emph{fully lifted random duality theory} (fl RDT) a powerful program is developed and utilized to handle the $\ell_0$ spherical perceptron and implicitly the ReLU layers injectivity. To put the entire fl RDT machinery in practical use, a sizeable set of numerical evaluations is conducted as well. The lifting mechanism is observed to converge remarkably fast with relative corrections in the estimated quantities not exceeding $\sim 0.1\%$ already on the third level of lifting. Closed form explicit analytical relations among key lifting parameters are uncovered as well. In addition to being of incredible importance in handling all the required numerical work, these relations also shed a new light on beautiful parametric interconnections within the lifting structure. Finally, the obtained results are also shown to fairly closely match the replica predictions from [40].</summary></entry><entry><title type="html">Integrating uncertainty quantification into randomized smoothing based robustness guarantees</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Integratinguncertaintyquantificationintorandomizedsmoothingbasedrobustnessguarantees.html" rel="alternate" type="text/html" title="Integrating uncertainty quantification into randomized smoothing based robustness guarantees" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Integratinguncertaintyquantificationintorandomizedsmoothingbasedrobustnessguarantees</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Integratinguncertaintyquantificationintorandomizedsmoothingbasedrobustnessguarantees.html">&lt;p&gt;Deep neural networks have proven to be extremely powerful, however, they are also vulnerable to adversarial attacks which can cause hazardous incorrect predictions in safety-critical applications. Certified robustness via randomized smoothing gives a probabilistic guarantee that the smoothed classifier’s predictions will not change within an $\ell_2$-ball around a given input. On the other hand (uncertainty) score-based rejection is a technique often applied in practice to defend models against adversarial attacks. In this work, we fuse these two approaches by integrating a classifier that abstains from predicting when uncertainty is high into the certified robustness framework. This allows us to derive two novel robustness guarantees for uncertainty aware classifiers, namely (i) the radius of an $\ell_2$-ball around the input in which the same label is predicted and uncertainty remains low and (ii) the $\ell_2$-radius of a ball in which the predictions will either not change or be uncertain. While the former provides robustness guarantees with respect to attacks aiming at increased uncertainty, the latter informs about the amount of input perturbation necessary to lead the uncertainty aware model into a wrong prediction. Notably, this is on CIFAR10 up to 20.93% larger than for models not allowing for uncertainty based rejection. We demonstrate, that the novel framework allows for a systematic robustness evaluation of different network architectures and uncertainty measures and to identify desired properties of uncertainty quantification techniques. Moreover, we show that leveraging uncertainty in a smoothed classifier helps out-of-distribution detection.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20432&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Sina Däubener, Kira Maag, David Krueger, Asja Fischer</name></author><category term="stat.ML" /><summary type="html">Deep neural networks have proven to be extremely powerful, however, they are also vulnerable to adversarial attacks which can cause hazardous incorrect predictions in safety-critical applications. Certified robustness via randomized smoothing gives a probabilistic guarantee that the smoothed classifier’s predictions will not change within an $\ell_2$-ball around a given input. On the other hand (uncertainty) score-based rejection is a technique often applied in practice to defend models against adversarial attacks. In this work, we fuse these two approaches by integrating a classifier that abstains from predicting when uncertainty is high into the certified robustness framework. This allows us to derive two novel robustness guarantees for uncertainty aware classifiers, namely (i) the radius of an $\ell_2$-ball around the input in which the same label is predicted and uncertainty remains low and (ii) the $\ell_2$-radius of a ball in which the predictions will either not change or be uncertain. While the former provides robustness guarantees with respect to attacks aiming at increased uncertainty, the latter informs about the amount of input perturbation necessary to lead the uncertainty aware model into a wrong prediction. Notably, this is on CIFAR10 up to 20.93% larger than for models not allowing for uncertainty based rejection. We demonstrate, that the novel framework allows for a systematic robustness evaluation of different network architectures and uncertainty measures and to identify desired properties of uncertainty quantification techniques. Moreover, we show that leveraging uncertainty in a smoothed classifier helps out-of-distribution detection.</summary></entry><entry><title type="html">Introducing Spectral Attention for Long-Range Dependency in Time Series Forecasting</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/IntroducingSpectralAttentionforLongRangeDependencyinTimeSeriesForecasting.html" rel="alternate" type="text/html" title="Introducing Spectral Attention for Long-Range Dependency in Time Series Forecasting" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/IntroducingSpectralAttentionforLongRangeDependencyinTimeSeriesForecasting</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/IntroducingSpectralAttentionforLongRangeDependencyinTimeSeriesForecasting.html">&lt;p&gt;Sequence modeling faces challenges in capturing long-range dependencies across diverse tasks. Recent linear and transformer-based forecasters have shown superior performance in time series forecasting. However, they are constrained by their inherent inability to effectively address long-range dependencies in time series data, primarily due to using fixed-size inputs for prediction. Furthermore, they typically sacrifice essential temporal correlation among consecutive training samples by shuffling them into mini-batches. To overcome these limitations, we introduce a fast and effective Spectral Attention mechanism, which preserves temporal correlations among samples and facilitates the handling of long-range information while maintaining the base model structure. Spectral Attention preserves long-period trends through a low-pass filter and facilitates gradient to flow between samples. Spectral Attention can be seamlessly integrated into most sequence models, allowing models with fixed-sized look-back windows to capture long-range dependencies over thousands of steps. Through extensive experiments on 11 real-world time series datasets using 7 recent forecasting models, we consistently demonstrate the efficacy of our Spectral Attention mechanism, achieving state-of-the-art results.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20772&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Bong Gyun Kang, Dongjun Lee, HyunGi Kim, DoHyun Chung</name></author><category term="stat.ML" /><summary type="html">Sequence modeling faces challenges in capturing long-range dependencies across diverse tasks. Recent linear and transformer-based forecasters have shown superior performance in time series forecasting. However, they are constrained by their inherent inability to effectively address long-range dependencies in time series data, primarily due to using fixed-size inputs for prediction. Furthermore, they typically sacrifice essential temporal correlation among consecutive training samples by shuffling them into mini-batches. To overcome these limitations, we introduce a fast and effective Spectral Attention mechanism, which preserves temporal correlations among samples and facilitates the handling of long-range information while maintaining the base model structure. Spectral Attention preserves long-period trends through a low-pass filter and facilitates gradient to flow between samples. Spectral Attention can be seamlessly integrated into most sequence models, allowing models with fixed-sized look-back windows to capture long-range dependencies over thousands of steps. Through extensive experiments on 11 real-world time series datasets using 7 recent forecasting models, we consistently demonstrate the efficacy of our Spectral Attention mechanism, achieving state-of-the-art results.</summary></entry><entry><title type="html">Kernel Approximation of Fisher-Rao Gradient Flows</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/KernelApproximationofFisherRaoGradientFlows.html" rel="alternate" type="text/html" title="Kernel Approximation of Fisher-Rao Gradient Flows" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/KernelApproximationofFisherRaoGradientFlows</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/KernelApproximationofFisherRaoGradientFlows.html">&lt;p&gt;The purpose of this paper is to answer a few open questions in the interface of kernel methods and PDE gradient flows. Motivated by recent advances in machine learning, particularly in generative modeling and sampling, we present a rigorous investigation of Fisher-Rao and Wasserstein type gradient flows concerning their gradient structures, flow equations, and their kernel approximations. Specifically, we focus on the Fisher-Rao (also known as Hellinger) geometry and its various kernel-based approximations, developing a principled theoretical framework using tools from PDE gradient flows and optimal transport theory. We also provide a complete characterization of gradient flows in the maximum-mean discrepancy (MMD) space, with connections to existing learning and inference algorithms. Our analysis reveals precise theoretical insights linking Fisher-Rao flows, Stein flows, kernel discrepancies, and nonparametric regression. We then rigorously prove evolutionary $\Gamma$-convergence for kernel-approximated Fisher-Rao flows, providing theoretical guarantees beyond pointwise convergence. Finally, we analyze energy dissipation using the Helmholtz-Rayleigh principle, establishing important connections between classical theory in mechanics and modern machine learning practice. Our results provide a unified theoretical foundation for understanding and analyzing approximations of gradient flows in machine learning applications through a rigorous gradient flow and variational method perspective.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20622&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jia-Jie Zhu, Alexander Mielke</name></author><category term="stat.ML" /><summary type="html">The purpose of this paper is to answer a few open questions in the interface of kernel methods and PDE gradient flows. Motivated by recent advances in machine learning, particularly in generative modeling and sampling, we present a rigorous investigation of Fisher-Rao and Wasserstein type gradient flows concerning their gradient structures, flow equations, and their kernel approximations. Specifically, we focus on the Fisher-Rao (also known as Hellinger) geometry and its various kernel-based approximations, developing a principled theoretical framework using tools from PDE gradient flows and optimal transport theory. We also provide a complete characterization of gradient flows in the maximum-mean discrepancy (MMD) space, with connections to existing learning and inference algorithms. Our analysis reveals precise theoretical insights linking Fisher-Rao flows, Stein flows, kernel discrepancies, and nonparametric regression. We then rigorously prove evolutionary $\Gamma$-convergence for kernel-approximated Fisher-Rao flows, providing theoretical guarantees beyond pointwise convergence. Finally, we analyze energy dissipation using the Helmholtz-Rayleigh principle, establishing important connections between classical theory in mechanics and modern machine learning practice. Our results provide a unified theoretical foundation for understanding and analyzing approximations of gradient flows in machine learning applications through a rigorous gradient flow and variational method perspective.</summary></entry><entry><title type="html">LLM4Causal: Democratized Causal Tools for Everyone via Large Language Model</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LLM4CausalDemocratizedCausalToolsforEveryoneviaLargeLanguageModel.html" rel="alternate" type="text/html" title="LLM4Causal: Democratized Causal Tools for Everyone via Large Language Model" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LLM4CausalDemocratizedCausalToolsforEveryoneviaLargeLanguageModel</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LLM4CausalDemocratizedCausalToolsforEveryoneviaLargeLanguageModel.html">&lt;p&gt;Large Language Models (LLMs) have shown their success in language understanding and reasoning on general topics. However, their capability to perform inference based on user-specified structured data and knowledge in corpus-rare concepts, such as causal decision-making is still limited. In this work, we explore the possibility of fine-tuning an open-sourced LLM into LLM4Causal, which can identify the causal task, execute a corresponding function, and interpret its numerical results based on users’ queries and the provided dataset. Meanwhile, we propose a data generation process for more controllable GPT prompting and present two instruction-tuning datasets: (1) Causal-Retrieval-Bench for causal problem identification and input parameter extraction for causal function calling and (2) Causal-Interpret-Bench for in-context causal interpretation. By conducting end-to-end evaluations and two ablation studies, we showed that LLM4Causal can deliver end-to-end solutions for causal problems and provide easy-to-understand answers, which significantly outperforms the baselines.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2312.17122&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Haitao Jiang, Lin Ge, Yuhe Gao, Jianian Wang, Rui Song</name></author><category term="stat.ML" /><summary type="html">Large Language Models (LLMs) have shown their success in language understanding and reasoning on general topics. However, their capability to perform inference based on user-specified structured data and knowledge in corpus-rare concepts, such as causal decision-making is still limited. In this work, we explore the possibility of fine-tuning an open-sourced LLM into LLM4Causal, which can identify the causal task, execute a corresponding function, and interpret its numerical results based on users’ queries and the provided dataset. Meanwhile, we propose a data generation process for more controllable GPT prompting and present two instruction-tuning datasets: (1) Causal-Retrieval-Bench for causal problem identification and input parameter extraction for causal function calling and (2) Causal-Interpret-Bench for in-context causal interpretation. By conducting end-to-end evaluations and two ablation studies, we showed that LLM4Causal can deliver end-to-end solutions for causal problems and provide easy-to-understand answers, which significantly outperforms the baselines.</summary></entry><entry><title type="html">LLM-initialized Differentiable Causal Discovery</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LLMinitializedDifferentiableCausalDiscovery.html" rel="alternate" type="text/html" title="LLM-initialized Differentiable Causal Discovery" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LLMinitializedDifferentiableCausalDiscovery</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LLMinitializedDifferentiableCausalDiscovery.html">&lt;p&gt;The discovery of causal relationships between random variables is an important yet challenging problem that has applications across many scientific domains. Differentiable causal discovery (DCD) methods are effective in uncovering causal relationships from observational data; however, these approaches often suffer from limited interpretability and face challenges in incorporating domain-specific prior knowledge. In contrast, Large Language Models (LLMs)-based causal discovery approaches have recently been shown capable of providing useful priors for causal discovery but struggle with formal causal reasoning. In this paper, we propose LLM-DCD, which uses an LLM to initialize the optimization of the maximum likelihood objective function of DCD approaches, thereby incorporating strong priors into the discovery method. To achieve this initialization, we design our objective function to depend on an explicitly defined adjacency matrix of the causal graph as its only variational parameter. Directly optimizing the explicitly defined adjacency matrix provides a more interpretable approach to causal discovery. Additionally, we demonstrate higher accuracy on key benchmarking datasets of our approach compared to state-of-the-art alternatives, and provide empirical evidence that the quality of the initialization directly impacts the quality of the final output of our DCD approach. LLM-DCD opens up new opportunities for traditional causal discovery methods like DCD to benefit from future improvements in the causal reasoning capabilities of LLMs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21141&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Shiv Kampani, David Hidary, Constantijn van der Poel, Martin Ganahl, Brenda Miao</name></author><category term="stat.ML" /><summary type="html">The discovery of causal relationships between random variables is an important yet challenging problem that has applications across many scientific domains. Differentiable causal discovery (DCD) methods are effective in uncovering causal relationships from observational data; however, these approaches often suffer from limited interpretability and face challenges in incorporating domain-specific prior knowledge. In contrast, Large Language Models (LLMs)-based causal discovery approaches have recently been shown capable of providing useful priors for causal discovery but struggle with formal causal reasoning. In this paper, we propose LLM-DCD, which uses an LLM to initialize the optimization of the maximum likelihood objective function of DCD approaches, thereby incorporating strong priors into the discovery method. To achieve this initialization, we design our objective function to depend on an explicitly defined adjacency matrix of the causal graph as its only variational parameter. Directly optimizing the explicitly defined adjacency matrix provides a more interpretable approach to causal discovery. Additionally, we demonstrate higher accuracy on key benchmarking datasets of our approach compared to state-of-the-art alternatives, and provide empirical evidence that the quality of the initialization directly impacts the quality of the final output of our DCD approach. LLM-DCD opens up new opportunities for traditional causal discovery methods like DCD to benefit from future improvements in the causal reasoning capabilities of LLMs.</summary></entry><entry><title type="html">LOCAL: Learning with Orientation Matrix to Infer Causal Structure from Time Series Data</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LOCALLearningwithOrientationMatrixtoInferCausalStructurefromTimeSeriesData.html" rel="alternate" type="text/html" title="LOCAL: Learning with Orientation Matrix to Infer Causal Structure from Time Series Data" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LOCALLearningwithOrientationMatrixtoInferCausalStructurefromTimeSeriesData</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LOCALLearningwithOrientationMatrixtoInferCausalStructurefromTimeSeriesData.html">&lt;p&gt;Discovering the underlying Directed Acyclic Graph (DAG) from time series observational data is highly challenging due to the dynamic nature and complex nonlinear interactions between variables. Existing methods often struggle with inefficiency and the handling of high-dimensional data. To address these research gap, we propose LOCAL, a highly efficient, easy-to-implement, and constraint-free method for recovering dynamic causal structures. LOCAL is the first attempt to formulate a quasi-maximum likelihood-based score function for learning the dynamic DAG equivalent to the ground truth. On this basis, we propose two adaptive modules for enhancing the algebraic characterization of acyclicity with new capabilities: Asymptotic Causal Mask Learning (ACML) and Dynamic Graph Parameter Learning (DGPL). ACML generates causal masks using learnable priority vectors and the Gumbel-Sigmoid function, ensuring the creation of DAGs while optimizing computational efficiency. DGPL transforms causal learning into decomposed matrix products, capturing the dynamic causal structure of high-dimensional data and enhancing interpretability. Extensive experiments on synthetic and real-world datasets demonstrate that LOCAL significantly outperforms existing methods, and highlight LOCAL’s potential as a robust and efficient method for dynamic causal discovery. Our code will be available soon.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.19464&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yue Cheng, Jiajun Zhang, Weiwei Xing, Xiaoyu Guo, Xiaohui Gao</name></author><category term="stat.ML" /><summary type="html">Discovering the underlying Directed Acyclic Graph (DAG) from time series observational data is highly challenging due to the dynamic nature and complex nonlinear interactions between variables. Existing methods often struggle with inefficiency and the handling of high-dimensional data. To address these research gap, we propose LOCAL, a highly efficient, easy-to-implement, and constraint-free method for recovering dynamic causal structures. LOCAL is the first attempt to formulate a quasi-maximum likelihood-based score function for learning the dynamic DAG equivalent to the ground truth. On this basis, we propose two adaptive modules for enhancing the algebraic characterization of acyclicity with new capabilities: Asymptotic Causal Mask Learning (ACML) and Dynamic Graph Parameter Learning (DGPL). ACML generates causal masks using learnable priority vectors and the Gumbel-Sigmoid function, ensuring the creation of DAGs while optimizing computational efficiency. DGPL transforms causal learning into decomposed matrix products, capturing the dynamic causal structure of high-dimensional data and enhancing interpretability. Extensive experiments on synthetic and real-world datasets demonstrate that LOCAL significantly outperforms existing methods, and highlight LOCAL’s potential as a robust and efficient method for dynamic causal discovery. Our code will be available soon.</summary></entry><entry><title type="html">Language Agents Meet Causality – Bridging LLMs and Causal World Models</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LanguageAgentsMeetCausalityBridgingLLMsandCausalWorldModels.html" rel="alternate" type="text/html" title="Language Agents Meet Causality – Bridging LLMs and Causal World Models" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LanguageAgentsMeetCausalityBridgingLLMsandCausalWorldModels</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LanguageAgentsMeetCausalityBridgingLLMsandCausalWorldModels.html">&lt;p&gt;Large Language Models (LLMs) have recently shown great promise in planning and reasoning applications. These tasks demand robust systems, which arguably require a causal understanding of the environment. While LLMs can acquire and reflect common sense causal knowledge from their pretraining data, this information is often incomplete, incorrect, or inapplicable to a specific environment. In contrast, causal representation learning (CRL) focuses on identifying the underlying causal structure within a given environment. We propose a framework that integrates CRLs with LLMs to enable causally-aware reasoning and planning. This framework learns a causal world model, with causal variables linked to natural language expressions. This mapping provides LLMs with a flexible interface to process and generate descriptions of actions and states in text form. Effectively, the causal world model acts as a simulator that the LLM can query and interact with. We evaluate the framework on causal inference and planning tasks across temporal scales and environmental complexities. Our experiments demonstrate the effectiveness of the approach, with the causally-aware method outperforming LLM-based reasoners, especially for longer planning horizons.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.19923&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>John Gkountouras, Matthias Lindemann, Phillip Lippe, Efstratios Gavves, Ivan Titov</name></author><category term="stat.ME" /><summary type="html">Large Language Models (LLMs) have recently shown great promise in planning and reasoning applications. These tasks demand robust systems, which arguably require a causal understanding of the environment. While LLMs can acquire and reflect common sense causal knowledge from their pretraining data, this information is often incomplete, incorrect, or inapplicable to a specific environment. In contrast, causal representation learning (CRL) focuses on identifying the underlying causal structure within a given environment. We propose a framework that integrates CRLs with LLMs to enable causally-aware reasoning and planning. This framework learns a causal world model, with causal variables linked to natural language expressions. This mapping provides LLMs with a flexible interface to process and generate descriptions of actions and states in text form. Effectively, the causal world model acts as a simulator that the LLM can query and interact with. We evaluate the framework on causal inference and planning tasks across temporal scales and environmental complexities. Our experiments demonstrate the effectiveness of the approach, with the causally-aware method outperforming LLM-based reasoners, especially for longer planning horizons.</summary></entry><entry><title type="html">Learning Variational Inequalities from Data: Fast Generalization Rates under Strong Monotonicity</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LearningVariationalInequalitiesfromDataFastGeneralizationRatesunderStrongMonotonicity.html" rel="alternate" type="text/html" title="Learning Variational Inequalities from Data: Fast Generalization Rates under Strong Monotonicity" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LearningVariationalInequalitiesfromDataFastGeneralizationRatesunderStrongMonotonicity</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LearningVariationalInequalitiesfromDataFastGeneralizationRatesunderStrongMonotonicity.html">&lt;p&gt;Variational inequalities (VIs) are a broad class of optimization problems encompassing machine learning problems ranging from standard convex minimization to more complex scenarios like min-max optimization and computing the equilibria of multi-player games. In convex optimization, strong convexity allows for fast statistical learning rates requiring only $\Theta(1/\epsilon)$ stochastic first-order oracle calls to find an $\epsilon$-optimal solution, rather than the standard $\Theta(1/\epsilon^2)$ calls. In this paper, we explain how one can similarly obtain fast $\Theta(1/\epsilon)$ rates for learning VIs that satisfy strong monotonicity, a generalization of strong convexity. Specifically, we demonstrate that standard stability-based generalization arguments for convex minimization extend directly to VIs when the domain admits a small covering, or when the operator is integrable and suboptimality is measured by potential functions; such as when finding equilibria in multi-player games.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20649&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Eric Zhao, Tatjana Chavdarova, Michael Jordan</name></author><category term="stat.ML" /><summary type="html">Variational inequalities (VIs) are a broad class of optimization problems encompassing machine learning problems ranging from standard convex minimization to more complex scenarios like min-max optimization and computing the equilibria of multi-player games. In convex optimization, strong convexity allows for fast statistical learning rates requiring only $\Theta(1/\epsilon)$ stochastic first-order oracle calls to find an $\epsilon$-optimal solution, rather than the standard $\Theta(1/\epsilon^2)$ calls. In this paper, we explain how one can similarly obtain fast $\Theta(1/\epsilon)$ rates for learning VIs that satisfy strong monotonicity, a generalization of strong convexity. Specifically, we demonstrate that standard stability-based generalization arguments for convex minimization extend directly to VIs when the domain admits a small covering, or when the operator is integrable and suboptimality is measured by potential functions; such as when finding equilibria in multi-player games.</summary></entry><entry><title type="html">Likelihood approximations via Gaussian approximate inference</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LikelihoodapproximationsviaGaussianapproximateinference.html" rel="alternate" type="text/html" title="Likelihood approximations via Gaussian approximate inference" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LikelihoodapproximationsviaGaussianapproximateinference</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LikelihoodapproximationsviaGaussianapproximateinference.html">&lt;p&gt;Non-Gaussian likelihoods are essential for modelling complex real-world observations but pose significant computational challenges in learning and inference. Even with Gaussian priors, non-Gaussian likelihoods often lead to analytically intractable posteriors, necessitating approximation methods. To this end, we propose efficient schemes to approximate the effects of non-Gaussian likelihoods by Gaussian densities based on variational inference and moment matching in transformed bases. These enable efficient inference strategies originally designed for models with a Gaussian likelihood to be deployed. Our empirical results demonstrate that the proposed matching strategies attain good approximation quality for binary and multiclass classification in large-scale point-estimate and distributional inferential settings. In challenging streaming problems, the proposed methods outperform all existing likelihood approximations and approximate inference methods in the exact models. As a by-product, we show that the proposed approximate log-likelihoods are a superior alternative to least-squares on raw labels for neural network classification.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20754&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Thang D. Bui</name></author><category term="stat.ML" /><summary type="html">Non-Gaussian likelihoods are essential for modelling complex real-world observations but pose significant computational challenges in learning and inference. Even with Gaussian priors, non-Gaussian likelihoods often lead to analytically intractable posteriors, necessitating approximation methods. To this end, we propose efficient schemes to approximate the effects of non-Gaussian likelihoods by Gaussian densities based on variational inference and moment matching in transformed bases. These enable efficient inference strategies originally designed for models with a Gaussian likelihood to be deployed. Our empirical results demonstrate that the proposed matching strategies attain good approximation quality for binary and multiclass classification in large-scale point-estimate and distributional inferential settings. In challenging streaming problems, the proposed methods outperform all existing likelihood approximations and approximate inference methods in the exact models. As a by-product, we show that the proposed approximate log-likelihoods are a superior alternative to least-squares on raw labels for neural network classification.</summary></entry><entry><title type="html">Low-rank Bayesian matrix completion via geodesic Hamiltonian Monte Carlo on Stiefel manifolds</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LowrankBayesianmatrixcompletionviageodesicHamiltonianMonteCarloonStiefelmanifolds.html" rel="alternate" type="text/html" title="Low-rank Bayesian matrix completion via geodesic Hamiltonian Monte Carlo on Stiefel manifolds" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LowrankBayesianmatrixcompletionviageodesicHamiltonianMonteCarloonStiefelmanifolds</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/LowrankBayesianmatrixcompletionviageodesicHamiltonianMonteCarloonStiefelmanifolds.html">&lt;p&gt;We present a new sampling-based approach for enabling efficient computation of low-rank Bayesian matrix completion and quantifying the associated uncertainty. Firstly, we design a new prior model based on the singular-value-decomposition (SVD) parametrization of low-rank matrices. Our prior is analogous to the seminal nuclear-norm regularization used in non-Bayesian setting and enforces orthogonality in the factor matrices by constraining them to Stiefel manifolds. Then, we design a geodesic Hamiltonian Monte Carlo (-within-Gibbs) algorithm for generating posterior samples of the SVD factor matrices. We demonstrate that our approach resolves the sampling difficulties encountered by standard Gibbs samplers for the common two-matrix factorization used in matrix completion. More importantly, the geodesic Hamiltonian sampler allows for sampling in cases with more general likelihoods than the typical Gaussian likelihood and Gaussian prior assumptions adopted in most of the existing Bayesian matrix completion literature. We demonstrate an applications of our approach to fit the categorical data of a mice protein dataset and the MovieLens recommendation problem. Numerical examples demonstrate superior sampling performance, including better mixing and faster convergence to a stationary distribution. Moreover, they demonstrate improved accuracy on the two real-world benchmark problems we considered.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20318&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Tiangang Cui, Alex Gorodetsky</name></author><category term="stat.ML," /><category term="stat.CO," /><category term="stat.ME" /><summary type="html">We present a new sampling-based approach for enabling efficient computation of low-rank Bayesian matrix completion and quantifying the associated uncertainty. Firstly, we design a new prior model based on the singular-value-decomposition (SVD) parametrization of low-rank matrices. Our prior is analogous to the seminal nuclear-norm regularization used in non-Bayesian setting and enforces orthogonality in the factor matrices by constraining them to Stiefel manifolds. Then, we design a geodesic Hamiltonian Monte Carlo (-within-Gibbs) algorithm for generating posterior samples of the SVD factor matrices. We demonstrate that our approach resolves the sampling difficulties encountered by standard Gibbs samplers for the common two-matrix factorization used in matrix completion. More importantly, the geodesic Hamiltonian sampler allows for sampling in cases with more general likelihoods than the typical Gaussian likelihood and Gaussian prior assumptions adopted in most of the existing Bayesian matrix completion literature. We demonstrate an applications of our approach to fit the categorical data of a mice protein dataset and the MovieLens recommendation problem. Numerical examples demonstrate superior sampling performance, including better mixing and faster convergence to a stationary distribution. Moreover, they demonstrate improved accuracy on the two real-world benchmark problems we considered.</summary></entry><entry><title type="html">Lévy graphical models</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/L%C3%A9vygraphicalmodels.html" rel="alternate" type="text/html" title="Lévy graphical models" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/L%C3%A9vygraphicalmodels</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/L%C3%A9vygraphicalmodels.html">&lt;p&gt;Conditional independence and graphical models are crucial concepts for sparsity and statistical modeling in higher dimensions. For L&apos;evy processes, a widely applied class of stochastic processes, these notions have not been studied. By the L&apos;evy-It\^o decomposition, a multivariate L&apos;evy process can be decomposed into the sum of a Brownian motion part and an independent jump process. We show that conditional independence statements between the marginal processes can be studied separately for these two parts. While the Brownian part is well-understood, we derive a novel characterization of conditional independence between the sample paths of the jump process in terms of the L&apos;evy measure. We define L&apos;evy graphical models as L&apos;evy processes that satisfy undirected or directed Markov properties. We prove that the graph structure is invariant under changes of the univariate marginal processes. L&apos;evy graphical models allow the construction of flexible, sparse dependence models for L&apos;evy processes in large dimensions, which are interpretable thanks to the underlying graph. For trees, we develop statistical methodology to learn the underlying structure from low- or high-frequency observations of the L&apos;evy process and show consistent graph recovery. We apply our method to model stock returns from U.S. companies to illustrate the advantages of our approach.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.19952&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Sebastian Engelke, Jevgenijs Ivanovs, Jakob D. Th{\o}stesen</name></author><category term="stat.ME," /><category term="stat.TH" /><summary type="html">Conditional independence and graphical models are crucial concepts for sparsity and statistical modeling in higher dimensions. For L&apos;evy processes, a widely applied class of stochastic processes, these notions have not been studied. By the L&apos;evy-It\^o decomposition, a multivariate L&apos;evy process can be decomposed into the sum of a Brownian motion part and an independent jump process. We show that conditional independence statements between the marginal processes can be studied separately for these two parts. While the Brownian part is well-understood, we derive a novel characterization of conditional independence between the sample paths of the jump process in terms of the L&apos;evy measure. We define L&apos;evy graphical models as L&apos;evy processes that satisfy undirected or directed Markov properties. We prove that the graph structure is invariant under changes of the univariate marginal processes. L&apos;evy graphical models allow the construction of flexible, sparse dependence models for L&apos;evy processes in large dimensions, which are interpretable thanks to the underlying graph. For trees, we develop statistical methodology to learn the underlying structure from low- or high-frequency observations of the L&apos;evy process and show consistent graph recovery. We apply our method to model stock returns from U.S. companies to illustrate the advantages of our approach.</summary></entry><entry><title type="html">MPCR: Multi- and Mixed-Precision Computations Package in R</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MPCRMultiandMixedPrecisionComputationsPackageinR.html" rel="alternate" type="text/html" title="MPCR: Multi- and Mixed-Precision Computations Package in R" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MPCRMultiandMixedPrecisionComputationsPackageinR</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MPCRMultiandMixedPrecisionComputationsPackageinR.html">&lt;p&gt;Computational statistics has traditionally utilized double-precision (64-bit) data structures and full-precision operations, resulting in higher-than-necessary accuracy for certain applications. Recently, there has been a growing interest in exploring low-precision options that could reduce computational complexity while still achieving the required level of accuracy. This trend has been amplified by new hardware such as NVIDIA’s Tensor Cores in their V100, A100, and H100 GPUs, which are optimized for mixed-precision computations, Intel CPUs with Deep Learning (DL) boost, Google Tensor Processing Units (TPUs), Field Programmable Gate Arrays (FPGAs), ARM CPUs, and others. However, using lower precision may introduce numerical instabilities and accuracy issues. Nevertheless, some applications have shown robustness to low-precision computations, leading to new multi- and mixed-precision algorithms that balance accuracy and computational cost. To address this need, we introduce MPCR, a novel R package that supports three different precision types (16-, 32-, and 64-bit) and their combinations, along with its usage in commonly-used Frequentist/Bayesian statistical examples. The MPCR package is written in C++ and integrated into R through the \pkg{Rcpp} package, enabling highly optimized operations in various precisions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.02701&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Mary Lai O. Salvana, Sameh Abdulah, Minwoo Kim, David Helmy, Ying Sun, Marc G. Genton</name></author><category term="stat.CO" /><summary type="html">Computational statistics has traditionally utilized double-precision (64-bit) data structures and full-precision operations, resulting in higher-than-necessary accuracy for certain applications. Recently, there has been a growing interest in exploring low-precision options that could reduce computational complexity while still achieving the required level of accuracy. This trend has been amplified by new hardware such as NVIDIA’s Tensor Cores in their V100, A100, and H100 GPUs, which are optimized for mixed-precision computations, Intel CPUs with Deep Learning (DL) boost, Google Tensor Processing Units (TPUs), Field Programmable Gate Arrays (FPGAs), ARM CPUs, and others. However, using lower precision may introduce numerical instabilities and accuracy issues. Nevertheless, some applications have shown robustness to low-precision computations, leading to new multi- and mixed-precision algorithms that balance accuracy and computational cost. To address this need, we introduce MPCR, a novel R package that supports three different precision types (16-, 32-, and 64-bit) and their combinations, along with its usage in commonly-used Frequentist/Bayesian statistical examples. The MPCR package is written in C++ and integrated into R through the \pkg{Rcpp} package, enabling highly optimized operations in various precisions.</summary></entry><entry><title type="html">Making all pairwise comparisons in multi-arm clinical trials without control treatment</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Makingallpairwisecomparisonsinmultiarmclinicaltrialswithoutcontroltreatment.html" rel="alternate" type="text/html" title="Making all pairwise comparisons in multi-arm clinical trials without control treatment" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Makingallpairwisecomparisonsinmultiarmclinicaltrialswithoutcontroltreatment</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/Makingallpairwisecomparisonsinmultiarmclinicaltrialswithoutcontroltreatment.html">&lt;p&gt;The standard paradigm for confirmatory clinical trials is to compare experimental treatments with a control, for example the standard of care or a placebo. However, it is not always the case that a suitable control exists. Efficient statistical methodology is well studied in the setting of randomised controlled trials. This is not the case if one wishes to compare several experimental with no control arm. We propose hypothesis testing methods suitable for use in such a setting. These methods are efficient, ensuring the error rate is controlled at exactly the desired rate with no conservatism. This in turn yields an improvement in power when compared with standard methods one might otherwise consider using, such as a Bonferroni adjustment. The proposed testing procedure is also highly flexible. We show how it may be extended for use in multi-stage adaptive trials, covering the majority of scenarios in which one might consider the use of such procedures in the clinical trials setting. With such a highly flexible nature, these methods may also be applied more broadly outside of a clinical trials setting.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20908&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Thomas Burnett, Thomas Jaki</name></author><category term="stat.ME" /><summary type="html">The standard paradigm for confirmatory clinical trials is to compare experimental treatments with a control, for example the standard of care or a placebo. However, it is not always the case that a suitable control exists. Efficient statistical methodology is well studied in the setting of randomised controlled trials. This is not the case if one wishes to compare several experimental with no control arm. We propose hypothesis testing methods suitable for use in such a setting. These methods are efficient, ensuring the error rate is controlled at exactly the desired rate with no conservatism. This in turn yields an improvement in power when compared with standard methods one might otherwise consider using, such as a Bonferroni adjustment. The proposed testing procedure is also highly flexible. We show how it may be extended for use in multi-stage adaptive trials, covering the majority of scenarios in which one might consider the use of such procedures in the clinical trials setting. With such a highly flexible nature, these methods may also be applied more broadly outside of a clinical trials setting.</summary></entry><entry><title type="html">Markovian Flow Matching: Accelerating MCMC with Continuous Normalizing Flows</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MarkovianFlowMatchingAcceleratingMCMCwithContinuousNormalizingFlows.html" rel="alternate" type="text/html" title="Markovian Flow Matching: Accelerating MCMC with Continuous Normalizing Flows" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MarkovianFlowMatchingAcceleratingMCMCwithContinuousNormalizingFlows</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MarkovianFlowMatchingAcceleratingMCMCwithContinuousNormalizingFlows.html">&lt;p&gt;Continuous normalizing flows (CNFs) learn the probability path between a reference distribution and a target distribution by modeling the vector field generating said path using neural networks. Recently, Lipman et al. (2022) introduced a simple and inexpensive method for training CNFs in generative modeling, termed flow matching (FM). In this paper, we repurpose this method for probabilistic inference by incorporating Markovian sampling methods in evaluating the FM objective, and using the learned CNF to improve Monte Carlo sampling. Specifically, we propose an adaptive Markov chain Monte Carlo (MCMC) algorithm, which combines a local Markov transition kernel with a non-local, flow-informed transition kernel, defined using a CNF. This CNF is adapted on-the-fly using samples from the Markov chain, which are used to specify the probability path for the FM objective. Our method also includes an adaptive tempering mechanism that allows the discovery of multiple modes in the target distribution. Under mild assumptions, we establish convergence of our method to a local optimum of the FM objective. We then benchmark our approach on several synthetic and real-world examples, achieving similar performance to other state-of-the-art methods, but often at a significantly lower computational cost.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.14392&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Alberto Cabezas, Louis Sharrock, Christopher Nemeth</name></author><category term="stat.ME," /><category term="stat.ML" /><summary type="html">Continuous normalizing flows (CNFs) learn the probability path between a reference distribution and a target distribution by modeling the vector field generating said path using neural networks. Recently, Lipman et al. (2022) introduced a simple and inexpensive method for training CNFs in generative modeling, termed flow matching (FM). In this paper, we repurpose this method for probabilistic inference by incorporating Markovian sampling methods in evaluating the FM objective, and using the learned CNF to improve Monte Carlo sampling. Specifically, we propose an adaptive Markov chain Monte Carlo (MCMC) algorithm, which combines a local Markov transition kernel with a non-local, flow-informed transition kernel, defined using a CNF. This CNF is adapted on-the-fly using samples from the Markov chain, which are used to specify the probability path for the FM objective. Our method also includes an adaptive tempering mechanism that allows the discovery of multiple modes in the target distribution. Under mild assumptions, we establish convergence of our method to a local optimum of the FM objective. We then benchmark our approach on several synthetic and real-world examples, achieving similar performance to other state-of-the-art methods, but often at a significantly lower computational cost.</summary></entry><entry><title type="html">Matrix Denoising with Doubly Heteroscedastic Noise: Fundamental Limits and Optimal Spectral Methods</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MatrixDenoisingwithDoublyHeteroscedasticNoiseFundamentalLimitsandOptimalSpectralMethods.html" rel="alternate" type="text/html" title="Matrix Denoising with Doubly Heteroscedastic Noise: Fundamental Limits and Optimal Spectral Methods" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MatrixDenoisingwithDoublyHeteroscedasticNoiseFundamentalLimitsandOptimalSpectralMethods</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MatrixDenoisingwithDoublyHeteroscedasticNoiseFundamentalLimitsandOptimalSpectralMethods.html">&lt;p&gt;We study the matrix denoising problem of estimating the singular vectors of a rank-$1$ signal corrupted by noise with both column and row correlations. Existing works are either unable to pinpoint the exact asymptotic estimation error or, when they do so, the resulting approaches (e.g., based on whitening or singular value shrinkage) remain vastly suboptimal. On top of this, most of the literature has focused on the special case of estimating the left singular vector of the signal when the noise only possesses row correlation (one-sided heteroscedasticity). In contrast, our work establishes the information-theoretic and algorithmic limits of matrix denoising with doubly heteroscedastic noise. We characterize the exact asymptotic minimum mean square error, and design a novel spectral estimator with rigorous optimality guarantees: under a technical condition, it attains positive correlation with the signals whenever information-theoretically possible and, for one-sided heteroscedasticity, it also achieves the Bayes-optimal error. Numerical experiments demonstrate the significant advantage of our theoretically principled method with the state of the art. The proofs draw connections with statistical physics and approximate message passing, departing drastically from standard random matrix theory techniques.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.13912&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yihan Zhang, Marco Mondelli</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">We study the matrix denoising problem of estimating the singular vectors of a rank-$1$ signal corrupted by noise with both column and row correlations. Existing works are either unable to pinpoint the exact asymptotic estimation error or, when they do so, the resulting approaches (e.g., based on whitening or singular value shrinkage) remain vastly suboptimal. On top of this, most of the literature has focused on the special case of estimating the left singular vector of the signal when the noise only possesses row correlation (one-sided heteroscedasticity). In contrast, our work establishes the information-theoretic and algorithmic limits of matrix denoising with doubly heteroscedastic noise. We characterize the exact asymptotic minimum mean square error, and design a novel spectral estimator with rigorous optimality guarantees: under a technical condition, it attains positive correlation with the signals whenever information-theoretically possible and, for one-sided heteroscedasticity, it also achieves the Bayes-optimal error. Numerical experiments demonstrate the significant advantage of our theoretically principled method with the state of the art. The proofs draw connections with statistical physics and approximate message passing, departing drastically from standard random matrix theory techniques.</summary></entry><entry><title type="html">Mechanism learning: Reverse causal inference in the presence of multiple unknown confounding through front-door causal bootstrapping</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MechanismlearningReversecausalinferenceinthepresenceofmultipleunknownconfoundingthroughfrontdoorcausalbootstrapping.html" rel="alternate" type="text/html" title="Mechanism learning: Reverse causal inference in the presence of multiple unknown confounding through front-door causal bootstrapping" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MechanismlearningReversecausalinferenceinthepresenceofmultipleunknownconfoundingthroughfrontdoorcausalbootstrapping</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MechanismlearningReversecausalinferenceinthepresenceofmultipleunknownconfoundingthroughfrontdoorcausalbootstrapping.html">&lt;p&gt;A major limitation of machine learning (ML) prediction models is that they recover associational, rather than causal, predictive relationships between variables. In high-stakes automation applications of ML this is problematic, as the model often learns spurious, non-causal associations. This paper proposes mechanism learning, a simple method which uses front-door causal bootstrapping to deconfound observational data such that any appropriate ML model is forced to learn predictive relationships between effects and their causes (reverse causal inference), despite the potential presence of multiple unknown and unmeasured confounding. Effect variables can be very high dimensional, and the predictive relationship nonlinear, as is common in ML applications. This novel method is widely applicable, the only requirement is the existence of a mechanism variable mediating the cause (prediction target) and effect (feature data), which is independent of the (unmeasured) confounding variables. We test our method on fully synthetic, semi-synthetic and real-world datasets, demonstrating that it can discover reliable, unbiased, causal ML predictors where by contrast, the same ML predictor trained naively using classical supervised learning on the original observational data, is heavily biased by spurious associations. We provide code to implement the results in the paper, online.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20057&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jianqiao Mao, Max A. Little</name></author><category term="stat.ML" /><summary type="html">A major limitation of machine learning (ML) prediction models is that they recover associational, rather than causal, predictive relationships between variables. In high-stakes automation applications of ML this is problematic, as the model often learns spurious, non-causal associations. This paper proposes mechanism learning, a simple method which uses front-door causal bootstrapping to deconfound observational data such that any appropriate ML model is forced to learn predictive relationships between effects and their causes (reverse causal inference), despite the potential presence of multiple unknown and unmeasured confounding. Effect variables can be very high dimensional, and the predictive relationship nonlinear, as is common in ML applications. This novel method is widely applicable, the only requirement is the existence of a mechanism variable mediating the cause (prediction target) and effect (feature data), which is independent of the (unmeasured) confounding variables. We test our method on fully synthetic, semi-synthetic and real-world datasets, demonstrating that it can discover reliable, unbiased, causal ML predictors where by contrast, the same ML predictor trained naively using classical supervised learning on the original observational data, is heavily biased by spurious associations. We provide code to implement the results in the paper, online.</summary></entry><entry><title type="html">Median Based Unit Weibull (MBUW): a new unit distribution Properties</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MedianBasedUnitWeibullMBUWanewunitdistributionProperties.html" rel="alternate" type="text/html" title="Median Based Unit Weibull (MBUW): a new unit distribution Properties" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MedianBasedUnitWeibullMBUWanewunitdistributionProperties</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MedianBasedUnitWeibullMBUWanewunitdistributionProperties.html">&lt;p&gt;A new 2 parameter unit Weibull distribution is defined on the unit interval (0,1). The methodology of deducing its PDF, some of its properties and related functions are discussed. The paper is supplied by many figures illustrating the new distribution and how this can make it illegible to fit a wide range of skewed data. The new distribution holds a name (Attia) as a nickname.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.19019&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Iman Mohammed Attia</name></author><category term="stat.ME" /><summary type="html">A new 2 parameter unit Weibull distribution is defined on the unit interval (0,1). The methodology of deducing its PDF, some of its properties and related functions are discussed. The paper is supplied by many figures illustrating the new distribution and how this can make it illegible to fit a wide range of skewed data. The new distribution holds a name (Attia) as a nickname.</summary></entry><entry><title type="html">Modular Duality in Deep Learning</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ModularDualityinDeepLearning.html" rel="alternate" type="text/html" title="Modular Duality in Deep Learning" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ModularDualityinDeepLearning</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ModularDualityinDeepLearning.html">&lt;p&gt;An old idea in optimization theory says that since the gradient is a dual vector it may not be subtracted from the weights without first being mapped to the primal space where the weights reside. We take this idea seriously in this paper and construct such a duality map for general neural networks. Our map, which we call modular dualization, forms a unifying theoretical basis for training algorithms that are a) fast and b) scalable. Modular dualization involves first assigning operator norms to layers based on the semantics of each layer, and then using these layerwise norms to recursively induce a duality map on the weight space of the full neural architecture. We conclude by deriving GPU-friendly algorithms for dualizing Embed, Linear and Conv2D layers – the latter two methods are based on a new rectangular Newton-Schulz iteration that we propose. Our iteration was recently used to set new speed records for training NanoGPT. Overall, we hope that our theory of modular duality will yield a next generation of fast and scalable optimizers for general neural architectures.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21265&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jeremy Bernstein, Laker Newhouse</name></author><category term="stat.ML" /><summary type="html">An old idea in optimization theory says that since the gradient is a dual vector it may not be subtracted from the weights without first being mapped to the primal space where the weights reside. We take this idea seriously in this paper and construct such a duality map for general neural networks. Our map, which we call modular dualization, forms a unifying theoretical basis for training algorithms that are a) fast and b) scalable. Modular dualization involves first assigning operator norms to layers based on the semantics of each layer, and then using these layerwise norms to recursively induce a duality map on the weight space of the full neural architecture. We conclude by deriving GPU-friendly algorithms for dualizing Embed, Linear and Conv2D layers – the latter two methods are based on a new rectangular Newton-Schulz iteration that we propose. Our iteration was recently used to set new speed records for training NanoGPT. Overall, we hope that our theory of modular duality will yield a next generation of fast and scalable optimizers for general neural architectures.</summary></entry><entry><title type="html">Modular Learning of Deep Causal Generative Models for High-dimensional Causal Inference</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ModularLearningofDeepCausalGenerativeModelsforHighdimensionalCausalInference.html" rel="alternate" type="text/html" title="Modular Learning of Deep Causal Generative Models for High-dimensional Causal Inference" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ModularLearningofDeepCausalGenerativeModelsforHighdimensionalCausalInference</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/ModularLearningofDeepCausalGenerativeModelsforHighdimensionalCausalInference.html">&lt;p&gt;Sound and complete algorithms have been proposed to compute identifiable causal queries using the causal structure and data. However, most of these algorithms assume accurate estimation of the data distribution, which is impractical for high-dimensional variables such as images. On the other hand, modern deep generative architectures can be trained to sample from high-dimensional distributions. However, training these networks are typically very costly. Thus, it is desirable to leverage pre-trained models to answer causal queries using such high-dimensional data. To address this, we propose modular training of deep causal generative models that not only makes learning more efficient, but also allows us to utilize large, pre-trained conditional generative models. To the best of our knowledge, our algorithm, Modular-DCM is the first algorithm that, given the causal structure, uses adversarial training to learn the network weights, and can make use of pre-trained models to provably sample from any identifiable causal query in the presence of latent confounders. With extensive experiments on the Colored-MNIST dataset, we demonstrate that our algorithm outperforms the baselines. We also show our algorithm’s convergence on the COVIDx dataset and its utility with a causal invariant prediction problem on CelebA-HQ.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2401.01426&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Md Musfiqur Rahman, Murat Kocaoglu</name></author><category term="stat.ME," /><category term="stat.ML" /><summary type="html">Sound and complete algorithms have been proposed to compute identifiable causal queries using the causal structure and data. However, most of these algorithms assume accurate estimation of the data distribution, which is impractical for high-dimensional variables such as images. On the other hand, modern deep generative architectures can be trained to sample from high-dimensional distributions. However, training these networks are typically very costly. Thus, it is desirable to leverage pre-trained models to answer causal queries using such high-dimensional data. To address this, we propose modular training of deep causal generative models that not only makes learning more efficient, but also allows us to utilize large, pre-trained conditional generative models. To the best of our knowledge, our algorithm, Modular-DCM is the first algorithm that, given the causal structure, uses adversarial training to learn the network weights, and can make use of pre-trained models to provably sample from any identifiable causal query in the presence of latent confounders. With extensive experiments on the Colored-MNIST dataset, we demonstrate that our algorithm outperforms the baselines. We also show our algorithm’s convergence on the COVIDx dataset and its utility with a causal invariant prediction problem on CelebA-HQ.</summary></entry><entry><title type="html">Multiscale Hodge Scattering Networks for Data Analysis</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MultiscaleHodgeScatteringNetworksforDataAnalysis.html" rel="alternate" type="text/html" title="Multiscale Hodge Scattering Networks for Data Analysis" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MultiscaleHodgeScatteringNetworksforDataAnalysis</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/MultiscaleHodgeScatteringNetworksforDataAnalysis.html">&lt;p&gt;We propose new scattering networks for signals measured on simplicial complexes, which we call \emph{Multiscale Hodge Scattering Networks} (MHSNs). Our construction is based on multiscale basis dictionaries on simplicial complexes, i.e., the $\kappa$-GHWT and $\kappa$-HGLET, which we recently developed for simplices of dimension $\kappa \in \mathbb{N}$ in a given simplicial complex by generalizing the node-based Generalized Haar-Walsh Transform (GHWT) and Hierarchical Graph Laplacian Eigen Transform (HGLET). The $\kappa$-GHWT and the $\kappa$-HGLET both form redundant sets (i.e., dictionaries) of multiscale basis vectors and the corresponding expansion coefficients of a given signal. Our MHSNs use a layered structure analogous to a convolutional neural network (CNN) to cascade the moments of the modulus of the dictionary coefficients. The resulting features are invariant to reordering of the simplices (i.e., node permutation of the underlying graphs). Importantly, the use of multiscale basis dictionaries in our MHSNs admits a natural pooling operation that is akin to local pooling in CNNs, and which may be performed either locally or per-scale. These pooling operations are harder to define in both traditional scattering networks based on Morlet wavelets, and geometric scattering networks based on Diffusion Wavelets. As a result, we are able to extract a rich set of descriptive yet robust features that can be used along with very simple machine learning methods (i.e., logistic regression or support vector machines) to achieve high-accuracy classification systems with far fewer parameters to train than most modern graph neural networks. Finally, we demonstrate the usefulness of our MHSNs in three distinct types of problems: signal classification, domain (i.e., graph/simplex) classification, and molecular dynamics prediction.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2311.10270&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Naoki Saito, Stefan C. Schonsheck, Eugene Shvarts</name></author><category term="stat.ML" /><summary type="html">We propose new scattering networks for signals measured on simplicial complexes, which we call \emph{Multiscale Hodge Scattering Networks} (MHSNs). Our construction is based on multiscale basis dictionaries on simplicial complexes, i.e., the $\kappa$-GHWT and $\kappa$-HGLET, which we recently developed for simplices of dimension $\kappa \in \mathbb{N}$ in a given simplicial complex by generalizing the node-based Generalized Haar-Walsh Transform (GHWT) and Hierarchical Graph Laplacian Eigen Transform (HGLET). The $\kappa$-GHWT and the $\kappa$-HGLET both form redundant sets (i.e., dictionaries) of multiscale basis vectors and the corresponding expansion coefficients of a given signal. Our MHSNs use a layered structure analogous to a convolutional neural network (CNN) to cascade the moments of the modulus of the dictionary coefficients. The resulting features are invariant to reordering of the simplices (i.e., node permutation of the underlying graphs). Importantly, the use of multiscale basis dictionaries in our MHSNs admits a natural pooling operation that is akin to local pooling in CNNs, and which may be performed either locally or per-scale. These pooling operations are harder to define in both traditional scattering networks based on Morlet wavelets, and geometric scattering networks based on Diffusion Wavelets. As a result, we are able to extract a rich set of descriptive yet robust features that can be used along with very simple machine learning methods (i.e., logistic regression or support vector machines) to achieve high-accuracy classification systems with far fewer parameters to train than most modern graph neural networks. Finally, we demonstrate the usefulness of our MHSNs in three distinct types of problems: signal classification, domain (i.e., graph/simplex) classification, and molecular dynamics prediction.</summary></entry><entry><title type="html">Near Optimal Pure Exploration in Logistic Bandits</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NearOptimalPureExplorationinLogisticBandits.html" rel="alternate" type="text/html" title="Near Optimal Pure Exploration in Logistic Bandits" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NearOptimalPureExplorationinLogisticBandits</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NearOptimalPureExplorationinLogisticBandits.html">&lt;p&gt;Bandit algorithms have garnered significant attention due to their practical applications in real-world scenarios. However, beyond simple settings such as multi-arm or linear bandits, optimal algorithms remain scarce. Notably, no optimal solution exists for pure exploration problems in the context of generalized linear model (GLM) bandits. In this paper, we narrow this gap and develop the first track-and-stop algorithm for general pure exploration problems under the logistic bandit called logistic track-and-stop (Log-TS). Log-TS is an efficient algorithm that asymptotically matches an approximation for the instance-specific lower bound of the expected sample complexity up to a logarithmic factor.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20640&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Eduardo Ochoa Rivera, Ambuj Tewari</name></author><category term="stat.ML" /><summary type="html">Bandit algorithms have garnered significant attention due to their practical applications in real-world scenarios. However, beyond simple settings such as multi-arm or linear bandits, optimal algorithms remain scarce. Notably, no optimal solution exists for pure exploration problems in the context of generalized linear model (GLM) bandits. In this paper, we narrow this gap and develop the first track-and-stop algorithm for general pure exploration problems under the logistic bandit called logistic track-and-stop (Log-TS). Log-TS is an efficient algorithm that asymptotically matches an approximation for the instance-specific lower bound of the expected sample complexity up to a logarithmic factor.</summary></entry><entry><title type="html">Near-Optimal Streaming Heavy-Tailed Statistical Estimation with Clipped SGD</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NearOptimalStreamingHeavyTailedStatisticalEstimationwithClippedSGD.html" rel="alternate" type="text/html" title="Near-Optimal Streaming Heavy-Tailed Statistical Estimation with Clipped SGD" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NearOptimalStreamingHeavyTailedStatisticalEstimationwithClippedSGD</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NearOptimalStreamingHeavyTailedStatisticalEstimationwithClippedSGD.html">&lt;p&gt;We consider the problem of high-dimensional heavy-tailed statistical estimation in the streaming setting, which is much harder than the traditional batch setting due to memory constraints. We cast this problem as stochastic convex optimization with heavy tailed stochastic gradients, and prove that the widely used Clipped-SGD algorithm attains near-optimal sub-Gaussian statistical rates whenever the second moment of the stochastic gradient noise is finite. More precisely, with $T$ samples, we show that Clipped-SGD, for smooth and strongly convex objectives, achieves an error of $\sqrt{\frac{\mathsf{Tr}(\Sigma)+\sqrt{\mathsf{Tr}(\Sigma)|\Sigma|_2}\log(\frac{\log(T)}{\delta})}{T}}$ with probability $1-\delta$, where $\Sigma$ is the covariance of the clipped gradient. Note that the fluctuations (depending on $\frac{1}{\delta}$) are of lower order than the term $\mathsf{Tr}(\Sigma)$. This improves upon the current best rate of $\sqrt{\frac{\mathsf{Tr}(\Sigma)\log(\frac{1}{\delta})}{T}}$ for Clipped-SGD, known only for smooth and strongly convex objectives. Our results also extend to smooth convex and lipschitz convex objectives. Key to our result is a novel iterative refinement strategy for martingale concentration, improving upon the PAC-Bayes approach of Catoni and Giulini.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20135&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Aniket Das, Dheeraj Nagaraj, Soumyabrata Pal, Arun Suggala, Prateek Varshney</name></author><category term="stat.ML" /><summary type="html">We consider the problem of high-dimensional heavy-tailed statistical estimation in the streaming setting, which is much harder than the traditional batch setting due to memory constraints. We cast this problem as stochastic convex optimization with heavy tailed stochastic gradients, and prove that the widely used Clipped-SGD algorithm attains near-optimal sub-Gaussian statistical rates whenever the second moment of the stochastic gradient noise is finite. More precisely, with $T$ samples, we show that Clipped-SGD, for smooth and strongly convex objectives, achieves an error of $\sqrt{\frac{\mathsf{Tr}(\Sigma)+\sqrt{\mathsf{Tr}(\Sigma)|\Sigma|_2}\log(\frac{\log(T)}{\delta})}{T}}$ with probability $1-\delta$, where $\Sigma$ is the covariance of the clipped gradient. Note that the fluctuations (depending on $\frac{1}{\delta}$) are of lower order than the term $\mathsf{Tr}(\Sigma)$. This improves upon the current best rate of $\sqrt{\frac{\mathsf{Tr}(\Sigma)\log(\frac{1}{\delta})}{T}}$ for Clipped-SGD, known only for smooth and strongly convex objectives. Our results also extend to smooth convex and lipschitz convex objectives. Key to our result is a novel iterative refinement strategy for martingale concentration, improving upon the PAC-Bayes approach of Catoni and Giulini.</summary></entry><entry><title type="html">NeuZip: Memory-Efficient Training and Inference with Dynamic Compression of Neural Networks</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NeuZipMemoryEfficientTrainingandInferencewithDynamicCompressionofNeuralNetworks.html" rel="alternate" type="text/html" title="NeuZip: Memory-Efficient Training and Inference with Dynamic Compression of Neural Networks" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NeuZipMemoryEfficientTrainingandInferencewithDynamicCompressionofNeuralNetworks</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NeuZipMemoryEfficientTrainingandInferencewithDynamicCompressionofNeuralNetworks.html">&lt;p&gt;The performance of neural networks improves when more parameters are used. However, the model sizes are constrained by the available on-device memory during training and inference. Although applying techniques like quantization can alleviate the constraint, they suffer from performance degradation. In this work, we introduce NeuZip, a new weight compression scheme based on the entropy of floating-point numbers in neural networks. With NeuZip, we are able to achieve memory-efficient training and inference without sacrificing performance. Notably, we significantly reduce the memory footprint of training a Llama-3 8B model from 31GB to less than 16GB, while keeping the training dynamics fully unchanged. In inference, our method can reduce memory usage by more than half while maintaining near-lossless performance. Our code is publicly available.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20650&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yongchang Hao, Yanshuai Cao, Lili Mou</name></author><category term="stat.ML" /><summary type="html">The performance of neural networks improves when more parameters are used. However, the model sizes are constrained by the available on-device memory during training and inference. Although applying techniques like quantization can alleviate the constraint, they suffer from performance degradation. In this work, we introduce NeuZip, a new weight compression scheme based on the entropy of floating-point numbers in neural networks. With NeuZip, we are able to achieve memory-efficient training and inference without sacrificing performance. Notably, we significantly reduce the memory footprint of training a Llama-3 8B model from 31GB to less than 16GB, while keeping the training dynamics fully unchanged. In inference, our method can reduce memory usage by more than half while maintaining near-lossless performance. Our code is publicly available.</summary></entry><entry><title type="html">Nonparametric Density Estimation for Data Scattered on Irregular Spatial Domains: A Likelihood-Based Approach Using Bivariate Penalized Spline Smoothing</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NonparametricDensityEstimationforDataScatteredonIrregularSpatialDomainsALikelihoodBasedApproachUsingBivariatePenalizedSplineSmoothing.html" rel="alternate" type="text/html" title="Nonparametric Density Estimation for Data Scattered on Irregular Spatial Domains: A Likelihood-Based Approach Using Bivariate Penalized Spline Smoothing" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NonparametricDensityEstimationforDataScatteredonIrregularSpatialDomainsALikelihoodBasedApproachUsingBivariatePenalizedSplineSmoothing</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NonparametricDensityEstimationforDataScatteredonIrregularSpatialDomainsALikelihoodBasedApproachUsingBivariatePenalizedSplineSmoothing.html">&lt;p&gt;Accurately estimating data density is crucial for making informed decisions and modeling in various fields. This paper presents a novel nonparametric density estimation procedure that utilizes bivariate penalized spline smoothing over triangulation for data scattered over irregular spatial domains. The approach is likelihood-based with a regularization term that addresses the roughness of the logarithm of density based on a second-order differential operator. The proposed method offers greater efficiency and flexibility in estimating density over complex domains and has been theoretically supported by establishing the asymptotic convergence rate under mild natural conditions. Through extensive simulation studies and a real-world application that analyzes motor vehicle theft data from Portland City, Oregon, we demonstrate the advantages of the proposed method over existing techniques detailed in the literature.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2408.16963&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Kunal Das, Shan Yu, Guannan Wang, Li Wang</name></author><category term="stat.ME" /><summary type="html">Accurately estimating data density is crucial for making informed decisions and modeling in various fields. This paper presents a novel nonparametric density estimation procedure that utilizes bivariate penalized spline smoothing over triangulation for data scattered over irregular spatial domains. The approach is likelihood-based with a regularization term that addresses the roughness of the logarithm of density based on a second-order differential operator. The proposed method offers greater efficiency and flexibility in estimating density over complex domains and has been theoretically supported by establishing the asymptotic convergence rate under mild natural conditions. Through extensive simulation studies and a real-world application that analyzes motor vehicle theft data from Portland City, Oregon, we demonstrate the advantages of the proposed method over existing techniques detailed in the literature.</summary></entry><entry><title type="html">Non-stationary Spatio-Temporal Modeling Using the Stochastic Advection-Diffusion Equation</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NonstationarySpatioTemporalModelingUsingtheStochasticAdvectionDiffusionEquation.html" rel="alternate" type="text/html" title="Non-stationary Spatio-Temporal Modeling Using the Stochastic Advection-Diffusion Equation" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NonstationarySpatioTemporalModelingUsingtheStochasticAdvectionDiffusionEquation</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/NonstationarySpatioTemporalModelingUsingtheStochasticAdvectionDiffusionEquation.html">&lt;p&gt;We construct flexible spatio-temporal models through stochastic partial differential equations (SPDEs) where both diffusion and advection can be spatially varying. Computations are done through a Gaussian Markov random field approximation of the solution of the SPDE, which is constructed through a finite volume method. The new flexible non-separable model is compared to a flexible separable model both for reconstruction and forecasting, and evaluated in terms of root mean square errors and continuous rank probability scores. A simulation study demonstrates that the non-separable model performs better when the data is simulated from a non-separable model with diffusion and advection. Further, we estimate surrogate models for emulating the output of a ocean model in Trondheimsfjorden, Norway, and simulate observations of autonomous underwater vehicles. The results show that the flexible non-separable model outperforms the flexible separable model for real-time prediction of unobserved locations.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.03400&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Martin Outzen Berild, Geir-Arne Fuglstad</name></author><category term="stat.ME" /><summary type="html">We construct flexible spatio-temporal models through stochastic partial differential equations (SPDEs) where both diffusion and advection can be spatially varying. Computations are done through a Gaussian Markov random field approximation of the solution of the SPDE, which is constructed through a finite volume method. The new flexible non-separable model is compared to a flexible separable model both for reconstruction and forecasting, and evaluated in terms of root mean square errors and continuous rank probability scores. A simulation study demonstrates that the non-separable model performs better when the data is simulated from a non-separable model with diffusion and advection. Further, we estimate surrogate models for emulating the output of a ocean model in Trondheimsfjorden, Norway, and simulate observations of autonomous underwater vehicles. The results show that the flexible non-separable model outperforms the flexible separable model for real-time prediction of unobserved locations.</summary></entry><entry><title type="html">On Linear Convergence of PI Consensus Algorithm under the Restricted Secant Inequality</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/OnLinearConvergenceofPIConsensusAlgorithmundertheRestrictedSecantInequality.html" rel="alternate" type="text/html" title="On Linear Convergence of PI Consensus Algorithm under the Restricted Secant Inequality" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/OnLinearConvergenceofPIConsensusAlgorithmundertheRestrictedSecantInequality</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/OnLinearConvergenceofPIConsensusAlgorithmundertheRestrictedSecantInequality.html">&lt;p&gt;This paper considers solving distributed optimization problems in peer-to-peer multi-agent networks. The network is synchronous and connected. By using the proportional-integral (PI) control strategy, various algorithms with fixed stepsize have been developed. Two notable among them are the PI algorithm and the PI consensus algorithm. Although the PI algorithm has provable linear or exponential convergence without the standard requirement of (strong) convexity, a similar guarantee for the PI consensus algorithm is unavailable. In this paper, using Lyapunov theory, we guarantee exponential convergence of the PI consensus algorithm for global cost functions that satisfy the restricted secant inequality, with rate-matching discretization, without requiring convexity. To accelerate the PI consensus algorithm, we incorporate local pre-conditioning in the form of constant positive definite matrices and numerically validate its efficiency compared to the prominent distributed convex optimization algorithms. Unlike classical pre-conditioning, where only the gradients are multiplied by a pre-conditioner, the proposed pre-conditioning modifies both the gradients and the consensus terms, thereby controlling the effect of the communication graph on the algorithm.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2310.00419&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Kushal Chakrabarti, Mayank Baranwal</name></author><category term="stat.ML" /><summary type="html">This paper considers solving distributed optimization problems in peer-to-peer multi-agent networks. The network is synchronous and connected. By using the proportional-integral (PI) control strategy, various algorithms with fixed stepsize have been developed. Two notable among them are the PI algorithm and the PI consensus algorithm. Although the PI algorithm has provable linear or exponential convergence without the standard requirement of (strong) convexity, a similar guarantee for the PI consensus algorithm is unavailable. In this paper, using Lyapunov theory, we guarantee exponential convergence of the PI consensus algorithm for global cost functions that satisfy the restricted secant inequality, with rate-matching discretization, without requiring convexity. To accelerate the PI consensus algorithm, we incorporate local pre-conditioning in the form of constant positive definite matrices and numerically validate its efficiency compared to the prominent distributed convex optimization algorithms. Unlike classical pre-conditioning, where only the gradients are multiplied by a pre-conditioner, the proposed pre-conditioning modifies both the gradients and the consensus terms, thereby controlling the effect of the communication graph on the algorithm.</summary></entry><entry><title type="html">On Mesa-Optimization in Autoregressively Trained Transformers: Emergence and Capability</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/OnMesaOptimizationinAutoregressivelyTrainedTransformersEmergenceandCapability.html" rel="alternate" type="text/html" title="On Mesa-Optimization in Autoregressively Trained Transformers: Emergence and Capability" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/OnMesaOptimizationinAutoregressivelyTrainedTransformersEmergenceandCapability</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/OnMesaOptimizationinAutoregressivelyTrainedTransformersEmergenceandCapability.html">&lt;p&gt;Autoregressively trained transformers have brought a profound revolution to the world, especially with their in-context learning (ICL) ability to address downstream tasks. Recently, several studies suggest that transformers learn a mesa-optimizer during autoregressive (AR) pretraining to implement ICL. Namely, the forward pass of the trained transformer is equivalent to optimizing an inner objective function in-context. However, whether the practical non-convex training dynamics will converge to the ideal mesa-optimizer is still unclear. Towards filling this gap, we investigate the non-convex dynamics of a one-layer linear causal self-attention model autoregressively trained by gradient flow, where the sequences are generated by an AR process $x_{t+1} = W x_t$. First, under a certain condition of data distribution, we prove that an autoregressively trained transformer learns $W$ by implementing one step of gradient descent to minimize an ordinary least squares (OLS) problem in-context. It then applies the learned $\widehat{W}$ for next-token prediction, thereby verifying the mesa-optimization hypothesis. Next, under the same data conditions, we explore the capability limitations of the obtained mesa-optimizer. We show that a stronger assumption related to the moments of data is the sufficient and necessary condition that the learned mesa-optimizer recovers the distribution. Besides, we conduct exploratory analyses beyond the first data condition and prove that generally, the trained transformer will not perform vanilla gradient descent for the OLS problem. Finally, our simulation results verify the theoretical results.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.16845&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Chenyu Zheng, Wei Huang, Rongzhen Wang, Guoqiang Wu, Jun Zhu, Chongxuan Li</name></author><category term="stat.ML" /><summary type="html">Autoregressively trained transformers have brought a profound revolution to the world, especially with their in-context learning (ICL) ability to address downstream tasks. Recently, several studies suggest that transformers learn a mesa-optimizer during autoregressive (AR) pretraining to implement ICL. Namely, the forward pass of the trained transformer is equivalent to optimizing an inner objective function in-context. However, whether the practical non-convex training dynamics will converge to the ideal mesa-optimizer is still unclear. Towards filling this gap, we investigate the non-convex dynamics of a one-layer linear causal self-attention model autoregressively trained by gradient flow, where the sequences are generated by an AR process $x_{t+1} = W x_t$. First, under a certain condition of data distribution, we prove that an autoregressively trained transformer learns $W$ by implementing one step of gradient descent to minimize an ordinary least squares (OLS) problem in-context. It then applies the learned $\widehat{W}$ for next-token prediction, thereby verifying the mesa-optimization hypothesis. Next, under the same data conditions, we explore the capability limitations of the obtained mesa-optimizer. We show that a stronger assumption related to the moments of data is the sufficient and necessary condition that the learned mesa-optimizer recovers the distribution. Besides, we conduct exploratory analyses beyond the first data condition and prove that generally, the trained transformer will not perform vanilla gradient descent for the OLS problem. Finally, our simulation results verify the theoretical results.</summary></entry><entry><title type="html">On Probabilistic Pullback Metrics on Latent Hyperbolic Manifolds</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/OnProbabilisticPullbackMetricsonLatentHyperbolicManifolds.html" rel="alternate" type="text/html" title="On Probabilistic Pullback Metrics on Latent Hyperbolic Manifolds" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/OnProbabilisticPullbackMetricsonLatentHyperbolicManifolds</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/OnProbabilisticPullbackMetricsonLatentHyperbolicManifolds.html">&lt;p&gt;Gaussian Process Latent Variable Models (GPLVMs) have proven effective in capturing complex, high-dimensional data through lower-dimensional representations. Recent advances show that using Riemannian manifolds as latent spaces provides more flexibility to learn higher quality embeddings. This paper focuses on the hyperbolic manifold, a particularly suitable choice for modeling hierarchical relationships. While previous approaches relied on hyperbolic geodesics for interpolating the latent space, this often results in paths crossing low-data regions, leading to highly uncertain predictions. Instead, we propose augmenting the hyperbolic metric with a pullback metric to account for distortions introduced by the GPLVM’s nonlinear mapping. Through various experiments, we demonstrate that geodesics on the pullback metric not only respect the geometry of the hyperbolic latent space but also align with the underlying data distribution, significantly reducing uncertainty in predictions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20850&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Luis Augenstein, Noémie Jaquier, Tamim Asfour, Leonel Rozo</name></author><category term="stat.ML" /><summary type="html">Gaussian Process Latent Variable Models (GPLVMs) have proven effective in capturing complex, high-dimensional data through lower-dimensional representations. Recent advances show that using Riemannian manifolds as latent spaces provides more flexibility to learn higher quality embeddings. This paper focuses on the hyperbolic manifold, a particularly suitable choice for modeling hierarchical relationships. While previous approaches relied on hyperbolic geodesics for interpolating the latent space, this often results in paths crossing low-data regions, leading to highly uncertain predictions. Instead, we propose augmenting the hyperbolic metric with a pullback metric to account for distortions introduced by the GPLVM’s nonlinear mapping. Through various experiments, we demonstrate that geodesics on the pullback metric not only respect the geometry of the hyperbolic latent space but also align with the underlying data distribution, significantly reducing uncertainty in predictions.</summary></entry><entry><title type="html">On Spatio-Temporal Stochastic Frontier Models</title><link href="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/OnSpatioTemporalStochasticFrontierModels.html" rel="alternate" type="text/html" title="On Spatio-Temporal Stochastic Frontier Models" /><published>2024-10-29T00:00:00+00:00</published><updated>2024-10-29T00:00:00+00:00</updated><id>https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/OnSpatioTemporalStochasticFrontierModels</id><content type="html" xml:base="https://emanuelealiverti.github.io/arxiv_rss/2024/10/29/OnSpatioTemporalStochasticFrontierModels.html">&lt;p&gt;In the literature on stochastic frontier models until the early 2000s, the joint consideration of spatial and temporal dimensions was often inadequately addressed, if not completely neglected. However, from an evolutionary economics perspective, the production process of the decision-making units constantly changes over both dimensions: it is not stable over time due to managerial enhancements and/or internal or external shocks, and is influenced by the nearest territorial neighbours. This paper proposes an extension of the Fusco and Vidoli [2013] SEM-like approach, which globally accounts for spatial and temporal effects in the term of inefficiency. In particular, coherently with the stochastic panel frontier literature, two different versions of the model are proposed: the time-invariant and the time-varying spatial stochastic frontier models. In order to evaluate the inferential properties of the proposed estimators, we first run Monte Carlo experiments and we then present the results of an application to a set of commonly referenced data, demonstrating robustness and stability of estimates across all scenarios.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.20915&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Elisa Fusco, Giuseppe Arbia, Francesco Vidoli, Vincenzo Nardelli</name></author><category term="stat.ME," /><category term="stat.AP" /><summary type="html">In the literature on stochastic frontier models until the early 2000s, the joint consideration of spatial and temporal dimensions was often inadequately addressed, if not completely neglected. However, from an evolutionary economics perspective, the production process of the decision-making units constantly changes over both dimensions: it is not stable over time due to managerial enhancements and/or internal or external shocks, and is influenced by the nearest territorial neighbours. This paper proposes an extension of the Fusco and Vidoli [2013] SEM-like approach, which globally accounts for spatial and temporal effects in the term of inefficiency. In particular, coherently with the stochastic panel frontier literature, two different versions of the model are proposed: the time-invariant and the time-varying spatial stochastic frontier models. In order to evaluate the inferential properties of the proposed estimators, we first run Monte Carlo experiments and we then present the results of an application to a set of commonly referenced data, demonstrating robustness and stability of estimates across all scenarios.</summary></entry></feed>