<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="https://dedzago.github.io/arxiv_rss/feed.xml" rel="self" type="application/atom+xml" /><link href="https://dedzago.github.io/arxiv_rss/" rel="alternate" type="text/html" /><updated>2024-11-01T07:14:22+00:00</updated><id>https://dedzago.github.io/arxiv_rss/feed.xml</id><title type="html">Stat Arxiv of Today</title><subtitle></subtitle><author><name>Daniele Zago</name></author><entry><title type="html">A Martingale-Free Introduction to Conditional Gaussian Nonlinear Systems</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/AMartingaleFreeIntroductiontoConditionalGaussianNonlinearSystems.html" rel="alternate" type="text/html" title="A Martingale-Free Introduction to Conditional Gaussian Nonlinear Systems" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/AMartingaleFreeIntroductiontoConditionalGaussianNonlinearSystems</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/AMartingaleFreeIntroductiontoConditionalGaussianNonlinearSystems.html">&lt;p&gt;The Conditional Gaussian Nonlinear System (CGNS) is a broad class of nonlinear stochastic dynamical systems. Given the trajectories for a subset of state variables, the remaining follow a Gaussian distribution. Despite the conditionally linear structure, the CGNS exhibits strong nonlinearity, thus capturing many non-Gaussian characteristics observed in nature through its joint and marginal distributions. Desirably, it enjoys closed analytic formulae for the time evolution of its conditional Gaussian statistics, which facilitate the study of data assimilation and other related topics. In this paper, we develop a martingale-free approach to improve the understanding of CGNSs. This methodology provides a tractable approach to proving the time evolution of the conditional statistics by deriving results through time discretization schemes, with the continuous-time regime obtained via a formal limiting process as the discretization time-step vanishes. This discretized approach further allows for developing analytic formulae for optimal posterior sampling of unobserved state variables with correlated noise. These tools are particularly valuable for studying extreme events and intermittency and apply to high-dimensional systems. Moreover, the approach improves the understanding of different sampling methods in characterizing uncertainty. The effectiveness of the framework is demonstrated through a physics-constrained, triad-interaction climate model with cubic nonlinearity and state-dependent cross-interacting noise.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24056&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Marios Andreou, Nan Chen</name></author><category term="stat.ME" /><summary type="html">The Conditional Gaussian Nonlinear System (CGNS) is a broad class of nonlinear stochastic dynamical systems. Given the trajectories for a subset of state variables, the remaining follow a Gaussian distribution. Despite the conditionally linear structure, the CGNS exhibits strong nonlinearity, thus capturing many non-Gaussian characteristics observed in nature through its joint and marginal distributions. Desirably, it enjoys closed analytic formulae for the time evolution of its conditional Gaussian statistics, which facilitate the study of data assimilation and other related topics. In this paper, we develop a martingale-free approach to improve the understanding of CGNSs. This methodology provides a tractable approach to proving the time evolution of the conditional statistics by deriving results through time discretization schemes, with the continuous-time regime obtained via a formal limiting process as the discretization time-step vanishes. This discretized approach further allows for developing analytic formulae for optimal posterior sampling of unobserved state variables with correlated noise. These tools are particularly valuable for studying extreme events and intermittency and apply to high-dimensional systems. Moreover, the approach improves the understanding of different sampling methods in characterizing uncertainty. The effectiveness of the framework is demonstrated through a physics-constrained, triad-interaction climate model with cubic nonlinearity and state-dependent cross-interacting noise.</summary></entry><entry><title type="html">A Unified Confidence Sequence for Generalized Linear Models, with Applications to Bandits</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/AUnifiedConfidenceSequenceforGeneralizedLinearModelswithApplicationstoBandits.html" rel="alternate" type="text/html" title="A Unified Confidence Sequence for Generalized Linear Models, with Applications to Bandits" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/AUnifiedConfidenceSequenceforGeneralizedLinearModelswithApplicationstoBandits</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/AUnifiedConfidenceSequenceforGeneralizedLinearModelswithApplicationstoBandits.html">&lt;p&gt;We present a unified likelihood ratio-based confidence sequence (CS) for any (self-concordant) generalized linear model (GLM) that is guaranteed to be convex and numerically tight. We show that this is on par or improves upon known CSs for various GLMs, including Gaussian, Bernoulli, and Poisson. In particular, for the first time, our CS for Bernoulli has a $\mathrm{poly}(S)$-free radius where $S$ is the norm of the unknown parameter. Our first technical novelty is its derivation, which utilizes a time-uniform PAC-Bayesian bound with a uniform prior/posterior, despite the latter being a rather unpopular choice for deriving CSs. As a direct application of our new CS, we propose a simple and natural optimistic algorithm called OFUGLB, applicable to any generalized linear bandits (GLB; Filippi et al. (2010)). Our analysis shows that the celebrated optimistic approach simultaneously attains state-of-the-art regrets for various self-concordant (not necessarily bounded) GLBs, and even $\mathrm{poly}(S)$-free for bounded GLBs, including logistic bandits. The regret analysis, our second technical novelty, follows from combining our new CS with a new proof technique that completely avoids the previously widely used self-concordant control lemma (Faury et al., 2020, Lemma 9). Numerically, OFUGLB outperforms or is at par with prior algorithms for logistic bandits.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2407.13977&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Junghyun Lee, Se-Young Yun, Kwang-Sung Jun</name></author><category term="stat.ML" /><summary type="html">We present a unified likelihood ratio-based confidence sequence (CS) for any (self-concordant) generalized linear model (GLM) that is guaranteed to be convex and numerically tight. We show that this is on par or improves upon known CSs for various GLMs, including Gaussian, Bernoulli, and Poisson. In particular, for the first time, our CS for Bernoulli has a $\mathrm{poly}(S)$-free radius where $S$ is the norm of the unknown parameter. Our first technical novelty is its derivation, which utilizes a time-uniform PAC-Bayesian bound with a uniform prior/posterior, despite the latter being a rather unpopular choice for deriving CSs. As a direct application of our new CS, we propose a simple and natural optimistic algorithm called OFUGLB, applicable to any generalized linear bandits (GLB; Filippi et al. (2010)). Our analysis shows that the celebrated optimistic approach simultaneously attains state-of-the-art regrets for various self-concordant (not necessarily bounded) GLBs, and even $\mathrm{poly}(S)$-free for bounded GLBs, including logistic bandits. The regret analysis, our second technical novelty, follows from combining our new CS with a new proof technique that completely avoids the previously widely used self-concordant control lemma (Faury et al., 2020, Lemma 9). Numerically, OFUGLB outperforms or is at par with prior algorithms for logistic bandits.</summary></entry><entry><title type="html">A Visual Case Study of the Training Dynamics in Neural Networks</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/AVisualCaseStudyoftheTrainingDynamicsinNeuralNetworks.html" rel="alternate" type="text/html" title="A Visual Case Study of the Training Dynamics in Neural Networks" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/AVisualCaseStudyoftheTrainingDynamicsinNeuralNetworks</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/AVisualCaseStudyoftheTrainingDynamicsinNeuralNetworks.html">&lt;p&gt;This paper introduces a visual sandbox designed to explore the training dynamics of a small-scale transformer model, with the embedding dimension constrained to $d=2$. This restriction allows for a comprehensive two-dimensional visualization of each layer’s dynamics. Through this approach, we gain insights into training dynamics, circuit transferability, and the causes of loss spikes, including those induced by the high curvature of normalization layers. We propose strategies to mitigate these spikes, demonstrating how good visualization facilitates the design of innovative ideas of practical interest. Additionally, we believe our sandbox could assist theoreticians in assessing essential training dynamics mechanisms and integrating them into future theories. The code is available at https://github.com/facebookresearch/pal.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24050&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ambroise Odonnat, Wassim Bouaziz, Vivien Cabannes</name></author><category term="stat.ML" /><summary type="html">This paper introduces a visual sandbox designed to explore the training dynamics of a small-scale transformer model, with the embedding dimension constrained to $d=2$. This restriction allows for a comprehensive two-dimensional visualization of each layer’s dynamics. Through this approach, we gain insights into training dynamics, circuit transferability, and the causes of loss spikes, including those induced by the high curvature of normalization layers. We propose strategies to mitigate these spikes, demonstrating how good visualization facilitates the design of innovative ideas of practical interest. Additionally, we believe our sandbox could assist theoreticians in assessing essential training dynamics mechanisms and integrating them into future theories. The code is available at https://github.com/facebookresearch/pal.</summary></entry><entry><title type="html">Active, anytime-valid risk controlling prediction sets</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Activeanytimevalidriskcontrollingpredictionsets.html" rel="alternate" type="text/html" title="Active, anytime-valid risk controlling prediction sets" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Activeanytimevalidriskcontrollingpredictionsets</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Activeanytimevalidriskcontrollingpredictionsets.html">&lt;p&gt;Rigorously establishing the safety of black-box machine learning models concerning critical risk measures is important for providing guarantees about model behavior. Recently, Bates et. al. (JACM ‘24) introduced the notion of a risk controlling prediction set (RCPS) for producing prediction sets that are statistically guaranteed low risk from machine learning models. Our method extends this notion to the sequential setting, where we provide guarantees even when the data is collected adaptively, and ensures that the risk guarantee is anytime-valid, i.e., simultaneously holds at all time steps. Further, we propose a framework for constructing RCPSes for active labeling, i.e., allowing one to use a labeling policy that chooses whether to query the true label for each received data point and ensures that the expected proportion of data points whose labels are queried are below a predetermined label budget. We also describe how to use predictors (i.e., the machine learning model for which we provide risk control guarantees) to further improve the utility of our RCPSes by estimating the expected risk conditioned on the covariates. We characterize the optimal choices of label policy and predictor under a fixed label budget and show a regret result that relates the estimation error of the optimal labeling policy and predictor to the wealth process that underlies our RCPSes. Lastly, we present practical ways of formulating label policies and empirically show that our label policies use fewer labels to reach higher utility than naive baseline labeling strategies on both simulations and real data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.10490&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ziyu Xu, Nikos Karampatziakis, Paul Mineiro</name></author><category term="stat.ML" /><summary type="html">Rigorously establishing the safety of black-box machine learning models concerning critical risk measures is important for providing guarantees about model behavior. Recently, Bates et. al. (JACM ‘24) introduced the notion of a risk controlling prediction set (RCPS) for producing prediction sets that are statistically guaranteed low risk from machine learning models. Our method extends this notion to the sequential setting, where we provide guarantees even when the data is collected adaptively, and ensures that the risk guarantee is anytime-valid, i.e., simultaneously holds at all time steps. Further, we propose a framework for constructing RCPSes for active labeling, i.e., allowing one to use a labeling policy that chooses whether to query the true label for each received data point and ensures that the expected proportion of data points whose labels are queried are below a predetermined label budget. We also describe how to use predictors (i.e., the machine learning model for which we provide risk control guarantees) to further improve the utility of our RCPSes by estimating the expected risk conditioned on the covariates. We characterize the optimal choices of label policy and predictor under a fixed label budget and show a regret result that relates the estimation error of the optimal labeling policy and predictor to the wealth process that underlies our RCPSes. Lastly, we present practical ways of formulating label policies and empirically show that our label policies use fewer labels to reach higher utility than naive baseline labeling strategies on both simulations and real data.</summary></entry><entry><title type="html">Adaptive Sphericity Tests for High Dimensional Data</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/AdaptiveSphericityTestsforHighDimensionalData.html" rel="alternate" type="text/html" title="Adaptive Sphericity Tests for High Dimensional Data" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/AdaptiveSphericityTestsforHighDimensionalData</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/AdaptiveSphericityTestsforHighDimensionalData.html">&lt;p&gt;In this paper, we investigate sphericity testing in high-dimensional settings, where existing methods primarily rely on sum-type test procedures that often underperform under sparse alternatives. To address this limitation, we propose two max-type test procedures utilizing the sample covariance matrix and the sample spatial-sign covariance matrix, respectively. Furthermore, we introduce two Cauchy combination test procedures that integrate both sum-type and max-type tests, demonstrating their superiority across a wide range of sparsity levels in the alternative hypothesis. Our simulation studies corroborate these findings, highlighting the enhanced performance of our proposed methodologies in high-dimensional sphericity testi&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24094&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ping Zhao, Wenwan Yang, Long Feng, Zhaojun Wang</name></author><category term="stat.ME" /><summary type="html">In this paper, we investigate sphericity testing in high-dimensional settings, where existing methods primarily rely on sum-type test procedures that often underperform under sparse alternatives. To address this limitation, we propose two max-type test procedures utilizing the sample covariance matrix and the sample spatial-sign covariance matrix, respectively. Furthermore, we introduce two Cauchy combination test procedures that integrate both sum-type and max-type tests, demonstrating their superiority across a wide range of sparsity levels in the alternative hypothesis. Our simulation studies corroborate these findings, highlighting the enhanced performance of our proposed methodologies in high-dimensional sphericity testi</summary></entry><entry><title type="html">All or None: Identifiable Linear Properties of Next-token Predictors in Language Modeling</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/AllorNoneIdentifiableLinearPropertiesofNexttokenPredictorsinLanguageModeling.html" rel="alternate" type="text/html" title="All or None: Identifiable Linear Properties of Next-token Predictors in Language Modeling" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/AllorNoneIdentifiableLinearPropertiesofNexttokenPredictorsinLanguageModeling</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/AllorNoneIdentifiableLinearPropertiesofNexttokenPredictorsinLanguageModeling.html">&lt;p&gt;We analyze identifiability as a possible explanation for the ubiquity of linear properties across language models, such as the vector difference between the representations of “easy” and “easiest” being parallel to that between “lucky” and “luckiest”. For this, we ask whether finding a linear property in one model implies that any model that induces the same distribution has that property, too. To answer that, we first prove an identifiability result to characterize distribution-equivalent next-token predictors, lifting a diversity requirement of previous results. Second, based on a refinement of relational linearity [Paccanaro and Hinton, 2001; Hernandez et al., 2024], we show how many notions of linearity are amenable to our analysis. Finally, we show that under suitable conditions, these linear properties either hold in all or none distribution-equivalent next-token predictors.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23501&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Emanuele Marconato, Sébastien Lachapelle, Sebastian Weichwald, Luigi Gresele</name></author><category term="stat.ML" /><summary type="html">We analyze identifiability as a possible explanation for the ubiquity of linear properties across language models, such as the vector difference between the representations of “easy” and “easiest” being parallel to that between “lucky” and “luckiest”. For this, we ask whether finding a linear property in one model implies that any model that induces the same distribution has that property, too. To answer that, we first prove an identifiability result to characterize distribution-equivalent next-token predictors, lifting a diversity requirement of previous results. Second, based on a refinement of relational linearity [Paccanaro and Hinton, 2001; Hernandez et al., 2024], we show how many notions of linearity are amenable to our analysis. Finally, we show that under suitable conditions, these linear properties either hold in all or none distribution-equivalent next-token predictors.</summary></entry><entry><title type="html">Annealed Multiple Choice Learning: Overcoming limitations of Winner-takes-all with annealing</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/AnnealedMultipleChoiceLearningOvercominglimitationsofWinnertakesallwithannealing.html" rel="alternate" type="text/html" title="Annealed Multiple Choice Learning: Overcoming limitations of Winner-takes-all with annealing" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/AnnealedMultipleChoiceLearningOvercominglimitationsofWinnertakesallwithannealing</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/AnnealedMultipleChoiceLearningOvercominglimitationsofWinnertakesallwithannealing.html">&lt;p&gt;We introduce Annealed Multiple Choice Learning (aMCL) which combines simulated annealing with MCL. MCL is a learning framework handling ambiguous tasks by predicting a small set of plausible hypotheses. These hypotheses are trained using the Winner-takes-all (WTA) scheme, which promotes the diversity of the predictions. However, this scheme may converge toward an arbitrarily suboptimal local minimum, due to the greedy nature of WTA. We overcome this limitation using annealing, which enhances the exploration of the hypothesis space during training. We leverage insights from statistical physics and information theory to provide a detailed description of the model training trajectory. Additionally, we validate our algorithm by extensive experiments on synthetic datasets, on the standard UCI benchmark, and on speech separation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2407.15580&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>David Perera, Victor Letzelter, Théo Mariotte, Adrien Cortés, Mickael Chen, Slim Essid, Gaël Richard</name></author><category term="stat.ML" /><summary type="html">We introduce Annealed Multiple Choice Learning (aMCL) which combines simulated annealing with MCL. MCL is a learning framework handling ambiguous tasks by predicting a small set of plausible hypotheses. These hypotheses are trained using the Winner-takes-all (WTA) scheme, which promotes the diversity of the predictions. However, this scheme may converge toward an arbitrarily suboptimal local minimum, due to the greedy nature of WTA. We overcome this limitation using annealing, which enhances the exploration of the hypothesis space during training. We leverage insights from statistical physics and information theory to provide a detailed description of the model training trajectory. Additionally, we validate our algorithm by extensive experiments on synthetic datasets, on the standard UCI benchmark, and on speech separation.</summary></entry><entry><title type="html">Approximate Bayesian Computation with Statistical Distances for Model Selection</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/ApproximateBayesianComputationwithStatisticalDistancesforModelSelection.html" rel="alternate" type="text/html" title="Approximate Bayesian Computation with Statistical Distances for Model Selection" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/ApproximateBayesianComputationwithStatisticalDistancesforModelSelection</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/ApproximateBayesianComputationwithStatisticalDistancesforModelSelection.html">&lt;p&gt;Model selection is a key task in statistics, playing a critical role across various scientific disciplines. While no model can fully capture the complexities of a real-world data-generating process, identifying the model that best approximates it can provide valuable insights. Bayesian statistics offers a flexible framework for model selection by updating prior beliefs as new data becomes available, allowing for ongoing refinement of candidate models. This is typically achieved by calculating posterior probabilities, which quantify the support for each model given the observed data. However, in cases where likelihood functions are intractable, exact computation of these posterior probabilities becomes infeasible. Approximate Bayesian Computation (ABC) has emerged as a likelihood-free method and it is traditionally used with summary statistics to reduce data dimensionality, however this often results in information loss difficult to quantify, particularly in model selection contexts. Recent advancements propose the use of full data approaches based on statistical distances, offering a promising alternative that bypasses the need for summary statistics and potentially allows recovery of the exact posterior distribution. Despite these developments, full data ABC approaches have not yet been widely applied to model selection problems. This paper seeks to address this gap by investigating the performance of ABC with statistical distances in model selection. Through simulation studies and an application to toad movement models, this work explores whether full data approaches can overcome the limitations of summary statistic-based ABC for model choice.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21603&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Christian Angelopoulos, Clara Grazian</name></author><category term="stat.ME," /><category term="stat.CO" /><summary type="html">Model selection is a key task in statistics, playing a critical role across various scientific disciplines. While no model can fully capture the complexities of a real-world data-generating process, identifying the model that best approximates it can provide valuable insights. Bayesian statistics offers a flexible framework for model selection by updating prior beliefs as new data becomes available, allowing for ongoing refinement of candidate models. This is typically achieved by calculating posterior probabilities, which quantify the support for each model given the observed data. However, in cases where likelihood functions are intractable, exact computation of these posterior probabilities becomes infeasible. Approximate Bayesian Computation (ABC) has emerged as a likelihood-free method and it is traditionally used with summary statistics to reduce data dimensionality, however this often results in information loss difficult to quantify, particularly in model selection contexts. Recent advancements propose the use of full data approaches based on statistical distances, offering a promising alternative that bypasses the need for summary statistics and potentially allows recovery of the exact posterior distribution. Despite these developments, full data ABC approaches have not yet been widely applied to model selection problems. This paper seeks to address this gap by investigating the performance of ABC with statistical distances in model selection. Through simulation studies and an application to toad movement models, this work explores whether full data approaches can overcome the limitations of summary statistic-based ABC for model choice.</summary></entry><entry><title type="html">Asynchronous Jump Testing and Estimation in High Dimensions Under Complex Temporal Dynamics</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/AsynchronousJumpTestingandEstimationinHighDimensionsUnderComplexTemporalDynamics.html" rel="alternate" type="text/html" title="Asynchronous Jump Testing and Estimation in High Dimensions Under Complex Temporal Dynamics" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/AsynchronousJumpTestingandEstimationinHighDimensionsUnderComplexTemporalDynamics</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/AsynchronousJumpTestingandEstimationinHighDimensionsUnderComplexTemporalDynamics.html">&lt;p&gt;Most high dimensional changepoint detection methods assume the error process is stationary and changepoints occur synchronously across dimensions. The violation of these assumptions, which in applied settings is increasingly likely as the dimensionality of the time series being analyzed grows, can dramatically curtail the sensitivity or the accuracy of these methods. We propose AJDN (Asynchronous Jump Detection under Nonstationary noise). AJDN is a high dimensional multiscale jump detection method that tests and estimates jumps in an otherwise smoothly varying mean function for high dimensional time series with nonstationary noise where the jumps across dimensions may not occur at the same time. AJDN is correct in the sense that it detects the correct number of jumps with a prescribed probability asymptotically and its accuracy in estimating the locations of the jumps is asymptotically nearly optimal under the asynchronous jump assumption. Through a simulation study we demonstrate AJDN’s robustness across a wide variety of stationary and nonstationary high dimensional time series, and we show its strong performance relative to some existing high dimensional changepoint detection methods. We apply AJDN to a seismic time series to demonstrate its ability to accurately detect jumps in real-world high dimensional time series with complex temporal dynamics.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23706&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Weichi Wu, David Veitch, Zhou Zhou</name></author><category term="stat.ME" /><summary type="html">Most high dimensional changepoint detection methods assume the error process is stationary and changepoints occur synchronously across dimensions. The violation of these assumptions, which in applied settings is increasingly likely as the dimensionality of the time series being analyzed grows, can dramatically curtail the sensitivity or the accuracy of these methods. We propose AJDN (Asynchronous Jump Detection under Nonstationary noise). AJDN is a high dimensional multiscale jump detection method that tests and estimates jumps in an otherwise smoothly varying mean function for high dimensional time series with nonstationary noise where the jumps across dimensions may not occur at the same time. AJDN is correct in the sense that it detects the correct number of jumps with a prescribed probability asymptotically and its accuracy in estimating the locations of the jumps is asymptotically nearly optimal under the asynchronous jump assumption. Through a simulation study we demonstrate AJDN’s robustness across a wide variety of stationary and nonstationary high dimensional time series, and we show its strong performance relative to some existing high dimensional changepoint detection methods. We apply AJDN to a seismic time series to demonstrate its ability to accurately detect jumps in real-world high dimensional time series with complex temporal dynamics.</summary></entry><entry><title type="html">Average Controlled and Average Natural Micro Direct Effects in Summary Causal Graphs</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/AverageControlledandAverageNaturalMicroDirectEffectsinSummaryCausalGraphs.html" rel="alternate" type="text/html" title="Average Controlled and Average Natural Micro Direct Effects in Summary Causal Graphs" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/AverageControlledandAverageNaturalMicroDirectEffectsinSummaryCausalGraphs</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/AverageControlledandAverageNaturalMicroDirectEffectsinSummaryCausalGraphs.html">&lt;p&gt;In this paper, we investigate the identifiability of average controlled direct effects and average natural direct effects in causal systems represented by summary causal graphs, which are abstractions of full causal graphs, often used in dynamic systems where cycles and omitted temporal information complicate causal inference. Unlike in the traditional linear setting, where direct effects are typically easier to identify and estimate, non-parametric direct effects, which are crucial for handling real-world complexities, particularly in epidemiological contexts where relationships between variables (e.g, genetic, environmental, and behavioral factors) are often non-linear, are much harder to define and identify. In particular, we give sufficient conditions for identifying average controlled micro direct effect and average natural micro direct effect from summary causal graphs in the presence of hidden confounding. Furthermore, we show that the conditions given for the average controlled micro direct effect become also necessary in the setting where there is no hidden confounding and where we are only interested in identifiability by adjustment.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23975&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Simon Ferreira, Charles K. Assaad</name></author><category term="stat.ME" /><summary type="html">In this paper, we investigate the identifiability of average controlled direct effects and average natural direct effects in causal systems represented by summary causal graphs, which are abstractions of full causal graphs, often used in dynamic systems where cycles and omitted temporal information complicate causal inference. Unlike in the traditional linear setting, where direct effects are typically easier to identify and estimate, non-parametric direct effects, which are crucial for handling real-world complexities, particularly in epidemiological contexts where relationships between variables (e.g, genetic, environmental, and behavioral factors) are often non-linear, are much harder to define and identify. In particular, we give sufficient conditions for identifying average controlled micro direct effect and average natural micro direct effect from summary causal graphs in the presence of hidden confounding. Furthermore, we show that the conditions given for the average controlled micro direct effect become also necessary in the setting where there is no hidden confounding and where we are only interested in identifiability by adjustment.</summary></entry><entry><title type="html">BAMITA: Bayesian Multiple Imputation for Tensor Arrays</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/BAMITABayesianMultipleImputationforTensorArrays.html" rel="alternate" type="text/html" title="BAMITA: Bayesian Multiple Imputation for Tensor Arrays" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/BAMITABayesianMultipleImputationforTensorArrays</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/BAMITABayesianMultipleImputationforTensorArrays.html">&lt;p&gt;Data increasingly take the form of a multi-way array, or tensor, in several biomedical domains. Such tensors are often incompletely observed. For example, we are motivated by longitudinal microbiome studies in which several timepoints are missing for several subjects. There is a growing literature on missing data imputation for tensors. However, existing methods give a point estimate for missing values without capturing uncertainty. We propose a multiple imputation approach for tensors in a flexible Bayesian framework, that yields realistic simulated values for missing entries and can propagate uncertainty through subsequent analyses. Our model uses efficient and widely applicable conjugate priors for a CANDECOMP/PARAFAC (CP) factorization, with a separable residual covariance structure. This approach is shown to perform well with respect to both imputation accuracy and uncertainty calibration, for scenarios in which either single entries or entire fibers of the tensor are missing. For two microbiome applications, it is shown to accurately capture uncertainty in the full microbiome profile at missing timepoints and used to infer trends in species diversity for the population. Documented R code to perform our multiple imputation approach is available at https://github.com/lockEF/MultiwayImputation .&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23412&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ziren Jiang, Gen Li, Eric F. Lock</name></author><category term="stat.ME," /><category term="stat.ML" /><summary type="html">Data increasingly take the form of a multi-way array, or tensor, in several biomedical domains. Such tensors are often incompletely observed. For example, we are motivated by longitudinal microbiome studies in which several timepoints are missing for several subjects. There is a growing literature on missing data imputation for tensors. However, existing methods give a point estimate for missing values without capturing uncertainty. We propose a multiple imputation approach for tensors in a flexible Bayesian framework, that yields realistic simulated values for missing entries and can propagate uncertainty through subsequent analyses. Our model uses efficient and widely applicable conjugate priors for a CANDECOMP/PARAFAC (CP) factorization, with a separable residual covariance structure. This approach is shown to perform well with respect to both imputation accuracy and uncertainty calibration, for scenarios in which either single entries or entire fibers of the tensor are missing. For two microbiome applications, it is shown to accurately capture uncertainty in the full microbiome profile at missing timepoints and used to infer trends in species diversity for the population. Documented R code to perform our multiple imputation approach is available at https://github.com/lockEF/MultiwayImputation .</summary></entry><entry><title type="html">Bayesian Hierarchical Model for Synthesizing Registry and Survey Data on Female Breast Cancer Prevalence</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/BayesianHierarchicalModelforSynthesizingRegistryandSurveyDataonFemaleBreastCancerPrevalence.html" rel="alternate" type="text/html" title="Bayesian Hierarchical Model for Synthesizing Registry and Survey Data on Female Breast Cancer Prevalence" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/BayesianHierarchicalModelforSynthesizingRegistryandSurveyDataonFemaleBreastCancerPrevalence</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/BayesianHierarchicalModelforSynthesizingRegistryandSurveyDataonFemaleBreastCancerPrevalence.html">&lt;p&gt;In public health, it is critical for policymakers to assess the relationship between the disease prevalence and associated risk factors or clinical characteristics, facilitating effective resources allocation. However, for diseases like female breast cancer (FBC), reliable prevalence data at specific geographical levels, such as the county-level, are limited because the gold standard data typically come from long-term cancer registries, which do not necessarily collect needed risk factors. In addition, it remains unclear whether fitting each model separately or jointly results in better estimation. In this paper, we identify two data sources to produce reliable county-level prevalence estimates in Missouri, USA: the population-based Missouri Cancer Registry (MCR) and the survey-based Missouri County-Level Study (CLS). We propose a two-stage Bayesian model to synthesize these sources, accounting for their differences in the methodological design, case definitions, and collected information. The first stage involves estimating the county-level FBC prevalence using the raking method for CLS data and the counting method for MCR data, calibrating the differences in the methodological design and case definition. The second stage includes synthesizing two sources with different sets of covariates using a Bayesian generalized linear mixed model with Zeller-Siow prior for the coefficients. Our data analyses demonstrate that using both data sources have better results than at least one data source, and including a data source membership matters when there exist systematic differences in these sources. Finally, we translate results into policy making and discuss methodological differences for data synthesis of registry and survey data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23580&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Qiao Wang, Chester Lee Schmaltz, Jeannette Jackson-Thompson, Dongchu Sun, Zhuoqiong He, Zhongheng Cai, Hwanhee Hong</name></author><category term="stat.AP," /><category term="stat.ME" /><summary type="html">In public health, it is critical for policymakers to assess the relationship between the disease prevalence and associated risk factors or clinical characteristics, facilitating effective resources allocation. However, for diseases like female breast cancer (FBC), reliable prevalence data at specific geographical levels, such as the county-level, are limited because the gold standard data typically come from long-term cancer registries, which do not necessarily collect needed risk factors. In addition, it remains unclear whether fitting each model separately or jointly results in better estimation. In this paper, we identify two data sources to produce reliable county-level prevalence estimates in Missouri, USA: the population-based Missouri Cancer Registry (MCR) and the survey-based Missouri County-Level Study (CLS). We propose a two-stage Bayesian model to synthesize these sources, accounting for their differences in the methodological design, case definitions, and collected information. The first stage involves estimating the county-level FBC prevalence using the raking method for CLS data and the counting method for MCR data, calibrating the differences in the methodological design and case definition. The second stage includes synthesizing two sources with different sets of covariates using a Bayesian generalized linear mixed model with Zeller-Siow prior for the coefficients. Our data analyses demonstrate that using both data sources have better results than at least one data source, and including a data source membership matters when there exist systematic differences in these sources. Finally, we translate results into policy making and discuss methodological differences for data synthesis of registry and survey data.</summary></entry><entry><title type="html">Bayesian Online Natural Gradient (BONG)</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/BayesianOnlineNaturalGradientBONG.html" rel="alternate" type="text/html" title="Bayesian Online Natural Gradient (BONG)" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/BayesianOnlineNaturalGradientBONG</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/BayesianOnlineNaturalGradientBONG.html">&lt;p&gt;We propose a novel approach to sequential Bayesian inference based on variational Bayes (VB). The key insight is that, in the online setting, we do not need to add the KL term to regularize to the prior (which comes from the posterior at the previous timestep); instead we can optimize just the expected log-likelihood, performing a single step of natural gradient descent starting at the prior predictive. We prove this method recovers exact Bayesian inference if the model is conjugate. We also show how to compute an efficient deterministic approximation to the VB objective, as well as our simplified objective, when the variational distribution is Gaussian or a sub-family, including the case of a diagonal plus low-rank precision matrix. We show empirically that our method outperforms other online VB methods in the non-conjugate setting, such as online learning for neural networks, especially when controlling for computational costs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.19681&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Matt Jones, Peter Chang, Kevin Murphy</name></author><category term="stat.ML," /><category term="stat.CO" /><summary type="html">We propose a novel approach to sequential Bayesian inference based on variational Bayes (VB). The key insight is that, in the online setting, we do not need to add the KL term to regularize to the prior (which comes from the posterior at the previous timestep); instead we can optimize just the expected log-likelihood, performing a single step of natural gradient descent starting at the prior predictive. We prove this method recovers exact Bayesian inference if the model is conjugate. We also show how to compute an efficient deterministic approximation to the VB objective, as well as our simplified objective, when the variational distribution is Gaussian or a sub-family, including the case of a diagonal plus low-rank precision matrix. We show empirically that our method outperforms other online VB methods in the non-conjugate setting, such as online learning for neural networks, especially when controlling for computational costs.</summary></entry><entry><title type="html">Bayesian hierarchical models with calibrated mixtures of g-priors for assessing treatment effect moderation in meta-analysis</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Bayesianhierarchicalmodelswithcalibratedmixturesofgpriorsforassessingtreatmenteffectmoderationinmetaanalysis.html" rel="alternate" type="text/html" title="Bayesian hierarchical models with calibrated mixtures of g-priors for assessing treatment effect moderation in meta-analysis" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Bayesianhierarchicalmodelswithcalibratedmixturesofgpriorsforassessingtreatmenteffectmoderationinmetaanalysis</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Bayesianhierarchicalmodelswithcalibratedmixturesofgpriorsforassessingtreatmenteffectmoderationinmetaanalysis.html">&lt;p&gt;Assessing treatment effect moderation is critical in biomedical research and many other fields, as it guides personalized intervention strategies to improve participant’s outcomes. Individual participant-level data meta-analysis (IPD-MA) offers a robust framework for such assessments by leveraging data from multiple trials. However, its performance is often compromised by challenges such as high between-trial variability. Traditional Bayesian shrinkage methods have gained popularity, but are less suitable in this context, as their priors do not discern heterogeneous studies. In this paper, we propose the calibrated mixtures of g-priors methods in IPD-MA to enhance efficiency and reduce risk in the estimation of moderation effects. Our approach incorporates a trial-level sample size tuning function, and a moderator-level shrinkage parameter in the prior, offering a flexible spectrum of shrinkage levels that enables practitioners to evaluate moderator importance, from conservative to optimistic perspectives. Compared with existing Bayesian shrinkage methods, our extensive simulation studies demonstrate that the calibrated mixtures of g-priors exhibit superior performances in terms of efficiency and risk metrics, particularly under high between-trial variability, high model sparsity, weak moderation effects and correlated design matrices. We further illustrate their application in assessing effect moderators of two active treatments for major depressive disorder, using IPD from four randomized controlled trials.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24194&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Qiao Wang, Hwanhee Hong</name></author><category term="stat.ME," /><category term="stat.AP" /><summary type="html">Assessing treatment effect moderation is critical in biomedical research and many other fields, as it guides personalized intervention strategies to improve participant’s outcomes. Individual participant-level data meta-analysis (IPD-MA) offers a robust framework for such assessments by leveraging data from multiple trials. However, its performance is often compromised by challenges such as high between-trial variability. Traditional Bayesian shrinkage methods have gained popularity, but are less suitable in this context, as their priors do not discern heterogeneous studies. In this paper, we propose the calibrated mixtures of g-priors methods in IPD-MA to enhance efficiency and reduce risk in the estimation of moderation effects. Our approach incorporates a trial-level sample size tuning function, and a moderator-level shrinkage parameter in the prior, offering a flexible spectrum of shrinkage levels that enables practitioners to evaluate moderator importance, from conservative to optimistic perspectives. Compared with existing Bayesian shrinkage methods, our extensive simulation studies demonstrate that the calibrated mixtures of g-priors exhibit superior performances in terms of efficiency and risk metrics, particularly under high between-trial variability, high model sparsity, weak moderation effects and correlated design matrices. We further illustrate their application in assessing effect moderators of two active treatments for major depressive disorder, using IPD from four randomized controlled trials.</summary></entry><entry><title type="html">Bridging Geometric States via Geometric Diffusion Bridge</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/BridgingGeometricStatesviaGeometricDiffusionBridge.html" rel="alternate" type="text/html" title="Bridging Geometric States via Geometric Diffusion Bridge" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/BridgingGeometricStatesviaGeometricDiffusionBridge</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/BridgingGeometricStatesviaGeometricDiffusionBridge.html">&lt;p&gt;The accurate prediction of geometric state evolution in complex systems is critical for advancing scientific domains such as quantum chemistry and material modeling. Traditional experimental and computational methods face challenges in terms of environmental constraints and computational demands, while current deep learning approaches still fall short in terms of precision and generality. In this work, we introduce the Geometric Diffusion Bridge (GDB), a novel generative modeling framework that accurately bridges initial and target geometric states. GDB leverages a probabilistic approach to evolve geometric state distributions, employing an equivariant diffusion bridge derived by a modified version of Doob’s $h$-transform for connecting geometric states. This tailored diffusion process is anchored by initial and target geometric states as fixed endpoints and governed by equivariant transition kernels. Moreover, trajectory data can be seamlessly leveraged in our GDB framework by using a chain of equivariant diffusion bridges, providing a more detailed and accurate characterization of evolution dynamics. Theoretically, we conduct a thorough examination to confirm our framework’s ability to preserve joint distributions of geometric states and capability to completely model the underlying dynamics inducing trajectory distributions with negligible error. Experimental evaluations across various real-world scenarios show that GDB surpasses existing state-of-the-art approaches, opening up a new pathway for accurately bridging geometric states and tackling crucial scientific challenges with improved accuracy and applicability.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24220&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Shengjie Luo, Yixian Xu, Di He, Shuxin Zheng, Tie-Yan Liu, Liwei Wang</name></author><category term="stat.ML" /><summary type="html">The accurate prediction of geometric state evolution in complex systems is critical for advancing scientific domains such as quantum chemistry and material modeling. Traditional experimental and computational methods face challenges in terms of environmental constraints and computational demands, while current deep learning approaches still fall short in terms of precision and generality. In this work, we introduce the Geometric Diffusion Bridge (GDB), a novel generative modeling framework that accurately bridges initial and target geometric states. GDB leverages a probabilistic approach to evolve geometric state distributions, employing an equivariant diffusion bridge derived by a modified version of Doob’s $h$-transform for connecting geometric states. This tailored diffusion process is anchored by initial and target geometric states as fixed endpoints and governed by equivariant transition kernels. Moreover, trajectory data can be seamlessly leveraged in our GDB framework by using a chain of equivariant diffusion bridges, providing a more detailed and accurate characterization of evolution dynamics. Theoretically, we conduct a thorough examination to confirm our framework’s ability to preserve joint distributions of geometric states and capability to completely model the underlying dynamics inducing trajectory distributions with negligible error. Experimental evaluations across various real-world scenarios show that GDB surpasses existing state-of-the-art approaches, opening up a new pathway for accurately bridging geometric states and tackling crucial scientific challenges with improved accuracy and applicability.</summary></entry><entry><title type="html">Conformal inference for cell type annotation with graph-structured constraints</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Conformalinferenceforcelltypeannotationwithgraphstructuredconstraints.html" rel="alternate" type="text/html" title="Conformal inference for cell type annotation with graph-structured constraints" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Conformalinferenceforcelltypeannotationwithgraphstructuredconstraints</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Conformalinferenceforcelltypeannotationwithgraphstructuredconstraints.html">&lt;p&gt;Conformal inference is a method that provides prediction sets for machine learning models, operating independently of the underlying distributional assumptions and relying solely on the exchangeability of training and test data. Despite its wide applicability and popularity, its application in graph-structured problems remains underexplored. This paper addresses this gap by developing an approach that leverages the rich information encoded in the graph structure of predicted classes to enhance the interpretability of conformal sets. Using a motivating example from genomics, specifically imaging-based spatial transcriptomics data and single-cell RNA sequencing data, we demonstrate how incorporating graph-structured constraints can improve the interpretation of cell type predictions. This approach aims to generate more coherent conformal sets that align with the inherent relationships among classes, facilitating clearer and more intuitive interpretations of model predictions. Additionally, we provide a technique to address non-exchangeability, particularly when the distribution of the response variable changes between training and test datasets. We implemented our method in the open-source R package scConform, available at https://github.com/ccb-hms/scConform.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23786&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Daniela Corbetta, Livio Finos, Ludwig Geistlinger, Davide Risso</name></author><category term="stat.ME," /><category term="stat.AP" /><summary type="html">Conformal inference is a method that provides prediction sets for machine learning models, operating independently of the underlying distributional assumptions and relying solely on the exchangeability of training and test data. Despite its wide applicability and popularity, its application in graph-structured problems remains underexplored. This paper addresses this gap by developing an approach that leverages the rich information encoded in the graph structure of predicted classes to enhance the interpretability of conformal sets. Using a motivating example from genomics, specifically imaging-based spatial transcriptomics data and single-cell RNA sequencing data, we demonstrate how incorporating graph-structured constraints can improve the interpretation of cell type predictions. This approach aims to generate more coherent conformal sets that align with the inherent relationships among classes, facilitating clearer and more intuitive interpretations of model predictions. Additionally, we provide a technique to address non-exchangeability, particularly when the distribution of the response variable changes between training and test datasets. We implemented our method in the open-source R package scConform, available at https://github.com/ccb-hms/scConform.</summary></entry><entry><title type="html">Conformal prediction of circular data</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Conformalpredictionofcirculardata.html" rel="alternate" type="text/html" title="Conformal prediction of circular data" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Conformalpredictionofcirculardata</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Conformalpredictionofcirculardata.html">&lt;p&gt;Split conformal prediction techniques are applied to regression problems with circular responses by introducing a suitable conformity score, leading to prediction sets with adaptive arc length and finite-sample coverage guarantees for any circular predictive model under exchangeable data. Leveraging the high performance of existing predictive models designed for linear responses, we analyze a general projection procedure that converts any linear response regression model into one suitable for circular responses. When random forests serve as basis models in this projection procedure, we harness the out-of-bag dynamics to eliminate the necessity for a separate calibration sample in the construction of prediction sets. For synthetic and real datasets the resulting projected random forests model produces more efficient out-of-bag conformal prediction sets, with shorter median arc length, when compared to the split conformal prediction sets generated by two existing alternative models.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24145&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Paulo C. Marques F., Rinaldo Artes, Helton Graziadei</name></author><category term="stat.ML," /><category term="stat.ME" /><summary type="html">Split conformal prediction techniques are applied to regression problems with circular responses by introducing a suitable conformity score, leading to prediction sets with adaptive arc length and finite-sample coverage guarantees for any circular predictive model under exchangeable data. Leveraging the high performance of existing predictive models designed for linear responses, we analyze a general projection procedure that converts any linear response regression model into one suitable for circular responses. When random forests serve as basis models in this projection procedure, we harness the out-of-bag dynamics to eliminate the necessity for a separate calibration sample in the construction of prediction sets. For synthetic and real datasets the resulting projected random forests model produces more efficient out-of-bag conformal prediction sets, with shorter median arc length, when compared to the split conformal prediction sets generated by two existing alternative models.</summary></entry><entry><title type="html">Controlling Continuous Relaxation for Combinatorial Optimization</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/ControllingContinuousRelaxationforCombinatorialOptimization.html" rel="alternate" type="text/html" title="Controlling Continuous Relaxation for Combinatorial Optimization" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/ControllingContinuousRelaxationforCombinatorialOptimization</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/ControllingContinuousRelaxationforCombinatorialOptimization.html">&lt;p&gt;Unsupervised learning (UL)-based solvers for combinatorial optimization (CO) train a neural network that generates a soft solution by directly optimizing the CO objective using a continuous relaxation strategy. These solvers offer several advantages over traditional methods and other learning-based methods, particularly for large-scale CO problems. However, UL-based solvers face two practical issues: (I) an optimization issue, where UL-based solvers are easily trapped at local optima, and (II) a rounding issue, where UL-based solvers require artificial post-learning rounding from the continuous space back to the original discrete space, undermining the robustness of the results. This study proposes a Continuous Relaxation Annealing (CRA) strategy, an effective rounding-free learning method for UL-based solvers. CRA introduces a penalty term that dynamically shifts from prioritizing continuous solutions, effectively smoothing the non-convexity of the objective function, to enforcing discreteness, eliminating artificial rounding. Experimental results demonstrate that CRA significantly enhances the performance of UL-based solvers, outperforming existing UL-based solvers and greedy algorithms in complex CO problems. Additionally, CRA effectively eliminates artificial rounding and accelerates the learning process.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2309.16965&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Yuma Ichikawa</name></author><category term="stat.ML," /><category term="stat.CO," /><category term="stat.ME" /><summary type="html">Unsupervised learning (UL)-based solvers for combinatorial optimization (CO) train a neural network that generates a soft solution by directly optimizing the CO objective using a continuous relaxation strategy. These solvers offer several advantages over traditional methods and other learning-based methods, particularly for large-scale CO problems. However, UL-based solvers face two practical issues: (I) an optimization issue, where UL-based solvers are easily trapped at local optima, and (II) a rounding issue, where UL-based solvers require artificial post-learning rounding from the continuous space back to the original discrete space, undermining the robustness of the results. This study proposes a Continuous Relaxation Annealing (CRA) strategy, an effective rounding-free learning method for UL-based solvers. CRA introduces a penalty term that dynamically shifts from prioritizing continuous solutions, effectively smoothing the non-convexity of the objective function, to enforcing discreteness, eliminating artificial rounding. Experimental results demonstrate that CRA significantly enhances the performance of UL-based solvers, outperforming existing UL-based solvers and greedy algorithms in complex CO problems. Additionally, CRA effectively eliminates artificial rounding and accelerates the learning process.</summary></entry><entry><title type="html">Cost-aware Bayesian Optimization via the Pandora’s Box Gittins Index</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/CostawareBayesianOptimizationviathePandorasBoxGittinsIndex.html" rel="alternate" type="text/html" title="Cost-aware Bayesian Optimization via the Pandora’s Box Gittins Index" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/CostawareBayesianOptimizationviathePandorasBoxGittinsIndex</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/CostawareBayesianOptimizationviathePandorasBoxGittinsIndex.html">&lt;p&gt;Bayesian optimization is a technique for efficiently optimizing unknown functions in a black-box manner. To handle practical settings where gathering data requires use of finite resources, it is desirable to explicitly incorporate function evaluation costs into Bayesian optimization policies. To understand how to do so, we develop a previously-unexplored connection between cost-aware Bayesian optimization and the Pandora’s Box problem, a decision problem from economics. The Pandora’s Box problem admits a Bayesian-optimal solution based on an expression called the Gittins index, which can be reinterpreted as an acquisition function. We study the use of this acquisition function for cost-aware Bayesian optimization, and demonstrate empirically that it performs well, particularly in medium-high dimensions. We further show that this performance carries over to classical Bayesian optimization without explicit evaluation costs. Our work constitutes a first step towards integrating techniques from Gittins index theory into Bayesian optimization.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.20062&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Qian Xie, Raul Astudillo, Peter I. Frazier, Ziv Scully, Alexander Terenin</name></author><category term="stat.ML" /><summary type="html">Bayesian optimization is a technique for efficiently optimizing unknown functions in a black-box manner. To handle practical settings where gathering data requires use of finite resources, it is desirable to explicitly incorporate function evaluation costs into Bayesian optimization policies. To understand how to do so, we develop a previously-unexplored connection between cost-aware Bayesian optimization and the Pandora’s Box problem, a decision problem from economics. The Pandora’s Box problem admits a Bayesian-optimal solution based on an expression called the Gittins index, which can be reinterpreted as an acquisition function. We study the use of this acquisition function for cost-aware Bayesian optimization, and demonstrate empirically that it performs well, particularly in medium-high dimensions. We further show that this performance carries over to classical Bayesian optimization without explicit evaluation costs. Our work constitutes a first step towards integrating techniques from Gittins index theory into Bayesian optimization.</summary></entry><entry><title type="html">Credit Attribution and Stable Compression</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/CreditAttributionandStableCompression.html" rel="alternate" type="text/html" title="Credit Attribution and Stable Compression" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/CreditAttributionandStableCompression</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/CreditAttributionandStableCompression.html">&lt;p&gt;Credit attribution is crucial across various fields. In academic research, proper citation acknowledges prior work and establishes original contributions. Similarly, in generative models, such as those trained on existing artworks or music, it is important to ensure that any generated content influenced by these works appropriately credits the original creators.
  We study credit attribution by machine learning algorithms. We propose new definitions–relaxations of Differential Privacy–that weaken the stability guarantees for a designated subset of $k$ datapoints. These $k$ datapoints can be used non-stably with permission from their owners, potentially in exchange for compensation. Meanwhile, the remaining datapoints are guaranteed to have no significant influence on the algorithm’s output.
  Our framework extends well-studied notions of stability, including Differential Privacy ($k = 0$), differentially private learning with public data (where the $k$ public datapoints are fixed in advance), and stable sample compression (where the $k$ datapoints are selected adaptively by the algorithm). We examine the expressive power of these stability notions within the PAC learning framework, provide a comprehensive characterization of learnability for algorithms adhering to these principles, and propose directions and questions for future research.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.15916&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Roi Livni, Shay Moran, Kobbi Nissim, Chirag Pabbaraju</name></author><category term="stat.ML" /><summary type="html">Credit attribution is crucial across various fields. In academic research, proper citation acknowledges prior work and establishes original contributions. Similarly, in generative models, such as those trained on existing artworks or music, it is important to ensure that any generated content influenced by these works appropriately credits the original creators. We study credit attribution by machine learning algorithms. We propose new definitions–relaxations of Differential Privacy–that weaken the stability guarantees for a designated subset of $k$ datapoints. These $k$ datapoints can be used non-stably with permission from their owners, potentially in exchange for compensation. Meanwhile, the remaining datapoints are guaranteed to have no significant influence on the algorithm’s output. Our framework extends well-studied notions of stability, including Differential Privacy ($k = 0$), differentially private learning with public data (where the $k$ public datapoints are fixed in advance), and stable sample compression (where the $k$ datapoints are selected adaptively by the algorithm). We examine the expressive power of these stability notions within the PAC learning framework, provide a comprehensive characterization of learnability for algorithms adhering to these principles, and propose directions and questions for future research.</summary></entry><entry><title type="html">Decision-Focused Learning with Directional Gradients</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/DecisionFocusedLearningwithDirectionalGradients.html" rel="alternate" type="text/html" title="Decision-Focused Learning with Directional Gradients" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/DecisionFocusedLearningwithDirectionalGradients</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/DecisionFocusedLearningwithDirectionalGradients.html">&lt;p&gt;We propose a novel family of decision-aware surrogate losses, called Perturbation Gradient (PG) losses, for the predict-then-optimize framework. The key idea is to connect the expected downstream decision loss with the directional derivative of a particular plug-in objective, and then approximate this derivative using zeroth order gradient techniques. Unlike the original decision loss which is typically piecewise constant and discontinuous, our new PG losses is a Lipschitz continuous, difference of concave functions that can be optimized using off-the-shelf gradient-based methods. Most importantly, unlike existing surrogate losses, the approximation error of our PG losses vanishes as the number of samples grows. Hence, optimizing our surrogate loss yields a best-in-class policy asymptotically, even in misspecified settings. This is the first such result in misspecified settings, and we provide numerical evidence confirming our PG losses substantively outperform existing proposals when the underlying model is misspecified.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.03256&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Michael Huang, Vishal Gupta</name></author><category term="stat.ML" /><summary type="html">We propose a novel family of decision-aware surrogate losses, called Perturbation Gradient (PG) losses, for the predict-then-optimize framework. The key idea is to connect the expected downstream decision loss with the directional derivative of a particular plug-in objective, and then approximate this derivative using zeroth order gradient techniques. Unlike the original decision loss which is typically piecewise constant and discontinuous, our new PG losses is a Lipschitz continuous, difference of concave functions that can be optimized using off-the-shelf gradient-based methods. Most importantly, unlike existing surrogate losses, the approximation error of our PG losses vanishes as the number of samples grows. Hence, optimizing our surrogate loss yields a best-in-class policy asymptotically, even in misspecified settings. This is the first such result in misspecified settings, and we provide numerical evidence confirming our PG losses substantively outperform existing proposals when the underlying model is misspecified.</summary></entry><entry><title type="html">Demystifying Linear MDPs and Novel Dynamics Aggregation Framework</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/DemystifyingLinearMDPsandNovelDynamicsAggregationFramework.html" rel="alternate" type="text/html" title="Demystifying Linear MDPs and Novel Dynamics Aggregation Framework" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/DemystifyingLinearMDPsandNovelDynamicsAggregationFramework</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/DemystifyingLinearMDPsandNovelDynamicsAggregationFramework.html">&lt;p&gt;In this work, we prove that, in linear MDPs, the feature dimension $d$ is lower bounded by $S/U$ in order to aptly represent transition probabilities, where $S$ is the size of the state space and $U$ is the maximum size of directly reachable states. Hence, $d$ can still scale with $S$ depending on the direct reachability of the environment. To address this limitation of linear MDPs, we propose a novel structural aggregation framework based on dynamics, named as the “dynamics aggregation”. For this newly proposed framework, we design a provably efficient hierarchical reinforcement learning algorithm in linear function approximation that leverages aggregated sub-structures. Our proposed algorithm exhibits statistical efficiency, achieving a regret of $ \tilde{O} ( d_{\psi}^{3/2} H^{3/2}\sqrt{ N T} )$, where $d_{\psi}$ represents the feature dimension of aggregated subMDPs and $N$ signifies the number of aggregated subMDPs. We establish that the condition $d_{\psi}^3 N \ll d^{3}$ is readily met in most real-world environments with hierarchical structures, enabling a substantial improvement in the regret bound compared to LSVI-UCB, which enjoys a regret of $ \tilde{O} (d^{3/2} H^{3/2} \sqrt{ T})$. To the best of our knowledge, this work presents the first HRL algorithm with linear function approximation that offers provable guarantees.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24089&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Joongkyu Lee, Min-hwan Oh</name></author><category term="stat.ML" /><summary type="html">In this work, we prove that, in linear MDPs, the feature dimension $d$ is lower bounded by $S/U$ in order to aptly represent transition probabilities, where $S$ is the size of the state space and $U$ is the maximum size of directly reachable states. Hence, $d$ can still scale with $S$ depending on the direct reachability of the environment. To address this limitation of linear MDPs, we propose a novel structural aggregation framework based on dynamics, named as the “dynamics aggregation”. For this newly proposed framework, we design a provably efficient hierarchical reinforcement learning algorithm in linear function approximation that leverages aggregated sub-structures. Our proposed algorithm exhibits statistical efficiency, achieving a regret of $ \tilde{O} ( d_{\psi}^{3/2} H^{3/2}\sqrt{ N T} )$, where $d_{\psi}$ represents the feature dimension of aggregated subMDPs and $N$ signifies the number of aggregated subMDPs. We establish that the condition $d_{\psi}^3 N \ll d^{3}$ is readily met in most real-world environments with hierarchical structures, enabling a substantial improvement in the regret bound compared to LSVI-UCB, which enjoys a regret of $ \tilde{O} (d^{3/2} H^{3/2} \sqrt{ T})$. To the best of our knowledge, this work presents the first HRL algorithm with linear function approximation that offers provable guarantees.</summary></entry><entry><title type="html">Denoising and Multilinear Projected-Estimation of High-Dimensional Matrix-Variate Factor Time Series</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/DenoisingandMultilinearProjectedEstimationofHighDimensionalMatrixVariateFactorTimeSeries.html" rel="alternate" type="text/html" title="Denoising and Multilinear Projected-Estimation of High-Dimensional Matrix-Variate Factor Time Series" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/DenoisingandMultilinearProjectedEstimationofHighDimensionalMatrixVariateFactorTimeSeries</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/DenoisingandMultilinearProjectedEstimationofHighDimensionalMatrixVariateFactorTimeSeries.html">&lt;p&gt;This paper proposes a new multi-linear projection method for denoising and estimation of high-dimensional matrix-variate factor time series. It assumes that a $p_1\times p_2$ matrix-variate time series consists of a dynamically dependent, lower-dimensional matrix-variate factor process and a $p_1\times p_2$ matrix idiosyncratic series. In addition, the latter series assumes a matrix-variate factor structure such that its row and column covariances may have diverging/spiked eigenvalues to accommodate the case of low signal-to-noise ratio often encountered in applications. We use an iterative projection procedure to reduce the dimensions and noise effects in estimating front and back loading matrices and to obtain faster convergence rates than those of the traditional methods available in the literature. We further introduce a two-way projected Principal Component Analysis to mitigate the diverging noise effects, and implement a high-dimensional white-noise testing procedure to estimate the dimension of the matrix factor process. Asymptotic properties of the proposed method are established if the dimensions and sample size go to infinity. We also use simulations and real examples to assess the performance of the proposed method in finite samples and to compare its forecasting ability with some existing ones in the literature. The proposed method fares well in out-of-sample forecasting. In a supplement, we demonstrate the efficacy of the proposed approach even when the idiosyncratic terms exhibit serial correlations with or without a diverging white noise effect.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2309.02674&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Zhaoxing Gao, Ruey S. Tsay</name></author><category term="stat.ME" /><summary type="html">This paper proposes a new multi-linear projection method for denoising and estimation of high-dimensional matrix-variate factor time series. It assumes that a $p_1\times p_2$ matrix-variate time series consists of a dynamically dependent, lower-dimensional matrix-variate factor process and a $p_1\times p_2$ matrix idiosyncratic series. In addition, the latter series assumes a matrix-variate factor structure such that its row and column covariances may have diverging/spiked eigenvalues to accommodate the case of low signal-to-noise ratio often encountered in applications. We use an iterative projection procedure to reduce the dimensions and noise effects in estimating front and back loading matrices and to obtain faster convergence rates than those of the traditional methods available in the literature. We further introduce a two-way projected Principal Component Analysis to mitigate the diverging noise effects, and implement a high-dimensional white-noise testing procedure to estimate the dimension of the matrix factor process. Asymptotic properties of the proposed method are established if the dimensions and sample size go to infinity. We also use simulations and real examples to assess the performance of the proposed method in finite samples and to compare its forecasting ability with some existing ones in the literature. The proposed method fares well in out-of-sample forecasting. In a supplement, we demonstrate the efficacy of the proposed approach even when the idiosyncratic terms exhibit serial correlations with or without a diverging white noise effect.</summary></entry><entry><title type="html">Differentially Private Optimization with Sparse Gradients</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/DifferentiallyPrivateOptimizationwithSparseGradients.html" rel="alternate" type="text/html" title="Differentially Private Optimization with Sparse Gradients" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/DifferentiallyPrivateOptimizationwithSparseGradients</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/DifferentiallyPrivateOptimizationwithSparseGradients.html">&lt;p&gt;Motivated by applications of large embedding models, we study differentially private (DP) optimization problems under sparsity of individual gradients. We start with new near-optimal bounds for the classic mean estimation problem but with sparse data, improving upon existing algorithms particularly for the high-dimensional regime. Building on this, we obtain pure- and approximate-DP algorithms with almost optimal rates for stochastic convex optimization with sparse gradients; the former represents the first nearly dimension-independent rates for this problem. Finally, we study the approximation of stationary points for the empirical loss in approximate-DP optimization and obtain rates that depend on sparsity instead of dimension, modulo polylogarithmic factors.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2404.10881&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Badih Ghazi, Cristóbal Guzmán, Pritish Kamath, Ravi Kumar, Pasin Manurangsi</name></author><category term="stat.ML" /><summary type="html">Motivated by applications of large embedding models, we study differentially private (DP) optimization problems under sparsity of individual gradients. We start with new near-optimal bounds for the classic mean estimation problem but with sparse data, improving upon existing algorithms particularly for the high-dimensional regime. Building on this, we obtain pure- and approximate-DP algorithms with almost optimal rates for stochastic convex optimization with sparse gradients; the former represents the first nearly dimension-independent rates for this problem. Finally, we study the approximation of stationary points for the empirical loss in approximate-DP optimization and obtain rates that depend on sparsity instead of dimension, modulo polylogarithmic factors.</summary></entry><entry><title type="html">Discovery of the Hidden World with Large Language Models</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/DiscoveryoftheHiddenWorldwithLargeLanguageModels.html" rel="alternate" type="text/html" title="Discovery of the Hidden World with Large Language Models" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/DiscoveryoftheHiddenWorldwithLargeLanguageModels</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/DiscoveryoftheHiddenWorldwithLargeLanguageModels.html">&lt;p&gt;Revealing the underlying causal mechanisms in the real world is the key to the development of science. Despite the progress in the past decades, traditional causal discovery approaches (CDs) mainly rely on high-quality measured variables, usually given by human experts, to find causal relations. The lack of well-defined high-level variables in many real-world applications has already been a longstanding roadblock to a broader application of CDs. To this end, this paper presents Causal representatiOn AssistanT (COAT) that introduces large language models (LLMs) to bridge the gap. LLMs are trained on massive observations of the world and have demonstrated great capability in extracting key information from unstructured data. Therefore, it is natural to employ LLMs to assist with proposing useful high-level factors and crafting their measurements. Meanwhile, COAT also adopts CDs to find causal relations among the identified variables as well as to provide feedback to LLMs to iteratively refine the proposed factors. We show that LLMs and CDs are mutually beneficial and the constructed feedback provably also helps with the factor proposal. We construct and curate several synthetic and real-world benchmarks including analysis of human reviews and diagnosis of neuropathic and brain tumors, to comprehensively evaluate COAT. Extensive empirical results confirm the effectiveness and reliability of COAT with significant improvements.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.03941&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Chenxi Liu, Yongqiang Chen, Tongliang Liu, Mingming Gong, James Cheng, Bo Han, Kun Zhang</name></author><category term="stat.ME" /><summary type="html">Revealing the underlying causal mechanisms in the real world is the key to the development of science. Despite the progress in the past decades, traditional causal discovery approaches (CDs) mainly rely on high-quality measured variables, usually given by human experts, to find causal relations. The lack of well-defined high-level variables in many real-world applications has already been a longstanding roadblock to a broader application of CDs. To this end, this paper presents Causal representatiOn AssistanT (COAT) that introduces large language models (LLMs) to bridge the gap. LLMs are trained on massive observations of the world and have demonstrated great capability in extracting key information from unstructured data. Therefore, it is natural to employ LLMs to assist with proposing useful high-level factors and crafting their measurements. Meanwhile, COAT also adopts CDs to find causal relations among the identified variables as well as to provide feedback to LLMs to iteratively refine the proposed factors. We show that LLMs and CDs are mutually beneficial and the constructed feedback provably also helps with the factor proposal. We construct and curate several synthetic and real-world benchmarks including analysis of human reviews and diagnosis of neuropathic and brain tumors, to comprehensively evaluate COAT. Extensive empirical results confirm the effectiveness and reliability of COAT with significant improvements.</summary></entry><entry><title type="html">Disentangling Interactions and Dependencies in Feature Attribution</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/DisentanglingInteractionsandDependenciesinFeatureAttribution.html" rel="alternate" type="text/html" title="Disentangling Interactions and Dependencies in Feature Attribution" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/DisentanglingInteractionsandDependenciesinFeatureAttribution</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/DisentanglingInteractionsandDependenciesinFeatureAttribution.html">&lt;p&gt;In explainable machine learning, global feature importance methods try to determine how much each individual feature contributes to predicting the target variable, resulting in one importance score for each feature. But often, predicting the target variable requires interactions between several features (such as in the XOR function), and features might have complex statistical dependencies that allow to partially replace one feature with another one. In commonly used feature importance scores these cooperative effects are conflated with the features’ individual contributions, making them prone to misinterpretations. In this work, we derive DIP, a new mathematical decomposition of individual feature importance scores that disentangles three components: the standalone contribution and the contributions stemming from interactions and dependencies. We prove that the DIP decomposition is unique and show how it can be estimated in practice. Based on these results, we propose a new visualization of feature importance scores that clearly illustrates the different contributions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23772&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Gunnar König, Eric Günther, Ulrike von Luxburg</name></author><category term="stat.ML" /><summary type="html">In explainable machine learning, global feature importance methods try to determine how much each individual feature contributes to predicting the target variable, resulting in one importance score for each feature. But often, predicting the target variable requires interactions between several features (such as in the XOR function), and features might have complex statistical dependencies that allow to partially replace one feature with another one. In commonly used feature importance scores these cooperative effects are conflated with the features’ individual contributions, making them prone to misinterpretations. In this work, we derive DIP, a new mathematical decomposition of individual feature importance scores that disentangles three components: the standalone contribution and the contributions stemming from interactions and dependencies. We prove that the DIP decomposition is unique and show how it can be estimated in practice. Based on these results, we propose a new visualization of feature importance scores that clearly illustrates the different contributions.</summary></entry><entry><title type="html">Disentangling Interpretable Factors with Supervised Independent Subspace Principal Component Analysis</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/DisentanglingInterpretableFactorswithSupervisedIndependentSubspacePrincipalComponentAnalysis.html" rel="alternate" type="text/html" title="Disentangling Interpretable Factors with Supervised Independent Subspace Principal Component Analysis" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/DisentanglingInterpretableFactorswithSupervisedIndependentSubspacePrincipalComponentAnalysis</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/DisentanglingInterpretableFactorswithSupervisedIndependentSubspacePrincipalComponentAnalysis.html">&lt;p&gt;The success of machine learning models relies heavily on effectively representing high-dimensional data. However, ensuring data representations capture human-understandable concepts remains difficult, often requiring the incorporation of prior knowledge and decomposition of data into multiple subspaces. Traditional linear methods fall short in modeling more than one space, while more expressive deep learning approaches lack interpretability. Here, we introduce Supervised Independent Subspace Principal Component Analysis ($\texttt{sisPCA}$), a PCA extension designed for multi-subspace learning. Leveraging the Hilbert-Schmidt Independence Criterion (HSIC), $\texttt{sisPCA}$ incorporates supervision and simultaneously ensures subspace disentanglement. We demonstrate $\texttt{sisPCA}$’s connections with autoencoders and regularized linear regression and showcase its ability to identify and separate hidden data structures through extensive applications, including breast cancer diagnosis from image features, learning aging-associated DNA methylation changes, and single-cell analysis of malaria infection. Our results reveal distinct functional pathways associated with malaria colonization, underscoring the essentiality of explainable representation in high-dimensional data analysis.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23595&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jiayu Su, David A. Knowles, Raul Rabadan</name></author><category term="stat.ML" /><summary type="html">The success of machine learning models relies heavily on effectively representing high-dimensional data. However, ensuring data representations capture human-understandable concepts remains difficult, often requiring the incorporation of prior knowledge and decomposition of data into multiple subspaces. Traditional linear methods fall short in modeling more than one space, while more expressive deep learning approaches lack interpretability. Here, we introduce Supervised Independent Subspace Principal Component Analysis ($\texttt{sisPCA}$), a PCA extension designed for multi-subspace learning. Leveraging the Hilbert-Schmidt Independence Criterion (HSIC), $\texttt{sisPCA}$ incorporates supervision and simultaneously ensures subspace disentanglement. We demonstrate $\texttt{sisPCA}$’s connections with autoencoders and regularized linear regression and showcase its ability to identify and separate hidden data structures through extensive applications, including breast cancer diagnosis from image features, learning aging-associated DNA methylation changes, and single-cell analysis of malaria infection. Our results reveal distinct functional pathways associated with malaria colonization, underscoring the essentiality of explainable representation in high-dimensional data analysis.</summary></entry><entry><title type="html">Efficient multi-prompt evaluation of LLMs</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/EfficientmultipromptevaluationofLLMs.html" rel="alternate" type="text/html" title="Efficient multi-prompt evaluation of LLMs" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/EfficientmultipromptevaluationofLLMs</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/EfficientmultipromptevaluationofLLMs.html">&lt;p&gt;Most popular benchmarks for comparing LLMs rely on a limited set of prompt templates, which may not fully capture the LLMs’ abilities and can affect the reproducibility of results on leaderboards. Many recent works empirically verify prompt sensitivity and advocate for changes in LLM evaluation. In this paper, we consider the problem of estimating the performance distribution across many prompt variants instead of finding a single prompt to evaluate with. We introduce PromptEval, a method for estimating performance across a large set of prompts borrowing strength across prompts and examples to produce accurate estimates under practical evaluation budgets. The resulting distribution can be used to obtain performance quantiles to construct various robust performance metrics (e.g., top 95% quantile or median). We prove that PromptEval consistently estimates the performance distribution and demonstrate its efficacy empirically on three prominent LLM benchmarks: MMLU, BIG-bench Hard, and LMentry; for example, PromptEval can accurately estimate performance quantiles across 100 prompt templates on MMLU with a budget equivalent to two single-prompt evaluations. Moreover, we show how PromptEval can be useful in LLM-as-a-judge and best prompt identification applications.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.17202&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Felipe Maia Polo, Ronald Xu, Lucas Weber, Mírian Silva, Onkar Bhardwaj, Leshem Choshen, Allysson Flavio Melo de Oliveira, Yuekai Sun, Mikhail Yurochkin</name></author><category term="stat.ML" /><summary type="html">Most popular benchmarks for comparing LLMs rely on a limited set of prompt templates, which may not fully capture the LLMs’ abilities and can affect the reproducibility of results on leaderboards. Many recent works empirically verify prompt sensitivity and advocate for changes in LLM evaluation. In this paper, we consider the problem of estimating the performance distribution across many prompt variants instead of finding a single prompt to evaluate with. We introduce PromptEval, a method for estimating performance across a large set of prompts borrowing strength across prompts and examples to produce accurate estimates under practical evaluation budgets. The resulting distribution can be used to obtain performance quantiles to construct various robust performance metrics (e.g., top 95% quantile or median). We prove that PromptEval consistently estimates the performance distribution and demonstrate its efficacy empirically on three prominent LLM benchmarks: MMLU, BIG-bench Hard, and LMentry; for example, PromptEval can accurately estimate performance quantiles across 100 prompt templates on MMLU with a budget equivalent to two single-prompt evaluations. Moreover, we show how PromptEval can be useful in LLM-as-a-judge and best prompt identification applications.</summary></entry><entry><title type="html">EigenVI: score-based variational inference with orthogonal function expansions</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/EigenVIscorebasedvariationalinferencewithorthogonalfunctionexpansions.html" rel="alternate" type="text/html" title="EigenVI: score-based variational inference with orthogonal function expansions" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/EigenVIscorebasedvariationalinferencewithorthogonalfunctionexpansions</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/EigenVIscorebasedvariationalinferencewithorthogonalfunctionexpansions.html">&lt;p&gt;We develop EigenVI, an eigenvalue-based approach for black-box variational inference (BBVI). EigenVI constructs its variational approximations from orthogonal function expansions. For distributions over $\mathbb{R}^D$, the lowest order term in these expansions provides a Gaussian variational approximation, while higher-order terms provide a systematic way to model non-Gaussianity. These approximations are flexible enough to model complex distributions (multimodal, asymmetric), but they are simple enough that one can calculate their low-order moments and draw samples from them. EigenVI can also model other types of random variables (e.g., nonnegative, bounded) by constructing variational approximations from different families of orthogonal functions. Within these families, EigenVI computes the variational approximation that best matches the score function of the target distribution by minimizing a stochastic estimate of the Fisher divergence. Notably, this optimization reduces to solving a minimum eigenvalue problem, so that EigenVI effectively sidesteps the iterative gradient-based optimizations that are required for many other BBVI algorithms. (Gradient-based methods can be sensitive to learning rates, termination criteria, and other tunable hyperparameters.) We use EigenVI to approximate a variety of target distributions, including a benchmark suite of Bayesian models from posteriordb. On these distributions, we find that EigenVI is more accurate than existing methods for Gaussian BBVI.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24054&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Diana Cai, Chirag Modi, Charles C. Margossian, Robert M. Gower, David M. Blei, Lawrence K. Saul</name></author><category term="stat.ML," /><category term="stat.CO" /><summary type="html">We develop EigenVI, an eigenvalue-based approach for black-box variational inference (BBVI). EigenVI constructs its variational approximations from orthogonal function expansions. For distributions over $\mathbb{R}^D$, the lowest order term in these expansions provides a Gaussian variational approximation, while higher-order terms provide a systematic way to model non-Gaussianity. These approximations are flexible enough to model complex distributions (multimodal, asymmetric), but they are simple enough that one can calculate their low-order moments and draw samples from them. EigenVI can also model other types of random variables (e.g., nonnegative, bounded) by constructing variational approximations from different families of orthogonal functions. Within these families, EigenVI computes the variational approximation that best matches the score function of the target distribution by minimizing a stochastic estimate of the Fisher divergence. Notably, this optimization reduces to solving a minimum eigenvalue problem, so that EigenVI effectively sidesteps the iterative gradient-based optimizations that are required for many other BBVI algorithms. (Gradient-based methods can be sensitive to learning rates, termination criteria, and other tunable hyperparameters.) We use EigenVI to approximate a variety of target distributions, including a benchmark suite of Bayesian models from posteriordb. On these distributions, we find that EigenVI is more accurate than existing methods for Gaussian BBVI.</summary></entry><entry><title type="html">Ensemble sampling for linear bandits: small ensembles suffice</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Ensemblesamplingforlinearbanditssmallensemblessuffice.html" rel="alternate" type="text/html" title="Ensemble sampling for linear bandits: small ensembles suffice" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Ensemblesamplingforlinearbanditssmallensemblessuffice</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Ensemblesamplingforlinearbanditssmallensemblessuffice.html">&lt;p&gt;We provide the first useful and rigorous analysis of ensemble sampling for the stochastic linear bandit setting. In particular, we show that, under standard assumptions, for a $d$-dimensional stochastic linear bandit with an interaction horizon $T$, ensemble sampling with an ensemble of size of order $\smash{d \log T}$ incurs regret at most of the order $\smash{(d \log T)^{5/2} \sqrt{T}}$. Ours is the first result in any structured setting not to require the size of the ensemble to scale linearly with $T$ – which defeats the purpose of ensemble sampling – while obtaining near $\smash{\sqrt{T}}$ order regret. Ours is also the first result that allows infinite action sets.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2311.08376&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>David Janz, Alexander E. Litvak, Csaba Szepesvári</name></author><category term="stat.ML" /><summary type="html">We provide the first useful and rigorous analysis of ensemble sampling for the stochastic linear bandit setting. In particular, we show that, under standard assumptions, for a $d$-dimensional stochastic linear bandit with an interaction horizon $T$, ensemble sampling with an ensemble of size of order $\smash{d \log T}$ incurs regret at most of the order $\smash{(d \log T)^{5/2} \sqrt{T}}$. Ours is the first result in any structured setting not to require the size of the ensemble to scale linearly with $T$ – which defeats the purpose of ensemble sampling – while obtaining near $\smash{\sqrt{T}}$ order regret. Ours is also the first result that allows infinite action sets.</summary></entry><entry><title type="html">Epsilon-Greedy Thompson Sampling to Bayesian Optimization</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/EpsilonGreedyThompsonSamplingtoBayesianOptimization.html" rel="alternate" type="text/html" title="Epsilon-Greedy Thompson Sampling to Bayesian Optimization" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/EpsilonGreedyThompsonSamplingtoBayesianOptimization</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/EpsilonGreedyThompsonSamplingtoBayesianOptimization.html">&lt;p&gt;Bayesian optimization (BO) has become a powerful tool for solving simulation-based engineering optimization problems thanks to its ability to integrate physical and mathematical understandings, consider uncertainty, and address the exploitation-exploration dilemma. Thompson sampling (TS) is a preferred solution for BO to handle the exploitation-exploration trade-off. While it prioritizes exploration by generating and minimizing random sample paths from probabilistic models – a fundamental ingredient of BO – TS weakly manages exploitation by gathering information about the true objective function after it obtains new observations. In this work, we improve the exploitation of TS by incorporating the $\varepsilon$-greedy policy, a well-established selection strategy in reinforcement learning. We first delineate two extremes of TS, namely the generic TS and the sample-average TS. The former promotes exploration, while the latter favors exploitation. We then adopt the $\varepsilon$-greedy policy to randomly switch between these two extremes. Small and large values of $\varepsilon$ govern exploitation and exploration, respectively. By minimizing two benchmark functions and solving an inverse problem of a steel cantilever beam, we empirically show that $\varepsilon$-greedy TS equipped with an appropriate $\varepsilon$ is more robust than its two extremes, matching or outperforming the better of the generic TS and the sample-average TS.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2403.00540&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Bach Do, Taiwo Adebiyi, Ruda Zhang</name></author><category term="stat.ML" /><summary type="html">Bayesian optimization (BO) has become a powerful tool for solving simulation-based engineering optimization problems thanks to its ability to integrate physical and mathematical understandings, consider uncertainty, and address the exploitation-exploration dilemma. Thompson sampling (TS) is a preferred solution for BO to handle the exploitation-exploration trade-off. While it prioritizes exploration by generating and minimizing random sample paths from probabilistic models – a fundamental ingredient of BO – TS weakly manages exploitation by gathering information about the true objective function after it obtains new observations. In this work, we improve the exploitation of TS by incorporating the $\varepsilon$-greedy policy, a well-established selection strategy in reinforcement learning. We first delineate two extremes of TS, namely the generic TS and the sample-average TS. The former promotes exploration, while the latter favors exploitation. We then adopt the $\varepsilon$-greedy policy to randomly switch between these two extremes. Small and large values of $\varepsilon$ govern exploitation and exploration, respectively. By minimizing two benchmark functions and solving an inverse problem of a steel cantilever beam, we empirically show that $\varepsilon$-greedy TS equipped with an appropriate $\varepsilon$ is more robust than its two extremes, matching or outperforming the better of the generic TS and the sample-average TS.</summary></entry><entry><title type="html">Fast Rate Information-theoretic Bounds on Generalization Errors</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/FastRateInformationtheoreticBoundsonGeneralizationErrors.html" rel="alternate" type="text/html" title="Fast Rate Information-theoretic Bounds on Generalization Errors" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/FastRateInformationtheoreticBoundsonGeneralizationErrors</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/FastRateInformationtheoreticBoundsonGeneralizationErrors.html">&lt;p&gt;The generalization error of a learning algorithm refers to the discrepancy between the loss of a learning algorithm on training data and that on unseen testing data. Various information-theoretic bounds on the generalization error have been derived in the literature, where the mutual information between the training data and the hypothesis (the output of the learning algorithm) plays an important role. Focusing on the individual sample mutual information bound by Bu et al., which itself is a tightened version of the first bound on the topic by Russo et al. and Xu et al., this paper investigates the tightness of these bounds, in terms of the dependence of their convergence rates on the sample size $n$. It has been recognized that these bounds are in general not tight, readily verified for the exemplary quadratic Gaussian mean estimation problem, where the individual sample mutual information bound scales as $O(\sqrt{1/n})$ while the true generalization error scales as $O(1/n)$. The first contribution of this paper is to show that the same bound can in fact be asymptotically tight if an appropriate assumption is made. In particular, we show that the fast rate can be recovered when the assumption is made on the excess risk instead of the loss function, which was usually done in existing literature. A theoretical justification is given for this choice. The second contribution of the paper is a new set of generalization error bounds based on the $(\eta, c)$-central condition, a condition relatively easy to verify and has the property that the mutual information term directly determines the convergence rate of the bound. Several analytical and numerical examples are given to show the effectiveness of these bounds.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2303.14658&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Xuetong Wu, Jonathan H. Manton, Uwe Aickelin, Jingge Zhu</name></author><category term="stat.ML" /><summary type="html">The generalization error of a learning algorithm refers to the discrepancy between the loss of a learning algorithm on training data and that on unseen testing data. Various information-theoretic bounds on the generalization error have been derived in the literature, where the mutual information between the training data and the hypothesis (the output of the learning algorithm) plays an important role. Focusing on the individual sample mutual information bound by Bu et al., which itself is a tightened version of the first bound on the topic by Russo et al. and Xu et al., this paper investigates the tightness of these bounds, in terms of the dependence of their convergence rates on the sample size $n$. It has been recognized that these bounds are in general not tight, readily verified for the exemplary quadratic Gaussian mean estimation problem, where the individual sample mutual information bound scales as $O(\sqrt{1/n})$ while the true generalization error scales as $O(1/n)$. The first contribution of this paper is to show that the same bound can in fact be asymptotically tight if an appropriate assumption is made. In particular, we show that the fast rate can be recovered when the assumption is made on the excess risk instead of the loss function, which was usually done in existing literature. A theoretical justification is given for this choice. The second contribution of the paper is a new set of generalization error bounds based on the $(\eta, c)$-central condition, a condition relatively easy to verify and has the property that the mutual information term directly determines the convergence rate of the bound. Several analytical and numerical examples are given to show the effectiveness of these bounds.</summary></entry><entry><title type="html">FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/FlowLLMFlowMatchingforMaterialGenerationwithLargeLanguageModelsasBaseDistributions.html" rel="alternate" type="text/html" title="FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/FlowLLMFlowMatchingforMaterialGenerationwithLargeLanguageModelsasBaseDistributions</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/FlowLLMFlowMatchingforMaterialGenerationwithLargeLanguageModelsasBaseDistributions.html">&lt;p&gt;Material discovery is a critical area of research with the potential to revolutionize various fields, including carbon capture, renewable energy, and electronics. However, the immense scale of the chemical space makes it challenging to explore all possible materials experimentally. In this paper, we introduce FlowLLM, a novel generative model that combines large language models (LLMs) and Riemannian flow matching (RFM) to design novel crystalline materials. FlowLLM first fine-tunes an LLM to learn an effective base distribution of meta-stable crystals in a text representation. After converting to a graph representation, the RFM model takes samples from the LLM and iteratively refines the coordinates and lattice parameters. Our approach significantly outperforms state-of-the-art methods, increasing the generation rate of stable materials by over three times and increasing the rate for stable, unique, and novel crystals by $\sim50\%$ - a huge improvement on a difficult problem. Additionally, the crystals generated by FlowLLM are much closer to their relaxed state when compared with another leading model, significantly reducing post-hoc computational cost.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23405&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Anuroop Sriram, Benjamin Kurt Miller, Ricky T. Q. Chen, Brandon M. Wood</name></author><category term="stat.ML" /><summary type="html">Material discovery is a critical area of research with the potential to revolutionize various fields, including carbon capture, renewable energy, and electronics. However, the immense scale of the chemical space makes it challenging to explore all possible materials experimentally. In this paper, we introduce FlowLLM, a novel generative model that combines large language models (LLMs) and Riemannian flow matching (RFM) to design novel crystalline materials. FlowLLM first fine-tunes an LLM to learn an effective base distribution of meta-stable crystals in a text representation. After converting to a graph representation, the RFM model takes samples from the LLM and iteratively refines the coordinates and lattice parameters. Our approach significantly outperforms state-of-the-art methods, increasing the generation rate of stable materials by over three times and increasing the rate for stable, unique, and novel crystals by $\sim50\%$ - a huge improvement on a difficult problem. Additionally, the crystals generated by FlowLLM are much closer to their relaxed state when compared with another leading model, significantly reducing post-hoc computational cost.</summary></entry><entry><title type="html">Fractional Moments by the Moment-Generating Function</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/FractionalMomentsbytheMomentGeneratingFunction.html" rel="alternate" type="text/html" title="Fractional Moments by the Moment-Generating Function" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/FractionalMomentsbytheMomentGeneratingFunction</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/FractionalMomentsbytheMomentGeneratingFunction.html">&lt;p&gt;We introduce a novel method for obtaining a wide variety of moments of a random variable with a well-defined moment-generating function (MGF). We derive new expressions for fractional moments and fractional absolute moments, both central and non-central moments. The new moment expressions are relatively simple integrals that involve the MGF, but do not require its derivatives. We label the new method CMGF because it uses a complex extension of the MGF and can be used to obtain complex moments. We illustrate the new method with three applications where the MGF is available in closed-form, while the corresponding densities and the derivatives of the MGF are either unavailable or very difficult to obtain.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23587&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Peter Reinhard Hansen, Chen Tong</name></author><category term="stat.CO" /><summary type="html">We introduce a novel method for obtaining a wide variety of moments of a random variable with a well-defined moment-generating function (MGF). We derive new expressions for fractional moments and fractional absolute moments, both central and non-central moments. The new moment expressions are relatively simple integrals that involve the MGF, but do not require its derivatives. We label the new method CMGF because it uses a complex extension of the MGF and can be used to obtain complex moments. We illustrate the new method with three applications where the MGF is available in closed-form, while the corresponding densities and the derivatives of the MGF are either unavailable or very difficult to obtain.</summary></entry><entry><title type="html">Gaussian Universality in Neural Network Dynamics with Generalized Structured Input Distributions</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/GaussianUniversalityinNeuralNetworkDynamicswithGeneralizedStructuredInputDistributions.html" rel="alternate" type="text/html" title="Gaussian Universality in Neural Network Dynamics with Generalized Structured Input Distributions" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/GaussianUniversalityinNeuralNetworkDynamicswithGeneralizedStructuredInputDistributions</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/GaussianUniversalityinNeuralNetworkDynamicswithGeneralizedStructuredInputDistributions.html">&lt;p&gt;Bridging the gap between the practical performance of deep learning and its theoretical foundations often involves analyzing neural networks through stochastic gradient descent (SGD). Expanding on previous research that focused on modeling structured inputs under a simple Gaussian setting, we analyze the behavior of a deep learning system trained on inputs modeled as Gaussian mixtures to better simulate more general structured inputs. Through empirical analysis and theoretical investigation, we demonstrate that under certain standardization schemes, the deep learning model converges toward Gaussian setting behavior, even when the input data follow more complex or real-world distributions. This finding exhibits a form of universality in which diverse structured distributions yield results consistent with Gaussian assumptions, which can support the theoretical understanding of deep learning models.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.00642&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jaeyong Bae, Hawoong Jeong</name></author><category term="stat.ML," /><category term="cond-mat.stat-mech" /><summary type="html">Bridging the gap between the practical performance of deep learning and its theoretical foundations often involves analyzing neural networks through stochastic gradient descent (SGD). Expanding on previous research that focused on modeling structured inputs under a simple Gaussian setting, we analyze the behavior of a deep learning system trained on inputs modeled as Gaussian mixtures to better simulate more general structured inputs. Through empirical analysis and theoretical investigation, we demonstrate that under certain standardization schemes, the deep learning model converges toward Gaussian setting behavior, even when the input data follow more complex or real-world distributions. This finding exhibits a form of universality in which diverse structured distributions yield results consistent with Gaussian assumptions, which can support the theoretical understanding of deep learning models.</summary></entry><entry><title type="html">Generative Fractional Diffusion Models</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/GenerativeFractionalDiffusionModels.html" rel="alternate" type="text/html" title="Generative Fractional Diffusion Models" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/GenerativeFractionalDiffusionModels</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/GenerativeFractionalDiffusionModels.html">&lt;p&gt;We introduce the first continuous-time score-based generative model that leverages fractional diffusion processes for its underlying dynamics. Although diffusion models have excelled at capturing data distributions, they still suffer from various limitations such as slow convergence, mode-collapse on imbalanced data, and lack of diversity. These issues are partially linked to the use of light-tailed Brownian motion (BM) with independent increments. In this paper, we replace BM with an approximation of its non-Markovian counterpart, fractional Brownian motion (fBM), characterized by correlated increments and Hurst index $H \in (0,1)$, where $H=0.5$ recovers the classical BM. To ensure tractable inference and learning, we employ a recently popularized Markov approximation of fBM (MA-fBM) and derive its reverse-time model, resulting in generative fractional diffusion models (GFDM). We characterize the forward dynamics using a continuous reparameterization trick and propose augmented score matching to efficiently learn the score function, which is partly known in closed form, at minimal added cost. The ability to drive our diffusion model via MA-fBM offers flexibility and control. $H \leq 0.5$ enters the regime of rough paths whereas $H&amp;gt;0.5$ regularizes diffusion paths and invokes long-term memory. The Markov approximation allows added control by varying the number of Markov processes linearly combined to approximate fBM. Our evaluations on real image datasets demonstrate that GFDM achieves greater pixel-wise diversity and enhanced image quality, as indicated by a lower FID, offering a promising alternative to traditional diffusion models&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2310.17638&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Gabriel Nobis, Maximilian Springenberg, Marco Aversa, Michael Detzel, Rembert Daems, Roderick Murray-Smith, Shinichi Nakajima, Sebastian Lapuschkin, Stefano Ermon, Tolga Birdal, Manfred Opper, Christoph Knochenhauer, Luis Oala, Wojciech Samek</name></author><category term="stat.ML" /><summary type="html">We introduce the first continuous-time score-based generative model that leverages fractional diffusion processes for its underlying dynamics. Although diffusion models have excelled at capturing data distributions, they still suffer from various limitations such as slow convergence, mode-collapse on imbalanced data, and lack of diversity. These issues are partially linked to the use of light-tailed Brownian motion (BM) with independent increments. In this paper, we replace BM with an approximation of its non-Markovian counterpart, fractional Brownian motion (fBM), characterized by correlated increments and Hurst index $H \in (0,1)$, where $H=0.5$ recovers the classical BM. To ensure tractable inference and learning, we employ a recently popularized Markov approximation of fBM (MA-fBM) and derive its reverse-time model, resulting in generative fractional diffusion models (GFDM). We characterize the forward dynamics using a continuous reparameterization trick and propose augmented score matching to efficiently learn the score function, which is partly known in closed form, at minimal added cost. The ability to drive our diffusion model via MA-fBM offers flexibility and control. $H \leq 0.5$ enters the regime of rough paths whereas $H&amp;gt;0.5$ regularizes diffusion paths and invokes long-term memory. The Markov approximation allows added control by varying the number of Markov processes linearly combined to approximate fBM. Our evaluations on real image datasets demonstrate that GFDM achieves greater pixel-wise diversity and enhanced image quality, as indicated by a lower FID, offering a promising alternative to traditional diffusion models</summary></entry><entry><title type="html">Global Convergence in Training Large-Scale Transformers</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/GlobalConvergenceinTrainingLargeScaleTransformers.html" rel="alternate" type="text/html" title="Global Convergence in Training Large-Scale Transformers" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/GlobalConvergenceinTrainingLargeScaleTransformers</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/GlobalConvergenceinTrainingLargeScaleTransformers.html">&lt;p&gt;Despite the widespread success of Transformers across various domains, their optimization guarantees in large-scale model settings are not well-understood. This paper rigorously analyzes the convergence properties of gradient flow in training Transformers with weight decay regularization. First, we construct the mean-field limit of large-scale Transformers, showing that as the model width and depth go to infinity, gradient flow converges to the Wasserstein gradient flow, which is represented by a partial differential equation. Then, we demonstrate that the gradient flow reaches a global minimum consistent with the PDE solution when the weight decay regularization parameter is sufficiently small. Our analysis is based on a series of novel mean-field techniques that adapt to Transformers. Compared with existing tools for deep networks (Lu et al., 2020) that demand homogeneity and global Lipschitz smoothness, we utilize a refined analysis assuming only $\textit{partial homogeneity}$ and $\textit{local Lipschitz smoothness}$. These new techniques may be of independent interest.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23610&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Cheng Gao, Yuan Cao, Zihao Li, Yihan He, Mengdi Wang, Han Liu, Jason Matthew Klusowski, Jianqing Fan</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">Despite the widespread success of Transformers across various domains, their optimization guarantees in large-scale model settings are not well-understood. This paper rigorously analyzes the convergence properties of gradient flow in training Transformers with weight decay regularization. First, we construct the mean-field limit of large-scale Transformers, showing that as the model width and depth go to infinity, gradient flow converges to the Wasserstein gradient flow, which is represented by a partial differential equation. Then, we demonstrate that the gradient flow reaches a global minimum consistent with the PDE solution when the weight decay regularization parameter is sufficiently small. Our analysis is based on a series of novel mean-field techniques that adapt to Transformers. Compared with existing tools for deep networks (Lu et al., 2020) that demand homogeneity and global Lipschitz smoothness, we utilize a refined analysis assuming only $\textit{partial homogeneity}$ and $\textit{local Lipschitz smoothness}$. These new techniques may be of independent interest.</summary></entry><entry><title type="html">Hamiltonian Monte Carlo Inference of Marginalized Linear Mixed-Effects Models</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/HamiltonianMonteCarloInferenceofMarginalizedLinearMixedEffectsModels.html" rel="alternate" type="text/html" title="Hamiltonian Monte Carlo Inference of Marginalized Linear Mixed-Effects Models" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/HamiltonianMonteCarloInferenceofMarginalizedLinearMixedEffectsModels</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/HamiltonianMonteCarloInferenceofMarginalizedLinearMixedEffectsModels.html">&lt;p&gt;Bayesian reasoning in linear mixed-effects models (LMMs) is challenging and often requires advanced sampling techniques like Markov chain Monte Carlo (MCMC). A common approach is to write the model in a probabilistic programming language and then sample via Hamiltonian Monte Carlo (HMC). However, there are many ways a user can transform a model that make inference more or less efficient. In particular, marginalizing some variables can greatly improve inference but is difficult for users to do manually. We develop an algorithm to easily marginalize random effects in LMMs. A naive approach introduces cubic time operations within an inference algorithm like HMC, but we reduce the running time to linear using fast linear algebra techniques. We show that marginalization is always beneficial when applicable and highlight improvements in various models, especially ones from cognitive sciences.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24079&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jinlin Lai, Daniel Sheldon, Justin Domke</name></author><category term="stat.ML" /><summary type="html">Bayesian reasoning in linear mixed-effects models (LMMs) is challenging and often requires advanced sampling techniques like Markov chain Monte Carlo (MCMC). A common approach is to write the model in a probabilistic programming language and then sample via Hamiltonian Monte Carlo (HMC). However, there are many ways a user can transform a model that make inference more or less efficient. In particular, marginalizing some variables can greatly improve inference but is difficult for users to do manually. We develop an algorithm to easily marginalize random effects in LMMs. A naive approach introduces cubic time operations within an inference algorithm like HMC, but we reduce the running time to linear using fast linear algebra techniques. We show that marginalization is always beneficial when applicable and highlight improvements in various models, especially ones from cognitive sciences.</summary></entry><entry><title type="html">Healthy Live Births Should be Considered as Competing Events when Estimating the Total Effect of Prenatal Medication Use on Pregnancy Outcomes</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/HealthyLiveBirthsShouldbeConsideredasCompetingEventswhenEstimatingtheTotalEffectofPrenatalMedicationUseonPregnancyOutcomes.html" rel="alternate" type="text/html" title="Healthy Live Births Should be Considered as Competing Events when Estimating the Total Effect of Prenatal Medication Use on Pregnancy Outcomes" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/HealthyLiveBirthsShouldbeConsideredasCompetingEventswhenEstimatingtheTotalEffectofPrenatalMedicationUseonPregnancyOutcomes</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/HealthyLiveBirthsShouldbeConsideredasCompetingEventswhenEstimatingtheTotalEffectofPrenatalMedicationUseonPregnancyOutcomes.html">&lt;p&gt;Pregnancy loss is recognized as an important competing event in studies of prenatal medication use. However, a healthy live birth also precludes subsequent adverse pregnancy outcomes, yet these events are often censored. Using Monte Carlo simulation, we examine bias that results from failure to account for healthy live birth as a competing event in estimates of the total effect of prenatal medication use on pregnancy outcomes. We simulated data for 12 trials estimating the effect of antihypertensive initiation versus non-initiation on two outcomes: (1) composite fetal death or severe prenatal preeclampsia and (2) small-for-gestational-age (SGA) live birth. We used time-to-event methods to estimate absolute risks, risk differences and risk ratios. For the composite outcome, we conducted two analyses where non-preeclamptic live birth was (1) a censoring event and (2) a competing event. For SGA live birth, we conducted three analyses where fetal death and non-SGA live birth were (1) censoring events, (2) a competing event and censoring event, respectively; and (3) competing events. In all analyses, censoring healthy live births led to inflated absolute risk estimates as well as bias and imprecise treatment effect estimates. Studies of prenatal exposures on pregnancy outcomes should analyze healthy live births as competing risks to estimate unbiased total treatment effects.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23521&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Chase D. Latour, Mark Klose, Jessie K. Edwards, Zoey Song, Michele Jonsson Funk, Mollie E. Wood</name></author><category term="stat.AP" /><summary type="html">Pregnancy loss is recognized as an important competing event in studies of prenatal medication use. However, a healthy live birth also precludes subsequent adverse pregnancy outcomes, yet these events are often censored. Using Monte Carlo simulation, we examine bias that results from failure to account for healthy live birth as a competing event in estimates of the total effect of prenatal medication use on pregnancy outcomes. We simulated data for 12 trials estimating the effect of antihypertensive initiation versus non-initiation on two outcomes: (1) composite fetal death or severe prenatal preeclampsia and (2) small-for-gestational-age (SGA) live birth. We used time-to-event methods to estimate absolute risks, risk differences and risk ratios. For the composite outcome, we conducted two analyses where non-preeclamptic live birth was (1) a censoring event and (2) a competing event. For SGA live birth, we conducted three analyses where fetal death and non-SGA live birth were (1) censoring events, (2) a competing event and censoring event, respectively; and (3) competing events. In all analyses, censoring healthy live births led to inflated absolute risk estimates as well as bias and imprecise treatment effect estimates. Studies of prenatal exposures on pregnancy outcomes should analyze healthy live births as competing risks to estimate unbiased total treatment effects.</summary></entry><entry><title type="html">High-Dimensional Tensor Discriminant Analysis with Incomplete Tensors</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/HighDimensionalTensorDiscriminantAnalysiswithIncompleteTensors.html" rel="alternate" type="text/html" title="High-Dimensional Tensor Discriminant Analysis with Incomplete Tensors" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/HighDimensionalTensorDiscriminantAnalysiswithIncompleteTensors</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/HighDimensionalTensorDiscriminantAnalysiswithIncompleteTensors.html">&lt;p&gt;Tensor classification is gaining importance across fields, yet handling partially observed data remains challenging. In this paper, we introduce a novel approach to tensor classification with incomplete data, framed within high-dimensional tensor linear discriminant analysis. Specifically, we consider a high-dimensional tensor predictor with missing observations under the Missing Completely at Random (MCR) assumption and employ the Tensor Gaussian Mixture Model (TGMM) to capture the relationship between the tensor predictor and class label. We propose a Tensor Linear Discriminant Analysis with Missing Data (Tensor LDA-MD) algorithm, which manages high-dimensional tensor predictors with missing entries by leveraging the decomposable low-rank structure of the discriminant tensor. Our work establishes convergence rates for the estimation error of the discriminant tensor with incomplete data and minimax optimal bounds for the misclassification rate, addressing key gaps in the literature. Additionally, we derive large deviation bounds for the generalized mode-wise sample covariance matrix and its inverse, which are crucial tools in our analysis and hold independent interest. Our method demonstrates excellent performance in simulations and real data analysis, even with significant proportions of missing data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.14783&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Elynn Chen, Yuefeng Han, Jiayu Li</name></author><category term="stat.ML," /><category term="stat.ME" /><summary type="html">Tensor classification is gaining importance across fields, yet handling partially observed data remains challenging. In this paper, we introduce a novel approach to tensor classification with incomplete data, framed within high-dimensional tensor linear discriminant analysis. Specifically, we consider a high-dimensional tensor predictor with missing observations under the Missing Completely at Random (MCR) assumption and employ the Tensor Gaussian Mixture Model (TGMM) to capture the relationship between the tensor predictor and class label. We propose a Tensor Linear Discriminant Analysis with Missing Data (Tensor LDA-MD) algorithm, which manages high-dimensional tensor predictors with missing entries by leveraging the decomposable low-rank structure of the discriminant tensor. Our work establishes convergence rates for the estimation error of the discriminant tensor with incomplete data and minimax optimal bounds for the misclassification rate, addressing key gaps in the literature. Additionally, we derive large deviation bounds for the generalized mode-wise sample covariance matrix and its inverse, which are crucial tools in our analysis and hold independent interest. Our method demonstrates excellent performance in simulations and real data analysis, even with significant proportions of missing data.</summary></entry><entry><title type="html">How Do Flow Matching Models Memorize and Generalize in Sample Data Subspaces?</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/HowDoFlowMatchingModelsMemorizeandGeneralizeinSampleDataSubspaces.html" rel="alternate" type="text/html" title="How Do Flow Matching Models Memorize and Generalize in Sample Data Subspaces?" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/HowDoFlowMatchingModelsMemorizeandGeneralizeinSampleDataSubspaces</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/HowDoFlowMatchingModelsMemorizeandGeneralizeinSampleDataSubspaces.html">&lt;p&gt;Real-world data is often assumed to lie within a low-dimensional structure embedded in high-dimensional space. In practical settings, we observe only a finite set of samples, forming what we refer to as the sample data subspace. It serves an essential approximation supporting tasks such as dimensionality reduction and generation. A major challenge lies in whether generative models can reliably synthesize samples that stay within this subspace rather than drifting away from the underlying structure. In this work, we provide theoretical insights into this challenge by leveraging Flow Matching models, which transform a simple prior into a complex target distribution via a learned velocity field. By treating the real data distribution as discrete, we derive analytical expressions for the optimal velocity field under a Gaussian prior, showing that generated samples memorize real data points and represent the sample data subspace exactly. To generalize to suboptimal scenarios, we introduce the Orthogonal Subspace Decomposition Network (OSDNet), which systematically decomposes the velocity field into subspace and off-subspace components. Our analysis shows that the off-subspace component decays, while the subspace component generalizes within the sample data subspace, ensuring generated samples preserve both proximity and diversity.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23594&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Weiguo Gao, Ming Li</name></author><category term="stat.ML" /><summary type="html">Real-world data is often assumed to lie within a low-dimensional structure embedded in high-dimensional space. In practical settings, we observe only a finite set of samples, forming what we refer to as the sample data subspace. It serves an essential approximation supporting tasks such as dimensionality reduction and generation. A major challenge lies in whether generative models can reliably synthesize samples that stay within this subspace rather than drifting away from the underlying structure. In this work, we provide theoretical insights into this challenge by leveraging Flow Matching models, which transform a simple prior into a complex target distribution via a learned velocity field. By treating the real data distribution as discrete, we derive analytical expressions for the optimal velocity field under a Gaussian prior, showing that generated samples memorize real data points and represent the sample data subspace exactly. To generalize to suboptimal scenarios, we introduce the Orthogonal Subspace Decomposition Network (OSDNet), which systematically decomposes the velocity field into subspace and off-subspace components. Our analysis shows that the off-subspace component decays, while the subspace component generalizes within the sample data subspace, ensuring generated samples preserve both proximity and diversity.</summary></entry><entry><title type="html">Hypothesis testing with e-values</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Hypothesistestingwithevalues.html" rel="alternate" type="text/html" title="Hypothesis testing with e-values" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Hypothesistestingwithevalues</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Hypothesistestingwithevalues.html">&lt;p&gt;This book is written to offer a humble, but unified, treatment of e-values in hypothesis testing. The book is organized into three parts: Fundamental Concepts, Core Ideas, and Advanced Topics. The first part includes three chapters that introduce the basic concepts. The second part includes five chapters of core ideas such as universal inference, log-optimality, e-processes, operations on e-values, and e-values in multiple testing. The third part contains five chapters of advanced topics. We hope that, by putting the materials together in this book, the concept of e-values becomes more accessible for educational, research, and practical use.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23614&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Aaditya Ramdas, Ruodu Wang</name></author><category term="stat.ME," /><category term="stat.TH" /><summary type="html">This book is written to offer a humble, but unified, treatment of e-values in hypothesis testing. The book is organized into three parts: Fundamental Concepts, Core Ideas, and Advanced Topics. The first part includes three chapters that introduce the basic concepts. The second part includes five chapters of core ideas such as universal inference, log-optimality, e-processes, operations on e-values, and e-values in multiple testing. The third part contains five chapters of advanced topics. We hope that, by putting the materials together in this book, the concept of e-values becomes more accessible for educational, research, and practical use.</summary></entry><entry><title type="html">Identifiability Guarantees for Causal Disentanglement from Purely Observational Data</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/IdentifiabilityGuaranteesforCausalDisentanglementfromPurelyObservationalData.html" rel="alternate" type="text/html" title="Identifiability Guarantees for Causal Disentanglement from Purely Observational Data" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/IdentifiabilityGuaranteesforCausalDisentanglementfromPurelyObservationalData</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/IdentifiabilityGuaranteesforCausalDisentanglementfromPurelyObservationalData.html">&lt;p&gt;Causal disentanglement aims to learn about latent causal factors behind data, holding the promise to augment existing representation learning methods in terms of interpretability and extrapolation. Recent advances establish identifiability results assuming that interventions on (single) latent factors are available; however, it remains debatable whether such assumptions are reasonable due to the inherent nature of intervening on latent variables. Accordingly, we reconsider the fundamentals and ask what can be learned using just observational data.
  We provide a precise characterization of latent factors that can be identified in nonlinear causal models with additive Gaussian noise and linear mixing, without any interventions or graphical restrictions. In particular, we show that the causal variables can be identified up to a layer-wise transformation and that further disentanglement is not possible. We transform these theoretical results into a practical algorithm consisting of solving a quadratic program over the score estimation of the observed data. We provide simulation results to support our theoretical guarantees and demonstrate that our algorithm can derive meaningful causal representations from purely observational data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23620&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ryan Welch, Jiaqi Zhang, Caroline Uhler</name></author><category term="stat.ML" /><summary type="html">Causal disentanglement aims to learn about latent causal factors behind data, holding the promise to augment existing representation learning methods in terms of interpretability and extrapolation. Recent advances establish identifiability results assuming that interventions on (single) latent factors are available; however, it remains debatable whether such assumptions are reasonable due to the inherent nature of intervening on latent variables. Accordingly, we reconsider the fundamentals and ask what can be learned using just observational data. We provide a precise characterization of latent factors that can be identified in nonlinear causal models with additive Gaussian noise and linear mixing, without any interventions or graphical restrictions. In particular, we show that the causal variables can be identified up to a layer-wise transformation and that further disentanglement is not possible. We transform these theoretical results into a practical algorithm consisting of solving a quadratic program over the score estimation of the observed data. We provide simulation results to support our theoretical guarantees and demonstrate that our algorithm can derive meaningful causal representations from purely observational data.</summary></entry><entry><title type="html">Identifying General Mechanism Shifts in Linear Causal Representations</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/IdentifyingGeneralMechanismShiftsinLinearCausalRepresentations.html" rel="alternate" type="text/html" title="Identifying General Mechanism Shifts in Linear Causal Representations" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/IdentifyingGeneralMechanismShiftsinLinearCausalRepresentations</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/IdentifyingGeneralMechanismShiftsinLinearCausalRepresentations.html">&lt;p&gt;We consider the linear causal representation learning setting where we observe a linear mixing of $d$ unknown latent factors, which follow a linear structural causal model. Recent work has shown that it is possible to recover the latent factors as well as the underlying structural causal model over them, up to permutation and scaling, provided that we have at least $d$ environments, each of which corresponds to perfect interventions on a single latent node (factor). After this powerful result, a key open problem faced by the community has been to relax these conditions: allow for coarser than perfect single-node interventions, and allow for fewer than $d$ of them, since the number of latent factors $d$ could be very large. In this work, we consider precisely such a setting, where we allow a smaller than $d$ number of environments, and also allow for very coarse interventions that can very coarsely \textit{change the entire causal graph over the latent factors}. On the flip side, we relax what we wish to extract to simply the \textit{list of nodes that have shifted between one or more environments}. We provide a surprising identifiability result that it is indeed possible, under some very mild standard assumptions, to identify the set of shifted nodes. Our identifiability proof moreover is a constructive one: we explicitly provide necessary and sufficient conditions for a node to be a shifted node, and show that we can check these conditions given observed data. Our algorithm lends itself very naturally to the sample setting where instead of just interventional distributions, we are provided datasets of samples from each of these distributions. We corroborate our results on both synthetic experiments as well as an interesting psychometric dataset. The code can be found at https://github.com/TianyuCodings/iLCS.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24059&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Tianyu Chen, Kevin Bello, Francesco Locatello, Bryon Aragam, Pradeep Ravikumar</name></author><category term="stat.ML" /><summary type="html">We consider the linear causal representation learning setting where we observe a linear mixing of $d$ unknown latent factors, which follow a linear structural causal model. Recent work has shown that it is possible to recover the latent factors as well as the underlying structural causal model over them, up to permutation and scaling, provided that we have at least $d$ environments, each of which corresponds to perfect interventions on a single latent node (factor). After this powerful result, a key open problem faced by the community has been to relax these conditions: allow for coarser than perfect single-node interventions, and allow for fewer than $d$ of them, since the number of latent factors $d$ could be very large. In this work, we consider precisely such a setting, where we allow a smaller than $d$ number of environments, and also allow for very coarse interventions that can very coarsely \textit{change the entire causal graph over the latent factors}. On the flip side, we relax what we wish to extract to simply the \textit{list of nodes that have shifted between one or more environments}. We provide a surprising identifiability result that it is indeed possible, under some very mild standard assumptions, to identify the set of shifted nodes. Our identifiability proof moreover is a constructive one: we explicitly provide necessary and sufficient conditions for a node to be a shifted node, and show that we can check these conditions given observed data. Our algorithm lends itself very naturally to the sample setting where instead of just interventional distributions, we are provided datasets of samples from each of these distributions. We corroborate our results on both synthetic experiments as well as an interesting psychometric dataset. The code can be found at https://github.com/TianyuCodings/iLCS.</summary></entry><entry><title type="html">Implicit Optimization Bias of Next-Token Prediction in Linear Models</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/ImplicitOptimizationBiasofNextTokenPredictioninLinearModels.html" rel="alternate" type="text/html" title="Implicit Optimization Bias of Next-Token Prediction in Linear Models" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/ImplicitOptimizationBiasofNextTokenPredictioninLinearModels</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/ImplicitOptimizationBiasofNextTokenPredictioninLinearModels.html">&lt;p&gt;We initiate an investigation into the optimization properties of next-token prediction (NTP), the dominant training paradigm for modern language models. Specifically, we study the structural properties of the solutions selected by gradient-based optimizers among the many possible minimizers of the NTP objective. By framing NTP as cross-entropy minimization across distinct contexts, each tied with a sparse conditional probability distribution across a finite vocabulary of tokens, we introduce “NTP-separability conditions” that enable reaching the data-entropy lower bound. With this setup, and focusing on linear models with fixed context embeddings, we characterize the optimization bias of gradient descent (GD): Within the data subspace defined by the sparsity patterns of distinct contexts, GD selects parameters that equate the logits’ differences of in-support tokens to their log-odds. In the orthogonal subspace, the GD parameters diverge in norm and select the direction that maximizes a margin specific to NTP. These findings extend previous research on implicit bias in one-hot classification to the NTP setting, highlighting key differences and prompting further research into the optimization and generalization properties of NTP, irrespective of the specific architecture used to generate the context embeddings.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.18551&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Christos Thrampoulidis</name></author><category term="stat.ML" /><summary type="html">We initiate an investigation into the optimization properties of next-token prediction (NTP), the dominant training paradigm for modern language models. Specifically, we study the structural properties of the solutions selected by gradient-based optimizers among the many possible minimizers of the NTP objective. By framing NTP as cross-entropy minimization across distinct contexts, each tied with a sparse conditional probability distribution across a finite vocabulary of tokens, we introduce “NTP-separability conditions” that enable reaching the data-entropy lower bound. With this setup, and focusing on linear models with fixed context embeddings, we characterize the optimization bias of gradient descent (GD): Within the data subspace defined by the sparsity patterns of distinct contexts, GD selects parameters that equate the logits’ differences of in-support tokens to their log-odds. In the orthogonal subspace, the GD parameters diverge in norm and select the direction that maximizes a margin specific to NTP. These findings extend previous research on implicit bias in one-hot classification to the NTP setting, highlighting key differences and prompting further research into the optimization and generalization properties of NTP, irrespective of the specific architecture used to generate the context embeddings.</summary></entry><entry><title type="html">Improve the Precision of Area Under the Curve Estimation for Recurrent Events Through Covariate Adjustment</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/ImprovethePrecisionofAreaUndertheCurveEstimationforRecurrentEventsThroughCovariateAdjustment.html" rel="alternate" type="text/html" title="Improve the Precision of Area Under the Curve Estimation for Recurrent Events Through Covariate Adjustment" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/ImprovethePrecisionofAreaUndertheCurveEstimationforRecurrentEventsThroughCovariateAdjustment</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/ImprovethePrecisionofAreaUndertheCurveEstimationforRecurrentEventsThroughCovariateAdjustment.html">&lt;p&gt;The area under the curve (AUC) of the mean cumulative function (MCF) has recently been introduced as a novel estimand for evaluating treatment effects in recurrent event settings, capturing a totality of evidence in relation to disease progression. While the Lin-Wei-Yang-Ying (LWYY) model is commonly used for analyzing recurrent events, it relies on the proportional rate assumption between treatment arms, which is often violated in practice. In contrast, the AUC under MCFs does not depend on such proportionality assumptions and offers a clinically interpretable measure of treatment effect. To improve the precision of the AUC estimation while preserving its unconditional interpretability, we propose a nonparametric covariate adjustment approach. This approach guarantees efficiency gain compared to unadjusted analysis, as demonstrated by theoretical asymptotic distributions, and is universally applicable to various randomization schemes, including both simple and covariate-adaptive designs. Extensive simulations across different scenarios further support its advantage in increasing statistical power. Our findings highlight the importance of covariate adjustment for the analysis of AUC in recurrent event settings, offering practical guidance for its application in randomized clinical trials.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24163&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jiren Sun, Tuo Wang, Yanyao Yi, Ting Ye, Jun Shao, Yu Du</name></author><category term="stat.ME," /><category term="stat.AP," /><category term="stat.TH" /><summary type="html">The area under the curve (AUC) of the mean cumulative function (MCF) has recently been introduced as a novel estimand for evaluating treatment effects in recurrent event settings, capturing a totality of evidence in relation to disease progression. While the Lin-Wei-Yang-Ying (LWYY) model is commonly used for analyzing recurrent events, it relies on the proportional rate assumption between treatment arms, which is often violated in practice. In contrast, the AUC under MCFs does not depend on such proportionality assumptions and offers a clinically interpretable measure of treatment effect. To improve the precision of the AUC estimation while preserving its unconditional interpretability, we propose a nonparametric covariate adjustment approach. This approach guarantees efficiency gain compared to unadjusted analysis, as demonstrated by theoretical asymptotic distributions, and is universally applicable to various randomization schemes, including both simple and covariate-adaptive designs. Extensive simulations across different scenarios further support its advantage in increasing statistical power. Our findings highlight the importance of covariate adjustment for the analysis of AUC in recurrent event settings, offering practical guidance for its application in randomized clinical trials.</summary></entry><entry><title type="html">Improving Linear System Solvers for Hyperparameter Optimisation in Iterative Gaussian Processes</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/ImprovingLinearSystemSolversforHyperparameterOptimisationinIterativeGaussianProcesses.html" rel="alternate" type="text/html" title="Improving Linear System Solvers for Hyperparameter Optimisation in Iterative Gaussian Processes" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/ImprovingLinearSystemSolversforHyperparameterOptimisationinIterativeGaussianProcesses</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/ImprovingLinearSystemSolversforHyperparameterOptimisationinIterativeGaussianProcesses.html">&lt;p&gt;Scaling hyperparameter optimisation to very large datasets remains an open problem in the Gaussian process community. This paper focuses on iterative methods, which use linear system solvers, like conjugate gradients, alternating projections or stochastic gradient descent, to construct an estimate of the marginal likelihood gradient. We discuss three key improvements which are applicable across solvers: (i) a pathwise gradient estimator, which reduces the required number of solver iterations and amortises the computational cost of making predictions, (ii) warm starting linear system solvers with the solution from the previous step, which leads to faster solver convergence at the cost of negligible bias, (iii) early stopping linear system solvers after a limited computational budget, which synergises with warm starting, allowing solver progress to accumulate over multiple marginal likelihood steps. These techniques provide speed-ups of up to $72\times$ when solving to tolerance, and decrease the average residual norm by up to $7\times$ when stopping early.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.18457&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jihao Andreas Lin, Shreyas Padhy, Bruno Mlodozeniec, Javier Antorán, José Miguel Hernández-Lobato</name></author><category term="stat.ML" /><summary type="html">Scaling hyperparameter optimisation to very large datasets remains an open problem in the Gaussian process community. This paper focuses on iterative methods, which use linear system solvers, like conjugate gradients, alternating projections or stochastic gradient descent, to construct an estimate of the marginal likelihood gradient. We discuss three key improvements which are applicable across solvers: (i) a pathwise gradient estimator, which reduces the required number of solver iterations and amortises the computational cost of making predictions, (ii) warm starting linear system solvers with the solution from the previous step, which leads to faster solver convergence at the cost of negligible bias, (iii) early stopping linear system solvers after a limited computational budget, which synergises with warm starting, allowing solver progress to accumulate over multiple marginal likelihood steps. These techniques provide speed-ups of up to $72\times$ when solving to tolerance, and decrease the average residual norm by up to $7\times$ when stopping early.</summary></entry><entry><title type="html">Infeasible Deterministic, Stochastic, and Variance-Reduction Algorithms for Optimization under Orthogonality Constraints</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/InfeasibleDeterministicStochasticandVarianceReductionAlgorithmsforOptimizationunderOrthogonalityConstraints.html" rel="alternate" type="text/html" title="Infeasible Deterministic, Stochastic, and Variance-Reduction Algorithms for Optimization under Orthogonality Constraints" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/InfeasibleDeterministicStochasticandVarianceReductionAlgorithmsforOptimizationunderOrthogonalityConstraints</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/InfeasibleDeterministicStochasticandVarianceReductionAlgorithmsforOptimizationunderOrthogonalityConstraints.html">&lt;p&gt;Orthogonality constraints naturally appear in many machine learning problems, from principal component analysis to robust neural network training. They are usually solved using Riemannian optimization algorithms, which minimize the objective function while enforcing the constraint. However, enforcing the orthogonality constraint can be the most time-consuming operation in such algorithms. Recently, Ablin &amp;amp; Peyr&apos;e (2022) proposed the landing algorithm, a method with cheap iterations that does not enforce the orthogonality constraints but is attracted towards the manifold in a smooth manner. This article provides new practical and theoretical developments for the landing algorithm. First, the method is extended to the Stiefel manifold, the set of rectangular orthogonal matrices. We also consider stochastic and variance reduction algorithms when the cost function is an average of many functions. We demonstrate that all these methods have the same rate of convergence as their Riemannian counterparts that exactly enforce the constraint, and converge to the manifold. Finally, our experiments demonstrate the promise of our approach to an array of machine-learning problems that involve orthogonality constraints.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2303.16510&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Pierre Ablin, Simon Vary, Bin Gao, P. -A. Absil</name></author><category term="stat.ML" /><summary type="html">Orthogonality constraints naturally appear in many machine learning problems, from principal component analysis to robust neural network training. They are usually solved using Riemannian optimization algorithms, which minimize the objective function while enforcing the constraint. However, enforcing the orthogonality constraint can be the most time-consuming operation in such algorithms. Recently, Ablin &amp;amp; Peyr&apos;e (2022) proposed the landing algorithm, a method with cheap iterations that does not enforce the orthogonality constraints but is attracted towards the manifold in a smooth manner. This article provides new practical and theoretical developments for the landing algorithm. First, the method is extended to the Stiefel manifold, the set of rectangular orthogonal matrices. We also consider stochastic and variance reduction algorithms when the cost function is an average of many functions. We demonstrate that all these methods have the same rate of convergence as their Riemannian counterparts that exactly enforce the constraint, and converge to the manifold. Finally, our experiments demonstrate the promise of our approach to an array of machine-learning problems that involve orthogonality constraints.</summary></entry><entry><title type="html">Inference via Interpolation: Contrastive Representations Provably Enable Planning and Inference</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/InferenceviaInterpolationContrastiveRepresentationsProvablyEnablePlanningandInference.html" rel="alternate" type="text/html" title="Inference via Interpolation: Contrastive Representations Provably Enable Planning and Inference" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/InferenceviaInterpolationContrastiveRepresentationsProvablyEnablePlanningandInference</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/InferenceviaInterpolationContrastiveRepresentationsProvablyEnablePlanningandInference.html">&lt;p&gt;Given time series data, how can we answer questions like “what will happen in the future?” and “how did we get here?” These sorts of probabilistic inference questions are challenging when observations are high-dimensional. In this paper, we show how these questions can have compact, closed form solutions in terms of learned representations. The key idea is to apply a variant of contrastive learning to time series data. Prior work already shows that the representations learned by contrastive learning encode a probability ratio. By extending prior work to show that the marginal distribution over representations is Gaussian, we can then prove that joint distribution of representations is also Gaussian. Taken together, these results show that representations learned via temporal contrastive learning follow a Gauss-Markov chain, a graphical model where inference (e.g., prediction, planning) over representations corresponds to inverting a low-dimensional matrix. In one special case, inferring intermediate representations will be equivalent to interpolating between the learned representations. We validate our theory using numerical simulations on tasks up to 46-dimensions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2403.04082&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Benjamin Eysenbach, Vivek Myers, Ruslan Salakhutdinov, Sergey Levine</name></author><category term="stat.ML" /><summary type="html">Given time series data, how can we answer questions like “what will happen in the future?” and “how did we get here?” These sorts of probabilistic inference questions are challenging when observations are high-dimensional. In this paper, we show how these questions can have compact, closed form solutions in terms of learned representations. The key idea is to apply a variant of contrastive learning to time series data. Prior work already shows that the representations learned by contrastive learning encode a probability ratio. By extending prior work to show that the marginal distribution over representations is Gaussian, we can then prove that joint distribution of representations is also Gaussian. Taken together, these results show that representations learned via temporal contrastive learning follow a Gauss-Markov chain, a graphical model where inference (e.g., prediction, planning) over representations corresponds to inverting a low-dimensional matrix. In one special case, inferring intermediate representations will be equivalent to interpolating between the learned representations. We validate our theory using numerical simulations on tasks up to 46-dimensions.</summary></entry><entry><title type="html">Interaction-Force Transport Gradient Flows</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/InteractionForceTransportGradientFlows.html" rel="alternate" type="text/html" title="Interaction-Force Transport Gradient Flows" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/InteractionForceTransportGradientFlows</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/InteractionForceTransportGradientFlows.html">&lt;p&gt;This paper presents a new gradient flow dissipation geometry over non-negative and probability measures. This is motivated by a principled construction that combines the unbalanced optimal transport and interaction forces modeled by reproducing kernels. Using a precise connection between the Hellinger geometry and the maximum mean discrepancy (MMD), we propose the interaction-force transport (IFT) gradient flows and its spherical variant via an infimal convolution of the Wasserstein and spherical MMD tensors. We then develop a particle-based optimization algorithm based on the JKO-splitting scheme of the mass-preserving spherical IFT gradient flows. Finally, we provide both theoretical global exponential convergence guarantees and improved empirical simulation results for applying the IFT gradient flows to the sampling task of MMD-minimization. Furthermore, we prove that the spherical IFT gradient flow enjoys the best of both worlds by providing the global exponential convergence guarantee for both the MMD and KL energy.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.17075&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Egor Gladin, Pavel Dvurechensky, Alexander Mielke, Jia-Jie Zhu</name></author><category term="stat.ML" /><summary type="html">This paper presents a new gradient flow dissipation geometry over non-negative and probability measures. This is motivated by a principled construction that combines the unbalanced optimal transport and interaction forces modeled by reproducing kernels. Using a precise connection between the Hellinger geometry and the maximum mean discrepancy (MMD), we propose the interaction-force transport (IFT) gradient flows and its spherical variant via an infimal convolution of the Wasserstein and spherical MMD tensors. We then develop a particle-based optimization algorithm based on the JKO-splitting scheme of the mass-preserving spherical IFT gradient flows. Finally, we provide both theoretical global exponential convergence guarantees and improved empirical simulation results for applying the IFT gradient flows to the sampling task of MMD-minimization. Furthermore, we prove that the spherical IFT gradient flow enjoys the best of both worlds by providing the global exponential convergence guarantee for both the MMD and KL energy.</summary></entry><entry><title type="html">Kernel-Based Function Approximation for Average Reward Reinforcement Learning: An Optimist No-Regret Algorithm</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/KernelBasedFunctionApproximationforAverageRewardReinforcementLearningAnOptimistNoRegretAlgorithm.html" rel="alternate" type="text/html" title="Kernel-Based Function Approximation for Average Reward Reinforcement Learning: An Optimist No-Regret Algorithm" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/KernelBasedFunctionApproximationforAverageRewardReinforcementLearningAnOptimistNoRegretAlgorithm</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/KernelBasedFunctionApproximationforAverageRewardReinforcementLearningAnOptimistNoRegretAlgorithm.html">&lt;p&gt;Reinforcement learning utilizing kernel ridge regression to predict the expected value function represents a powerful method with great representational capacity. This setting is a highly versatile framework amenable to analytical results. We consider kernel-based function approximation for RL in the infinite horizon average reward setting, also referred to as the undiscounted setting. We propose an optimistic algorithm, similar to acquisition function based algorithms in the special case of bandits. We establish novel no-regret performance guarantees for our algorithm, under kernel-based modelling assumptions. Additionally, we derive a novel confidence interval for the kernel-based prediction of the expected value function, applicable across various RL problems.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23498&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Sattar Vakili, Julia Olkhovskaya</name></author><category term="stat.ML" /><summary type="html">Reinforcement learning utilizing kernel ridge regression to predict the expected value function represents a powerful method with great representational capacity. This setting is a highly versatile framework amenable to analytical results. We consider kernel-based function approximation for RL in the infinite horizon average reward setting, also referred to as the undiscounted setting. We propose an optimistic algorithm, similar to acquisition function based algorithms in the special case of bandits. We establish novel no-regret performance guarantees for our algorithm, under kernel-based modelling assumptions. Additionally, we derive a novel confidence interval for the kernel-based prediction of the expected value function, applicable across various RL problems.</summary></entry><entry><title type="html">Large language model validity via enhanced conformal prediction methods</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Largelanguagemodelvalidityviaenhancedconformalpredictionmethods.html" rel="alternate" type="text/html" title="Large language model validity via enhanced conformal prediction methods" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Largelanguagemodelvalidityviaenhancedconformalpredictionmethods</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Largelanguagemodelvalidityviaenhancedconformalpredictionmethods.html">&lt;p&gt;We develop new conformal inference methods for obtaining validity guarantees on the output of large language models (LLMs). Prior work in conformal language modeling identifies a subset of the text that satisfies a high-probability guarantee of correctness. These methods work by filtering claims from the LLM’s original response if a scoring function evaluated on the claim fails to exceed a threshold calibrated via split conformal prediction. Existing methods in this area suffer from two deficiencies. First, the guarantee stated is not conditionally valid. The trustworthiness of the filtering step may vary based on the topic of the response. Second, because the scoring function is imperfect, the filtering step can remove many valuable and accurate claims. We address both of these challenges via two new conformal methods. First, we generalize the conditional conformal procedure of Gibbs et al. (2023) in order to adaptively issue weaker guarantees when they are required to preserve the utility of the output. Second, we show how to systematically improve the quality of the scoring function via a novel algorithm for differentiating through the conditional conformal procedure. We demonstrate the efficacy of our approach on biography and medical question-answering datasets.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.09714&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>John J. Cherian, Isaac Gibbs, Emmanuel J. Candès</name></author><category term="stat.ML," /><category term="stat.ME" /><summary type="html">We develop new conformal inference methods for obtaining validity guarantees on the output of large language models (LLMs). Prior work in conformal language modeling identifies a subset of the text that satisfies a high-probability guarantee of correctness. These methods work by filtering claims from the LLM’s original response if a scoring function evaluated on the claim fails to exceed a threshold calibrated via split conformal prediction. Existing methods in this area suffer from two deficiencies. First, the guarantee stated is not conditionally valid. The trustworthiness of the filtering step may vary based on the topic of the response. Second, because the scoring function is imperfect, the filtering step can remove many valuable and accurate claims. We address both of these challenges via two new conformal methods. First, we generalize the conditional conformal procedure of Gibbs et al. (2023) in order to adaptively issue weaker guarantees when they are required to preserve the utility of the output. Second, we show how to systematically improve the quality of the scoring function via a novel algorithm for differentiating through the conditional conformal procedure. We demonstrate the efficacy of our approach on biography and medical question-answering datasets.</summary></entry><entry><title type="html">Lasso Multinomial Performance Indicators for in-play Basketball Data</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/LassoMultinomialPerformanceIndicatorsforinplayBasketballData.html" rel="alternate" type="text/html" title="Lasso Multinomial Performance Indicators for in-play Basketball Data" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/LassoMultinomialPerformanceIndicatorsforinplayBasketballData</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/LassoMultinomialPerformanceIndicatorsforinplayBasketballData.html">&lt;p&gt;A typical approach to quantify the contribution of each player in basketball uses the plus-minus method. The ratings obtained by such a method are estimated using simple regression models and their regularized variants, with response variable being either the points scored or the point differences. To capture more precisely the effect of each player, detailed possession-based play-by-play data may be used. This is the direction we take in this article, in which we investigate the performance of regularized adjusted plus-minus (RAPM) indicators estimated by different regularized models having as a response the number of points scored in each possession. Therefore, we use possession play-by-play data from all NBA games for the season 2021-22 (322,852 possessions). We initially present simple regression model-based indices starting from the implementation of ridge regression which is the standard technique in the relevant literature. We proceed with the lasso approach which has specific advantages and better performance than ridge regression when compared with selected objective validation criteria. Then, we implement regularized binary and multinomial logistic regression models to obtain more accurate performance indicators since the response is a discrete variable taking values mainly from zero to three. Our final proposal is an improved RAPM measure which is based on the expected points of a multinomial logistic regression model where each player’s contribution is weighted by his participation in the team’s possessions. The proposed indicator, called weighted expected points (wEPTS), outperforms all other RAPM measures we investigate in this study.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.09895&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Argyro Damoulaki, Ioannis Ntzoufras, Konstantinos Pelechrinis</name></author><category term="stat.AP" /><summary type="html">A typical approach to quantify the contribution of each player in basketball uses the plus-minus method. The ratings obtained by such a method are estimated using simple regression models and their regularized variants, with response variable being either the points scored or the point differences. To capture more precisely the effect of each player, detailed possession-based play-by-play data may be used. This is the direction we take in this article, in which we investigate the performance of regularized adjusted plus-minus (RAPM) indicators estimated by different regularized models having as a response the number of points scored in each possession. Therefore, we use possession play-by-play data from all NBA games for the season 2021-22 (322,852 possessions). We initially present simple regression model-based indices starting from the implementation of ridge regression which is the standard technique in the relevant literature. We proceed with the lasso approach which has specific advantages and better performance than ridge regression when compared with selected objective validation criteria. Then, we implement regularized binary and multinomial logistic regression models to obtain more accurate performance indicators since the response is a discrete variable taking values mainly from zero to three. Our final proposal is an improved RAPM measure which is based on the expected points of a multinomial logistic regression model where each player’s contribution is weighted by his participation in the team’s possessions. The proposed indicator, called weighted expected points (wEPTS), outperforms all other RAPM measures we investigate in this study.</summary></entry><entry><title type="html">Linearized Wasserstein Barycenters: Synthesis, Analysis, Representational Capacity, and Applications</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/LinearizedWassersteinBarycentersSynthesisAnalysisRepresentationalCapacityandApplications.html" rel="alternate" type="text/html" title="Linearized Wasserstein Barycenters: Synthesis, Analysis, Representational Capacity, and Applications" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/LinearizedWassersteinBarycentersSynthesisAnalysisRepresentationalCapacityandApplications</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/LinearizedWassersteinBarycentersSynthesisAnalysisRepresentationalCapacityandApplications.html">&lt;p&gt;We propose the \textit{linear barycentric coding model (LBCM)} that utilizes the linear optimal transport (LOT) metric for analysis and synthesis of probability measures. We provide a closed-form solution to the variational problem characterizing the probability measures in the LBCM and establish equivalence of the LBCM to the set of Wasserstein-2 barycenters in the special case of compatible measures. Computational methods for synthesizing and analyzing measures in the LBCM are developed with finite sample guarantees. One of our main theoretical contributions is to identify an LBCM, expressed in terms of a simple family, which is sufficient to express all probability measures on the interval $[0,1]$. We show that a natural analogous construction of an LBCM in $\mathbb{R}^2$ fails, and we leave it as an open problem to identify the proper extension in more than one dimension. We conclude by demonstrating the utility of LBCM for covariance estimation and data imputation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23602&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Matthew Werenski, Brendan Mallery, Shuchin Aeron, James M. Murphy</name></author><category term="stat.ML" /><summary type="html">We propose the \textit{linear barycentric coding model (LBCM)} that utilizes the linear optimal transport (LOT) metric for analysis and synthesis of probability measures. We provide a closed-form solution to the variational problem characterizing the probability measures in the LBCM and establish equivalence of the LBCM to the set of Wasserstein-2 barycenters in the special case of compatible measures. Computational methods for synthesizing and analyzing measures in the LBCM are developed with finite sample guarantees. One of our main theoretical contributions is to identify an LBCM, expressed in terms of a simple family, which is sufficient to express all probability measures on the interval $[0,1]$. We show that a natural analogous construction of an LBCM in $\mathbb{R}^2$ fails, and we leave it as an open problem to identify the proper extension in more than one dimension. We conclude by demonstrating the utility of LBCM for covariance estimation and data imputation.</summary></entry><entry><title type="html">Logarithmic Smoothing for Pessimistic Off-Policy Evaluation, Selection and Learning</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/LogarithmicSmoothingforPessimisticOffPolicyEvaluationSelectionandLearning.html" rel="alternate" type="text/html" title="Logarithmic Smoothing for Pessimistic Off-Policy Evaluation, Selection and Learning" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/LogarithmicSmoothingforPessimisticOffPolicyEvaluationSelectionandLearning</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/LogarithmicSmoothingforPessimisticOffPolicyEvaluationSelectionandLearning.html">&lt;p&gt;This work investigates the offline formulation of the contextual bandit problem, where the goal is to leverage past interactions collected under a behavior policy to evaluate, select, and learn new, potentially better-performing, policies. Motivated by critical applications, we move beyond point estimators. Instead, we adopt the principle of pessimism where we construct upper bounds that assess a policy’s worst-case performance, enabling us to confidently select and learn improved policies. Precisely, we introduce novel, fully empirical concentration bounds for a broad class of importance weighting risk estimators. These bounds are general enough to cover most existing estimators and pave the way for the development of new ones. In particular, our pursuit of the tightest bound within this class motivates a novel estimator (LS), that logarithmically smooths large importance weights. The bound for LS is provably tighter than its competitors, and naturally results in improved policy selection and learning strategies. Extensive policy evaluation, selection, and learning experiments highlight the versatility and favorable performance of LS.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.14335&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Otmane Sakhi, Imad Aouali, Pierre Alquier, Nicolas Chopin</name></author><category term="stat.ML" /><summary type="html">This work investigates the offline formulation of the contextual bandit problem, where the goal is to leverage past interactions collected under a behavior policy to evaluate, select, and learn new, potentially better-performing, policies. Motivated by critical applications, we move beyond point estimators. Instead, we adopt the principle of pessimism where we construct upper bounds that assess a policy’s worst-case performance, enabling us to confidently select and learn improved policies. Precisely, we introduce novel, fully empirical concentration bounds for a broad class of importance weighting risk estimators. These bounds are general enough to cover most existing estimators and pave the way for the development of new ones. In particular, our pursuit of the tightest bound within this class motivates a novel estimator (LS), that logarithmically smooths large importance weights. The bound for LS is provably tighter than its competitors, and naturally results in improved policy selection and learning strategies. Extensive policy evaluation, selection, and learning experiments highlight the versatility and favorable performance of LS.</summary></entry><entry><title type="html">MambaLRP: Explaining Selective State Space Sequence Models</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/MambaLRPExplainingSelectiveStateSpaceSequenceModels.html" rel="alternate" type="text/html" title="MambaLRP: Explaining Selective State Space Sequence Models" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/MambaLRPExplainingSelectiveStateSpaceSequenceModels</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/MambaLRPExplainingSelectiveStateSpaceSequenceModels.html">&lt;p&gt;Recent sequence modeling approaches using selective state space sequence models, referred to as Mamba models, have seen a surge of interest. These models allow efficient processing of long sequences in linear time and are rapidly being adopted in a wide range of applications such as language modeling, demonstrating promising performance. To foster their reliable use in real-world scenarios, it is crucial to augment their transparency. Our work bridges this critical gap by bringing explainability, particularly Layer-wise Relevance Propagation (LRP), to the Mamba architecture. Guided by the axiom of relevance conservation, we identify specific components in the Mamba architecture, which cause unfaithful explanations. To remedy this issue, we propose MambaLRP, a novel algorithm within the LRP framework, which ensures a more stable and reliable relevance propagation through these components. Our proposed method is theoretically sound and excels in achieving state-of-the-art explanation performance across a diverse range of models and datasets. Moreover, MambaLRP facilitates a deeper inspection of Mamba architectures, uncovering various biases and evaluating their significance. It also enables the analysis of previous speculations regarding the long-range capabilities of Mamba models.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.07592&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Farnoush Rezaei Jafari, Grégoire Montavon, Klaus-Robert Müller, Oliver Eberle</name></author><category term="stat.ML" /><summary type="html">Recent sequence modeling approaches using selective state space sequence models, referred to as Mamba models, have seen a surge of interest. These models allow efficient processing of long sequences in linear time and are rapidly being adopted in a wide range of applications such as language modeling, demonstrating promising performance. To foster their reliable use in real-world scenarios, it is crucial to augment their transparency. Our work bridges this critical gap by bringing explainability, particularly Layer-wise Relevance Propagation (LRP), to the Mamba architecture. Guided by the axiom of relevance conservation, we identify specific components in the Mamba architecture, which cause unfaithful explanations. To remedy this issue, we propose MambaLRP, a novel algorithm within the LRP framework, which ensures a more stable and reliable relevance propagation through these components. Our proposed method is theoretically sound and excels in achieving state-of-the-art explanation performance across a diverse range of models and datasets. Moreover, MambaLRP facilitates a deeper inspection of Mamba architectures, uncovering various biases and evaluating their significance. It also enables the analysis of previous speculations regarding the long-range capabilities of Mamba models.</summary></entry><entry><title type="html">Max-Rank: Efficient Multiple Testing for Conformal Prediction</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/MaxRankEfficientMultipleTestingforConformalPrediction.html" rel="alternate" type="text/html" title="Max-Rank: Efficient Multiple Testing for Conformal Prediction" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/MaxRankEfficientMultipleTestingforConformalPrediction</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/MaxRankEfficientMultipleTestingforConformalPrediction.html">&lt;p&gt;Multiple hypothesis testing (MHT) commonly arises in various scientific fields, from genomics to psychology, where testing many hypotheses simultaneously increases the risk of Type-I errors. These errors can mislead scientific inquiry, rendering MHT corrections essential. In this paper, we address MHT within the context of conformal prediction, a flexible method for predictive uncertainty quantification. Some conformal prediction settings can require simultaneous testing, and positive dependencies among tests typically exist. We propose a novel correction named $\texttt{max-rank}$ that leverages these dependencies, whilst ensuring that the joint Type-I error rate is efficiently controlled. Inspired by permutation-based corrections from Westfall &amp;amp; Young (1993), $\texttt{max-rank}$ exploits rank order information to improve performance, and readily integrates with any conformal procedure. We demonstrate both its theoretical and empirical advantages over the common Bonferroni correction and its compatibility with conformal prediction, highlighting the potential to enhance predictive uncertainty quantification.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2311.10900&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Alexander Timans, Christoph-Nikolas Straehle, Kaspar Sakmann, Christian A. Naesseth, Eric Nalisnick</name></author><category term="stat.ME," /><category term="stat.ML," /><category term="stat.TH" /><summary type="html">Multiple hypothesis testing (MHT) commonly arises in various scientific fields, from genomics to psychology, where testing many hypotheses simultaneously increases the risk of Type-I errors. These errors can mislead scientific inquiry, rendering MHT corrections essential. In this paper, we address MHT within the context of conformal prediction, a flexible method for predictive uncertainty quantification. Some conformal prediction settings can require simultaneous testing, and positive dependencies among tests typically exist. We propose a novel correction named $\texttt{max-rank}$ that leverages these dependencies, whilst ensuring that the joint Type-I error rate is efficiently controlled. Inspired by permutation-based corrections from Westfall &amp;amp; Young (1993), $\texttt{max-rank}$ exploits rank order information to improve performance, and readily integrates with any conformal procedure. We demonstrate both its theoretical and empirical advantages over the common Bonferroni correction and its compatibility with conformal prediction, highlighting the potential to enhance predictive uncertainty quantification.</summary></entry><entry><title type="html">Multi-fidelity Machine Learning for Uncertainty Quantification and Optimization</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/MultifidelityMachineLearningforUncertaintyQuantificationandOptimization.html" rel="alternate" type="text/html" title="Multi-fidelity Machine Learning for Uncertainty Quantification and Optimization" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/MultifidelityMachineLearningforUncertaintyQuantificationandOptimization</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/MultifidelityMachineLearningforUncertaintyQuantificationandOptimization.html">&lt;p&gt;In system analysis and design optimization, multiple computational models are typically available to represent a given physical system. These models can be broadly classified as high-fidelity models, which provide highly accurate predictions but require significant computational resources, and low-fidelity models, which are computationally efficient but less accurate. Multi-fidelity methods integrate high- and low-fidelity models to balance computational cost and predictive accuracy. This perspective paper provides an in-depth overview of the emerging field of machine learning-based multi-fidelity methods, with a particular emphasis on uncertainty quantification and optimization. For uncertainty quantification, a particular focus is on multi-fidelity graph neural networks, compared with multi-fidelity polynomial chaos expansion. For optimization, our emphasis is on multi-fidelity Bayesian optimization, offering a unified perspective on multi-fidelity priors and proposing an application strategy when the objective function is an integral or a weighted sum. We highlight the current state of the art, identify critical gaps in the literature, and outline key research opportunities in this evolving field.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23482&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ruda Zhang, Negin Alemazkoor</name></author><category term="stat.ML" /><summary type="html">In system analysis and design optimization, multiple computational models are typically available to represent a given physical system. These models can be broadly classified as high-fidelity models, which provide highly accurate predictions but require significant computational resources, and low-fidelity models, which are computationally efficient but less accurate. Multi-fidelity methods integrate high- and low-fidelity models to balance computational cost and predictive accuracy. This perspective paper provides an in-depth overview of the emerging field of machine learning-based multi-fidelity methods, with a particular emphasis on uncertainty quantification and optimization. For uncertainty quantification, a particular focus is on multi-fidelity graph neural networks, compared with multi-fidelity polynomial chaos expansion. For optimization, our emphasis is on multi-fidelity Bayesian optimization, offering a unified perspective on multi-fidelity priors and proposing an application strategy when the objective function is an integral or a weighted sum. We highlight the current state of the art, identify critical gaps in the literature, and outline key research opportunities in this evolving field.</summary></entry><entry><title type="html">Natural Counterfactuals With Necessary Backtracking</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/NaturalCounterfactualsWithNecessaryBacktracking.html" rel="alternate" type="text/html" title="Natural Counterfactuals With Necessary Backtracking" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/NaturalCounterfactualsWithNecessaryBacktracking</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/NaturalCounterfactualsWithNecessaryBacktracking.html">&lt;p&gt;Counterfactual reasoning is pivotal in human cognition and especially important for providing explanations and making decisions. While Judea Pearl’s influential approach is theoretically elegant, its generation of a counterfactual scenario often requires too much deviation from the observed scenarios to be feasible, as we show using simple examples. To mitigate this difficulty, we propose a framework of \emph{natural counterfactuals} and a method for generating counterfactuals that are more feasible with respect to the actual data distribution. Our methodology incorporates a certain amount of backtracking when needed, allowing changes in causally preceding variables to minimize deviations from realistic scenarios. Specifically, we introduce a novel optimization framework that permits but also controls the extent of backtracking with a naturalness criterion. Empirical experiments demonstrate the effectiveness of our method. The code is available at https://github.com/GuangyuanHao/natural_counterfactuals.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.01607&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Guang-Yuan Hao, Jiji Zhang, Biwei Huang, Hao Wang, Kun Zhang</name></author><category term="stat.ME" /><summary type="html">Counterfactual reasoning is pivotal in human cognition and especially important for providing explanations and making decisions. While Judea Pearl’s influential approach is theoretically elegant, its generation of a counterfactual scenario often requires too much deviation from the observed scenarios to be feasible, as we show using simple examples. To mitigate this difficulty, we propose a framework of \emph{natural counterfactuals} and a method for generating counterfactuals that are more feasible with respect to the actual data distribution. Our methodology incorporates a certain amount of backtracking when needed, allowing changes in causally preceding variables to minimize deviations from realistic scenarios. Specifically, we introduce a novel optimization framework that permits but also controls the extent of backtracking with a naturalness criterion. Empirical experiments demonstrate the effectiveness of our method. The code is available at https://github.com/GuangyuanHao/natural_counterfactuals.</summary></entry><entry><title type="html">On Elliptical and Inverse Elliptical Wishart distributions</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/OnEllipticalandInverseEllipticalWishartdistributions.html" rel="alternate" type="text/html" title="On Elliptical and Inverse Elliptical Wishart distributions" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/OnEllipticalandInverseEllipticalWishartdistributions</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/OnEllipticalandInverseEllipticalWishartdistributions.html">&lt;p&gt;This paper deals with the Elliptical Wishart and Inverse Elliptical Wishart distributions, which play a major role when handling covariance matrices. Similarly to multivariate elliptical distributions, these form a large family of covariance distributions, encompassing, e.g., the Wishart or \textit{t}-Wishart ones. Our first major contribution is to derive a stochastic representation for Elliptical Wishart and Inverse Elliptical Wishart matrices. This later enables us to obtain various key statistical properties of Elliptical Wishart and Inverse Elliptical Wishart distributions such as expectations, variances, and Kronecker moments up to any orders. The stochastic representation also allows us to provide an efficient method to generate random matrices from Elliptical Wishart and Inverse Elliptical Wishart distributions. Finally, the practical interest of Elliptical Wishart distributions - in particular the \textit{t}-Wishart one - is demonstrated through a fitting experiment on real electroencephalographic data. This showcases their effectiveness in accurately modeling real covariance matrices.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2404.17468&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Imen Ayadi, Florent Bouchard, Frédéric Pascal</name></author><category term="stat.ME," /><category term="stat.TH" /><summary type="html">This paper deals with the Elliptical Wishart and Inverse Elliptical Wishart distributions, which play a major role when handling covariance matrices. Similarly to multivariate elliptical distributions, these form a large family of covariance distributions, encompassing, e.g., the Wishart or \textit{t}-Wishart ones. Our first major contribution is to derive a stochastic representation for Elliptical Wishart and Inverse Elliptical Wishart matrices. This later enables us to obtain various key statistical properties of Elliptical Wishart and Inverse Elliptical Wishart distributions such as expectations, variances, and Kronecker moments up to any orders. The stochastic representation also allows us to provide an efficient method to generate random matrices from Elliptical Wishart and Inverse Elliptical Wishart distributions. Finally, the practical interest of Elliptical Wishart distributions - in particular the \textit{t}-Wishart one - is demonstrated through a fitting experiment on real electroencephalographic data. This showcases their effectiveness in accurately modeling real covariance matrices.</summary></entry><entry><title type="html">On Statistical Rates and Provably Efficient Criteria of Latent Diffusion Transformers (DiTs)</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/OnStatisticalRatesandProvablyEfficientCriteriaofLatentDiffusionTransformersDiTs.html" rel="alternate" type="text/html" title="On Statistical Rates and Provably Efficient Criteria of Latent Diffusion Transformers (DiTs)" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/OnStatisticalRatesandProvablyEfficientCriteriaofLatentDiffusionTransformersDiTs</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/OnStatisticalRatesandProvablyEfficientCriteriaofLatentDiffusionTransformersDiTs.html">&lt;p&gt;We investigate the statistical and computational limits of latent Diffusion Transformers (DiTs) under the low-dimensional linear latent space assumption. Statistically, we study the universal approximation and sample complexity of the DiTs score function, as well as the distribution recovery property of the initial data. Specifically, under mild data assumptions, we derive an approximation error bound for the score network of latent DiTs, which is sub-linear in the latent space dimension. Additionally, we derive the corresponding sample complexity bound and show that the data distribution generated from the estimated score function converges toward a proximate area of the original one. Computationally, we characterize the hardness of both forward inference and backward computation of latent DiTs, assuming the Strong Exponential Time Hypothesis (SETH). For forward inference, we identify efficient criteria for all possible latent DiTs inference algorithms and showcase our theory by pushing the efficiency toward almost-linear time inference. For backward computation, we leverage the low-rank structure within the gradient computation of DiTs training for possible algorithmic speedup. Specifically, we show that such speedup achieves almost-linear time latent DiTs training by casting the DiTs gradient as a series of chained low-rank approximations with bounded error. Under the low-dimensional assumption, we show that the statistical rates and the computational efficiency are all dominated by the dimension of the subspace, suggesting that latent DiTs have the potential to bypass the challenges associated with the high dimensionality of initial data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2407.01079&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jerry Yao-Chieh Hu, Weimin Wu, Zhao Song, Han Liu</name></author><category term="stat.ML" /><summary type="html">We investigate the statistical and computational limits of latent Diffusion Transformers (DiTs) under the low-dimensional linear latent space assumption. Statistically, we study the universal approximation and sample complexity of the DiTs score function, as well as the distribution recovery property of the initial data. Specifically, under mild data assumptions, we derive an approximation error bound for the score network of latent DiTs, which is sub-linear in the latent space dimension. Additionally, we derive the corresponding sample complexity bound and show that the data distribution generated from the estimated score function converges toward a proximate area of the original one. Computationally, we characterize the hardness of both forward inference and backward computation of latent DiTs, assuming the Strong Exponential Time Hypothesis (SETH). For forward inference, we identify efficient criteria for all possible latent DiTs inference algorithms and showcase our theory by pushing the efficiency toward almost-linear time inference. For backward computation, we leverage the low-rank structure within the gradient computation of DiTs training for possible algorithmic speedup. Specifically, we show that such speedup achieves almost-linear time latent DiTs training by casting the DiTs gradient as a series of chained low-rank approximations with bounded error. Under the low-dimensional assumption, we show that the statistical rates and the computational efficiency are all dominated by the dimension of the subspace, suggesting that latent DiTs have the potential to bypass the challenges associated with the high dimensionality of initial data.</summary></entry><entry><title type="html">On harmonic oscillator hazard functions</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Onharmonicoscillatorhazardfunctions.html" rel="alternate" type="text/html" title="On harmonic oscillator hazard functions" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Onharmonicoscillatorhazardfunctions</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Onharmonicoscillatorhazardfunctions.html">&lt;p&gt;We propose a parametric hazard model obtained by enforcing positivity in the damped harmonic oscillator. The resulting model has closed-form hazard and cumulative hazard functions, facilitating likelihood and Bayesian inference on the parameters. We show that this model can capture a range of hazard shapes, such as increasing, decreasing, unimodal, bathtub, and oscillatory patterns, and characterize the tails of the corresponding survival function. We illustrate the use of this model in survival analysis using real data.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2408.15964&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>J. A. Christen, F. J. Rubio</name></author><category term="stat.ME" /><summary type="html">We propose a parametric hazard model obtained by enforcing positivity in the damped harmonic oscillator. The resulting model has closed-form hazard and cumulative hazard functions, facilitating likelihood and Bayesian inference on the parameters. We show that this model can capture a range of hazard shapes, such as increasing, decreasing, unimodal, bathtub, and oscillatory patterns, and characterize the tails of the corresponding survival function. We illustrate the use of this model in survival analysis using real data.</summary></entry><entry><title type="html">Online Consistency of the Nearest Neighbor Rule</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/OnlineConsistencyoftheNearestNeighborRule.html" rel="alternate" type="text/html" title="Online Consistency of the Nearest Neighbor Rule" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/OnlineConsistencyoftheNearestNeighborRule</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/OnlineConsistencyoftheNearestNeighborRule.html">&lt;p&gt;In the realizable online setting, a learner is tasked with making predictions for a stream of instances, where the correct answer is revealed after each prediction. A learning rule is online consistent if its mistake rate eventually vanishes. The nearest neighbor rule (Fix and Hodges, 1951) is a fundamental prediction strategy, but it is only known to be consistent under strong statistical or geometric assumptions: the instances come i.i.d. or the label classes are well-separated. We prove online consistency for all measurable functions in doubling metric spaces under the mild assumption that the instances are generated by a process that is uniformly absolutely continuous with respect to a finite, upper doubling measure.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23644&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Sanjoy Dasgupta, Geelon So</name></author><category term="stat.ML" /><summary type="html">In the realizable online setting, a learner is tasked with making predictions for a stream of instances, where the correct answer is revealed after each prediction. A learning rule is online consistent if its mistake rate eventually vanishes. The nearest neighbor rule (Fix and Hodges, 1951) is a fundamental prediction strategy, but it is only known to be consistent under strong statistical or geometric assumptions: the instances come i.i.d. or the label classes are well-separated. We prove online consistency for all measurable functions in doubling metric spaces under the mild assumption that the instances are generated by a process that is uniformly absolutely continuous with respect to a finite, upper doubling measure.</summary></entry><entry><title type="html">On testing for independence between generalized error models of several time series</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Ontestingforindependencebetweengeneralizederrormodelsofseveraltimeseries.html" rel="alternate" type="text/html" title="On testing for independence between generalized error models of several time series" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Ontestingforindependencebetweengeneralizederrormodelsofseveraltimeseries</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Ontestingforindependencebetweengeneralizederrormodelsofseveraltimeseries.html">&lt;p&gt;We propose new copula-based models for multivariate time series having continuous or discrete distributions, or a mixture of both. These models include stochastic volatility models and regime-switching models. We also propose statistics for testing independence between the generalized errors of these models, extending previous results of Duchesne, Ghoudi and Remillard (2012) obtained for stochastic volatility models. We define families of empirical processes constructed from lagged generalized errors, and we show that their joint asymptotic distributions are Gaussian and independent of the estimated parameters of the individual time series. Moebius transformations of the empirical processes are used to obtain tractable covariances. Several tests statistics are then proposed, based on Cramer-von Mises statistics and dependence measures, as well as graphical methods to visualize the dependence. In addition, numerical experiments are performed to assess the power of the proposed tests. Finally, to show the usefulness of our methodologies, examples of applications for financial data and crime data are given to cover both discrete and continuous cases. ll developed methodologies are implemented in the CRAN package IndGenErrors.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24003&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Kilani Ghoudi, Bouchra R. Nasri, Bruno N. Remillard</name></author><category term="stat.ME" /><summary type="html">We propose new copula-based models for multivariate time series having continuous or discrete distributions, or a mixture of both. These models include stochastic volatility models and regime-switching models. We also propose statistics for testing independence between the generalized errors of these models, extending previous results of Duchesne, Ghoudi and Remillard (2012) obtained for stochastic volatility models. We define families of empirical processes constructed from lagged generalized errors, and we show that their joint asymptotic distributions are Gaussian and independent of the estimated parameters of the individual time series. Moebius transformations of the empirical processes are used to obtain tractable covariances. Several tests statistics are then proposed, based on Cramer-von Mises statistics and dependence measures, as well as graphical methods to visualize the dependence. In addition, numerical experiments are performed to assess the power of the proposed tests. Finally, to show the usefulness of our methodologies, examples of applications for financial data and crime data are given to cover both discrete and continuous cases. ll developed methodologies are implemented in the CRAN package IndGenErrors.</summary></entry><entry><title type="html">On the Sparsity of the Strong Lottery Ticket Hypothesis</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/OntheSparsityoftheStrongLotteryTicketHypothesis.html" rel="alternate" type="text/html" title="On the Sparsity of the Strong Lottery Ticket Hypothesis" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/OntheSparsityoftheStrongLotteryTicketHypothesis</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/OntheSparsityoftheStrongLotteryTicketHypothesis.html">&lt;p&gt;Considerable research efforts have recently been made to show that a random neural network $N$ contains subnetworks capable of accurately approximating any given neural network that is sufficiently smaller than $N$, without any training. This line of research, known as the Strong Lottery Ticket Hypothesis (SLTH), was originally motivated by the weaker Lottery Ticket Hypothesis, which states that a sufficiently large random neural network $N$ contains \emph{sparse} subnetworks that can be trained efficiently to achieve performance comparable to that of training the entire network $N$. Despite its original motivation, results on the SLTH have so far not provided any guarantee on the size of subnetworks. Such limitation is due to the nature of the main technical tool leveraged by these results, the Random Subset Sum (RSS) Problem. Informally, the RSS Problem asks how large a random i.i.d. sample $\Omega$ should be so that we are able to approximate any number in $[-1,1]$, up to an error of $ \epsilon$, as the sum of a suitable subset of $\Omega$. We provide the first proof of the SLTH in classical settings, such as dense and equivariant networks, with guarantees on the sparsity of the subnetworks. Central to our results, is the proof of an essentially tight bound on the Random Fixed-Size Subset Sum Problem (RFSS), a variant of the RSS Problem in which we only ask for subsets of a given size, which is of independent interest.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.14754&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Emanuele Natale , Davide Ferre&apos; , Giordano Giambartolomei , Frédéric Giroire , Frederik Mallmann-Trenn</name></author><category term="stat.ML" /><summary type="html">Considerable research efforts have recently been made to show that a random neural network $N$ contains subnetworks capable of accurately approximating any given neural network that is sufficiently smaller than $N$, without any training. This line of research, known as the Strong Lottery Ticket Hypothesis (SLTH), was originally motivated by the weaker Lottery Ticket Hypothesis, which states that a sufficiently large random neural network $N$ contains \emph{sparse} subnetworks that can be trained efficiently to achieve performance comparable to that of training the entire network $N$. Despite its original motivation, results on the SLTH have so far not provided any guarantee on the size of subnetworks. Such limitation is due to the nature of the main technical tool leveraged by these results, the Random Subset Sum (RSS) Problem. Informally, the RSS Problem asks how large a random i.i.d. sample $\Omega$ should be so that we are able to approximate any number in $[-1,1]$, up to an error of $ \epsilon$, as the sum of a suitable subset of $\Omega$. We provide the first proof of the SLTH in classical settings, such as dense and equivariant networks, with guarantees on the sparsity of the subnetworks. Central to our results, is the proof of an essentially tight bound on the Random Fixed-Size Subset Sum Problem (RFSS), a variant of the RSS Problem in which we only ask for subsets of a given size, which is of independent interest.</summary></entry><entry><title type="html">Operator World Models for Reinforcement Learning</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/OperatorWorldModelsforReinforcementLearning.html" rel="alternate" type="text/html" title="Operator World Models for Reinforcement Learning" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/OperatorWorldModelsforReinforcementLearning</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/OperatorWorldModelsforReinforcementLearning.html">&lt;p&gt;Policy Mirror Descent (PMD) is a powerful and theoretically sound methodology for sequential decision-making. However, it is not directly applicable to Reinforcement Learning (RL) due to the inaccessibility of explicit action-value functions. We address this challenge by introducing a novel approach based on learning a world model of the environment using conditional mean embeddings. Leveraging tools from operator theory we derive a closed-form expression of the action-value function in terms of the world model via simple matrix operations. Combining these estimators with PMD leads to POWR, a new RL algorithm for which we prove convergence rates to the global optimum. Preliminary experiments in finite and infinite state settings support the effectiveness of our method&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.19861&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Pietro Novelli, Marco Pratticò, Massimiliano Pontil, Carlo Ciliberto</name></author><category term="stat.ML" /><summary type="html">Policy Mirror Descent (PMD) is a powerful and theoretically sound methodology for sequential decision-making. However, it is not directly applicable to Reinforcement Learning (RL) due to the inaccessibility of explicit action-value functions. We address this challenge by introducing a novel approach based on learning a world model of the environment using conditional mean embeddings. Leveraging tools from operator theory we derive a closed-form expression of the action-value function in terms of the world model via simple matrix operations. Combining these estimators with PMD leads to POWR, a new RL algorithm for which we prove convergence rates to the global optimum. Preliminary experiments in finite and infinite state settings support the effectiveness of our method</summary></entry><entry><title type="html">Policy Mirror Descent with Lookahead</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/PolicyMirrorDescentwithLookahead.html" rel="alternate" type="text/html" title="Policy Mirror Descent with Lookahead" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/PolicyMirrorDescentwithLookahead</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/PolicyMirrorDescentwithLookahead.html">&lt;p&gt;Policy Mirror Descent (PMD) stands as a versatile algorithmic framework encompassing several seminal policy gradient algorithms such as natural policy gradient, with connections with state-of-the-art reinforcement learning (RL) algorithms such as TRPO and PPO. PMD can be seen as a soft Policy Iteration algorithm implementing regularized 1-step greedy policy improvement. However, 1-step greedy policies might not be the best choice and recent remarkable empirical successes in RL such as AlphaGo and AlphaZero have demonstrated that greedy approaches with respect to multiple steps outperform their 1-step counterpart. In this work, we propose a new class of PMD algorithms called $h$-PMD which incorporates multi-step greedy policy improvement with lookahead depth $h$ to the PMD update rule. To solve discounted infinite horizon Markov Decision Processes with discount factor $\gamma$, we show that $h$-PMD which generalizes the standard PMD enjoys a faster dimension-free $\gamma^h$-linear convergence rate, contingent on the computation of multi-step greedy policies. We propose an inexact version of $h$-PMD where lookahead action values are estimated. Under a generative model, we establish a sample complexity for $h$-PMD which improves over prior work. Finally, we extend our result to linear function approximation to scale to large state spaces. Under suitable assumptions, our sample complexity only involves dependence on the dimension of the feature map space instead of the state space size.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2403.14156&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Kimon Protopapas, Anas Barakat</name></author><category term="stat.ML" /><summary type="html">Policy Mirror Descent (PMD) stands as a versatile algorithmic framework encompassing several seminal policy gradient algorithms such as natural policy gradient, with connections with state-of-the-art reinforcement learning (RL) algorithms such as TRPO and PPO. PMD can be seen as a soft Policy Iteration algorithm implementing regularized 1-step greedy policy improvement. However, 1-step greedy policies might not be the best choice and recent remarkable empirical successes in RL such as AlphaGo and AlphaZero have demonstrated that greedy approaches with respect to multiple steps outperform their 1-step counterpart. In this work, we propose a new class of PMD algorithms called $h$-PMD which incorporates multi-step greedy policy improvement with lookahead depth $h$ to the PMD update rule. To solve discounted infinite horizon Markov Decision Processes with discount factor $\gamma$, we show that $h$-PMD which generalizes the standard PMD enjoys a faster dimension-free $\gamma^h$-linear convergence rate, contingent on the computation of multi-step greedy policies. We propose an inexact version of $h$-PMD where lookahead action values are estimated. Under a generative model, we establish a sample complexity for $h$-PMD which improves over prior work. Finally, we extend our result to linear function approximation to scale to large state spaces. Under suitable assumptions, our sample complexity only involves dependence on the dimension of the feature map space instead of the state space size.</summary></entry><entry><title type="html">Progressive Entropic Optimal Transport Solvers</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/ProgressiveEntropicOptimalTransportSolvers.html" rel="alternate" type="text/html" title="Progressive Entropic Optimal Transport Solvers" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/ProgressiveEntropicOptimalTransportSolvers</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/ProgressiveEntropicOptimalTransportSolvers.html">&lt;p&gt;Optimal transport (OT) has profoundly impacted machine learning by providing theoretical and computational tools to realign datasets. In this context, given two large point clouds of sizes $n$ and $m$ in $\mathbb{R}^d$, entropic OT (EOT) solvers have emerged as the most reliable tool to either solve the Kantorovich problem and output a $n\times m$ coupling matrix, or to solve the Monge problem and learn a vector-valued push-forward map. While the robustness of EOT couplings/maps makes them a go-to choice in practical applications, EOT solvers remain difficult to tune because of a small but influential set of hyperparameters, notably the omnipresent entropic regularization strength $\varepsilon$. Setting $\varepsilon$ can be difficult, as it simultaneously impacts various performance metrics, such as compute speed, statistical performance, generalization, and bias. In this work, we propose a new class of EOT solvers (ProgOT), that can estimate both plans and transport maps. We take advantage of several opportunities to optimize the computation of EOT solutions by dividing mass displacement using a time discretization, borrowing inspiration from dynamic OT formulations, and conquering each of these steps using EOT with properly scheduled parameters. We provide experimental evidence demonstrating that ProgOT is a faster and more robust alternative to standard solvers when computing couplings at large scales, even outperforming neural network-based approaches. We also prove statistical consistency of our approach for estimating optimal transport maps.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.05061&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Parnian Kassraie, Aram-Alexandre Pooladian, Michal Klein, James Thornton, Jonathan Niles-Weed, Marco Cuturi</name></author><category term="stat.ML" /><summary type="html">Optimal transport (OT) has profoundly impacted machine learning by providing theoretical and computational tools to realign datasets. In this context, given two large point clouds of sizes $n$ and $m$ in $\mathbb{R}^d$, entropic OT (EOT) solvers have emerged as the most reliable tool to either solve the Kantorovich problem and output a $n\times m$ coupling matrix, or to solve the Monge problem and learn a vector-valued push-forward map. While the robustness of EOT couplings/maps makes them a go-to choice in practical applications, EOT solvers remain difficult to tune because of a small but influential set of hyperparameters, notably the omnipresent entropic regularization strength $\varepsilon$. Setting $\varepsilon$ can be difficult, as it simultaneously impacts various performance metrics, such as compute speed, statistical performance, generalization, and bias. In this work, we propose a new class of EOT solvers (ProgOT), that can estimate both plans and transport maps. We take advantage of several opportunities to optimize the computation of EOT solutions by dividing mass displacement using a time discretization, borrowing inspiration from dynamic OT formulations, and conquering each of these steps using EOT with properly scheduled parameters. We provide experimental evidence demonstrating that ProgOT is a faster and more robust alternative to standard solvers when computing couplings at large scales, even outperforming neural network-based approaches. We also prove statistical consistency of our approach for estimating optimal transport maps.</summary></entry><entry><title type="html">Projected Neural Differential Equations for Learning Constrained Dynamics</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/ProjectedNeuralDifferentialEquationsforLearningConstrainedDynamics.html" rel="alternate" type="text/html" title="Projected Neural Differential Equations for Learning Constrained Dynamics" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/ProjectedNeuralDifferentialEquationsforLearningConstrainedDynamics</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/ProjectedNeuralDifferentialEquationsforLearningConstrainedDynamics.html">&lt;p&gt;Neural differential equations offer a powerful approach for learning dynamics from data. However, they do not impose known constraints that should be obeyed by the learned model. It is well-known that enforcing constraints in surrogate models can enhance their generalizability and numerical stability. In this paper, we introduce projected neural differential equations (PNDEs), a new method for constraining neural differential equations based on projection of the learned vector field to the tangent space of the constraint manifold. In tests on several challenging examples, including chaotic dynamical systems and state-of-the-art power grid models, PNDEs outperform existing methods while requiring fewer hyperparameters. The proposed approach demonstrates significant potential for enhancing the modeling of constrained dynamical systems, particularly in complex domains where accuracy and reliability are essential.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23667&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Alistair White, Anna Büttner, Maximilian Gelbrecht, Valentin Duruisseaux, Niki Kilbertus, Frank Hellmann, Niklas Boers</name></author><category term="stat.ML" /><summary type="html">Neural differential equations offer a powerful approach for learning dynamics from data. However, they do not impose known constraints that should be obeyed by the learned model. It is well-known that enforcing constraints in surrogate models can enhance their generalizability and numerical stability. In this paper, we introduce projected neural differential equations (PNDEs), a new method for constraining neural differential equations based on projection of the learned vector field to the tangent space of the constraint manifold. In tests on several challenging examples, including chaotic dynamical systems and state-of-the-art power grid models, PNDEs outperform existing methods while requiring fewer hyperparameters. The proposed approach demonstrates significant potential for enhancing the modeling of constrained dynamical systems, particularly in complex domains where accuracy and reliability are essential.</summary></entry><entry><title type="html">Provable Benefit of Cutout and CutMix for Feature Learning</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/ProvableBenefitofCutoutandCutMixforFeatureLearning.html" rel="alternate" type="text/html" title="Provable Benefit of Cutout and CutMix for Feature Learning" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/ProvableBenefitofCutoutandCutMixforFeatureLearning</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/ProvableBenefitofCutoutandCutMixforFeatureLearning.html">&lt;p&gt;Patch-level data augmentation techniques such as Cutout and CutMix have demonstrated significant efficacy in enhancing the performance of vision tasks. However, a comprehensive theoretical understanding of these methods remains elusive. In this paper, we study two-layer neural networks trained using three distinct methods: vanilla training without augmentation, Cutout training, and CutMix training. Our analysis focuses on a feature-noise data model, which consists of several label-dependent features of varying rarity and label-independent noises of differing strengths. Our theorems demonstrate that Cutout training can learn low-frequency features that vanilla training cannot, while CutMix training can learn even rarer features that Cutout cannot capture. From this, we establish that CutMix yields the highest test accuracy among the three. Our novel analysis reveals that CutMix training makes the network learn all features and noise vectors “evenly” regardless of the rarity and strength, which provides an interesting insight into understanding patch-level augmentation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23672&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Junsoo Oh, Chulhee Yun</name></author><category term="stat.ML" /><summary type="html">Patch-level data augmentation techniques such as Cutout and CutMix have demonstrated significant efficacy in enhancing the performance of vision tasks. However, a comprehensive theoretical understanding of these methods remains elusive. In this paper, we study two-layer neural networks trained using three distinct methods: vanilla training without augmentation, Cutout training, and CutMix training. Our analysis focuses on a feature-noise data model, which consists of several label-dependent features of varying rarity and label-independent noises of differing strengths. Our theorems demonstrate that Cutout training can learn low-frequency features that vanilla training cannot, while CutMix training can learn even rarer features that Cutout cannot capture. From this, we establish that CutMix yields the highest test accuracy among the three. Our novel analysis reveals that CutMix training makes the network learn all features and noise vectors “evenly” regardless of the rarity and strength, which provides an interesting insight into understanding patch-level augmentation.</summary></entry><entry><title type="html">Quantifying Uncertainty: All We Need is the Bootstrap?</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/QuantifyingUncertaintyAllWeNeedistheBootstrap.html" rel="alternate" type="text/html" title="Quantifying Uncertainty: All We Need is the Bootstrap?" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/QuantifyingUncertaintyAllWeNeedistheBootstrap</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/QuantifyingUncertaintyAllWeNeedistheBootstrap.html">&lt;p&gt;Quantifying uncertainty through standard errors, confidence intervals, hypothesis tests, and related measures is a fundamental aspect of statistical practice. However, these techniques involve a variety of methods, mathematical formulas, and underlying concepts, which can be complex. Could the non-parametric bootstrap, known for its simplicity and general applicability, serve as a universal alternative? In this study, we address this question through a review of existing literature and a simulation analysis of one- and two-sided confidence intervals across varying sample sizes, confidence levels, data-generating processes, and statistical functionals. Our findings indicate that the double bootstrap consistently performs best and is a promising alternative to traditional methods used for common statistical tasks. These results suggest that the bootstrap, particularly the double bootstrap, could simplify statistical education and practice without compromising effectiveness.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2403.20182&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Urša Zrimšek, Erik Štrumbelj</name></author><category term="stat.ME" /><summary type="html">Quantifying uncertainty through standard errors, confidence intervals, hypothesis tests, and related measures is a fundamental aspect of statistical practice. However, these techniques involve a variety of methods, mathematical formulas, and underlying concepts, which can be complex. Could the non-parametric bootstrap, known for its simplicity and general applicability, serve as a universal alternative? In this study, we address this question through a review of existing literature and a simulation analysis of one- and two-sided confidence intervals across varying sample sizes, confidence levels, data-generating processes, and statistical functionals. Our findings indicate that the double bootstrap consistently performs best and is a promising alternative to traditional methods used for common statistical tasks. These results suggest that the bootstrap, particularly the double bootstrap, could simplify statistical education and practice without compromising effectiveness.</summary></entry><entry><title type="html">Quasi-randomization tests for network interference</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Quasirandomizationtestsfornetworkinterference.html" rel="alternate" type="text/html" title="Quasi-randomization tests for network interference" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Quasirandomizationtestsfornetworkinterference</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Quasirandomizationtestsfornetworkinterference.html">&lt;p&gt;Network interference amounts to the treatment status of one unit affecting the potential outcome of other units in the population. Testing for spillover effects in this setting makes the null hypothesis non-sharp. An interesting approach to tackling the non-sharp nature of the null hypothesis in this setup is constructing conditional randomization tests such that the null is sharp on the restricted population. Such approaches can pose computational challenges as finding these appropriate sub-populations based on experimental design can involve solving an NP-hard problem. In this paper, we view the network amongst the population as a random variable instead of being fixed. We propose a new approach that builds a conditional quasi-randomization test. We build the (non-sharp) null distribution of no spillover effects using random graph null models. We show that our method is exactly valid in finite samples under mild assumptions. Our method displays enhanced power over other methods, substantially improving cluster randomized trials. We illustrate our methodology to test for interference in a weather insurance adoption experiment run in rural China.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2403.16673&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Supriya Tiwari, Pallavi Basu</name></author><category term="stat.ME" /><summary type="html">Network interference amounts to the treatment status of one unit affecting the potential outcome of other units in the population. Testing for spillover effects in this setting makes the null hypothesis non-sharp. An interesting approach to tackling the non-sharp nature of the null hypothesis in this setup is constructing conditional randomization tests such that the null is sharp on the restricted population. Such approaches can pose computational challenges as finding these appropriate sub-populations based on experimental design can involve solving an NP-hard problem. In this paper, we view the network amongst the population as a random variable instead of being fixed. We propose a new approach that builds a conditional quasi-randomization test. We build the (non-sharp) null distribution of no spillover effects using random graph null models. We show that our method is exactly valid in finite samples under mild assumptions. Our method displays enhanced power over other methods, substantially improving cluster randomized trials. We illustrate our methodology to test for interference in a weather insurance adoption experiment run in rural China.</summary></entry><entry><title type="html">Randomized Exploration for Reinforcement Learning with Multinomial Logistic Function Approximation</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/RandomizedExplorationforReinforcementLearningwithMultinomialLogisticFunctionApproximation.html" rel="alternate" type="text/html" title="Randomized Exploration for Reinforcement Learning with Multinomial Logistic Function Approximation" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/RandomizedExplorationforReinforcementLearningwithMultinomialLogisticFunctionApproximation</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/RandomizedExplorationforReinforcementLearningwithMultinomialLogisticFunctionApproximation.html">&lt;p&gt;We study reinforcement learning with multinomial logistic (MNL) function approximation where the underlying transition probability kernel of the Markov decision processes (MDPs) is parametrized by an unknown transition core with features of state and action. For the finite horizon episodic setting with inhomogeneous state transitions, we propose provably efficient algorithms with randomized exploration having frequentist regret guarantees. For our first algorithm, $\texttt{RRL-MNL}$, we adapt optimistic sampling to ensure the optimism of the estimated value function with sufficient frequency. We establish that $\texttt{RRL-MNL}$ achieves a $\tilde{O}(\kappa^{-1} d^{\frac{3}{2}} H^{\frac{3}{2}} \sqrt{T})$ frequentist regret bound with constant-time computational cost per episode. Here, $d$ is the dimension of the transition core, $H$ is the horizon length, $T$ is the total number of steps, and $\kappa$ is a problem-dependent constant. Despite the simplicity and practicality of $\texttt{RRL-MNL}$, its regret bound scales with $\kappa^{-1}$, which is potentially large in the worst case. To improve the dependence on $\kappa^{-1}$, we propose $\texttt{ORRL-MNL}$, which estimates the value function using the local gradient information of the MNL transition model. We show that its frequentist regret bound is $\tilde{O}(d^{\frac{3}{2}} H^{\frac{3}{2}} \sqrt{T} + \kappa^{-1} d^2 H^2)$. To the best of our knowledge, these are the first randomized RL algorithms for the MNL transition model that achieve statistical guarantees with constant-time computational cost per episode. Numerical experiments demonstrate the superior performance of the proposed algorithms.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.20165&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Wooseong Cho, Taehyun Hwang, Joongkyu Lee, Min-hwan Oh</name></author><category term="stat.ML" /><summary type="html">We study reinforcement learning with multinomial logistic (MNL) function approximation where the underlying transition probability kernel of the Markov decision processes (MDPs) is parametrized by an unknown transition core with features of state and action. For the finite horizon episodic setting with inhomogeneous state transitions, we propose provably efficient algorithms with randomized exploration having frequentist regret guarantees. For our first algorithm, $\texttt{RRL-MNL}$, we adapt optimistic sampling to ensure the optimism of the estimated value function with sufficient frequency. We establish that $\texttt{RRL-MNL}$ achieves a $\tilde{O}(\kappa^{-1} d^{\frac{3}{2}} H^{\frac{3}{2}} \sqrt{T})$ frequentist regret bound with constant-time computational cost per episode. Here, $d$ is the dimension of the transition core, $H$ is the horizon length, $T$ is the total number of steps, and $\kappa$ is a problem-dependent constant. Despite the simplicity and practicality of $\texttt{RRL-MNL}$, its regret bound scales with $\kappa^{-1}$, which is potentially large in the worst case. To improve the dependence on $\kappa^{-1}$, we propose $\texttt{ORRL-MNL}$, which estimates the value function using the local gradient information of the MNL transition model. We show that its frequentist regret bound is $\tilde{O}(d^{\frac{3}{2}} H^{\frac{3}{2}} \sqrt{T} + \kappa^{-1} d^2 H^2)$. To the best of our knowledge, these are the first randomized RL algorithms for the MNL transition model that achieve statistical guarantees with constant-time computational cost per episode. Numerical experiments demonstrate the superior performance of the proposed algorithms.</summary></entry><entry><title type="html">Return Augmented Decision Transformer for Off-Dynamics Reinforcement Learning</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/ReturnAugmentedDecisionTransformerforOffDynamicsReinforcementLearning.html" rel="alternate" type="text/html" title="Return Augmented Decision Transformer for Off-Dynamics Reinforcement Learning" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/ReturnAugmentedDecisionTransformerforOffDynamicsReinforcementLearning</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/ReturnAugmentedDecisionTransformerforOffDynamicsReinforcementLearning.html">&lt;p&gt;We study offline off-dynamics reinforcement learning (RL) to utilize data from an easily accessible source domain to enhance policy learning in a target domain with limited data. Our approach centers on return-conditioned supervised learning (RCSL), particularly focusing on the decision transformer (DT), which can predict actions conditioned on desired return guidance and complete trajectory history. Previous works tackle the dynamics shift problem by augmenting the reward in the trajectory from the source domain to match the optimal trajectory in the target domain. However, this strategy can not be directly applicable in RCSL owing to (1) the unique form of the RCSL policy class, which explicitly depends on the return, and (2) the absence of a straightforward representation of the optimal trajectory distribution. We propose the Return Augmented Decision Transformer (RADT) method, where we augment the return in the source domain by aligning its distribution with that in the target domain. We provide the theoretical analysis demonstrating that the RCSL policy learned from RADT achieves the same level of suboptimality as would be obtained without a dynamics shift. We introduce two practical implementations RADT-DARA and RADT-MV respectively. Extensive experiments conducted on D4RL datasets reveal that our methods generally outperform dynamic programming based methods in off-dynamics RL scenarios.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23450&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ruhan Wang, Yu Yang, Zhishuai Liu, Dongruo Zhou, Pan Xu</name></author><category term="stat.ML" /><summary type="html">We study offline off-dynamics reinforcement learning (RL) to utilize data from an easily accessible source domain to enhance policy learning in a target domain with limited data. Our approach centers on return-conditioned supervised learning (RCSL), particularly focusing on the decision transformer (DT), which can predict actions conditioned on desired return guidance and complete trajectory history. Previous works tackle the dynamics shift problem by augmenting the reward in the trajectory from the source domain to match the optimal trajectory in the target domain. However, this strategy can not be directly applicable in RCSL owing to (1) the unique form of the RCSL policy class, which explicitly depends on the return, and (2) the absence of a straightforward representation of the optimal trajectory distribution. We propose the Return Augmented Decision Transformer (RADT) method, where we augment the return in the source domain by aligning its distribution with that in the target domain. We provide the theoretical analysis demonstrating that the RCSL policy learned from RADT achieves the same level of suboptimality as would be obtained without a dynamics shift. We introduce two practical implementations RADT-DARA and RADT-MV respectively. Extensive experiments conducted on D4RL datasets reveal that our methods generally outperform dynamic programming based methods in off-dynamics RL scenarios.</summary></entry><entry><title type="html">Ridge Regularization: an Essential Concept in Data Science</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/RidgeRegularizationanEssentialConceptinDataScience.html" rel="alternate" type="text/html" title="Ridge Regularization: an Essential Concept in Data Science" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/RidgeRegularizationanEssentialConceptinDataScience</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/RidgeRegularizationanEssentialConceptinDataScience.html">&lt;p&gt;Ridge or more formally $\ell_2$ regularization shows up in many areas of statistics and machine learning. It is one of those essential devices that any good data scientist needs to master for their craft. In this brief ridge fest I have collected together some of the magic and beauty of ridge that my colleagues and I have encountered over the past 40 years in applied statistics.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2006.00371&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Trevor Hastie</name></author><category term="stat.ME," /><category term="stat.ML" /><summary type="html">Ridge or more formally $\ell_2$ regularization shows up in many areas of statistics and machine learning. It is one of those essential devices that any good data scientist needs to master for their craft. In this brief ridge fest I have collected together some of the magic and beauty of ridge that my colleagues and I have encountered over the past 40 years in applied statistics.</summary></entry><entry><title type="html">Robust Gaussian Processes via Relevance Pursuit</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/RobustGaussianProcessesviaRelevancePursuit.html" rel="alternate" type="text/html" title="Robust Gaussian Processes via Relevance Pursuit" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/RobustGaussianProcessesviaRelevancePursuit</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/RobustGaussianProcessesviaRelevancePursuit.html">&lt;p&gt;Gaussian processes (GPs) are non-parametric probabilistic regression models that are popular due to their flexibility, data efficiency, and well-calibrated uncertainty estimates. However, standard GP models assume homoskedastic Gaussian noise, while many real-world applications are subject to non-Gaussian corruptions. Variants of GPs that are more robust to alternative noise models have been proposed, and entail significant trade-offs between accuracy and robustness, and between computational requirements and theoretical guarantees. In this work, we propose and study a GP model that achieves robustness against sparse outliers by inferring data-point-specific noise levels with a sequential selection procedure maximizing the log marginal likelihood that we refer to as relevance pursuit. We show, surprisingly, that the model can be parameterized such that the associated log marginal likelihood is strongly concave in the data-point-specific noise variances, a property rarely found in either robust regression objectives or GP marginal likelihoods. This in turn implies the weak submodularity of the corresponding subset selection problem, and thereby proves approximation guarantees for the proposed algorithm. We compare the model’s performance relative to other approaches on diverse regression and Bayesian optimization tasks, including the challenging but common setting of sparse corruptions of the labels within or close to the function range.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24222&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Sebastian Ament, Elizabeth Santorella, David Eriksson, Ben Letham, Maximilian Balandat, Eytan Bakshy</name></author><category term="stat.ML" /><summary type="html">Gaussian processes (GPs) are non-parametric probabilistic regression models that are popular due to their flexibility, data efficiency, and well-calibrated uncertainty estimates. However, standard GP models assume homoskedastic Gaussian noise, while many real-world applications are subject to non-Gaussian corruptions. Variants of GPs that are more robust to alternative noise models have been proposed, and entail significant trade-offs between accuracy and robustness, and between computational requirements and theoretical guarantees. In this work, we propose and study a GP model that achieves robustness against sparse outliers by inferring data-point-specific noise levels with a sequential selection procedure maximizing the log marginal likelihood that we refer to as relevance pursuit. We show, surprisingly, that the model can be parameterized such that the associated log marginal likelihood is strongly concave in the data-point-specific noise variances, a property rarely found in either robust regression objectives or GP marginal likelihoods. This in turn implies the weak submodularity of the corresponding subset selection problem, and thereby proves approximation guarantees for the proposed algorithm. We compare the model’s performance relative to other approaches on diverse regression and Bayesian optimization tasks, including the challenging but common setting of sparse corruptions of the labels within or close to the function range.</summary></entry><entry><title type="html">Robust Sparse Regression with Non-Isotropic Designs</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/RobustSparseRegressionwithNonIsotropicDesigns.html" rel="alternate" type="text/html" title="Robust Sparse Regression with Non-Isotropic Designs" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/RobustSparseRegressionwithNonIsotropicDesigns</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/RobustSparseRegressionwithNonIsotropicDesigns.html">&lt;p&gt;We develop a technique to design efficiently computable estimators for sparse linear regression in the simultaneous presence of two adversaries: oblivious and adaptive. We design several robust algorithms that outperform the state of the art even in the special case when oblivious adversary simply adds Gaussian noise. In particular, we provide a polynomial-time algorithm that with high probability recovers the signal up to error $O(\sqrt{\varepsilon})$ as long as the number of samples $n \ge \tilde{O}(k^2/\varepsilon)$, only assuming some bounds on the third and the fourth moments of the distribution ${D}$ of the design.
  In addition, prior to this work, even in the special case of Gaussian design and noise, no polynomial time algorithm was known to achieve error $o(\sqrt{\varepsilon})$ in the sparse setting $n &amp;lt; d^2$. We show that under some assumptions on the fourth and the eighth moments of ${D}$, there is a polynomial-time algorithm that achieves error $o(\sqrt{\varepsilon})$ as long as $n \ge \tilde{O}(k^4 / \varepsilon^3)$. For Gaussian distribution, this algorithm achieves error $O(\varepsilon^{3/4})$. Moreover, our algorithm achieves error $o(\sqrt{\varepsilon})$ for all log-concave distributions if $\varepsilon \le 1/\text{polylog(d)}$.
  Our algorithms are based on the filtering of the covariates that uses sum-of-squares relaxations, and weighted Huber loss minimization with $\ell_1$ regularizer. We provide a novel analysis of weighted penalized Huber loss that is suitable for heavy-tailed designs in the presence of two adversaries. Furthermore, we complement our algorithmic results with Statistical Query lower bounds, providing evidence that our estimators are likely to have nearly optimal sample complexity.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23937&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Chih-Hung Liu, Gleb Novikov</name></author><category term="stat.ML" /><summary type="html">We develop a technique to design efficiently computable estimators for sparse linear regression in the simultaneous presence of two adversaries: oblivious and adaptive. We design several robust algorithms that outperform the state of the art even in the special case when oblivious adversary simply adds Gaussian noise. In particular, we provide a polynomial-time algorithm that with high probability recovers the signal up to error $O(\sqrt{\varepsilon})$ as long as the number of samples $n \ge \tilde{O}(k^2/\varepsilon)$, only assuming some bounds on the third and the fourth moments of the distribution ${D}$ of the design. In addition, prior to this work, even in the special case of Gaussian design and noise, no polynomial time algorithm was known to achieve error $o(\sqrt{\varepsilon})$ in the sparse setting $n &amp;lt; d^2$. We show that under some assumptions on the fourth and the eighth moments of ${D}$, there is a polynomial-time algorithm that achieves error $o(\sqrt{\varepsilon})$ as long as $n \ge \tilde{O}(k^4 / \varepsilon^3)$. For Gaussian distribution, this algorithm achieves error $O(\varepsilon^{3/4})$. Moreover, our algorithm achieves error $o(\sqrt{\varepsilon})$ for all log-concave distributions if $\varepsilon \le 1/\text{polylog(d)}$. Our algorithms are based on the filtering of the covariates that uses sum-of-squares relaxations, and weighted Huber loss minimization with $\ell_1$ regularizer. We provide a novel analysis of weighted penalized Huber loss that is suitable for heavy-tailed designs in the presence of two adversaries. Furthermore, we complement our algorithmic results with Statistical Query lower bounds, providing evidence that our estimators are likely to have nearly optimal sample complexity.</summary></entry><entry><title type="html">Sample-Efficient Agnostic Boosting</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/SampleEfficientAgnosticBoosting.html" rel="alternate" type="text/html" title="Sample-Efficient Agnostic Boosting" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/SampleEfficientAgnosticBoosting</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/SampleEfficientAgnosticBoosting.html">&lt;p&gt;The theory of boosting provides a computational framework for aggregating approximate weak learning algorithms, which perform marginally better than a random predictor, into an accurate strong learner. In the realizable case, the success of the boosting approach is underscored by a remarkable fact that the resultant sample complexity matches that of a computationally demanding alternative, namely Empirical Risk Minimization (ERM). This in particular implies that the realizable boosting methodology has the potential to offer computational relief without compromising on sample efficiency.
  Despite recent progress, in agnostic boosting, where assumptions on the conditional distribution of labels given feature descriptions are absent, ERM outstrips the agnostic boosting methodology in being quadratically more sample efficient than all known agnostic boosting algorithms. In this paper, we make progress on closing this gap, and give a substantially more sample efficient agnostic boosting algorithm than those known, without compromising on the computational (or oracle) complexity. A key feature of our algorithm is that it leverages the ability to reuse samples across multiple rounds of boosting, while guaranteeing a generalization error strictly better than those obtained by blackbox applications of uniform convergence arguments. We also apply our approach to other previously studied learning problems, including boosting for reinforcement learning, and demonstrate improved results.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23632&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Udaya Ghai, Karan Singh</name></author><category term="stat.ML" /><summary type="html">The theory of boosting provides a computational framework for aggregating approximate weak learning algorithms, which perform marginally better than a random predictor, into an accurate strong learner. In the realizable case, the success of the boosting approach is underscored by a remarkable fact that the resultant sample complexity matches that of a computationally demanding alternative, namely Empirical Risk Minimization (ERM). This in particular implies that the realizable boosting methodology has the potential to offer computational relief without compromising on sample efficiency. Despite recent progress, in agnostic boosting, where assumptions on the conditional distribution of labels given feature descriptions are absent, ERM outstrips the agnostic boosting methodology in being quadratically more sample efficient than all known agnostic boosting algorithms. In this paper, we make progress on closing this gap, and give a substantially more sample efficient agnostic boosting algorithm than those known, without compromising on the computational (or oracle) complexity. A key feature of our algorithm is that it leverages the ability to reuse samples across multiple rounds of boosting, while guaranteeing a generalization error strictly better than those obtained by blackbox applications of uniform convergence arguments. We also apply our approach to other previously studied learning problems, including boosting for reinforcement learning, and demonstrate improved results.</summary></entry><entry><title type="html">Seeding with Differentially Private Network Information</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/SeedingwithDifferentiallyPrivateNetworkInformation.html" rel="alternate" type="text/html" title="Seeding with Differentially Private Network Information" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/SeedingwithDifferentiallyPrivateNetworkInformation</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/SeedingwithDifferentiallyPrivateNetworkInformation.html">&lt;p&gt;In public health interventions such as the distribution of preexposure prophylaxis (PrEP) for HIV prevention, decision makers rely on seeding algorithms to identify key individuals who can amplify the impact of their interventions. In such cases, building a complete sexual activity network is often infeasible due to privacy concerns. Instead, contact tracing can provide influence samples, that is, sequences of sexual contacts without requiring complete network information. This presents two challenges: protecting individual privacy in contact data and adapting seeding algorithms to work effectively with incomplete network information. To solve these two problems, we study privacy guarantees for influence maximization algorithms when the social network is unknown and the inputs are samples of prior influence cascades that are collected at random and need privacy protection. Building on recent results that address seeding with costly network information, our privacy-preserving algorithms introduce randomization in the collected data or the algorithm output and can bound the privacy loss of each node (or group of nodes) in deciding to include their data in the algorithm input. We provide theoretical guarantees of seeding performance with a limited sample size subject to differential privacy budgets in both central and local privacy regimes. Simulations on synthetic random graphs and empirically grounded sexual contacts of men who have sex with men reveal the diminishing value of network information with decreasing privacy budget in both regimes and graceful decrease in performance with decreasing privacy budget in the central regime. Achieving good performance with local privacy guarantees requires relatively higher privacy budgets that confirm our theoretical expectations.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2305.16590&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>M. Amin Rahimian, Fang-Yi Yu, Yuxin Liu, Carlos Hurtado</name></author><category term="stat.AP" /><summary type="html">In public health interventions such as the distribution of preexposure prophylaxis (PrEP) for HIV prevention, decision makers rely on seeding algorithms to identify key individuals who can amplify the impact of their interventions. In such cases, building a complete sexual activity network is often infeasible due to privacy concerns. Instead, contact tracing can provide influence samples, that is, sequences of sexual contacts without requiring complete network information. This presents two challenges: protecting individual privacy in contact data and adapting seeding algorithms to work effectively with incomplete network information. To solve these two problems, we study privacy guarantees for influence maximization algorithms when the social network is unknown and the inputs are samples of prior influence cascades that are collected at random and need privacy protection. Building on recent results that address seeding with costly network information, our privacy-preserving algorithms introduce randomization in the collected data or the algorithm output and can bound the privacy loss of each node (or group of nodes) in deciding to include their data in the algorithm input. We provide theoretical guarantees of seeding performance with a limited sample size subject to differential privacy budgets in both central and local privacy regimes. Simulations on synthetic random graphs and empirically grounded sexual contacts of men who have sex with men reveal the diminishing value of network information with decreasing privacy budget in both regimes and graceful decrease in performance with decreasing privacy budget in the central regime. Achieving good performance with local privacy guarantees requires relatively higher privacy budgets that confirm our theoretical expectations.</summary></entry><entry><title type="html">Self-Calibrating Conformal Prediction</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/SelfCalibratingConformalPrediction.html" rel="alternate" type="text/html" title="Self-Calibrating Conformal Prediction" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/SelfCalibratingConformalPrediction</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/SelfCalibratingConformalPrediction.html">&lt;p&gt;In machine learning, model calibration and predictive inference are essential for producing reliable predictions and quantifying uncertainty to support decision-making. Recognizing the complementary roles of point and interval predictions, we introduce Self-Calibrating Conformal Prediction, a method that combines Venn-Abers calibration and conformal prediction to deliver calibrated point predictions alongside prediction intervals with finite-sample validity conditional on these predictions. To achieve this, we extend the original Venn-Abers procedure from binary classification to regression. Our theoretical framework supports analyzing conformal prediction methods that involve calibrating model predictions and subsequently constructing conditionally valid prediction intervals on the same data, where the conditioning set or conformity scores may depend on the calibrated predictions. Real-data experiments show that our method improves interval efficiency through model calibration and offers a practical alternative to feature-conditional validity.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.07307&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Lars van der Laan, Ahmed M. Alaa</name></author><category term="stat.ML," /><category term="stat.ME" /><summary type="html">In machine learning, model calibration and predictive inference are essential for producing reliable predictions and quantifying uncertainty to support decision-making. Recognizing the complementary roles of point and interval predictions, we introduce Self-Calibrating Conformal Prediction, a method that combines Venn-Abers calibration and conformal prediction to deliver calibrated point predictions alongside prediction intervals with finite-sample validity conditional on these predictions. To achieve this, we extend the original Venn-Abers procedure from binary classification to regression. Our theoretical framework supports analyzing conformal prediction methods that involve calibrating model predictions and subsequently constructing conditionally valid prediction intervals on the same data, where the conditioning set or conformity scores may depend on the calibrated predictions. Real-data experiments show that our method improves interval efficiency through model calibration and offers a practical alternative to feature-conditional validity.</summary></entry><entry><title type="html">Separation-based distance measures for causal graphs</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Separationbaseddistancemeasuresforcausalgraphs.html" rel="alternate" type="text/html" title="Separation-based distance measures for causal graphs" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Separationbaseddistancemeasuresforcausalgraphs</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Separationbaseddistancemeasuresforcausalgraphs.html">&lt;p&gt;Assessing the accuracy of the output of causal discovery algorithms is crucial in developing and comparing novel methods. Common evaluation metrics such as the structural Hamming distance are useful for assessing individual links of causal graphs. However, many state-of-the-art causal discovery methods do not output single causal graphs, but rather their Markov equivalence classes (MECs) which encode all of the graph’s separation and connection statements. In this work, we propose additional measures of distance that capture the difference in separations of two causal graphs which link-based distances are not fit to assess. The proposed distances have low polynomial time complexity and are applicable to directed acyclic graphs (DAGs) as well as to maximal ancestral graph (MAGs) that may contain bidirected edges. We complement our theoretical analysis with toy examples and empirical experiments that highlight the differences to existing comparison metrics.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.04952&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jonas Wahl, Jakob Runge</name></author><category term="stat.ME," /><category term="stat.ML" /><summary type="html">Assessing the accuracy of the output of causal discovery algorithms is crucial in developing and comparing novel methods. Common evaluation metrics such as the structural Hamming distance are useful for assessing individual links of causal graphs. However, many state-of-the-art causal discovery methods do not output single causal graphs, but rather their Markov equivalence classes (MECs) which encode all of the graph’s separation and connection statements. In this work, we propose additional measures of distance that capture the difference in separations of two causal graphs which link-based distances are not fit to assess. The proposed distances have low polynomial time complexity and are applicable to directed acyclic graphs (DAGs) as well as to maximal ancestral graph (MAGs) that may contain bidirected edges. We complement our theoretical analysis with toy examples and empirical experiments that highlight the differences to existing comparison metrics.</summary></entry><entry><title type="html">Sequential Order-Robust Mamba for Time Series Forecasting</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/SequentialOrderRobustMambaforTimeSeriesForecasting.html" rel="alternate" type="text/html" title="Sequential Order-Robust Mamba for Time Series Forecasting" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/SequentialOrderRobustMambaforTimeSeriesForecasting</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/SequentialOrderRobustMambaforTimeSeriesForecasting.html">&lt;p&gt;Mamba has recently emerged as a promising alternative to Transformers, offering near-linear complexity in processing sequential data. However, while channels in time series (TS) data have no specific order in general, recent studies have adopted Mamba to capture channel dependencies (CD) in TS, introducing a sequential order bias. To address this issue, we propose SOR-Mamba, a TS forecasting method that 1) incorporates a regularization strategy to minimize the discrepancy between two embedding vectors generated from data with reversed channel orders, thereby enhancing robustness to channel order, and 2) eliminates the 1D-convolution originally designed to capture local information in sequential data. Furthermore, we introduce channel correlation modeling (CCM), a pretraining task aimed at preserving correlations between channels from the data space to the latent space in order to enhance the ability to capture CD. Extensive experiments demonstrate the efficacy of the proposed method across standard and transfer learning scenarios. Code is available at https://github.com/seunghan96/SOR-Mamba.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23356&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Seunghan Lee, Juri Hong, Kibok Lee, Taeyoung Park</name></author><category term="stat.ML" /><summary type="html">Mamba has recently emerged as a promising alternative to Transformers, offering near-linear complexity in processing sequential data. However, while channels in time series (TS) data have no specific order in general, recent studies have adopted Mamba to capture channel dependencies (CD) in TS, introducing a sequential order bias. To address this issue, we propose SOR-Mamba, a TS forecasting method that 1) incorporates a regularization strategy to minimize the discrepancy between two embedding vectors generated from data with reversed channel orders, thereby enhancing robustness to channel order, and 2) eliminates the 1D-convolution originally designed to capture local information in sequential data. Furthermore, we introduce channel correlation modeling (CCM), a pretraining task aimed at preserving correlations between channels from the data space to the latent space in order to enhance the ability to capture CD. Extensive experiments demonstrate the efficacy of the proposed method across standard and transfer learning scenarios. Code is available at https://github.com/seunghan96/SOR-Mamba.</summary></entry><entry><title type="html">Single CASANOVA? Not in multiple comparisons</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/SingleCASANOVANotinmultiplecomparisons.html" rel="alternate" type="text/html" title="Single CASANOVA? Not in multiple comparisons" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/SingleCASANOVANotinmultiplecomparisons</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/SingleCASANOVANotinmultiplecomparisons.html">&lt;p&gt;When comparing multiple groups in clinical trials, we are not only interested in whether there is a difference between any groups but rather the location. Such research questions lead to testing multiple individual hypotheses. To control the familywise error rate (FWER), we must apply some corrections or introduce tests that control the FWER by design. In the case of time-to-event data, a Bonferroni-corrected log-rank test is commonly used. This approach has two significant drawbacks: (i) it loses power when the proportional hazards assumption is violated [1] and (ii) the correction generally leads to a lower power, especially when the test statistics are not independent [2]. We propose two new tests based on combined weighted log-rank tests. One as a simple multiple contrast test of weighted log-rank tests and one as an extension of the so-called CASANOVA test [3]. The latter was introduced for factorial designs. We propose a new multiple contrast test based on the CASANOVA approach. Our test promises to be more powerful under crossing hazards and eliminates the need for additional p-value correction. We assess the performance of our tests through extensive Monte Carlo simulation studies covering both proportional and non-proportional hazard scenarios. Finally, we apply the new and reference methods to a real-world data example. The new approaches control the FWER and show reasonable power in all scenarios. They outperform the adjusted approaches in some non-proportional settings in terms of power.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.21098&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Ina Dormuth, Carolin Herrmann, Frank Konietschke, Markus Pauly, Matthias Wirth, Marc Ditzhaus</name></author><category term="stat.ME" /><summary type="html">When comparing multiple groups in clinical trials, we are not only interested in whether there is a difference between any groups but rather the location. Such research questions lead to testing multiple individual hypotheses. To control the familywise error rate (FWER), we must apply some corrections or introduce tests that control the FWER by design. In the case of time-to-event data, a Bonferroni-corrected log-rank test is commonly used. This approach has two significant drawbacks: (i) it loses power when the proportional hazards assumption is violated [1] and (ii) the correction generally leads to a lower power, especially when the test statistics are not independent [2]. We propose two new tests based on combined weighted log-rank tests. One as a simple multiple contrast test of weighted log-rank tests and one as an extension of the so-called CASANOVA test [3]. The latter was introduced for factorial designs. We propose a new multiple contrast test based on the CASANOVA approach. Our test promises to be more powerful under crossing hazards and eliminates the need for additional p-value correction. We assess the performance of our tests through extensive Monte Carlo simulation studies covering both proportional and non-proportional hazard scenarios. Finally, we apply the new and reference methods to a real-world data example. The new approaches control the FWER and show reasonable power in all scenarios. They outperform the adjusted approaches in some non-proportional settings in terms of power.</summary></entry><entry><title type="html">Stabilizing Linear Passive-Aggressive Online Learning with Weighted Reservoir Sampling</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/StabilizingLinearPassiveAggressiveOnlineLearningwithWeightedReservoirSampling.html" rel="alternate" type="text/html" title="Stabilizing Linear Passive-Aggressive Online Learning with Weighted Reservoir Sampling" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/StabilizingLinearPassiveAggressiveOnlineLearningwithWeightedReservoirSampling</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/StabilizingLinearPassiveAggressiveOnlineLearningwithWeightedReservoirSampling.html">&lt;p&gt;Online learning methods, like the seminal Passive-Aggressive (PA) classifier, are still highly effective for high-dimensional streaming data, out-of-core processing, and other throughput-sensitive applications. Many such algorithms rely on fast adaptation to individual errors as a key to their convergence. While such algorithms enjoy low theoretical regret, in real-world deployment they can be sensitive to individual outliers that cause the algorithm to over-correct. When such outliers occur at the end of the data stream, this can cause the final solution to have unexpectedly low accuracy. We design a weighted reservoir sampling (WRS) approach to obtain a stable ensemble model from the sequence of solutions without requiring additional passes over the data, hold-out sets, or a growing amount of memory. Our key insight is that good solutions tend to be error-free for more iterations than bad solutions, and thus, the number of passive rounds provides an estimate of a solution’s relative quality. Our reservoir thus contains $K$ previous intermediate weight vectors with high survival times. We demonstrate our WRS approach on the Passive-Aggressive Classifier (PAC) and First-Order Sparse Online Learning (FSOL), where our method consistently and significantly outperforms the unmodified approach. We show that the risk of the ensemble classifier is bounded with respect to the regret of the underlying online learning method.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23601&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Skyler Wu, Fred Lu, Edward Raff, James Holt</name></author><category term="stat.ML" /><summary type="html">Online learning methods, like the seminal Passive-Aggressive (PA) classifier, are still highly effective for high-dimensional streaming data, out-of-core processing, and other throughput-sensitive applications. Many such algorithms rely on fast adaptation to individual errors as a key to their convergence. While such algorithms enjoy low theoretical regret, in real-world deployment they can be sensitive to individual outliers that cause the algorithm to over-correct. When such outliers occur at the end of the data stream, this can cause the final solution to have unexpectedly low accuracy. We design a weighted reservoir sampling (WRS) approach to obtain a stable ensemble model from the sequence of solutions without requiring additional passes over the data, hold-out sets, or a growing amount of memory. Our key insight is that good solutions tend to be error-free for more iterations than bad solutions, and thus, the number of passive rounds provides an estimate of a solution’s relative quality. Our reservoir thus contains $K$ previous intermediate weight vectors with high survival times. We demonstrate our WRS approach on the Passive-Aggressive Classifier (PAC) and First-Order Sparse Online Learning (FSOL), where our method consistently and significantly outperforms the unmodified approach. We show that the risk of the ensemble classifier is bounded with respect to the regret of the underlying online learning method.</summary></entry><entry><title type="html">Symmetric Linear Bandits with Hidden Symmetry</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/SymmetricLinearBanditswithHiddenSymmetry.html" rel="alternate" type="text/html" title="Symmetric Linear Bandits with Hidden Symmetry" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/SymmetricLinearBanditswithHiddenSymmetry</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/SymmetricLinearBanditswithHiddenSymmetry.html">&lt;p&gt;High-dimensional linear bandits with low-dimensional structure have received considerable attention in recent studies due to their practical significance. The most common structure in the literature is sparsity. However, it may not be available in practice. Symmetry, where the reward is invariant under certain groups of transformations on the set of arms, is another important inductive bias in the high-dimensional case that covers many standard structures, including sparsity. In this work, we study high-dimensional symmetric linear bandits where the symmetry is hidden from the learner, and the correct symmetry needs to be learned in an online setting. We examine the structure of a collection of hidden symmetry and provide a method based on model selection within the collection of low-dimensional subspaces. Our algorithm achieves a regret bound of $ O(d_0^{2/3} T^{2/3} \log(d))$, where $d$ is the ambient dimension which is potentially very large, and $d_0$ is the dimension of the true low-dimensional subspace such that $d_0 \ll d$. With an extra assumption on well-separated models, we can further improve the regret to $ O(d_0\sqrt{T\log(d)} )$.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.13899&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Nam Phuong Tran, The Anh Ta, Debmalya Mandal, Long Tran-Thanh</name></author><category term="stat.ML" /><summary type="html">High-dimensional linear bandits with low-dimensional structure have received considerable attention in recent studies due to their practical significance. The most common structure in the literature is sparsity. However, it may not be available in practice. Symmetry, where the reward is invariant under certain groups of transformations on the set of arms, is another important inductive bias in the high-dimensional case that covers many standard structures, including sparsity. In this work, we study high-dimensional symmetric linear bandits where the symmetry is hidden from the learner, and the correct symmetry needs to be learned in an online setting. We examine the structure of a collection of hidden symmetry and provide a method based on model selection within the collection of low-dimensional subspaces. Our algorithm achieves a regret bound of $ O(d_0^{2/3} T^{2/3} \log(d))$, where $d$ is the ambient dimension which is potentially very large, and $d_0$ is the dimension of the true low-dimensional subspace such that $d_0 \ll d$. With an extra assumption on well-separated models, we can further improve the regret to $ O(d_0\sqrt{T\log(d)} )$.</summary></entry><entry><title type="html">Tangent Space Causal Inference: Leveraging Vector Fields for Causal Discovery in Dynamical Systems</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/TangentSpaceCausalInferenceLeveragingVectorFieldsforCausalDiscoveryinDynamicalSystems.html" rel="alternate" type="text/html" title="Tangent Space Causal Inference: Leveraging Vector Fields for Causal Discovery in Dynamical Systems" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/TangentSpaceCausalInferenceLeveragingVectorFieldsforCausalDiscoveryinDynamicalSystems</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/TangentSpaceCausalInferenceLeveragingVectorFieldsforCausalDiscoveryinDynamicalSystems.html">&lt;p&gt;Causal discovery with time series data remains a challenging yet increasingly important task across many scientific domains. Convergent cross mapping (CCM) and related methods have been proposed to study time series that are generated by dynamical systems, where traditional approaches like Granger causality are unreliable. However, CCM often yields inaccurate results depending upon the quality of the data. We propose the Tangent Space Causal Inference (TSCI) method for detecting causalities in dynamical systems. TSCI works by considering vector fields as explicit representations of the systems’ dynamics and checks for the degree of synchronization between the learned vector fields. The TSCI approach is model-agnostic and can be used as a drop-in replacement for CCM and its generalizations. We first present a basic version of the TSCI algorithm, which is shown to be more effective than the basic CCM algorithm with very little additional computation. We additionally present augmented versions of TSCI that leverage the expressive power of latent variable models and deep learning. We validate our theory on standard systems, and we demonstrate improved causal inference performance across a number of benchmark tasks.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23499&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Kurt Butler, Daniel Waxman, Petar M. Djurić</name></author><category term="stat.ML" /><summary type="html">Causal discovery with time series data remains a challenging yet increasingly important task across many scientific domains. Convergent cross mapping (CCM) and related methods have been proposed to study time series that are generated by dynamical systems, where traditional approaches like Granger causality are unreliable. However, CCM often yields inaccurate results depending upon the quality of the data. We propose the Tangent Space Causal Inference (TSCI) method for detecting causalities in dynamical systems. TSCI works by considering vector fields as explicit representations of the systems’ dynamics and checks for the degree of synchronization between the learned vector fields. The TSCI approach is model-agnostic and can be used as a drop-in replacement for CCM and its generalizations. We first present a basic version of the TSCI algorithm, which is shown to be more effective than the basic CCM algorithm with very little additional computation. We additionally present augmented versions of TSCI that leverage the expressive power of latent variable models and deep learning. We validate our theory on standard systems, and we demonstrate improved causal inference performance across a number of benchmark tasks.</summary></entry><entry><title type="html">Task-Agnostic Machine-Learning-Assisted Inference</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/TaskAgnosticMachineLearningAssistedInference.html" rel="alternate" type="text/html" title="Task-Agnostic Machine-Learning-Assisted Inference" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/TaskAgnosticMachineLearningAssistedInference</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/TaskAgnosticMachineLearningAssistedInference.html">&lt;p&gt;Machine learning (ML) is playing an increasingly important role in scientific research. In conjunction with classical statistical approaches, ML-assisted analytical strategies have shown great promise in accelerating research findings. This has also opened a whole field of methodological research focusing on integrative approaches that leverage both ML and statistics to tackle data science challenges. One type of study that has quickly gained popularity employs ML to predict unobserved outcomes in massive samples, and then uses predicted outcomes in downstream statistical inference. However, existing methods designed to ensure the validity of this type of post-prediction inference are limited to very basic tasks such as linear regression analysis. This is because any extension of these approaches to new, more sophisticated statistical tasks requires task-specific algebraic derivations and software implementations, which ignores the massive library of existing software tools already developed for the same scientific problem given observed data. This severely constrains the scope of application for post-prediction inference. To address this challenge, we introduce a novel statistical framework named PSPS for task-agnostic ML-assisted inference. It provides a post-prediction inference solution that can be easily plugged into almost any established data analysis routines. It delivers valid and efficient inference that is robust to arbitrary choice of ML model, allowing nearly all existing statistical frameworks to be incorporated into the analysis of ML-predicted data. Through extensive experiments, we showcase our method’s validity, versatility, and superiority compared to existing approaches. Our software is available at https://github.com/qlu-lab/psps.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2405.20039&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jiacheng Miao, Qiongshi Lu</name></author><category term="stat.ML," /><category term="stat.ME" /><summary type="html">Machine learning (ML) is playing an increasingly important role in scientific research. In conjunction with classical statistical approaches, ML-assisted analytical strategies have shown great promise in accelerating research findings. This has also opened a whole field of methodological research focusing on integrative approaches that leverage both ML and statistics to tackle data science challenges. One type of study that has quickly gained popularity employs ML to predict unobserved outcomes in massive samples, and then uses predicted outcomes in downstream statistical inference. However, existing methods designed to ensure the validity of this type of post-prediction inference are limited to very basic tasks such as linear regression analysis. This is because any extension of these approaches to new, more sophisticated statistical tasks requires task-specific algebraic derivations and software implementations, which ignores the massive library of existing software tools already developed for the same scientific problem given observed data. This severely constrains the scope of application for post-prediction inference. To address this challenge, we introduce a novel statistical framework named PSPS for task-agnostic ML-assisted inference. It provides a post-prediction inference solution that can be easily plugged into almost any established data analysis routines. It delivers valid and efficient inference that is robust to arbitrary choice of ML model, allowing nearly all existing statistical frameworks to be incorporated into the analysis of ML-predicted data. Through extensive experiments, we showcase our method’s validity, versatility, and superiority compared to existing approaches. Our software is available at https://github.com/qlu-lab/psps.</summary></entry><entry><title type="html">The Nudge Average Treatment Effect</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/TheNudgeAverageTreatmentEffect.html" rel="alternate" type="text/html" title="The Nudge Average Treatment Effect" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/TheNudgeAverageTreatmentEffect</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/TheNudgeAverageTreatmentEffect.html">&lt;p&gt;The instrumental variable method is a prominent approach to recover under certain conditions, valid inference about a treatment causal effect even when unmeasured confounding might be present. In a groundbreaking paper, Imbens and Angrist (1994) established that a valid instrument nonparametrically identifies the average causal effect among compliers, also known as the local average treatment effect under a certain monotonicity assumption which rules out the existence of so-called defiers. An often-cited attractive property of monotonicity is that it facilitates a causal interpretation of the instrumental variable estimand without restricting the degree of heterogeneity of the treatment causal effect. In this paper, we introduce an alternative equally straightforward and interpretable condition for identification, which accommodates both the presence of defiers and heterogenous treatment effects. Mainly, we show that under our new conditions, the instrumental variable estimand recovers the average causal effect for the subgroup of units for whom the treatment is manipulable by the instrument, a subgroup which may consist of both defiers and compliers, therefore recovering an effect estimand we aptly call the Nudge Average Treatment Effect.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23590&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Eric J Tchetgen Tchetgen</name></author><category term="stat.ME" /><summary type="html">The instrumental variable method is a prominent approach to recover under certain conditions, valid inference about a treatment causal effect even when unmeasured confounding might be present. In a groundbreaking paper, Imbens and Angrist (1994) established that a valid instrument nonparametrically identifies the average causal effect among compliers, also known as the local average treatment effect under a certain monotonicity assumption which rules out the existence of so-called defiers. An often-cited attractive property of monotonicity is that it facilitates a causal interpretation of the instrumental variable estimand without restricting the degree of heterogeneity of the treatment causal effect. In this paper, we introduce an alternative equally straightforward and interpretable condition for identification, which accommodates both the presence of defiers and heterogenous treatment effects. Mainly, we show that under our new conditions, the instrumental variable estimand recovers the average causal effect for the subgroup of units for whom the treatment is manipulable by the instrument, a subgroup which may consist of both defiers and compliers, therefore recovering an effect estimand we aptly call the Nudge Average Treatment Effect.</summary></entry><entry><title type="html">The VIX as Stochastic Volatility for Corporate Bonds</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/TheVIXasStochasticVolatilityforCorporateBonds.html" rel="alternate" type="text/html" title="The VIX as Stochastic Volatility for Corporate Bonds" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/TheVIXasStochasticVolatilityforCorporateBonds</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/TheVIXasStochasticVolatilityforCorporateBonds.html">&lt;p&gt;Classic stochastic volatility models assume volatility is unobservable. We use the VIX for consider it observable, and use the Volatility Index: S\&amp;amp;P 500 VIX. This index was designed to measure volatility of S&amp;amp;P 500. We apply it to a different segment: Corporate bond markets. We fit time series models for spreads between corporate and 10-year Treasury bonds. Next, we divide residuals by VIX. Our main idea is such division makes residuals closer to the ideal case of a Gaussian white noise. This is remarkable, since these residuals and VIX come from separate market segments. We conclude with the analysis of long-term behavior of these models.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.22498&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jihyun Park, Andrey Sarantsev</name></author><category term="stat.AP" /><summary type="html">Classic stochastic volatility models assume volatility is unobservable. We use the VIX for consider it observable, and use the Volatility Index: S\&amp;amp;P 500 VIX. This index was designed to measure volatility of S&amp;amp;P 500. We apply it to a different segment: Corporate bond markets. We fit time series models for spreads between corporate and 10-year Treasury bonds. Next, we divide residuals by VIX. Our main idea is such division makes residuals closer to the ideal case of a Gaussian white noise. This is remarkable, since these residuals and VIX come from separate market segments. We conclude with the analysis of long-term behavior of these models.</summary></entry><entry><title type="html">Tree of Attacks: Jailbreaking Black-Box LLMs Automatically</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/TreeofAttacksJailbreakingBlackBoxLLMsAutomatically.html" rel="alternate" type="text/html" title="Tree of Attacks: Jailbreaking Black-Box LLMs Automatically" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/TreeofAttacksJailbreakingBlackBoxLLMsAutomatically</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/TreeofAttacksJailbreakingBlackBoxLLMsAutomatically.html">&lt;p&gt;While Large Language Models (LLMs) display versatile functionality, they continue to generate harmful, biased, and toxic content, as demonstrated by the prevalence of human-designed jailbreaks. In this work, we present Tree of Attacks with Pruning (TAP), an automated method for generating jailbreaks that only requires black-box access to the target LLM. TAP utilizes an attacker LLM to iteratively refine candidate (attack) prompts until one of the refined prompts jailbreaks the target. In addition, before sending prompts to the target, TAP assesses them and prunes the ones unlikely to result in jailbreaks, reducing the number of queries sent to the target LLM. In empirical evaluations, we observe that TAP generates prompts that jailbreak state-of-the-art LLMs (including GPT4-Turbo and GPT4o) for more than 80% of the prompts. This significantly improves upon the previous state-of-the-art black-box methods for generating jailbreaks while using a smaller number of queries than them. Furthermore, TAP is also capable of jailbreaking LLMs protected by state-of-the-art guardrails, e.g., LlamaGuard.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2312.02119&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Anay Mehrotra, Manolis Zampetakis, Paul Kassianik, Blaine Nelson, Hyrum Anderson, Yaron Singer, Amin Karbasi</name></author><category term="stat.ML" /><summary type="html">While Large Language Models (LLMs) display versatile functionality, they continue to generate harmful, biased, and toxic content, as demonstrated by the prevalence of human-designed jailbreaks. In this work, we present Tree of Attacks with Pruning (TAP), an automated method for generating jailbreaks that only requires black-box access to the target LLM. TAP utilizes an attacker LLM to iteratively refine candidate (attack) prompts until one of the refined prompts jailbreaks the target. In addition, before sending prompts to the target, TAP assesses them and prunes the ones unlikely to result in jailbreaks, reducing the number of queries sent to the target LLM. In empirical evaluations, we observe that TAP generates prompts that jailbreak state-of-the-art LLMs (including GPT4-Turbo and GPT4o) for more than 80% of the prompts. This significantly improves upon the previous state-of-the-art black-box methods for generating jailbreaks while using a smaller number of queries than them. Furthermore, TAP is also capable of jailbreaking LLMs protected by state-of-the-art guardrails, e.g., LlamaGuard.</summary></entry><entry><title type="html">Two-sided conformalized survival analysis</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Twosidedconformalizedsurvivalanalysis.html" rel="alternate" type="text/html" title="Two-sided conformalized survival analysis" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Twosidedconformalizedsurvivalanalysis</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Twosidedconformalizedsurvivalanalysis.html">&lt;p&gt;This paper presents a novel method using conformal prediction to generate two-sided or one-sided prediction intervals for survival times. Specifically, the method provides both lower and upper predictive bounds for individuals deemed sufficiently similar to the non-censored population, while returning only a lower bound for others. The prediction intervals offer finite-sample coverage guarantees, requiring no distributional assumptions other than the sampled data points are independent and identically distributed. The performance of the procedure is assessed using both synthetic and real-world datasets.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24136&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Chris Holmes, Ariane Marandon</name></author><category term="stat.ME" /><summary type="html">This paper presents a novel method using conformal prediction to generate two-sided or one-sided prediction intervals for survival times. Specifically, the method provides both lower and upper predictive bounds for individuals deemed sufficiently similar to the non-censored population, while returning only a lower bound for others. The prediction intervals offer finite-sample coverage guarantees, requiring no distributional assumptions other than the sampled data points are independent and identically distributed. The performance of the procedure is assessed using both synthetic and real-world datasets.</summary></entry><entry><title type="html">Understanding Optimization in Deep Learning with Central Flows</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/UnderstandingOptimizationinDeepLearningwithCentralFlows.html" rel="alternate" type="text/html" title="Understanding Optimization in Deep Learning with Central Flows" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/UnderstandingOptimizationinDeepLearningwithCentralFlows</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/UnderstandingOptimizationinDeepLearningwithCentralFlows.html">&lt;p&gt;Optimization in deep learning remains poorly understood, even in the simple setting of deterministic (i.e. full-batch) training. A key difficulty is that much of an optimizer’s behavior is implicitly determined by complex oscillatory dynamics, referred to as the “edge of stability.” The main contribution of this paper is to show that an optimizer’s implicit behavior can be explicitly captured by a “central flow:” a differential equation which models the time-averaged optimization trajectory. We show that these flows can empirically predict long-term optimization trajectories of generic neural networks with a high degree of numerical accuracy. By interpreting these flows, we reveal for the first time 1) the precise sense in which RMSProp adapts to the local loss landscape, and 2) an “acceleration via regularization” mechanism, wherein adaptive optimizers implicitly navigate towards low-curvature regions in which they can take larger steps. This mechanism is key to the efficacy of these adaptive optimizers. Overall, we believe that central flows constitute a promising tool for reasoning about optimization in deep learning.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.24206&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Jeremy M. Cohen, Alex Damian, Ameet Talwalkar, Zico Kolter, Jason D. Lee</name></author><category term="stat.ML" /><summary type="html">Optimization in deep learning remains poorly understood, even in the simple setting of deterministic (i.e. full-batch) training. A key difficulty is that much of an optimizer’s behavior is implicitly determined by complex oscillatory dynamics, referred to as the “edge of stability.” The main contribution of this paper is to show that an optimizer’s implicit behavior can be explicitly captured by a “central flow:” a differential equation which models the time-averaged optimization trajectory. We show that these flows can empirically predict long-term optimization trajectories of generic neural networks with a high degree of numerical accuracy. By interpreting these flows, we reveal for the first time 1) the precise sense in which RMSProp adapts to the local loss landscape, and 2) an “acceleration via regularization” mechanism, wherein adaptive optimizers implicitly navigate towards low-curvature regions in which they can take larger steps. This mechanism is key to the efficacy of these adaptive optimizers. Overall, we believe that central flows constitute a promising tool for reasoning about optimization in deep learning.</summary></entry><entry><title type="html">Uniform Last-Iterate Guarantee for Bandits and Reinforcement Learning</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/UniformLastIterateGuaranteeforBanditsandReinforcementLearning.html" rel="alternate" type="text/html" title="Uniform Last-Iterate Guarantee for Bandits and Reinforcement Learning" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/UniformLastIterateGuaranteeforBanditsandReinforcementLearning</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/UniformLastIterateGuaranteeforBanditsandReinforcementLearning.html">&lt;p&gt;Existing metrics for reinforcement learning (RL) such as regret, PAC bounds, or uniform-PAC (Dann et al., 2017), typically evaluate the cumulative performance, while allowing the agent to play an arbitrarily bad policy at any finite time t. Such a behavior can be highly detrimental in high-stakes applications. This paper introduces a stronger metric, uniform last-iterate (ULI) guarantee, capturing both cumulative and instantaneous performance of RL algorithms. Specifically, ULI characterizes the instantaneous performance by ensuring that the per-round suboptimality of the played policy is bounded by a function, monotonically decreasing w.r.t. round t, preventing revisiting bad policies when sufficient samples are available. We demonstrate that a near-optimal ULI guarantee directly implies near-optimal cumulative performance across aforementioned metrics, but not the other way around. To examine the achievability of ULI, we first provide two positive results for bandit problems with finite arms, showing that elimination-based algorithms and high-probability adversarial algorithms with stronger analysis or additional designs, can attain near-optimal ULI guarantees. We also provide a negative result, indicating that optimistic algorithms cannot achieve near-optimal ULI guarantee. Furthermore, we propose an efficient algorithm for linear bandits with infinitely many arms, which achieves the ULI guarantee, given access to an optimization oracle. Finally, we propose an algorithm that achieves near-optimal ULI guarantee for the online reinforcement learning setting.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2402.12711&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Junyan Liu, Yunfan Li, Ruosong Wang, Lin F. Yang</name></author><category term="stat.ML" /><summary type="html">Existing metrics for reinforcement learning (RL) such as regret, PAC bounds, or uniform-PAC (Dann et al., 2017), typically evaluate the cumulative performance, while allowing the agent to play an arbitrarily bad policy at any finite time t. Such a behavior can be highly detrimental in high-stakes applications. This paper introduces a stronger metric, uniform last-iterate (ULI) guarantee, capturing both cumulative and instantaneous performance of RL algorithms. Specifically, ULI characterizes the instantaneous performance by ensuring that the per-round suboptimality of the played policy is bounded by a function, monotonically decreasing w.r.t. round t, preventing revisiting bad policies when sufficient samples are available. We demonstrate that a near-optimal ULI guarantee directly implies near-optimal cumulative performance across aforementioned metrics, but not the other way around. To examine the achievability of ULI, we first provide two positive results for bandit problems with finite arms, showing that elimination-based algorithms and high-probability adversarial algorithms with stronger analysis or additional designs, can attain near-optimal ULI guarantees. We also provide a negative result, indicating that optimistic algorithms cannot achieve near-optimal ULI guarantee. Furthermore, we propose an efficient algorithm for linear bandits with infinitely many arms, which achieves the ULI guarantee, given access to an optimization oracle. Finally, we propose an algorithm that achieves near-optimal ULI guarantee for the online reinforcement learning setting.</summary></entry><entry><title type="html">Unveiling the Hidden Structure of Self-Attention via Kernel Principal Component Analysis</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/UnveilingtheHiddenStructureofSelfAttentionviaKernelPrincipalComponentAnalysis.html" rel="alternate" type="text/html" title="Unveiling the Hidden Structure of Self-Attention via Kernel Principal Component Analysis" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/UnveilingtheHiddenStructureofSelfAttentionviaKernelPrincipalComponentAnalysis</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/UnveilingtheHiddenStructureofSelfAttentionviaKernelPrincipalComponentAnalysis.html">&lt;p&gt;The remarkable success of transformers in sequence modeling tasks, spanning various applications in natural language processing and computer vision, is attributed to the critical role of self-attention. Similar to the development of most deep learning models, the construction of these attention mechanisms relies on heuristics and experience. In our work, we derive self-attention from kernel principal component analysis (kernel PCA) and show that self-attention projects its query vectors onto the principal component axes of its key matrix in a feature space. We then formulate the exact formula for the value matrix in self-attention, theoretically and empirically demonstrating that this value matrix captures the eigenvectors of the Gram matrix of the key vectors in self-attention. Leveraging our kernel PCA framework, we propose Attention with Robust Principal Components (RPC-Attention), a novel class of robust attention that is resilient to data contamination. We empirically demonstrate the advantages of RPC-Attention over softmax attention on the ImageNet-1K object classification, WikiText-103 language modeling, and ADE20K image segmentation task.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2406.13762&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Rachel S. Y. Teo, Tan M. Nguyen</name></author><category term="stat.ML" /><summary type="html">The remarkable success of transformers in sequence modeling tasks, spanning various applications in natural language processing and computer vision, is attributed to the critical role of self-attention. Similar to the development of most deep learning models, the construction of these attention mechanisms relies on heuristics and experience. In our work, we derive self-attention from kernel principal component analysis (kernel PCA) and show that self-attention projects its query vectors onto the principal component axes of its key matrix in a feature space. We then formulate the exact formula for the value matrix in self-attention, theoretically and empirically demonstrating that this value matrix captures the eigenvectors of the Gram matrix of the key vectors in self-attention. Leveraging our kernel PCA framework, we propose Attention with Robust Principal Components (RPC-Attention), a novel class of robust attention that is resilient to data contamination. We empirically demonstrate the advantages of RPC-Attention over softmax attention on the ImageNet-1K object classification, WikiText-103 language modeling, and ADE20K image segmentation task.</summary></entry><entry><title type="html">Variance-Aware Estimation of Kernel Mean Embedding</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/VarianceAwareEstimationofKernelMeanEmbedding.html" rel="alternate" type="text/html" title="Variance-Aware Estimation of Kernel Mean Embedding" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/VarianceAwareEstimationofKernelMeanEmbedding</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/VarianceAwareEstimationofKernelMeanEmbedding.html">&lt;p&gt;An important feature of kernel mean embeddings (KME) is that the rate of convergence of the empirical KME to the true distribution KME can be bounded independently of the dimension of the space, properties of the distribution and smoothness features of the kernel. We show how to speed-up convergence by leveraging variance information in the reproducing kernel Hilbert space. Furthermore, we show that even when such information is a priori unknown, we can efficiently estimate it from the data, recovering the desiderata of a distribution agnostic bound that enjoys acceleration in fortuitous settings. We further extend our results from independent data to stationary mixing sequences and illustrate our methods in the context of hypothesis testing and robust parametric estimation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2210.06672&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Geoffrey Wolfer, Pierre Alquier</name></author><category term="stat.ML," /><category term="stat.TH" /><summary type="html">An important feature of kernel mean embeddings (KME) is that the rate of convergence of the empirical KME to the true distribution KME can be bounded independently of the dimension of the space, properties of the distribution and smoothness features of the kernel. We show how to speed-up convergence by leveraging variance information in the reproducing kernel Hilbert space. Furthermore, we show that even when such information is a priori unknown, we can efficiently estimate it from the data, recovering the desiderata of a distribution agnostic bound that enjoys acceleration in fortuitous settings. We further extend our results from independent data to stationary mixing sequences and illustrate our methods in the context of hypothesis testing and robust parametric estimation.</summary></entry><entry><title type="html">Weak Supervision Performance Evaluation via Partial Identification</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/WeakSupervisionPerformanceEvaluationviaPartialIdentification.html" rel="alternate" type="text/html" title="Weak Supervision Performance Evaluation via Partial Identification" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/WeakSupervisionPerformanceEvaluationviaPartialIdentification</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/WeakSupervisionPerformanceEvaluationviaPartialIdentification.html">&lt;p&gt;Programmatic Weak Supervision (PWS) enables supervised model training without direct access to ground truth labels, utilizing weak labels from heuristics, crowdsourcing, or pre-trained models. However, the absence of ground truth complicates model evaluation, as traditional metrics such as accuracy, precision, and recall cannot be directly calculated. In this work, we present a novel method to address this challenge by framing model evaluation as a partial identification problem and estimating performance bounds using Fr&apos;echet bounds. Our approach derives reliable bounds on key metrics without requiring labeled data, overcoming core limitations in current weak supervision evaluation techniques. Through scalable convex optimization, we obtain accurate and computationally efficient bounds for metrics including accuracy, precision, recall, and F1-score, even in high-dimensional settings. This framework offers a robust approach to assessing model quality without ground truth labels, enhancing the practicality of weakly supervised learning for real-world applications.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2312.04601&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Felipe Maia Polo, Subha Maity, Mikhail Yurochkin, Moulinath Banerjee, Yuekai Sun</name></author><category term="stat.ML," /><category term="stat.ME" /><summary type="html">Programmatic Weak Supervision (PWS) enables supervised model training without direct access to ground truth labels, utilizing weak labels from heuristics, crowdsourcing, or pre-trained models. However, the absence of ground truth complicates model evaluation, as traditional metrics such as accuracy, precision, and recall cannot be directly calculated. In this work, we present a novel method to address this challenge by framing model evaluation as a partial identification problem and estimating performance bounds using Fr&apos;echet bounds. Our approach derives reliable bounds on key metrics without requiring labeled data, overcoming core limitations in current weak supervision evaluation techniques. Through scalable convex optimization, we obtain accurate and computationally efficient bounds for metrics including accuracy, precision, recall, and F1-score, even in high-dimensional settings. This framework offers a robust approach to assessing model quality without ground truth labels, enhancing the practicality of weakly supervised learning for real-world applications.</summary></entry><entry><title type="html">Wide Two-Layer Networks can Learn from Adversarial Perturbations</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/WideTwoLayerNetworkscanLearnfromAdversarialPerturbations.html" rel="alternate" type="text/html" title="Wide Two-Layer Networks can Learn from Adversarial Perturbations" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/WideTwoLayerNetworkscanLearnfromAdversarialPerturbations</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/WideTwoLayerNetworkscanLearnfromAdversarialPerturbations.html">&lt;p&gt;Adversarial examples have raised several open questions, such as why they can deceive classifiers and transfer between different models. A prevailing hypothesis to explain these phenomena suggests that adversarial perturbations appear as random noise but contain class-specific features. This hypothesis is supported by the success of perturbation learning, where classifiers trained solely on adversarial examples and the corresponding incorrect labels generalize well to correctly labeled test data. Although this hypothesis and perturbation learning are effective in explaining intriguing properties of adversarial examples, their solid theoretical foundation is limited. In this study, we theoretically explain the counterintuitive success of perturbation learning. We assume wide two-layer networks and the results hold for any data distribution. We prove that adversarial perturbations contain sufficient class-specific features for networks to generalize from them. Moreover, the predictions of classifiers trained on mislabeled adversarial examples coincide with those of classifiers trained on correctly labeled clean samples. The code is available at https://github.com/s-kumano/perturbation-learning.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23677&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Soichiro Kumano, Hiroshi Kera, Toshihiko Yamasaki</name></author><category term="stat.ML" /><summary type="html">Adversarial examples have raised several open questions, such as why they can deceive classifiers and transfer between different models. A prevailing hypothesis to explain these phenomena suggests that adversarial perturbations appear as random noise but contain class-specific features. This hypothesis is supported by the success of perturbation learning, where classifiers trained solely on adversarial examples and the corresponding incorrect labels generalize well to correctly labeled test data. Although this hypothesis and perturbation learning are effective in explaining intriguing properties of adversarial examples, their solid theoretical foundation is limited. In this study, we theoretically explain the counterintuitive success of perturbation learning. We assume wide two-layer networks and the results hold for any data distribution. We prove that adversarial perturbations contain sufficient class-specific features for networks to generalize from them. Moreover, the predictions of classifiers trained on mislabeled adversarial examples coincide with those of classifiers trained on correctly labeled clean samples. The code is available at https://github.com/s-kumano/perturbation-learning.</summary></entry><entry><title type="html">Zero-inflated stochastic block modeling of efficiency-security tradeoffs in weighted criminal networks</title><link href="https://dedzago.github.io/arxiv_rss/2024/11/01/Zeroinflatedstochasticblockmodelingofefficiencysecuritytradeoffsinweightedcriminalnetworks.html" rel="alternate" type="text/html" title="Zero-inflated stochastic block modeling of efficiency-security tradeoffs in weighted criminal networks" /><published>2024-11-01T00:00:00+00:00</published><updated>2024-11-01T00:00:00+00:00</updated><id>https://dedzago.github.io/arxiv_rss/2024/11/01/Zeroinflatedstochasticblockmodelingofefficiencysecuritytradeoffsinweightedcriminalnetworks</id><content type="html" xml:base="https://dedzago.github.io/arxiv_rss/2024/11/01/Zeroinflatedstochasticblockmodelingofefficiencysecuritytradeoffsinweightedcriminalnetworks.html">&lt;p&gt;Criminal networks arise from the unique attempt to balance a need of establishing frequent ties among affiliates to facilitate the coordination of illegal activities, with the necessity to sparsify the overall connectivity architecture to hide from law enforcement. This efficiency-security tradeoff is also combined with the creation of groups of redundant criminals that exhibit similar connectivity patterns, thus guaranteeing resilient network architectures. State-of-the-art models for such data are not designed to infer these unique structures. In contrast to such solutions we develop a computationally-tractable Bayesian zero-inflated Poisson stochastic block model (ZIP-SBM), which identifies groups of redundant criminals with similar connectivity patterns, and infers both overt and covert block interactions within and across such groups. This is accomplished by modeling weighted ties (corresponding to counts of interactions among pairs of criminals) via zero-inflated Poisson distributions with block-specific parameters that quantify complex patterns in the excess of zero ties in each block (security) relative to the distribution of the observed weighted ties within that block (efficiency). The performance of ZIP-SBM is illustrated in simulations and in a study of summits co-attendances in a complex Mafia organization, where we unveil efficiency-security structures adopted by the criminal organization that were hidden to previous analyses.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2410.23838&quot;&gt;Read more&lt;/a&gt;&lt;/p&gt;</content><author><name>Chaoyi Lu, Daniele Durante, Nial Friel</name></author><category term="stat.AP," /><category term="stat.ME" /><summary type="html">Criminal networks arise from the unique attempt to balance a need of establishing frequent ties among affiliates to facilitate the coordination of illegal activities, with the necessity to sparsify the overall connectivity architecture to hide from law enforcement. This efficiency-security tradeoff is also combined with the creation of groups of redundant criminals that exhibit similar connectivity patterns, thus guaranteeing resilient network architectures. State-of-the-art models for such data are not designed to infer these unique structures. In contrast to such solutions we develop a computationally-tractable Bayesian zero-inflated Poisson stochastic block model (ZIP-SBM), which identifies groups of redundant criminals with similar connectivity patterns, and infers both overt and covert block interactions within and across such groups. This is accomplished by modeling weighted ties (corresponding to counts of interactions among pairs of criminals) via zero-inflated Poisson distributions with block-specific parameters that quantify complex patterns in the excess of zero ties in each block (security) relative to the distribution of the observed weighted ties within that block (efficiency). The performance of ZIP-SBM is illustrated in simulations and in a study of summits co-attendances in a complex Mafia organization, where we unveil efficiency-security structures adopted by the criminal organization that were hidden to previous analyses.</summary></entry></feed>